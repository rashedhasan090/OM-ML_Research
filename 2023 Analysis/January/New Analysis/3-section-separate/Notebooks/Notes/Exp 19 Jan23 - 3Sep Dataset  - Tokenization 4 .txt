Exp 9 Jan23 - Regular Dataset  - Tokenization 4 - 7 OM Dataset


Notes
Optimizers used: 'Adadelta', 'Adagrad', 'Adam', ‘SGD’, ‘RMSProp’


Tokenization structure:

- Comma separated tokenization, section based separation noticed.
- entity separation noticed.
- Labels are not considered separately but along with subsections
- Nothing was deducted from original context
- No space between the tokens

Ran multiple times to observe translations



- Run 1 : Adam (Sample 1 - 10) val steps=40, epochs 100
- Run 2 : Adadelta (Sample 11 - 20) val steps=40, epochs 100
- Run 3 : SGD(Sample 21 - 30) val steps=40, epochs 100
- Run 4 :  Adagrad(Sample 31 - 40) val steps=40, epochs 100
- Run 5 : RMSProp (Sample 41 - 50) val steps=40, epochs 100



- Run 6 : Adam (Sample 51 - 60) val steps=40, epochs 100
- Run 7 : Adadelta (Sample 61 - 70) val steps=40, epochs 100
- Run 8 : SGD(Sample 71 - 80) val steps=40, epochs 100
- Run 9 :  Adagrad(Sample 81 - 90) val steps=40, epochs 100
- Run 10 : RMSProp (Sample 41 - 50) val steps=40, epochs 100






---------------------------



Total Instance = 101

Pareto = 15
Not Pareto = 86


correctly predicted P = 0 (TP)
Incorrectly predicted P = 15 (FN)


correctly predicted NP = 86 (TN)
Incorrectly predicted NP = 0 (FP)

Incorrectly predicted = 15 predicted as NP but they were P | 0 predicted as P and they are P
0 predicted as P but they were NP | 86 predicted as NP and they are NP





Precision - TP / (TP + FP) = 0 / (0 + 0) = 0
Recall - TP / (TP + FN) = 0 / (0 + 15) = 0
Accuracy = (TN + TP ) / (TN + FP + TP + FN ) = (86 + 0) / (86 + 0 + 0 + 15) = 0.85
F1 = 2 * (Precision * Recall / Precision + Recall) = 2 * (0 * 0/ 0 + 0) = 2 * (0 / 0) = 0




018 198 226 19
