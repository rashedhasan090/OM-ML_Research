{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "[link text](https://)  \n",
        "#  series 4 : Language Model Performance assessment (without attention model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGFTkuRvzWqc",
        "outputId": "82fa3dc5-a638-4dc4-b574-44032863421f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text>=2.10\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text>=2.10) (0.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.29.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (15.0.6.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.3.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (21.3)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.51.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.19.6)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.25.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.1.21 keras-2.11.0 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text>=2.10\"\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "#### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('dummy_data2.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "87b1bf01-f198-428a-b91d-f33576860106"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                OM_Regular              OM_Prediction\n",
              "0  class1,table1,obj1,atr1  class1,table1,obj1,atr1,P\n",
              "1  class1,table2,obj1,atr1  class1,table2,obj1,atr1,P\n",
              "2  class1,table3,obj1,atr1  class1,table3,obj1,atr1,P\n",
              "3  class1,table4,obj1,atr1  class1,table4,obj1,atr1,P\n",
              "4  class1,table5,obj1,atr1  class1,table5,obj1,atr1,P"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc0fa1c3-c04b-454e-be20-a7d59085c605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class1,table1,obj1,atr1</td>\n",
              "      <td>class1,table1,obj1,atr1,P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>class1,table2,obj1,atr1</td>\n",
              "      <td>class1,table2,obj1,atr1,P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>class1,table3,obj1,atr1</td>\n",
              "      <td>class1,table3,obj1,atr1,P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>class1,table4,obj1,atr1</td>\n",
              "      <td>class1,table4,obj1,atr1,P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>class1,table5,obj1,atr1</td>\n",
              "      <td>class1,table5,obj1,atr1,P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc0fa1c3-c04b-454e-be20-a7d59085c605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc0fa1c3-c04b-454e-be20-a7d59085c605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc0fa1c3-c04b-454e-be20-a7d59085c605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTbSbBz55QtF",
        "outputId": "330f5128-dc32-461e-aab3-c8434dc09c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class34,table25,obj23,atr15\n"
          ]
        }
      ],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH_dPY8TRp3c",
        "outputId": "45a7650b-322f-433e-c782-d861b1bc4729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class34,table25,obj23,atr15,P\n"
          ]
        }
      ],
      "source": [
        "print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc6-NK1GtWQt",
        "outputId": "4fe2be5d-5399-4db6-ac58-6106b77f50a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'class5,table1,obj1,atr1'], shape=(1,), dtype=string)\n",
            "\n",
            "tf.Tensor([b'class5,table1,obj1,atr1,NP'], shape=(1,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD0e-DWGQ2Vo",
        "outputId": "a6e3a75e-e29d-4db2-8ea7-ed320e9a43bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'class1,table2,obj1,atr1'\n",
            "b'class1,table2,obj1,atr1'\n"
          ]
        }
      ],
      "source": [
        "#example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  #text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  #pattern = '\\s+'\n",
        "  #re.split(pattern, text, maxsplit=2)\n",
        "  #text = tf.strings.regex_replace(text, '\\s+', '')\n",
        "  #tf.strings.split(text, sep=', ', maxsplit=2, name=None)\n",
        "  #tf.strings.split (text, sep='\\s+', maxsplit=2, name=None)\n",
        "  #text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  #tf.strings.split(text, ',')\n",
        "  #text = tf.strings.split(text, sep=None, maxsplit=-1, name=None)\n",
        "  #text.tf.strings.split(', ')\n",
        "\n",
        "  # Add spaces around punctuation.\n",
        "  #text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  #text = tf.strings.strip(text)\n",
        "\n",
        "  #text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  #return text\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'\\0')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UREvDg3sEKYa",
        "outputId": "c8fbd560-7f29-48d3-bfe0-f9894f0e830c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table2,obj1,atr1\n",
            "[START] class1,table2,obj1,atr1 [END]\n"
          ]
        }
      ],
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmsI1Yql8FYe",
        "outputId": "4870c4a0-95f4-467b-ee73-480a1575f2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'class6,table9,obj1,atr1',\n",
              " 'class6,table6,obj1,atr1',\n",
              " 'class6,table5,obj1,atr1',\n",
              " 'class6,table4,obj1,atr1',\n",
              " 'class6,table2,obj1,atr1',\n",
              " 'class6,table18,obj1,atr1',\n",
              " 'class6,table17,obj1,atr1',\n",
              " 'class6,table15,obj1,atr1',\n",
              " 'class6,table14,obj1,atr1',\n",
              " 'class6,table13,obj1,atr1',\n",
              " 'class6,table12,obj1,atr1',\n",
              " 'class6,table11,obj1,atr1',\n",
              " 'class6,table10,obj1,atr1',\n",
              " 'class6,table1,obj1,atr1',\n",
              " 'class5,table9,obj1,atr1',\n",
              " 'class5,table6,obj1,atr1',\n",
              " 'class5,table5,obj1,atr1',\n",
              " 'class5,table4,obj1,atr1',\n",
              " 'class5,table2,obj1,atr1',\n",
              " 'class5,table17,obj1,atr1',\n",
              " 'class5,table16,obj1,atr1',\n",
              " 'class5,table15,obj1,atr1',\n",
              " 'class5,table13,obj1,atr1',\n",
              " 'class5,table11,obj1,atr1',\n",
              " 'class5,table10,obj1,atr1',\n",
              " 'class5,table1,obj1,atr1',\n",
              " 'class4,table9,obj2,atr2',\n",
              " 'class4,table8,obj2,atr2',\n",
              " 'class4,table7,obj2,atr2',\n",
              " 'class4,table6,obj2,atr2',\n",
              " 'class4,table5,obj2,atr2',\n",
              " 'class4,table4,obj2,atr2',\n",
              " 'class4,table3,obj2,atr2',\n",
              " 'class4,table2,obj2,atr2',\n",
              " 'class4,table18,obj2,atr2',\n",
              " 'class4,table17,obj2,atr2',\n",
              " 'class4,table16,obj2,atr2',\n",
              " 'class4,table15,obj2,atr2',\n",
              " 'class4,table13,obj2,atr2',\n",
              " 'class4,table12,obj2,atr2',\n",
              " 'class4,table11,obj2,atr2',\n",
              " 'class4,table10,obj2,atr2',\n",
              " 'class4,table1,obj2,atr2',\n",
              " 'class34,table25,obj23,atr15',\n",
              " 'class34,table23,obj23,atr13',\n",
              " 'class34,table22,obj23,atr12']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "context_text_processor.get_vocabulary()[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlC4xuZnKLBS",
        "outputId": "62360ec6-5172-474b-d185-3c168af65226"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'class6,table9,obj1,atr1,np',\n",
              " 'class6,table6,obj1,atr1,np',\n",
              " 'class6,table5,obj1,atr1,np',\n",
              " 'class6,table4,obj1,atr1,np',\n",
              " 'class6,table2,obj1,atr1,np',\n",
              " 'class6,table18,obj1,atr1,np',\n",
              " 'class6,table17,obj1,atr1,np',\n",
              " 'class6,table15,obj1,atr1,np',\n",
              " 'class6,table14,obj1,atr1,np',\n",
              " 'class6,table13,obj1,atr1,np',\n",
              " 'class6,table12,obj1,atr1,np',\n",
              " 'class6,table11,obj1,atr1,np',\n",
              " 'class6,table10,obj1,atr1,np',\n",
              " 'class6,table1,obj1,atr1,np',\n",
              " 'class5,table9,obj1,atr1,np',\n",
              " 'class5,table6,obj1,atr1,np',\n",
              " 'class5,table5,obj1,atr1,np',\n",
              " 'class5,table4,obj1,atr1,np',\n",
              " 'class5,table2,obj1,atr1,np',\n",
              " 'class5,table17,obj1,atr1,p',\n",
              " 'class5,table16,obj1,atr1,p',\n",
              " 'class5,table15,obj1,atr1,p',\n",
              " 'class5,table13,obj1,atr1,p',\n",
              " 'class5,table11,obj1,atr1,p',\n",
              " 'class5,table10,obj1,atr1,p',\n",
              " 'class5,table1,obj1,atr1,np',\n",
              " 'class4,table9,obj2,atr2,np',\n",
              " 'class4,table8,obj2,atr2,np',\n",
              " 'class4,table7,obj2,atr2,np',\n",
              " 'class4,table6,obj2,atr2,np',\n",
              " 'class4,table5,obj2,atr2,np',\n",
              " 'class4,table4,obj2,atr2,np',\n",
              " 'class4,table3,obj2,atr2,np',\n",
              " 'class4,table2,obj2,atr2,np',\n",
              " 'class4,table18,obj2,atr2,np',\n",
              " 'class4,table17,obj2,atr2,np',\n",
              " 'class4,table16,obj2,atr2,np',\n",
              " 'class4,table15,obj2,atr2,np',\n",
              " 'class4,table13,obj2,atr2,np',\n",
              " 'class4,table12,obj2,atr2,np',\n",
              " 'class4,table11,obj2,atr2,np',\n",
              " 'class4,table10,obj2,atr2,np',\n",
              " 'class4,table1,obj2,atr2,np',\n",
              " 'class34,table25,obj23,atr15,p',\n",
              " 'class34,table23,obj23,atr13,p',\n",
              " 'class34,table22,obj23,atr12,p']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "target_text_processor.get_vocabulary()[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "e7e9408f-0e15-4a1d-acca-caf5eeab60ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 29, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "98g9rcxGQY0I",
        "outputId": "531c0fb8-885f-4a00-b02b-0cd150a11939"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] class5,table1,obj1,atr1 [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "08773528-06c1-42ad-8233-f5dff480de08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "27a5bd33-d807-4a34-86a8-a5fc813dee50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 67  3]\n",
            "\n",
            "[ 2 67]\n",
            "[67  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "231f4524-3753-4f0c-8967-b06c72106774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y7hjPkNMmHh",
        "outputId": "5fb113de-957d-46d1-99e2-dd8df4432845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ],
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "86762e61-5c91-497f-d6ca-6bb11acc32ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Rqr8XGsAJlf6",
        "outputId": "241003d9-4516-4594-cb81-af46d19e2b73"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "d6b066bd-1d92-4df0-cd96-dd16e0aed671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 100)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuehagxL-JBZ",
        "outputId": "d9503bee-4725-4ce3-ea24-423d58df8c6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'class5,table16,obj1,atr1,p class4,table18,obj2,atr2,np class2,table4,obj2,atr2,np class34,table11,obj23,atr1,p class4,table1,obj2,atr2,np class6,table2,obj1,atr1,np class4,table16,obj2,atr2,np class6,table4,obj1,atr1,np class5,table1,obj1,atr1,np class3,table2,obj1,atr1,p'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ALTdqCMLGSY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "**Since the model's untrained, it outputs items from the vocabulary almost uniformly at random. **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "c5e01657-a2e7-4d49-96dc-6e1655b9a407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 100)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "844e634f-f2fb-48e0-9a4c-f02b1b2eb2b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 4.6051702, 'expected_acc': 0.01}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "0e2db4f3-38d0-4613-e643-f102db92f51a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/40 [============>.................] - ETA: 0s - loss: 4.6292 - masked_acc: 0.0000e+00 - masked_loss: 4.6292"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 13s 15ms/step - loss: 4.6292 - masked_acc: 0.0000e+00 - masked_loss: 4.6292\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 4.629204273223877,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 4.629204273223877}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=40, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "89008c95-179c-4eec-dae6-0c1d589636ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.1343 - masked_acc: 0.4949 - masked_loss: 3.1343"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 23s 35ms/step - loss: 3.1230 - masked_acc: 0.4950 - masked_loss: 3.1230 - val_loss: 2.7887 - val_masked_acc: 0.5000 - val_masked_loss: 2.7887\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.1624 - masked_acc: 0.5051 - masked_loss: 3.1624"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 3.1574 - masked_acc: 0.5050 - masked_loss: 3.1574\n",
            "Epoch 3/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.5166 - masked_acc: 0.5051 - masked_loss: 2.5166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 2.5125 - masked_acc: 0.5050 - masked_loss: 2.5125\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.3099 - masked_acc: 0.5101 - masked_loss: 2.3099"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 2.2925 - masked_acc: 0.5150 - masked_loss: 2.2925\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.8382 - masked_acc: 0.5300 - masked_loss: 1.8382"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.8382 - masked_acc: 0.5300 - masked_loss: 1.8382\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3500 - masked_acc: 0.6250 - masked_loss: 1.3500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 1.3500 - masked_acc: 0.6250 - masked_loss: 1.3500\n",
            "Epoch 7/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.7139 - masked_acc: 0.7980 - masked_loss: 0.7139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.7103 - masked_acc: 0.8000 - masked_loss: 0.7103\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2221 - masked_acc: 0.9697 - masked_loss: 0.2221"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.2224 - masked_acc: 0.9700 - masked_loss: 0.2224\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0446 - masked_acc: 1.0000 - masked_loss: 0.0446"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0446 - masked_acc: 1.0000 - masked_loss: 0.0446\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0172 - masked_acc: 1.0000 - masked_loss: 0.0172"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0172 - masked_acc: 1.0000 - masked_loss: 0.0172\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0116 - masked_acc: 1.0000 - masked_loss: 0.0116"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0116 - masked_acc: 1.0000 - masked_loss: 0.0116\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0096 - masked_acc: 1.0000 - masked_loss: 0.0096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0096 - masked_acc: 1.0000 - masked_loss: 0.0096\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0081 - masked_acc: 1.0000 - masked_loss: 0.0081"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0081 - masked_acc: 1.0000 - masked_loss: 0.0081\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0073 - masked_acc: 1.0000 - masked_loss: 0.0073"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0073 - masked_acc: 1.0000 - masked_loss: 0.0073\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0065 - masked_acc: 1.0000 - masked_loss: 0.0065"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0065 - masked_acc: 1.0000 - masked_loss: 0.0065\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0054 - masked_acc: 1.0000 - masked_loss: 0.0054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0054 - masked_acc: 1.0000 - masked_loss: 0.0054\n",
            "Epoch 17/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0051 - masked_acc: 1.0000 - masked_loss: 0.0051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0051 - masked_acc: 1.0000 - masked_loss: 0.0051\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0045 - masked_acc: 1.0000 - masked_loss: 0.0045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0045 - masked_acc: 1.0000 - masked_loss: 0.0045\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0042 - masked_acc: 1.0000 - masked_loss: 0.0042"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0042 - masked_acc: 1.0000 - masked_loss: 0.0042\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0038 - masked_acc: 1.0000 - masked_loss: 0.0038"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0038 - masked_acc: 1.0000 - masked_loss: 0.0038\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0034 - masked_acc: 1.0000 - masked_loss: 0.0034"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0034 - masked_acc: 1.0000 - masked_loss: 0.0034\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0032 - masked_acc: 1.0000 - masked_loss: 0.0032"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0032 - masked_acc: 1.0000 - masked_loss: 0.0032\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0029 - masked_acc: 1.0000 - masked_loss: 0.0029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0029 - masked_acc: 1.0000 - masked_loss: 0.0029\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0027 - masked_acc: 1.0000 - masked_loss: 0.0027"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0027 - masked_acc: 1.0000 - masked_loss: 0.0027\n",
            "Epoch 25/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0025 - masked_acc: 1.0000 - masked_loss: 0.0025"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0025 - masked_acc: 1.0000 - masked_loss: 0.0025\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0021 - masked_acc: 1.0000 - masked_loss: 0.0021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0021 - masked_acc: 1.0000 - masked_loss: 0.0021\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0020 - masked_acc: 1.0000 - masked_loss: 0.0020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0020 - masked_acc: 1.0000 - masked_loss: 0.0020\n",
            "Epoch 29/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0018 - masked_acc: 1.0000 - masked_loss: 0.0018"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0018 - masked_acc: 1.0000 - masked_loss: 0.0018\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017\n",
            "Epoch 31/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0016 - masked_acc: 1.0000 - masked_loss: 0.0016"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0016 - masked_acc: 1.0000 - masked_loss: 0.0016\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015\n",
            "Epoch 33/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0013 - masked_acc: 1.0000 - masked_loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0013 - masked_acc: 1.0000 - masked_loss: 0.0013\n",
            "Epoch 35/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0012 - masked_acc: 1.0000 - masked_loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0012 - masked_acc: 1.0000 - masked_loss: 0.0012\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0012 - masked_acc: 1.0000 - masked_loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0012 - masked_acc: 1.0000 - masked_loss: 0.0012\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 36ms/step - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.9873e-04 - masked_acc: 1.0000 - masked_loss: 9.9873e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 9.9873e-04 - masked_acc: 1.0000 - masked_loss: 9.9873e-04\n",
            "Epoch 39/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 9.6543e-04 - masked_acc: 1.0000 - masked_loss: 9.6543e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 9.6501e-04 - masked_acc: 1.0000 - masked_loss: 9.6501e-04\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.8181e-04 - masked_acc: 1.0000 - masked_loss: 8.8181e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 8.8181e-04 - masked_acc: 1.0000 - masked_loss: 8.8181e-04\n",
            "Epoch 41/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 8.5521e-04 - masked_acc: 1.0000 - masked_loss: 8.5521e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 8.5401e-04 - masked_acc: 1.0000 - masked_loss: 8.5401e-04\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 7.8084e-04 - masked_acc: 1.0000 - masked_loss: 7.8084e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 7.8135e-04 - masked_acc: 1.0000 - masked_loss: 7.8135e-04\n",
            "Epoch 43/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 7.5541e-04 - masked_acc: 1.0000 - masked_loss: 7.5541e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 7.5771e-04 - masked_acc: 1.0000 - masked_loss: 7.5771e-04\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.1313e-04 - masked_acc: 1.0000 - masked_loss: 7.1313e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 7.1313e-04 - masked_acc: 1.0000 - masked_loss: 7.1313e-04\n",
            "Epoch 45/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 6.6617e-04 - masked_acc: 1.0000 - masked_loss: 6.6617e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 6.6702e-04 - masked_acc: 1.0000 - masked_loss: 6.6702e-04\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 6.1927e-04 - masked_acc: 1.0000 - masked_loss: 6.1927e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 6.1959e-04 - masked_acc: 1.0000 - masked_loss: 6.1959e-04\n",
            "Epoch 47/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 5.9523e-04 - masked_acc: 1.0000 - masked_loss: 5.9523e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 5.9545e-04 - masked_acc: 1.0000 - masked_loss: 5.9545e-04\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.5855e-04 - masked_acc: 1.0000 - masked_loss: 5.5855e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 5.5855e-04 - masked_acc: 1.0000 - masked_loss: 5.5855e-04\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.2748e-04 - masked_acc: 1.0000 - masked_loss: 5.2748e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 5.2748e-04 - masked_acc: 1.0000 - masked_loss: 5.2748e-04\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.9634e-04 - masked_acc: 1.0000 - masked_loss: 4.9634e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 4.9630e-04 - masked_acc: 1.0000 - masked_loss: 4.9630e-04\n",
            "Epoch 51/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.7023e-04 - masked_acc: 1.0000 - masked_loss: 4.7023e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 4.7018e-04 - masked_acc: 1.0000 - masked_loss: 4.7018e-04\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.4562e-04 - masked_acc: 1.0000 - masked_loss: 4.4562e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 4.4569e-04 - masked_acc: 1.0000 - masked_loss: 4.4569e-04\n",
            "Epoch 53/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.2048e-04 - masked_acc: 1.0000 - masked_loss: 4.2048e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 4.2091e-04 - masked_acc: 1.0000 - masked_loss: 4.2091e-04\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.9649e-04 - masked_acc: 1.0000 - masked_loss: 3.9649e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 3.9731e-04 - masked_acc: 1.0000 - masked_loss: 3.9731e-04\n",
            "Epoch 55/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.7798e-04 - masked_acc: 1.0000 - masked_loss: 3.7798e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 3.7795e-04 - masked_acc: 1.0000 - masked_loss: 3.7795e-04\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.5742e-04 - masked_acc: 1.0000 - masked_loss: 3.5742e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 3.5715e-04 - masked_acc: 1.0000 - masked_loss: 3.5715e-04\n",
            "Epoch 57/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.3093e-04 - masked_acc: 1.0000 - masked_loss: 3.3093e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 3.3098e-04 - masked_acc: 1.0000 - masked_loss: 3.3098e-04\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.1929e-04 - masked_acc: 1.0000 - masked_loss: 3.1929e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 3.1899e-04 - masked_acc: 1.0000 - masked_loss: 3.1899e-04\n",
            "Epoch 59/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.0018e-04 - masked_acc: 1.0000 - masked_loss: 3.0018e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 3.0011e-04 - masked_acc: 1.0000 - masked_loss: 3.0011e-04\n",
            "Epoch 60/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.9136e-04 - masked_acc: 1.0000 - masked_loss: 2.9136e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 2.9146e-04 - masked_acc: 1.0000 - masked_loss: 2.9146e-04\n",
            "Epoch 61/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.7113e-04 - masked_acc: 1.0000 - masked_loss: 2.7113e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 2.7071e-04 - masked_acc: 1.0000 - masked_loss: 2.7071e-04\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5494e-04 - masked_acc: 1.0000 - masked_loss: 2.5494e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 2.5494e-04 - masked_acc: 1.0000 - masked_loss: 2.5494e-04\n",
            "Epoch 63/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.4488e-04 - masked_acc: 1.0000 - masked_loss: 2.4488e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 2.4503e-04 - masked_acc: 1.0000 - masked_loss: 2.4503e-04\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3078e-04 - masked_acc: 1.0000 - masked_loss: 2.3078e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 2.3078e-04 - masked_acc: 1.0000 - masked_loss: 2.3078e-04\n",
            "Epoch 65/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.1797e-04 - masked_acc: 1.0000 - masked_loss: 2.1797e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 2.1756e-04 - masked_acc: 1.0000 - masked_loss: 2.1756e-04\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0624e-04 - masked_acc: 1.0000 - masked_loss: 2.0624e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 2.0624e-04 - masked_acc: 1.0000 - masked_loss: 2.0624e-04\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9925e-04 - masked_acc: 1.0000 - masked_loss: 1.9925e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.9925e-04 - masked_acc: 1.0000 - masked_loss: 1.9925e-04\n",
            "Epoch 68/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.8440e-04 - masked_acc: 1.0000 - masked_loss: 1.8440e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.8403e-04 - masked_acc: 1.0000 - masked_loss: 1.8403e-04\n",
            "Epoch 69/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.7628e-04 - masked_acc: 1.0000 - masked_loss: 1.7628e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.7639e-04 - masked_acc: 1.0000 - masked_loss: 1.7639e-04\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.6751e-04 - masked_acc: 1.0000 - masked_loss: 1.6751e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 1.6760e-04 - masked_acc: 1.0000 - masked_loss: 1.6760e-04\n",
            "Epoch 71/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5915e-04 - masked_acc: 1.0000 - masked_loss: 1.5915e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.5923e-04 - masked_acc: 1.0000 - masked_loss: 1.5923e-04\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5043e-04 - masked_acc: 1.0000 - masked_loss: 1.5043e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 1.5043e-04 - masked_acc: 1.0000 - masked_loss: 1.5043e-04\n",
            "Epoch 73/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.4192e-04 - masked_acc: 1.0000 - masked_loss: 1.4192e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 1.4183e-04 - masked_acc: 1.0000 - masked_loss: 1.4183e-04\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3535e-04 - masked_acc: 1.0000 - masked_loss: 1.3535e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.3535e-04 - masked_acc: 1.0000 - masked_loss: 1.3535e-04\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2784e-04 - masked_acc: 1.0000 - masked_loss: 1.2784e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.2784e-04 - masked_acc: 1.0000 - masked_loss: 1.2784e-04\n",
            "Epoch 76/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2082e-04 - masked_acc: 1.0000 - masked_loss: 1.2082e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 1.2060e-04 - masked_acc: 1.0000 - masked_loss: 1.2060e-04\n",
            "Epoch 77/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.1628e-04 - masked_acc: 1.0000 - masked_loss: 1.1628e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 1.1645e-04 - masked_acc: 1.0000 - masked_loss: 1.1645e-04\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0918e-04 - masked_acc: 1.0000 - masked_loss: 1.0918e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.0918e-04 - masked_acc: 1.0000 - masked_loss: 1.0918e-04\n",
            "Epoch 79/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.0398e-04 - masked_acc: 1.0000 - masked_loss: 1.0398e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 1.0390e-04 - masked_acc: 1.0000 - masked_loss: 1.0390e-04\n",
            "Epoch 80/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 9.7008e-05 - masked_acc: 1.0000 - masked_loss: 9.7008e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 9.6953e-05 - masked_acc: 1.0000 - masked_loss: 9.6953e-05\n",
            "Epoch 81/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 9.3384e-05 - masked_acc: 1.0000 - masked_loss: 9.3384e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 9.3385e-05 - masked_acc: 1.0000 - masked_loss: 9.3385e-05\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.8839e-05 - masked_acc: 1.0000 - masked_loss: 8.8839e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 8.8839e-05 - masked_acc: 1.0000 - masked_loss: 8.8839e-05\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.3117e-05 - masked_acc: 1.0000 - masked_loss: 8.3117e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 8.3117e-05 - masked_acc: 1.0000 - masked_loss: 8.3117e-05\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.9944e-05 - masked_acc: 1.0000 - masked_loss: 7.9944e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 7.9944e-05 - masked_acc: 1.0000 - masked_loss: 7.9944e-05\n",
            "Epoch 85/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 7.5552e-05 - masked_acc: 1.0000 - masked_loss: 7.5552e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 7.5566e-05 - masked_acc: 1.0000 - masked_loss: 7.5566e-05\n",
            "Epoch 86/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 7.1518e-05 - masked_acc: 1.0000 - masked_loss: 7.1518e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 7.1491e-05 - masked_acc: 1.0000 - masked_loss: 7.1491e-05\n",
            "Epoch 87/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 6.7756e-05 - masked_acc: 1.0000 - masked_loss: 6.7756e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 6.7710e-05 - masked_acc: 1.0000 - masked_loss: 6.7710e-05\n",
            "Epoch 88/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 6.5102e-05 - masked_acc: 1.0000 - masked_loss: 6.5102e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 6.5155e-05 - masked_acc: 1.0000 - masked_loss: 6.5155e-05\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 6.0570e-05 - masked_acc: 1.0000 - masked_loss: 6.0570e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 6.0570e-05 - masked_acc: 1.0000 - masked_loss: 6.0570e-05\n",
            "Epoch 90/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 5.7721e-05 - masked_acc: 1.0000 - masked_loss: 5.7721e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 5.7648e-05 - masked_acc: 1.0000 - masked_loss: 5.7648e-05\n",
            "Epoch 91/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 5.5213e-05 - masked_acc: 1.0000 - masked_loss: 5.5213e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 5.5129e-05 - masked_acc: 1.0000 - masked_loss: 5.5129e-05\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.2412e-05 - masked_acc: 1.0000 - masked_loss: 5.2412e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 5.2412e-05 - masked_acc: 1.0000 - masked_loss: 5.2412e-05\n",
            "Epoch 93/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.9503e-05 - masked_acc: 1.0000 - masked_loss: 4.9503e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 4.9553e-05 - masked_acc: 1.0000 - masked_loss: 4.9553e-05\n",
            "Epoch 94/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.6818e-05 - masked_acc: 1.0000 - masked_loss: 4.6818e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 4.6872e-05 - masked_acc: 1.0000 - masked_loss: 4.6872e-05\n",
            "Epoch 95/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.4180e-05 - masked_acc: 1.0000 - masked_loss: 4.4180e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 4.4182e-05 - masked_acc: 1.0000 - masked_loss: 4.4182e-05\n",
            "Epoch 96/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.2168e-05 - masked_acc: 1.0000 - masked_loss: 4.2168e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 4.2202e-05 - masked_acc: 1.0000 - masked_loss: 4.2202e-05\n",
            "Epoch 97/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.0033e-05 - masked_acc: 1.0000 - masked_loss: 4.0033e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 4.0017e-05 - masked_acc: 1.0000 - masked_loss: 4.0017e-05\n",
            "Epoch 98/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.7806e-05 - masked_acc: 1.0000 - masked_loss: 3.7806e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 3.7803e-05 - masked_acc: 1.0000 - masked_loss: 3.7803e-05\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5763e-05 - masked_acc: 1.0000 - masked_loss: 3.5763e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 3.5763e-05 - masked_acc: 1.0000 - masked_loss: 3.5763e-05\n",
            "Epoch 100/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.4235e-05 - masked_acc: 1.0000 - masked_loss: 3.4235e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 3.4214e-05 - masked_acc: 1.0000 - masked_loss: 3.4214e-05\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 40,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "ea193e7b-2d22-4c61-fee2-863fdd27ae40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1d3baae910>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "998681dc-189b-4718-c2bd-b1e9db145ad9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1d3ba76400>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f238bd40-162e-4dd0-c342-656f1dc11c87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'class5,table10,obj1,atr1,p '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#sample Dataset Library_Management_Dataset_1_input_prerp_each_class_and_entitities_sep_experiment \n",
        "\n",
        "\n",
        "\n",
        "result1 = model.translate(['class1,table6,obj1,atr1'])\n",
        "\n",
        "result2 = model.translate(['class4,table17,obj2,atr2'])\n",
        "\n",
        "result23 = model.translate(['class14,table2,obj1,atr1'])\n",
        "\n",
        "result222 = model.translate(['class17,table4,obj2,atr2'])\n",
        "#result1[0].numpy().decode()\n",
        "result23[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "Use that to generate the attention plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rrGawQv2eiA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "9d3ab499-89a2-4e71-94f9-33312dee239b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model.plot_attention('class34,table12,obj23,atr2') # Are you still home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-FUHFLEvSMbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee97a19-e628-4b84-dbad-84f8d0e2e70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected output:\n",
            " class34,table25,obj23,atr15,P\n"
          ]
        }
      ],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing existing samples"
      ],
      "metadata": {
        "id": "wmCM_ou4X9EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "wnNs8LbU66N-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dummy_data_test_set2.csv')"
      ],
      "metadata": {
        "id": "R_4M4qPQdG9l"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o23nQwO3SKk7",
        "outputId": "9be02de0-3d18-459f-f22e-af85ad5f84c7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                OM_Regular  OM_Prediction\n",
              "0  class1,table1,obj1,atr1              1\n",
              "1  class1,table2,obj1,atr1              1\n",
              "2  class1,table3,obj1,atr1              1\n",
              "3  class1,table4,obj1,atr1              1\n",
              "4  class1,table5,obj1,atr1              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c24bdcf2-c783-467d-a9ae-e2f493ae12a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class1,table1,obj1,atr1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>class1,table2,obj1,atr1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>class1,table3,obj1,atr1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>class1,table4,obj1,atr1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>class1,table5,obj1,atr1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c24bdcf2-c783-467d-a9ae-e2f493ae12a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c24bdcf2-c783-467d-a9ae-e2f493ae12a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c24bdcf2-c783-467d-a9ae-e2f493ae12a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df['OM_Regular'].values\n",
        "y_test = df['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "a3VgzasFdlTz"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test.dtype)\n",
        "print(\"y data type: \", y_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp0Z6jW5d9v9",
        "outputId": "c93415f0-ca96-4e27-8eb8-930d3cd07b18"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(122,)\n",
            "(122,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KL_C7GZ627i",
        "outputId": "3ca7b883-1b24-4328-a6c8-87989ed8ec32"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test"
      ],
      "metadata": {
        "id": "-qZlNac5eSDL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PToqG3GiIUPM"
      },
      "source": [
        "The `translate` function works on batches, so if you have multiple texts to translate you can pass them all at once, which is much more efficient than translating them one at a time:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_train_pred = model.predict(X_train)"
      ],
      "metadata": {
        "id": "bNp4BPta5_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "sT68i4jYEQ7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac6547c-47a4-4bce-b294-d857eaa71e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table1,obj1,atr1,p \n",
            "class1,table2,obj1,atr1,p \n",
            "class1,table3,obj1,atr1,p \n",
            "class1,table4,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class1,table6,obj1,atr1,p \n",
            "class1,table7,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class1,table9,obj1,atr1,p \n",
            "class1,table10,obj1,atr1,p \n",
            "class1,table11,obj1,atr1,p \n",
            "class1,table12,obj1,atr1,p \n",
            "class1,table13,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class1,table15,obj1,atr1,p \n",
            "class1,table16,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table1,obj2,atr2,np \n",
            "class2,table2,obj2,atr2,np \n",
            "class2,table3,obj2,atr2,np \n",
            "class2,table4,obj2,atr2,np \n",
            "class2,table5,obj2,atr2,np \n",
            "class2,table6,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table8,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table10,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table12,obj2,atr2,np \n",
            "class2,table13,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table15,obj2,atr2,np \n",
            "class2,table16,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table18,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table2,obj1,atr1,p \n",
            "class3,table3,obj1,atr1,p \n",
            "class3,table4,obj1,atr1,p \n",
            "class3,table5,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table7,obj1,atr1,p \n",
            "class3,table8,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table10,obj1,atr1,p \n",
            "class3,table11,obj1,atr1,p \n",
            "class3,table12,obj1,atr1,p \n",
            "class3,table13,obj1,atr1,p \n",
            "class3,table14,obj1,atr1,p \n",
            "class3,table15,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table18,obj1,atr1,p \n",
            "class4,table1,obj2,atr2,np \n",
            "class4,table2,obj2,atr2,np \n",
            "class4,table3,obj2,atr2,np \n",
            "class4,table4,obj2,atr2,np \n",
            "class4,table5,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table7,obj2,atr2,np \n",
            "class4,table8,obj2,atr2,np \n",
            "class4,table9,obj2,atr2,np \n",
            "class4,table10,obj2,atr2,np \n",
            "class4,table11,obj2,atr2,np \n",
            "class4,table12,obj2,atr2,np \n",
            "class4,table13,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class4,table15,obj2,atr2,np \n",
            "class4,table16,obj2,atr2,np \n",
            "class4,table17,obj2,atr2,np \n",
            "class4,table18,obj2,atr2,np \n",
            "class5,table1,obj1,atr1,np \n",
            "class5,table2,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table4,obj1,atr1,np \n",
            "class5,table5,obj1,atr1,np \n",
            "class5,table6,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table9,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table11,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table13,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table15,obj1,atr1,p \n",
            "class5,table16,obj1,atr1,p \n",
            "class5,table17,obj1,atr1,p \n",
            "class6,table1,obj1,atr1,np \n",
            "class6,table2,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class6,table4,obj1,atr1,np \n",
            "class6,table5,obj1,atr1,np \n",
            "class6,table6,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class6,table9,obj1,atr1,np \n",
            "class6,table10,obj1,atr1,np \n",
            "class6,table11,obj1,atr1,np \n",
            "class6,table12,obj1,atr1,np \n",
            "class6,table13,obj1,atr1,np \n",
            "class6,table14,obj1,atr1,np \n",
            "class6,table15,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class6,table17,obj1,atr1,np \n",
            "class6,table18,obj1,atr1,np \n",
            "class34,table11,obj23,atr1,p \n",
            "class34,table12,obj23,atr2,p \n",
            "class34,table13,obj23,atr3,p \n",
            "class34,table14,obj23,atr4,p \n",
            "class34,table15,obj23,atr5,p \n",
            "class34,table16,obj23,atr6,p \n",
            "class34,table17,obj23,atr7,p \n",
            "class34,table18,obj23,atr8,p \n",
            "class34,table19,obj23,atr9,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class34,table21,obj23,atr11,p \n",
            "class34,table22,obj23,atr12,p \n",
            "class34,table23,obj23,atr13,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class34,table25,obj23,atr15,p \n",
            "\n",
            "CPU times: user 21.4 s, sys: 224 ms, total: 21.6 s\n",
            "Wall time: 21.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for t in inputs:\n",
        "  mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Existing samples)"
      ],
      "metadata": {
        "id": "OCkpjZl3YOhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dg = pd.read_csv('dummy_data_test_set_predictions2.csv')"
      ],
      "metadata": {
        "id": "scj5ksJ8f0nH"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred = dg['OM_Regular'].values\n",
        "y_test_pred = dg['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "5z16vFuixofS"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Y-62gL5HYP",
        "outputId": "b14de775-c295-4861-f161-d9eeb620984f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /-----/ /--/ /-/ /--------/ /---/ /---/ "
      ],
      "metadata": {
        "id": "X3fBkX6FRkNs"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test, y_test_pred) \n",
        "print(\"Training Data Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "print(\"Training Data Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, y_test_pred)\n",
        "print(\"Training Data F1 Score = %f\" % f1)\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nflFqA_4-HB",
        "outputId": "e8889b64-5150-46aa-9173-5cf8e90600e7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Precision = 0.816901\n",
            "Training Data Recall = 1.000000\n",
            "Training Data F1 Score = 0.899225\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[51 13]\n",
            " [ 0 58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSjhM_oPN7Tr",
        "outputId": "799d9804-0eb5-47c2-eea9-92ed71970681"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89        64\n",
            "           1       0.82      1.00      0.90        58\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.91      0.90      0.89       122\n",
            "weighted avg       0.91      0.89      0.89       122\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('dummy_data_unseen_below2.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "ba4c3a45-0db2-4540-c006-125b78982aac"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                OM_Regular  OM_Prediction\n",
              "0  table121,class221,obj31,atr1,obj32,atr2              0\n",
              "1  table122,class222,obj31,atr1,obj32,atr2              0\n",
              "2  table123,class223,obj31,atr1,obj32,atr2              0\n",
              "3  table124,class224,obj31,atr1,obj32,atr2              0\n",
              "4  table125,class225,obj31,atr1,obj32,atr2              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd15b8bd-cb65-40ec-b191-5175ddfe2662\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table121,class221,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table122,class222,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table123,class223,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table124,class224,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table125,class225,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd15b8bd-cb65-40ec-b191-5175ddfe2662')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd15b8bd-cb65-40ec-b191-5175ddfe2662 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd15b8bd-cb65-40ec-b191-5175ddfe2662');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = df['OM_Regular'].values\n",
        "y_test2 = df['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "40f787a6-cbed-445e-9d37-d8a04e533b1e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputo = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for t in inputo:\n",
        "  #mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qjPTIDB-8UZ",
        "outputId": "ff37ea27-8d23-40fc-d267-38260aef27c1"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table1,obj1,atr1,p \n",
            "class1,table2,obj1,atr1,p \n",
            "class1,table3,obj1,atr1,p \n",
            "class1,table4,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class1,table6,obj1,atr1,p \n",
            "class1,table7,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class1,table9,obj1,atr1,p \n",
            "class1,table10,obj1,atr1,p \n",
            "class1,table11,obj1,atr1,p \n",
            "class1,table12,obj1,atr1,p \n",
            "class1,table13,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class1,table15,obj1,atr1,p \n",
            "class1,table16,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table1,obj2,atr2,np \n",
            "class2,table2,obj2,atr2,np \n",
            "class2,table3,obj2,atr2,np \n",
            "class2,table4,obj2,atr2,np \n",
            "class2,table5,obj2,atr2,np \n",
            "class2,table6,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table8,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table10,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table12,obj2,atr2,np \n",
            "class2,table13,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table15,obj2,atr2,np \n",
            "class2,table16,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class2,table18,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table2,obj1,atr1,p \n",
            "class3,table3,obj1,atr1,p \n",
            "class3,table4,obj1,atr1,p \n",
            "class3,table5,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table7,obj1,atr1,p \n",
            "class3,table8,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table10,obj1,atr1,p \n",
            "class3,table11,obj1,atr1,p \n",
            "class3,table12,obj1,atr1,p \n",
            "class3,table13,obj1,atr1,p \n",
            "class3,table14,obj1,atr1,p \n",
            "class3,table15,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class3,table18,obj1,atr1,p \n",
            "class4,table1,obj2,atr2,np \n",
            "class4,table2,obj2,atr2,np \n",
            "class4,table3,obj2,atr2,np \n",
            "class4,table4,obj2,atr2,np \n",
            "class4,table5,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table7,obj2,atr2,np \n",
            "class4,table8,obj2,atr2,np \n",
            "class4,table9,obj2,atr2,np \n",
            "class4,table10,obj2,atr2,np \n",
            "class4,table11,obj2,atr2,np \n",
            "class4,table12,obj2,atr2,np \n",
            "class4,table13,obj2,atr2,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class4,table15,obj2,atr2,np \n",
            "class4,table16,obj2,atr2,np \n",
            "class4,table17,obj2,atr2,np \n",
            "class4,table18,obj2,atr2,np \n",
            "class5,table1,obj1,atr1,np \n",
            "class5,table2,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table4,obj1,atr1,np \n",
            "class5,table5,obj1,atr1,np \n",
            "class5,table6,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table9,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table11,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table13,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table15,obj1,atr1,p \n",
            "class5,table16,obj1,atr1,p \n",
            "class5,table17,obj1,atr1,p \n",
            "class6,table1,obj1,atr1,np \n",
            "class6,table2,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class6,table4,obj1,atr1,np \n",
            "class6,table5,obj1,atr1,np \n",
            "class6,table6,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class6,table9,obj1,atr1,np \n",
            "class6,table10,obj1,atr1,np \n",
            "class6,table11,obj1,atr1,np \n",
            "class6,table12,obj1,atr1,np \n",
            "class6,table13,obj1,atr1,np \n",
            "class6,table14,obj1,atr1,np \n",
            "class6,table15,obj1,atr1,np \n",
            "class5,table10,obj1,atr1,p \n",
            "class6,table17,obj1,atr1,np \n",
            "class6,table18,obj1,atr1,np \n",
            "class34,table11,obj23,atr1,p \n",
            "class34,table12,obj23,atr2,p \n",
            "class34,table13,obj23,atr3,p \n",
            "class34,table14,obj23,atr4,p \n",
            "class34,table15,obj23,atr5,p \n",
            "class34,table16,obj23,atr6,p \n",
            "class34,table17,obj23,atr7,p \n",
            "class34,table18,obj23,atr8,p \n",
            "class34,table19,obj23,atr9,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class34,table21,obj23,atr11,p \n",
            "class34,table22,obj23,atr12,p \n",
            "class34,table23,obj23,atr13,p \n",
            "class5,table10,obj1,atr1,p \n",
            "class34,table25,obj23,atr15,p \n",
            "\n",
            "CPU times: user 11.2 s, sys: 116 ms, total: 11.3 s\n",
            "Wall time: 11.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('dummy_data_unseen_below2_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "6672d269-0c9d-4abf-f464-a6c8a8d063c5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    OM_Regular  OM_Prediction\n",
              "0   class1,table1,obj1,atr1,p               1\n",
              "1   class1,table2,obj1,atr1,p               1\n",
              "2   class1,table3,obj1,atr1,p               1\n",
              "3   class1,table4,obj1,atr1,p               1\n",
              "4  class5,table10,obj1,atr1,p               1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfedc411-780b-4c9d-821f-f29ddf988092\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class1,table1,obj1,atr1,p</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>class1,table2,obj1,atr1,p</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>class1,table3,obj1,atr1,p</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>class1,table4,obj1,atr1,p</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>class5,table10,obj1,atr1,p</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfedc411-780b-4c9d-821f-f29ddf988092')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfedc411-780b-4c9d-821f-f29ddf988092 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfedc411-780b-4c9d-821f-f29ddf988092');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "c17012ff-756f-4ee2-8eb7-b86c40ea1783"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "9eb007d4-6609-4917-cc33-c8c8fdf778d4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.805556\n",
            "Testing: Recall = 1.000000\n",
            "Testing: F1 Score = 0.892308\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[50 14]\n",
            " [ 0 58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "e2c5bf47-d2e6-4294-d8d4-7508df539f23"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.78      0.88        64\n",
            "           1       0.81      1.00      0.89        58\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.90      0.89      0.88       122\n",
            "weighted avg       0.91      0.89      0.88       122\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples extended \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H3F2-mn7IWQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dx = pd.read_csv('dummy_data_unseen_extended.csv')"
      ],
      "metadata": {
        "id": "4PBeqFMtIazn"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dx.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NzfdmWjAItwp",
        "outputId": "63a92105-1055-46a9-d8bf-b8bff28ca0a2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                OM_Regular  OM_Prediction\n",
              "0  table121,class221,obj31,atr1,obj32,atr2              0\n",
              "1  table122,class222,obj31,atr1,obj32,atr2              0\n",
              "2  table123,class223,obj31,atr1,obj32,atr2              0\n",
              "3  table124,class224,obj31,atr1,obj32,atr2              0\n",
              "4  table125,class225,obj31,atr1,obj32,atr2              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75ed4c87-9fce-4a40-a3ae-93a54fadc003\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table121,class221,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table122,class222,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table123,class223,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table124,class224,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table125,class225,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75ed4c87-9fce-4a40-a3ae-93a54fadc003')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75ed4c87-9fce-4a40-a3ae-93a54fadc003 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75ed4c87-9fce-4a40-a3ae-93a54fadc003');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test3 = dx['OM_Regular'].values\n",
        "y_test3 = dx['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "H24W5gzGI4ck"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkMvlX1ZJK-S",
        "outputId": "67f05737-4460-4729-f822-980186f40352"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputg = X_test3"
      ],
      "metadata": {
        "id": "jhN_pT6GJd9W"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for t in inputg:\n",
        "  #mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3xkHEijJxmn",
        "outputId": "fcf18989-eb0b-4c04-ac6a-ec13078da29f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "\n",
            "CPU times: user 12 s, sys: 126 ms, total: 12.1 s\n",
            "Wall time: 12.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification Report (Unseen Extended samples)"
      ],
      "metadata": {
        "id": "HHRnQVxWK6X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dy = pd.read_csv('dummy_data_unseen_undersample.csv')"
      ],
      "metadata": {
        "id": "5-GTg604LCVF"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dy.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g42wnY4kLwyC",
        "outputId": "a31b8d3d-bc2e-455c-b278-6c86aee2adb2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                OM_Regular  OM_Prediction\n",
              "0  table121,class221,obj31,atr1,obj32,atr2              0\n",
              "1  table122,class222,obj31,atr1,obj32,atr2              0\n",
              "2  table123,class223,obj31,atr1,obj32,atr2              0\n",
              "3  table124,class224,obj31,atr1,obj32,atr2              0\n",
              "4  table125,class225,obj31,atr1,obj32,atr2              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45cd5110-9202-4d8a-885f-85b326e9bb88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table121,class221,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table122,class222,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table123,class223,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table124,class224,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table125,class225,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45cd5110-9202-4d8a-885f-85b326e9bb88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45cd5110-9202-4d8a-885f-85b326e9bb88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45cd5110-9202-4d8a-885f-85b326e9bb88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred3 = dy['OM_Regular'].values\n",
        "y_test_pred3 = dy['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "3ohsM1IoLzIj"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EDtlK3HL93A",
        "outputId": "308e2cae-6bcd-41b7-d075-8f049f80b5ab"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-qygf1jMHcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ValueError: Found input variables with inconsistent numbers of samples: [122, 155]"
      ],
      "metadata": {
        "id": "gXYSUeLQMZ4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples under samples\n"
      ],
      "metadata": {
        "id": "oewNFxyrSCHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dz = pd.read_csv('dummy_data_unseen_undersample.csv')"
      ],
      "metadata": {
        "id": "asSXqOK8SJeH"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dz.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3h8MVdk5SXIS",
        "outputId": "26edfcd6-c1f8-4f57-f65c-d77b6e890e3e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                OM_Regular  OM_Prediction\n",
              "0  table121,class221,obj31,atr1,obj32,atr2              0\n",
              "1  table122,class222,obj31,atr1,obj32,atr2              0\n",
              "2  table123,class223,obj31,atr1,obj32,atr2              0\n",
              "3  table124,class224,obj31,atr1,obj32,atr2              0\n",
              "4  table125,class225,obj31,atr1,obj32,atr2              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e6a8719-214a-404c-bc89-145afff0db41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table121,class221,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table122,class222,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table123,class223,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table124,class224,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table125,class225,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e6a8719-214a-404c-bc89-145afff0db41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e6a8719-214a-404c-bc89-145afff0db41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e6a8719-214a-404c-bc89-145afff0db41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test4 = dz['OM_Regular'].values\n",
        "y_test4 = dz['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "nvtnoxuhS-RB"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHF26aXsTE5g",
        "outputId": "8df71425-276c-4418-b9f8-e7e5b347146a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputop = X_test4"
      ],
      "metadata": {
        "id": "-Rnxlyu1TKdS"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for t in inputop:\n",
        "  #mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APWMDIcqTSxg",
        "outputId": "bd886639-5d57-4fbf-d648-05929152c203"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "\n",
            "CPU times: user 7.26 s, sys: 83.6 ms, total: 7.34 s\n",
            "Wall time: 7.39 s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wmCM_ou4X9EP",
        "OCkpjZl3YOhn",
        "Rc1aekzi9dLZ",
        "1t4_2FqbE9da",
        "H3F2-mn7IWQB",
        "HHRnQVxWK6X9",
        "oewNFxyrSCHi"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}