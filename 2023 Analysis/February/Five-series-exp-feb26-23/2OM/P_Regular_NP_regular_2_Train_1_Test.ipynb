{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "[link text](https://)  \n",
        "#Experiment with P Regular , NP Regular \n",
        "###2 OM - Dataset & Camping\n",
        "###1 OM - Testing - Library Management \n",
        "\n",
        "###Total Samples : 111. \n",
        "###P labeled : 24 \n",
        "### NP Labeled: 87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#!pip install \"tensorflow-text>=2.10\"\n",
        "#!pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('2-OM.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Dat from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "759a40a1-452e-430c-f3c8-c45daaf6208e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f845da8-8317-47f6-b57e-7c2e386ec381\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f845da8-8317-47f6-b57e-7c2e386ec381')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f845da8-8317-47f6-b57e-7c2e386ec381 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f845da8-8317-47f6-b57e-7c2e386ec381');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  #print(example_context_strings[:5])\n",
        "  #print()\n",
        "  #print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  #text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  #pattern = '\\s+'\n",
        "  #re.split(pattern, text, maxsplit=2)\n",
        "  #text = tf.strings.regex_replace(text, '\\s+', '')\n",
        "  #tf.strings.split(text, sep=', ', maxsplit=2, name=None)\n",
        "  #tf.strings.split (text, sep='\\s+', maxsplit=2, name=None)\n",
        "  #text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  #tf.strings.split(text, ',')\n",
        "  #text = tf.strings.split(text, sep=None, maxsplit=-1, name=None)\n",
        "  #text.tf.strings.split(', ')\n",
        "\n",
        "  # Add spaces around punctuation.\n",
        "  #text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  #text = tf.strings.strip(text)\n",
        "\n",
        "  #text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  #return text\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'\\0')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "#print(example_text.numpy().decode())\n",
        "#print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4cfb73e-79b2-4565-fbd2-bbe4f94b31ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "974fe1ca-95f2-4c7f-88a8-dc9b71f345f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 22, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "98g9rcxGQY0I",
        "outputId": "a7e9c92d-c6cd-4f6e-d758-c9d9818e2b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\u200b,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at2:c2_at2_typetable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class3_nameattributec3_at2:c3_at2_typetable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class4_nameattributec4_at2:c4_at2_typetable:class4_nameattributec4_at3:c4_at3_typetable:class4_nameattributec4_at4:c4_at4_typetable:class5_nameattributec5_at1:c5_at1_typeprimarykeytable:class5_nameattributec5_at2:c5_at2_typetable:class6_nameattributec6_at1:c6_at1_typeprimarykeytable:class6_nameattributec6_at2:c6_at2_typetablename:class6_nametable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class6_nameattributec6_at1:c6_at1_typeprimarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_namemappingstrategyoftableclass1_name:map_str2mappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2associationstrategyforassoc2:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc1`(`c6_at1`c6_at1_typenotnull,`c4_at1`c4_at1_typenotnull,key`fk_assoc1_c6_at1_idx`(`c6_at1`),fk_assoc1_c4_at1_idx`(`c4_at1`),primarykey(`c6_at1`,`c4_at1`));createtable`assoc4`(`c3_at1`c3_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc4_c3_at1_idx`(`c3_at1`),key`fk_assoc4_c1_at1_idx`(`c1_at1`),primarykey(`c3_at1`,`c1_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull,primarykey(`c3_at1`));createtable`class5_name`(`c5_at2`c5_at2_type,`c5_at1`c5_at1_type,`c4_at1`c4_at1_typenotnull,key`fk_class5_name_c4_at1_idx`(`c4_at1`),primarykey(`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type(64),`c2_at1`c2_at1_typenotnull,primarykey(`c2_at1`));createtable`assoc3`(`c4_at1`c4_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc3_c4_at1_idx`(`c4_at1`),key`fk_assoc3_c1_at1_idx`(`c1_at1`),primarykey(`c4_at1`,`c1_at1`));createtable`class6_name`(`c6_at3`c6_at3_type,`c6_at2`c6_at2_type,`c6_at1`c6_at1_typenotnull,`c2_at1`c2_at1_type,key`fk_class6_name_c2_at1_idx`(`c2_at1`),primarykey(`c6_at1`));createtable`class1_name`(`c1_at2`c1_at2_type,`c1_at1`c1_at1_typenotnull,primarykey(`c1_at1`));createtable`class4_name`(`c4_at2`c4_at2_type(64),`c4_at4`c4_at4_type,`c4_at3`c4_at3_type,`c4_at1`c4_at1_typenotnull,primarykey(`c4_at1`));altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`assoc4`addconstraint`fk_assoc4_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc4_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`class5_name`addconstraint`fk_class5_name_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc3_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`class6_name`addconstraint`fk_class6_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "a68fdafa-25e2-46e8-d92c-56d8c58ff387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "e9cb1eee-0c84-4225-cbe1-cd5f9e2869d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 38  3]\n",
            "\n",
            "[ 2 38]\n",
            "[38  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "b16dc604-84cb-4df9-8153-d248c6604b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "d98c1c13-ad80-47e0-902b-e26fcef1824f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "b060bc24-cf42-4824-b2dd-1acda9d105e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0000001, 1.       ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "6c69b6b8-b7db-4d14-8fa8-c88ecd55d728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "552ecac8-ddc5-4c37-f262-709ff48e6c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 82)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuehagxL-JBZ",
        "outputId": "712075c6-512f-4135-c46d-11f09d549f44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass10_name:map_str2mappingstrategyoftableclass9_name:map_str3associationstrategyforassoc1:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass10_name:map_str2mappingstrategyoftableclass9_name:map_str3associationstrategyforassoc1:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c5_at1`c5_at1_type`c1_at1`c1_at1_typenotnullkey`fk_class1_name_c5_at1_idx`(`c5_at1`),primarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class1_name`addconstraint`fk_class1_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np [START] moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass9_name:map_str3mappingstrategyoftableclass6_name:map_str3associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class10_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_class10_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass9_name:map_str3mappingstrategyoftableclass6_name:map_str3associationstrategyforassoc1:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class10_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_class10_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass10_name:map_str2associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2\\xe2\\x80\\x8b,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass10_name:map_str2associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2\\xe2\\x80\\x8b,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass10_name:map_str2associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass10_name:map_str2mappingstrategyoftableclass9_name:map_str3associationstrategyforassoc1:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str1mappingstrategyoftableclass8_name:map_str1mappingstrategyoftableclass10_name:map_str1associationstrategyforassoc1:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at2`c7_at2_type(64)`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c10_at1`c10_at1_type`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "741077d4-a914-4611-caaa-4b671f9117e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 82)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "d266c342-2918-41dc-84dc-0fd7f0e6473d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 4.406719, 'expected_acc': 0.012195121951219513}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "8425285e-1d3f-4073-8549-5445e82825a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/60 [===========>..................] - ETA: 0s - loss: 4.6519 - masked_acc: 0.0000e+00 - masked_loss: 4.6519"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/60 [==============================] - 8s 12ms/step - loss: 4.6505 - masked_acc: 0.0000e+00 - masked_loss: 4.6505\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 4.650485992431641,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 4.650485992431641}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=60, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "6aab9495-24f9-40fb-cd0e-583279ed09e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.1297 - masked_acc: 0.4899 - masked_loss: 3.1297"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 19s 29ms/step - loss: 3.1167 - masked_acc: 0.4900 - masked_loss: 3.1167 - val_loss: 3.6186 - val_masked_acc: 0.5000 - val_masked_loss: 3.6186\n",
            "Epoch 2/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.5907 - masked_acc: 0.5000 - masked_loss: 2.5907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 2.5861 - masked_acc: 0.5000 - masked_loss: 2.5861\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0770 - masked_acc: 0.5250 - masked_loss: 2.0770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 2.0770 - masked_acc: 0.5250 - masked_loss: 2.0770\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0953 - masked_acc: 0.7000 - masked_loss: 1.0953"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 1.0953 - masked_acc: 0.7000 - masked_loss: 1.0953\n",
            "Epoch 5/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3567 - masked_acc: 0.9192 - masked_loss: 0.3567"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.3533 - masked_acc: 0.9200 - masked_loss: 0.3533\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0965 - masked_acc: 0.9900 - masked_loss: 0.0965"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0965 - masked_acc: 0.9900 - masked_loss: 0.0965\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0572 - masked_acc: 0.9900 - masked_loss: 0.0572"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 35ms/step - loss: 0.0572 - masked_acc: 0.9900 - masked_loss: 0.0572\n",
            "Epoch 8/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.1128 - masked_acc: 0.9694 - masked_loss: 0.1128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.1106 - masked_acc: 0.9700 - masked_loss: 0.1106\n",
            "Epoch 9/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0512 - masked_acc: 0.9847 - masked_loss: 0.0512"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0503 - masked_acc: 0.9850 - masked_loss: 0.0503\n",
            "Epoch 10/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0908 - masked_acc: 0.9694 - masked_loss: 0.0908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0891 - masked_acc: 0.9700 - masked_loss: 0.0891\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0368 - masked_acc: 0.9850 - masked_loss: 0.0368"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0368 - masked_acc: 0.9850 - masked_loss: 0.0368\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0621 - masked_acc: 0.9798 - masked_loss: 0.0621"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0616 - masked_acc: 0.9800 - masked_loss: 0.0616\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0419 - masked_acc: 0.9850 - masked_loss: 0.0419"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0419 - masked_acc: 0.9850 - masked_loss: 0.0419\n",
            "Epoch 14/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0299 - masked_acc: 0.9898 - masked_loss: 0.0299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0294 - masked_acc: 0.9900 - masked_loss: 0.0294\n",
            "Epoch 15/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0541 - masked_acc: 0.9745 - masked_loss: 0.0541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0531 - masked_acc: 0.9750 - masked_loss: 0.0531\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0519 - masked_acc: 0.9798 - masked_loss: 0.0519"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0514 - masked_acc: 0.9800 - masked_loss: 0.0514\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0285 - masked_acc: 0.9900 - masked_loss: 0.0285"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0285 - masked_acc: 0.9900 - masked_loss: 0.0285\n",
            "Epoch 18/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0485 - masked_acc: 0.9796 - masked_loss: 0.0485"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0476 - masked_acc: 0.9800 - masked_loss: 0.0476\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0371 - masked_acc: 0.9850 - masked_loss: 0.0371"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0371 - masked_acc: 0.9850 - masked_loss: 0.0371\n",
            "Epoch 20/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0331 - masked_acc: 0.9796 - masked_loss: 0.0331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0324 - masked_acc: 0.9800 - masked_loss: 0.0324\n",
            "Epoch 21/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0640 - masked_acc: 0.9694 - masked_loss: 0.0640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0628 - masked_acc: 0.9700 - masked_loss: 0.0628\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0328 - masked_acc: 0.9848 - masked_loss: 0.0328"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0325 - masked_acc: 0.9850 - masked_loss: 0.0325\n",
            "Epoch 23/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0318 - masked_acc: 0.9847 - masked_loss: 0.0318"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.0312 - masked_acc: 0.9850 - masked_loss: 0.0312\n",
            "Epoch 24/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0351 - masked_acc: 0.9847 - masked_loss: 0.0351"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0344 - masked_acc: 0.9850 - masked_loss: 0.0344\n",
            "Epoch 25/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0278 - masked_acc: 0.9848 - masked_loss: 0.0278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0276 - masked_acc: 0.9850 - masked_loss: 0.0276\n",
            "Epoch 26/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0348 - masked_acc: 0.9796 - masked_loss: 0.0348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0341 - masked_acc: 0.9800 - masked_loss: 0.0341\n",
            "Epoch 27/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0361 - masked_acc: 0.9848 - masked_loss: 0.0361"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.0357 - masked_acc: 0.9850 - masked_loss: 0.0357\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0204 - masked_acc: 0.9899 - masked_loss: 0.0204"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0202 - masked_acc: 0.9900 - masked_loss: 0.0202\n",
            "Epoch 29/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0403 - masked_acc: 0.9796 - masked_loss: 0.0403"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0396 - masked_acc: 0.9800 - masked_loss: 0.0396\n",
            "Epoch 30/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0355 - masked_acc: 0.9796 - masked_loss: 0.0355"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0348 - masked_acc: 0.9800 - masked_loss: 0.0348\n",
            "Epoch 31/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0360 - masked_acc: 0.9798 - masked_loss: 0.0360"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0356 - masked_acc: 0.9800 - masked_loss: 0.0356\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0338 - masked_acc: 0.9798 - masked_loss: 0.0338"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0335 - masked_acc: 0.9800 - masked_loss: 0.0335\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0276 - masked_acc: 0.9850 - masked_loss: 0.0276"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.0276 - masked_acc: 0.9850 - masked_loss: 0.0276\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0354 - masked_acc: 0.9800 - masked_loss: 0.0354"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0354 - masked_acc: 0.9800 - masked_loss: 0.0354\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0283 - masked_acc: 0.9850 - masked_loss: 0.0283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0283 - masked_acc: 0.9850 - masked_loss: 0.0283\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0233 - masked_acc: 0.9848 - masked_loss: 0.0233"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0231 - masked_acc: 0.9850 - masked_loss: 0.0231\n",
            "Epoch 37/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0299 - masked_acc: 0.9798 - masked_loss: 0.0299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0296 - masked_acc: 0.9800 - masked_loss: 0.0296\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0377 - masked_acc: 0.9747 - masked_loss: 0.0377"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0373 - masked_acc: 0.9750 - masked_loss: 0.0373\n",
            "Epoch 39/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0248 - masked_acc: 0.9798 - masked_loss: 0.0248"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0246 - masked_acc: 0.9800 - masked_loss: 0.0246\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0252 - masked_acc: 0.9800 - masked_loss: 0.0252"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0252 - masked_acc: 0.9800 - masked_loss: 0.0252\n",
            "Epoch 41/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0246 - masked_acc: 0.9847 - masked_loss: 0.0246"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0241 - masked_acc: 0.9850 - masked_loss: 0.0241\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0453 - masked_acc: 0.9798 - masked_loss: 0.0453"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.0448 - masked_acc: 0.9800 - masked_loss: 0.0448\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0243 - masked_acc: 0.9800 - masked_loss: 0.0243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.0243 - masked_acc: 0.9800 - masked_loss: 0.0243\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0244 - masked_acc: 0.9850 - masked_loss: 0.0244"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0244 - masked_acc: 0.9850 - masked_loss: 0.0244\n",
            "Epoch 45/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0364 - masked_acc: 0.9747 - masked_loss: 0.0364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0360 - masked_acc: 0.9750 - masked_loss: 0.0360\n",
            "Epoch 46/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0311 - masked_acc: 0.9745 - masked_loss: 0.0311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0304 - masked_acc: 0.9750 - masked_loss: 0.0304\n",
            "Epoch 47/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0218 - masked_acc: 0.9848 - masked_loss: 0.0218"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0216 - masked_acc: 0.9850 - masked_loss: 0.0216\n",
            "Epoch 48/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0305 - masked_acc: 0.9796 - masked_loss: 0.0305"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0299 - masked_acc: 0.9800 - masked_loss: 0.0299\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0224 - masked_acc: 0.9850 - masked_loss: 0.0224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0224 - masked_acc: 0.9850 - masked_loss: 0.0224\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0253 - masked_acc: 0.9800 - masked_loss: 0.0253"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0253 - masked_acc: 0.9800 - masked_loss: 0.0253\n",
            "Epoch 51/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0240 - masked_acc: 0.9847 - masked_loss: 0.0240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0301 - masked_acc: 0.9800 - masked_loss: 0.0301\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0203 - masked_acc: 0.9800 - masked_loss: 0.0203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 0.0203 - masked_acc: 0.9800 - masked_loss: 0.0203\n",
            "Epoch 53/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0256 - masked_acc: 0.9848 - masked_loss: 0.0256"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0254 - masked_acc: 0.9850 - masked_loss: 0.0254\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0373 - masked_acc: 0.9747 - masked_loss: 0.0373"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0369 - masked_acc: 0.9750 - masked_loss: 0.0369\n",
            "Epoch 55/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0165 - masked_acc: 0.9898 - masked_loss: 0.0165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0162 - masked_acc: 0.9900 - masked_loss: 0.0162\n",
            "Epoch 56/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0272 - masked_acc: 0.9847 - masked_loss: 0.0272"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0266 - masked_acc: 0.9850 - masked_loss: 0.0266\n",
            "Epoch 57/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0240 - masked_acc: 0.9796 - masked_loss: 0.0240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0235 - masked_acc: 0.9800 - masked_loss: 0.0235\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0322 - masked_acc: 0.9798 - masked_loss: 0.0322"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0319 - masked_acc: 0.9800 - masked_loss: 0.0319\n",
            "Epoch 59/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0288 - masked_acc: 0.9848 - masked_loss: 0.0288"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0285 - masked_acc: 0.9850 - masked_loss: 0.0285\n",
            "Epoch 60/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0202 - masked_acc: 0.9899 - masked_loss: 0.0202"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0200 - masked_acc: 0.9900 - masked_loss: 0.0200\n",
            "Epoch 61/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0257 - masked_acc: 0.9796 - masked_loss: 0.0257"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0252 - masked_acc: 0.9800 - masked_loss: 0.0252\n",
            "Epoch 62/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0335 - masked_acc: 0.9798 - masked_loss: 0.0335"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 0.0332 - masked_acc: 0.9800 - masked_loss: 0.0332\n",
            "Epoch 63/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0141 - masked_acc: 0.9899 - masked_loss: 0.0141"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0140 - masked_acc: 0.9900 - masked_loss: 0.0140\n",
            "Epoch 64/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0290 - masked_acc: 0.9847 - masked_loss: 0.0290"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0285 - masked_acc: 0.9850 - masked_loss: 0.0285\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0245 - masked_acc: 0.9850 - masked_loss: 0.0245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0245 - masked_acc: 0.9850 - masked_loss: 0.0245\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0197 - masked_acc: 0.9850 - masked_loss: 0.0197"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0197 - masked_acc: 0.9850 - masked_loss: 0.0197\n",
            "Epoch 67/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.7136 - masked_acc: 0.6582 - masked_loss: 1.7136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 1.7464 - masked_acc: 0.6550 - masked_loss: 1.7464\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2720 - masked_acc: 0.5700 - masked_loss: 2.2720"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 2.2720 - masked_acc: 0.5700 - masked_loss: 2.2720\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8224 - masked_acc: 0.7950 - masked_loss: 0.8224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.8224 - masked_acc: 0.7950 - masked_loss: 0.8224\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2361 - masked_acc: 0.9300 - masked_loss: 0.2361"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.2361 - masked_acc: 0.9300 - masked_loss: 0.2361\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0774 - masked_acc: 0.9700 - masked_loss: 0.0774"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.0774 - masked_acc: 0.9700 - masked_loss: 0.0774\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0414 - masked_acc: 0.9850 - masked_loss: 0.0414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0414 - masked_acc: 0.9850 - masked_loss: 0.0414\n",
            "Epoch 73/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0337 - masked_acc: 0.9847 - masked_loss: 0.0337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0333 - masked_acc: 0.9850 - masked_loss: 0.0333\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0398 - masked_acc: 0.9850 - masked_loss: 0.0398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0398 - masked_acc: 0.9850 - masked_loss: 0.0398\n",
            "Epoch 75/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0178 - masked_acc: 0.9949 - masked_loss: 0.0178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0177 - masked_acc: 0.9950 - masked_loss: 0.0177\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0370 - masked_acc: 0.9850 - masked_loss: 0.0370"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0370 - masked_acc: 0.9850 - masked_loss: 0.0370\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0323 - masked_acc: 0.9850 - masked_loss: 0.0323"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0323 - masked_acc: 0.9850 - masked_loss: 0.0323\n",
            "Epoch 78/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0284 - masked_acc: 0.9899 - masked_loss: 0.0284"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0281 - masked_acc: 0.9900 - masked_loss: 0.0281\n",
            "Epoch 79/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0203 - masked_acc: 0.9899 - masked_loss: 0.0203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0202 - masked_acc: 0.9900 - masked_loss: 0.0202\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0359 - masked_acc: 0.9800 - masked_loss: 0.0359"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0359 - masked_acc: 0.9800 - masked_loss: 0.0359\n",
            "Epoch 81/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0329 - masked_acc: 0.9798 - masked_loss: 0.0329"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0326 - masked_acc: 0.9800 - masked_loss: 0.0326\n",
            "Epoch 82/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0245 - masked_acc: 0.9848 - masked_loss: 0.0245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0244 - masked_acc: 0.9850 - masked_loss: 0.0244\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0398 - masked_acc: 0.9650 - masked_loss: 0.0398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0398 - masked_acc: 0.9650 - masked_loss: 0.0398\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0108 - masked_acc: 0.9949 - masked_loss: 0.0108"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0108 - masked_acc: 0.9950 - masked_loss: 0.0108\n",
            "Epoch 85/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0383 - masked_acc: 0.9745 - masked_loss: 0.0383"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0376 - masked_acc: 0.9750 - masked_loss: 0.0376\n",
            "Epoch 86/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0221 - masked_acc: 0.9898 - masked_loss: 0.0221"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 35ms/step - loss: 0.0217 - masked_acc: 0.9900 - masked_loss: 0.0217\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0247 - masked_acc: 0.9850 - masked_loss: 0.0247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0247 - masked_acc: 0.9850 - masked_loss: 0.0247\n",
            "Epoch 88/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0336 - masked_acc: 0.9745 - masked_loss: 0.0336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0330 - masked_acc: 0.9750 - masked_loss: 0.0330\n",
            "Epoch 89/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0267 - masked_acc: 0.9798 - masked_loss: 0.0267"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0264 - masked_acc: 0.9800 - masked_loss: 0.0264\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0224 - masked_acc: 0.9850 - masked_loss: 0.0224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0224 - masked_acc: 0.9850 - masked_loss: 0.0224\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0227 - masked_acc: 0.9850 - masked_loss: 0.0227"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0227 - masked_acc: 0.9850 - masked_loss: 0.0227\n",
            "Epoch 92/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0224 - masked_acc: 0.9848 - masked_loss: 0.0224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0287 - masked_acc: 0.9800 - masked_loss: 0.0287\n",
            "Epoch 93/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0269 - masked_acc: 0.9798 - masked_loss: 0.0269"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0266 - masked_acc: 0.9800 - masked_loss: 0.0266\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0239 - masked_acc: 0.9800 - masked_loss: 0.0239"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0239 - masked_acc: 0.9800 - masked_loss: 0.0239\n",
            "Epoch 95/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0174 - masked_acc: 0.9848 - masked_loss: 0.0174"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0173 - masked_acc: 0.9850 - masked_loss: 0.0173\n",
            "Epoch 96/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0397 - masked_acc: 0.9643 - masked_loss: 0.0397"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0390 - masked_acc: 0.9650 - masked_loss: 0.0390\n",
            "Epoch 97/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0206 - masked_acc: 0.9847 - masked_loss: 0.0206"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0202 - masked_acc: 0.9850 - masked_loss: 0.0202\n",
            "Epoch 98/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0191 - masked_acc: 0.9898 - masked_loss: 0.0191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0187 - masked_acc: 0.9900 - masked_loss: 0.0187\n",
            "Epoch 99/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0199 - masked_acc: 0.9848 - masked_loss: 0.0199"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0197 - masked_acc: 0.9850 - masked_loss: 0.0197\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0220 - masked_acc: 0.9850 - masked_loss: 0.0220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.0220 - masked_acc: 0.9850 - masked_loss: 0.0220\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 60,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "a7ceb258-115e-4d6f-942a-5c7c8cdca7e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbfe7fd62e0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "3ca84bd2-73d0-492b-dca8-3a9723f10099"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbfde422dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('lbm_sample.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "f0542f64-922f-45f3-f7c0-c53f212568c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9a021c4-9f94-43b6-b50a-503779f563aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9a021c4-9f94-43b6-b50a-503779f563aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9a021c4-9f94-43b6-b50a-503779f563aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9a021c4-9f94-43b6-b50a-503779f563aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "7af7713f-8e56-4a90-999f-4c2f299ab61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "1aedeb3b-27f6-4db1-be44-ad89351b3269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "#for t in inputs:\n",
        "#  mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('lbm_sample_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "02610a13-b31c-4613-9dcd-0e80d4503605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "4  moduleom_name:0opendeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f41dfb7d-1e9f-4dcc-a409-07aa7cbfe6f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f41dfb7d-1e9f-4dcc-a409-07aa7cbfe6f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f41dfb7d-1e9f-4dcc-a409-07aa7cbfe6f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f41dfb7d-1e9f-4dcc-a409-07aa7cbfe6f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "b5d0bf7e-0704-4bd9-ba6e-f14e001c25a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "835a794e-c886-49c7-dbf9-96279b328400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.000000\n",
            "Testing: Recall = 0.000000\n",
            "Testing: F1 Score = 0.000000\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[85  0]\n",
            " [15  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "a58b86bd-83a1-4e54-f0dd-cbfdef92559d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92        85\n",
            "           1       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.85       100\n",
            "   macro avg       0.42      0.50      0.46       100\n",
            "weighted avg       0.72      0.85      0.78       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}