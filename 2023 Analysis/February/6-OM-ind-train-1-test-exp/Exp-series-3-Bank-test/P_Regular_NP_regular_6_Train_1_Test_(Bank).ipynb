{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJnMTPsgYlc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "[link text](https://)  \n",
        "#Experiment with P Regular , NP Regular \n",
        "###6 OM - Dataset , Camping,OnlineStore,  Library Management, Decider, Customer_order, E-Commerce\n",
        "###1 OM - Testing - Bank\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 374\n",
        "\n",
        "### P samples - 299\n",
        "### NP samples - 75 \n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 32\n",
        "\n",
        "### P samples - 9\n",
        "### NP samples - 23 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DGFTkuRvzWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d550d3-261e-4c3e-d610-5f197f7733ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text>=2.10\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text>=2.10) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text>=2.10) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.31.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (15.0.6.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.22.4)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.51.3)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (23.1.21)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (23.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.25.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.16.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.2.2)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ],
      "source": [
        " !pip install \"tensorflow-text>=2.10\"\n",
        " !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('6-OM-Bank-test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "6193b833-2f88-4380-ad9e-ec752a685366"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  module OM_name one sig class1_name extends Cla...   \n",
              "1  module OM_name one sig class1_name extends Cla...   \n",
              "2  module OM_name one sig class1_name extends Cla...   \n",
              "3  module OM_name one sig class1_name extends Cla...   \n",
              "4  module OM_name one sig class1_name extends Cla...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  module OM_name one sig class1_name extends Cla...  \n",
              "1  module OM_name one sig class1_name extends Cla...  \n",
              "2  module OM_name one sig class1_name extends Cla...  \n",
              "3  module OM_name one sig class1_name extends Cla...  \n",
              "4  module OM_name one sig class1_name extends Cla...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a510bf03-9b78-4c47-995e-3a7a44566151\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a510bf03-9b78-4c47-995e-3a7a44566151')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a510bf03-9b78-4c47-995e-3a7a44566151 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a510bf03-9b78-4c47-995e-3a7a44566151');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cTbSbBz55QtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6840b1a7-80cb-48a3-f3c8-432579c0fe2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsClassattrSet=c2_at1+c2_at2id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_type,onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5+c3_at6id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_typeonesigc3_at6extendsc3_at6_type,onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at3noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_type,onesigclass5_nameextendsClassattrSet=c5_at1oneparentparentinclass2_nameid=c2_at1isAbstract=No}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsClassattrSet=c6_at1_0+c6_at2+c6_at3+c6_at4id=c6_at2noparentisAbstract=No}onesigc6_at1_0extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_type,onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass2_nameid=c2_at1isAbstract=No}onesigc7_at1extendsc7_at1_type,onesigclass8_nameextendsClassattrSet=c8_at1+c8_at2+c2_at2+c6_at3id=c8_at1noparentisAbstract=No}onesigc8_at1extendsc8_at1_typeonesigc8_at1extendsc8_at1_type,onesigassoc1extendsAssociationsrc=class8_namedst=class2_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsAssociationsrc=class2_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc3extendsAssociationsrc=class8_namedst=class3_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc4extendsAssociationsrc=class8_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc5extendsAssociationsrc=class8_namedst=class6_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2,}onesigassoc6extendsAssociationsrc=class6_namedst=class1_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2,}onesigassoc7extendsAssociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc8extendsAssociationsrc=class1_namedst=class3_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc9extendsAssociationsrc=class1_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc10extendsAssociationsrc=class2_namedst=class3_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2,},MappingStrategyforclass1_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass2_name:map_str1MappingStrategyforclass5_name:map_str1MappingStrategyforclass7_name:map_str1AssociationStrategyforassoc3:assoc_str1AssociationStrategyforassoc7:assoc_str1AssociationStrategyforassoc8:assoc_str1AssociationStrategyforassoc9:assoc_str1AssociationStrategyforassoc1:assoc_str2AssociationStrategyforassoc10:assoc_str2AssociationStrategyforassoc4:assoc_str2AssociationStrategyforassoc5:assoc_str2AssociationStrategyforassoc6:assoc_str2,USEOM_name_0CREATETABLE`class3_name`(`c8_at1`c8_at1_type`c3_at6`c3_at6_type`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at3`c3_at3_type`c3_at2`c3_at2_typec3_at1`c3_at1_typeNOTNULLc1_at1`c1_at1_typeKEY`FK_class3_name_c8_at1_idx`(`c8_at1`)KEY`FK_class3_name_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c3_at1`),);CREATETABLE`class1_name`(`c1_at1`c1_at2_type(64)`c1_at1`c1_at1_typeNOTNULLPRIMARYKEY(`c1_at1`),);CREATETABLE`class2_name`(c2_at3`c2_at3_type(64),`c7_at1`c7_at1_type(64)`c5_at1`c5_at1_type,`c2_at2`c2_at2_type(64)c2_at1`c2_at1_typeNOTNULLPRIMARYKEY(`c1_at1`),);CREATETABLE`assoc10`(c3_at1`c3_at1_typeNOTNULLc2_at1`c2_at1_typeNOTNULLKEY`FK_assoc10_c3_at1_idx`(`c3_at1`)KEY`FK_assoc10_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1`,`c2_at1`),);CREATETABLE`class8_name`(`c8_at2`c8_at2_type(64)``c8_at1`c8_at1_typeNOTNULLPRIMARYKEY(`c8_at1`),);CREATETABLE`assoc5`(``c8_at1`c8_at1_typeNOTNULL`c2_at1`c2_at1_typeNOTNULLKEY`FK_assoc5_c8_at1_idx`(`c8_at1`),KEY`FK_assoc5_c6_at2_idx`(`c6_at2`)PRIMARYKEY(`c8_at1`,`c6_at2`),);CREATETABLE`assoc1`(``c8_at1`c8_at1_typeNOTNULLc2_at1`c2_at1_typeNOTNULLKEY`FK_assoc1_c8_at1_idx`(`c8_at1`)KEY`FK_assoc1_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c8_at1`,`c2_at1`));CREATETABLE`assoc4`(``c8_at1`c8_at1_typeNOTNULL`c4_at3`c4_at3_typeKEY`FK_assoc4_c8_at1_idx`(`c8_at1`)KEY`FK_assoc4_c4_at3_idx`(`c4_at3`)PRIMARYKEY(`c8_at1`,`c4_at3`));CREATETABLE`class4_name`(`c4_at4`c4_at4_type(64)`c4_at2`c4_at2_type(64)`c4_at1`c4_at1_type(64)`c6_at2`c6_at2_type`c4_at3`c4_at3_typec1_at1`c1_at1_typeKEY`FK_class4_name_c6_at2_idx`(`c6_at2`)KEY`FK_class4_name_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c4_at3`),);CREATETABLE`assoc6`(`c2_at1`c2_at1_typeNOTNULL`c1_at1`c1_at1_typeNOTNULL`c3_at1`c3_at1_typeNOTNULLKEY`FK_assoc6_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c6_at2`,`c1_at1`),);CREATETABLE`class6_name`(`c6_at4`c6_at4_type(64)`c6_at3`c6_at3_type(64)`c6_at1_0`c6_at1_type`c2_at1`c2_at1_typeNOTNULLPRIMARYKEY(`c6_at2`),);CREATETABLE`assoc2`(`c4_at3`c4_at3_typec2_at1`c2_at1_typeNOTNULLKEY`FK_assoc2_c4_at3_idx`(`c4_at3`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c4_at3`,`c2_at1`),);ALTERTABLE`class3_name`ADDCONSTRAINT`FK_class3_name_c8_at1`FOREIGNKEY(`c8_at1`)REFERENCES`class8_name`(`c8_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_class3_name_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc10`ADDCONSTRAINT`FK_assoc10_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINT`FK_assoc10_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c8_at1`FOREIGNKEY(`c8_at1`)REFERENCES`class8_name`(`c8_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c6_at2`FOREIGNKEY(`c6_at2`)REFERENCES`class6_name`(`c6_at2`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c8_at1`FOREIGNKEY(`c8_at1`)REFERENCES`class8_name`(`c8_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c8_at1`FOREIGNKEY(`c8_at1`)REFERENCES`class8_name`(`c8_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c4_at3`FOREIGNKEY(`c4_at3`)REFERENCES`class4_name`(`c4_at3`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`class4_name`ADDCONSTRAINT`FK_class4_name_c6_at2`FOREIGNKEY(`c8_at1`)REFERENCES`class8_name`(`c8_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_class4_name_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc6`ADDCONSTRAINT`FK_assoc6_c6_at2`FOREIGNKEY(`c6_at2`)REFERENCES`class6_name`(`c6_at2`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc6_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c4_at3`FOREIGNKEY(`c4_at3`)REFERENCES`class4_name`(`c4_at3`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE\n"
          ]
        }
      ],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0643d349-e155-4bda-c4f4-49d6abbc7132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1id=c1_at1isAbstract=Nonoparent}onesigc1_at1extendsc1_at1_type,onesigclass01_nameextendsClassattrSet=c01_at1id=c01_at1isAbstract=Nonoparent}onesigc01_at1extendsc01_at1_type,onesigassoc1extendsAssociationsrc=class1_namedst=class01_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass2_nameextendsClassattrSet=c2_at1id=c2_at1isAbstract=Nonoparent}onesigc2_at1extendsc2_at1_type,onesigassoc2extendsAssociationsrc=class1_namedst=class2_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2id=c3_at1isAbstract=Nonoparent}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_type,onesigclass4_nameextendsClassattrSet=c4_at1oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc4_at1extendsc4_at1_type,onesigassoc3extendsAssociationdst=class2_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass5_nameextendsClassattrSet=c5_at1+c5_at2oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc5_at2extendsc5_at2_typeonesigc5_at1extendsc5_at1_typeonesigassoc4extendsAssociationsrc=class01_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2id=categoryIDisAbstract=Nonoparent}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigclass7_nameextendsClassattrSet=c7_at1+c7_at2+c7_at3+c7_at4id=c7_at1isAbstract=Nonoparent}onesigc7_at1extendsc7_at1_typeonesigc7_at2extendsc7_at2_typeonesigc7_at3extendsc7_at3_typeonesigc7_at4extendsc7_at4_typeonesigassoc5extendsAssociationsrc=class7_namesrc=class6_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass8_nameextendsClassattrSet=c8_at1id=c8_at1isAbstract=Nonoparent}onesigc8_at1extendsIntegeronesigassoc6extendsAssociationsrc=class7_namedst=class8_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc7extendsAssociationsrc=class7_namedst=class3_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass9_nameextendsClassattrSet=c9_at1+c10_at2oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc9_at1extendsc9_at1_typeonesigc10_at2extendsc10_at2_typeonesigclass10_nameextendsClassattrSet=c10_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc10_at1extendsc10_at1_typeonesigclass11_nameextendsClassattrSet=c11_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc11_at1extendsstringonesigclass12_nameextendsClassattrSet=c12_at1+c12_at2+c12_at3id=c12_at1isAbstract=Nonoparent}onesigc12_at1extendsc12_at1_typeonesigc12_at2extendsc12_at2_typeonesigc12_at3extendsc12_at3_typeonesigassoc8extendsAssociationsrc=class7_namesrc=class12_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass13_nameextendsClassattrSet=c13_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc13_at1extendsc13_at1_typeonesigclass14_nameextendsClassattrSet=c14_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc14_at1extendsc14_at1_typepredshowrunshow,TableName:class1_nameTableName:class01_nameTableNameclass2_nameTableNameclass3_nameTableNameclass4_nameTableNameclass5_nameTableNameassoc7TableNameassoc5TableNameclass8_nameTableNameclass6_nameTableNameclass10_nameMappingStrategyforclass1_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass4_name:map_str3MappingStrategyforclass3_name:map_str3MappingStrategyforclass7_name:map_str1MappingStrategyforclass9_name:map_str1MappingStrategyforclass10_name:map_str1MappingStrategyforclass11_name:map_str1MappingStrategyforclass12_name:map_str1MappingStrategyforclass11_name:map_str1MappingStrategyforclass14_name:map_str1AssociationStrategyforassoc1:assoc_str1AssociationStrategyforassoc2:assoc_str1AssociationStrategyforassoc3:assoc_str1AssociationStrategyforassoc4:assoc_str1AssociationStrategyforassoc5:assoc_str2AssociationStrategyforassoc6:assoc_str2AssociationStrategyforassoc7:assoc_str2AssociationStrategyforassoc8:assoc_str2,USEOM_name_0CREATETABLE`class01_name`(`c01_at1`c01_at1_typeNOTNULL,`c1_at1`c1_at1_type,KEY`FK_class01_name_c1_at1_idx`(`c1_at1`),PRIMARYKEY(`c01_at1`),);CREATETABLE`class6_name`(`c7_at1`c7_at1_type(64)`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`),);CREATETABLE`class1_name`(`c1_at1`c1_at1_typeNOTNULLPRIMARYKEY(`c1_at1`),);CREATETABLE`ShippingCartItemAssociation`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeNOTNULLKEY`FK_ShippingCartItemAssociation_ItemID_idx`(`ItemID`),KEY`FK_ShippingCartItemAssociation_shippingCartID_idx`(`shippingCartID`),PRIMARYKEY(`ItemID`,`shippingCartID`));CREATETABLE`class13_name`(`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c13_at1`c13_at1_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`class7_name`(`DType`varchar(64),`c10_at2`c10_at2_type,`c11_at1`c11_at1_type(64)`c10_at1`c10_at1_type(64)`c7_at3`c7_at3_type(64)`c7_at2`c7_at2_type`c9_at1`c9_at1_type(20,5),`c7_at4`c7_at4_type(20,5)`c7_at1`c7_at1_typeNOTNULLPRIMARYKEY(`c7_at1`),);CREATETABLE`class2_name`(`c2_at1`c2_at1_typeNOTNULL`c1_at1`c1_at1_type,KEY`FK_class2_name_c1_at1_idx`(`c1_at1`),PRIMARYKEY(`c2_at1`),);CREATETABLE`class8_name`(`c8_at1`c8_at1_typeNOTNULL`c7_at1`c7_at1_typeKEY`FK_class8_name_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c8_at1`),);CREATETABLE`assoc7`(`c7_at1`c7_at1_typeNOTNULL`c3_at1`c3_at1_typeNOTNULLKEY`FK_assoc7_c7_at1_idx`(`c7_at1`)KEY`FK_assoc7_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c7_at1`,`c3_at1`),);CREATETABLE`class3_name`(`DType`varchar(64),`c5_at1`c5_at1_type,`c5_at2`c5_at2_type,`c4_at1`c4_at1_type,`c3_at2`c3_at2_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`),);CREATETABLE`assoc8`(`c12_at1`c12_at1_typeNOTNULL`c7_at1`c7_at1_typeNOTNULLKEY`FK_assoc8_c12_at1_idx`(`c12_at1`)KEY`FK_assoc8_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c12_at1`,`c7_at1`),);CREATETABLE`class14_name`(`c14_at1`c14_at1_type(64)`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`class12_name`(`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`OrderItemAssociation`(`c3_at1`c3_at1_typeNOTNULL`c01_at1`c01_at1_typeNOTNULL,KEY`FK_OrderItemAssociation_ItemID_idx`(`ItemID`),KEY`FK_OrderItemAssociation_orderID_idx`(`orderID`),PRIMARYKEY(`ItemID`,`orderID`));CREATETABLE`assoc5`(`c7_at1`c7_at1_typeNOTNULL`c6_at1`c6_at1_typeNOTNULLKEY`FK_assoc5_c7_at1_idx`(`c7_at1`)KEY`FK_assoc5_c6_at1_idx`(`c6_at1`)PRIMARYKEY(`c7_at1`,`c6_at1`),);ALTERTABLE`class01_name`ADDCONSTRAINT`FK_class01_name_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`ShippingCartItemAssociation`ADDCONSTRAINT`FK_ShippingCartItemAssociation_ItemID`FOREIGNKEY(`ItemID`)REFERENCES`Item`(`ItemID`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINT`FK_ShippingCartItemAssociation_shippingCartID`FOREIGNKEY(`shippingCartID`)REFERENCES`ShippingCart`(`shippingCartID`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`class2_name`ADDCONSTRAINT`FK_class2_name_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`class8_name`ADDCONSTRAINT`FK_class8_name_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc7`ADDCONSTRAINT`FK_assoc7_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc7_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc8`ADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINTFK_assoc8_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`OrderItemAssociation`ADDCONSTRAINT`FK_OrderItemAssociation_ItemID`FOREIGNKEY(`ItemID`)REFERENCES`Item`(`ItemID`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINT`FK_OrderItemAssociation_orderID`FOREIGNKEY(`orderID`)REFERENCES`Order`(`orderID`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE'], shape=(1,), dtype=string)\n",
            "\n",
            "tf.Tensor([b'moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1id=c1_at1isAbstract=Nonoparent}onesigc1_at1extendsc1_at1_type,onesigclass01_nameextendsClassattrSet=c01_at1id=c01_at1isAbstract=Nonoparent}onesigc01_at1extendsc01_at1_type,onesigassoc1extendsAssociationsrc=class1_namedst=class01_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass2_nameextendsClassattrSet=c2_at1id=c2_at1isAbstract=Nonoparent}onesigc2_at1extendsc2_at1_type,onesigassoc2extendsAssociationsrc=class1_namedst=class2_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2id=c3_at1isAbstract=Nonoparent}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_type,onesigclass4_nameextendsClassattrSet=c4_at1oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc4_at1extendsc4_at1_type,onesigassoc3extendsAssociationdst=class2_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass5_nameextendsClassattrSet=c5_at1+c5_at2oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc5_at2extendsc5_at2_typeonesigc5_at1extendsc5_at1_typeonesigassoc4extendsAssociationsrc=class01_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2id=categoryIDisAbstract=Nonoparent}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigclass7_nameextendsClassattrSet=c7_at1+c7_at2+c7_at3+c7_at4id=c7_at1isAbstract=Nonoparent}onesigc7_at1extendsc7_at1_typeonesigc7_at2extendsc7_at2_typeonesigc7_at3extendsc7_at3_typeonesigc7_at4extendsc7_at4_typeonesigassoc5extendsAssociationsrc=class7_namesrc=class6_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass8_nameextendsClassattrSet=c8_at1id=c8_at1isAbstract=Nonoparent}onesigc8_at1extendsIntegeronesigassoc6extendsAssociationsrc=class7_namedst=class8_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc7extendsAssociationsrc=class7_namedst=class3_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass9_nameextendsClassattrSet=c9_at1+c10_at2oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc9_at1extendsc9_at1_typeonesigc10_at2extendsc10_at2_typeonesigclass10_nameextendsClassattrSet=c10_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc10_at1extendsc10_at1_typeonesigclass11_nameextendsClassattrSet=c11_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc11_at1extendsstringonesigclass12_nameextendsClassattrSet=c12_at1+c12_at2+c12_at3id=c12_at1isAbstract=Nonoparent}onesigc12_at1extendsc12_at1_typeonesigc12_at2extendsc12_at2_typeonesigc12_at3extendsc12_at3_typeonesigassoc8extendsAssociationsrc=class7_namesrc=class12_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass13_nameextendsClassattrSet=c13_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc13_at1extendsc13_at1_typeonesigclass14_nameextendsClassattrSet=c14_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc14_at1extendsc14_at1_typepredshowrunshow,TableName:class1_nameTableName:class01_nameTableNameclass2_nameTableNameclass3_nameTableNameclass4_nameTableNameclass5_nameTableNameassoc7TableNameassoc5TableNameclass8_nameTableNameclass6_nameTableNameclass10_nameMappingStrategyforclass1_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass4_name:map_str3MappingStrategyforclass3_name:map_str3MappingStrategyforclass7_name:map_str1MappingStrategyforclass9_name:map_str1MappingStrategyforclass10_name:map_str1MappingStrategyforclass11_name:map_str1MappingStrategyforclass12_name:map_str1MappingStrategyforclass11_name:map_str1MappingStrategyforclass14_name:map_str1AssociationStrategyforassoc1:assoc_str1AssociationStrategyforassoc2:assoc_str1AssociationStrategyforassoc3:assoc_str1AssociationStrategyforassoc4:assoc_str1AssociationStrategyforassoc5:assoc_str2AssociationStrategyforassoc6:assoc_str2AssociationStrategyforassoc7:assoc_str2AssociationStrategyforassoc8:assoc_str2,USEOM_name_0CREATETABLE`class01_name`(`c01_at1`c01_at1_typeNOTNULL,`c1_at1`c1_at1_type,KEY`FK_class01_name_c1_at1_idx`(`c1_at1`),PRIMARYKEY(`c01_at1`),);CREATETABLE`class6_name`(`c7_at1`c7_at1_type(64)`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`),);CREATETABLE`class1_name`(`c1_at1`c1_at1_typeNOTNULLPRIMARYKEY(`c1_at1`),);CREATETABLE`ShippingCartItemAssociation`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeNOTNULLKEY`FK_ShippingCartItemAssociation_ItemID_idx`(`ItemID`),KEY`FK_ShippingCartItemAssociation_shippingCartID_idx`(`shippingCartID`),PRIMARYKEY(`ItemID`,`shippingCartID`));CREATETABLE`class13_name`(`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c13_at1`c13_at1_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`class7_name`(`DType`varchar(64),`c10_at2`c10_at2_type,`c11_at1`c11_at1_type(64)`c10_at1`c10_at1_type(64)`c7_at3`c7_at3_type(64)`c7_at2`c7_at2_type`c9_at1`c9_at1_type(20,5),`c7_at4`c7_at4_type(20,5)`c7_at1`c7_at1_typeNOTNULLPRIMARYKEY(`c7_at1`),);CREATETABLE`class2_name`(`c2_at1`c2_at1_typeNOTNULL`c1_at1`c1_at1_type,KEY`FK_class2_name_c1_at1_idx`(`c1_at1`),PRIMARYKEY(`c2_at1`),);CREATETABLE`class8_name`(`c8_at1`c8_at1_typeNOTNULL`c7_at1`c7_at1_typeKEY`FK_class8_name_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c8_at1`),);CREATETABLE`assoc7`(`c7_at1`c7_at1_typeNOTNULL`c3_at1`c3_at1_typeNOTNULLKEY`FK_assoc7_c7_at1_idx`(`c7_at1`)KEY`FK_assoc7_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c7_at1`,`c3_at1`),);CREATETABLE`class3_name`(`DType`varchar(64),`c5_at1`c5_at1_type,`c5_at2`c5_at2_type,`c4_at1`c4_at1_type,`c3_at2`c3_at2_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`),);CREATETABLE`assoc8`(`c12_at1`c12_at1_typeNOTNULL`c7_at1`c7_at1_typeNOTNULLKEY`FK_assoc8_c12_at1_idx`(`c12_at1`)KEY`FK_assoc8_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c12_at1`,`c7_at1`),);CREATETABLE`class14_name`(`c14_at1`c14_at1_type(64)`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`class12_name`(`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`OrderItemAssociation`(`c3_at1`c3_at1_typeNOTNULL`c01_at1`c01_at1_typeNOTNULL,KEY`FK_OrderItemAssociation_ItemID_idx`(`ItemID`),KEY`FK_OrderItemAssociation_orderID_idx`(`orderID`),PRIMARYKEY(`ItemID`,`orderID`));CREATETABLE`assoc5`(`c7_at1`c7_at1_typeNOTNULL`c6_at1`c6_at1_typeNOTNULLKEY`FK_assoc5_c7_at1_idx`(`c7_at1`)KEY`FK_assoc5_c6_at1_idx`(`c6_at1`)PRIMARYKEY(`c7_at1`,`c6_at1`),);ALTERTABLE`class01_name`ADDCONSTRAINT`FK_class01_name_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`ShippingCartItemAssociation`ADDCONSTRAINT`FK_ShippingCartItemAssociation_ItemID`FOREIGNKEY(`ItemID`)REFERENCES`Item`(`ItemID`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINT`FK_ShippingCartItemAssociation_shippingCartID`FOREIGNKEY(`shippingCartID`)REFERENCES`ShippingCart`(`shippingCartID`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`class2_name`ADDCONSTRAINT`FK_class2_name_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`class8_name`ADDCONSTRAINT`FK_class8_name_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc7`ADDCONSTRAINT`FK_assoc7_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc7_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc8`ADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINTFK_assoc8_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`OrderItemAssociation`ADDCONSTRAINT`FK_OrderItemAssociation_ItemID`FOREIGNKEY(`ItemID`)REFERENCES`Item`(`ItemID`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINT`FK_OrderItemAssociation_orderID`FOREIGNKEY(`orderID`)REFERENCES`Order`(`orderID`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,NP'], shape=(1,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "#print(example_text.numpy().decode())\n",
        "#print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "1c273cd1-13ab-4ba4-ef09-049058a03190"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 131, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "#context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "#tokens = context_vocab[example_tokens[0].numpy()]\n",
        "#' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "73c67f5a-142d-4279-8a45-546b92d17941"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "08749a41-3075-4e0e-eeed-995241abe3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 107   3]\n",
            "\n",
            "[  2 108]\n",
            "[108   3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "711579e5-4c21-42d4-a044-6ada72a9d745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "fcba313d-d79c-492d-d0d3-52a607fc54c7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "032c6c6f-bf6e-448b-d671-ae19478d0f85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.       , 1.0000001], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "b5cc2291-06f9-498c-82d3-50242c6928d4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "75459430-d4a8-4df1-b67b-f4bb1bb65e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 362)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "0dd69078-65ea-49f5-9f7f-c1b09e8c7533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 362)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "48e32b43-b16c-4a80-f293-15c8aad8ec06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.8916445, 'expected_acc': 0.0027624309392265192}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "3f7b94f5-0605-4426-dcdf-1b361d195969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/60 [==========================>...] - ETA: 0s - loss: 5.8612 - masked_acc: 0.0000e+00 - masked_loss: 5.8612"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/60 [==============================] - 9s 14ms/step - loss: 5.8576 - masked_acc: 0.0000e+00 - masked_loss: 5.8576\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.857638835906982,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 5.857638835906982}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=60, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "d9c9ab4d-aa46-41f2-eb65-5d01a008d8ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.5096 - masked_acc: 0.4849 - masked_loss: 3.5096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 21s 39ms/step - loss: 3.5088 - masked_acc: 0.4850 - masked_loss: 3.5088 - val_loss: 3.3498 - val_masked_acc: 0.5169 - val_masked_loss: 3.3498\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.7293 - masked_acc: 0.4749 - masked_loss: 3.7293"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 3.7256 - masked_acc: 0.4752 - masked_loss: 3.7256\n",
            "Epoch 3/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.6270 - masked_acc: 0.4949 - masked_loss: 3.6270"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 3.6346 - masked_acc: 0.4950 - masked_loss: 3.6346\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.3855 - masked_acc: 0.4801 - masked_loss: 3.3855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 3.3865 - masked_acc: 0.4803 - masked_loss: 3.3865\n",
            "Epoch 5/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.1920 - masked_acc: 0.4909 - masked_loss: 3.1920"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 3.1951 - masked_acc: 0.4910 - masked_loss: 3.1951\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2003 - masked_acc: 0.4954 - masked_loss: 3.2003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 3.2003 - masked_acc: 0.4954 - masked_loss: 3.2003\n",
            "Epoch 7/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.9194 - masked_acc: 0.4822 - masked_loss: 2.9194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 2.9168 - masked_acc: 0.4824 - masked_loss: 2.9168\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.7758 - masked_acc: 0.5012 - masked_loss: 2.7758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 2.7894 - masked_acc: 0.4968 - masked_loss: 2.7894\n",
            "Epoch 9/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.6405 - masked_acc: 0.5204 - masked_loss: 2.6405"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 2.6523 - masked_acc: 0.5200 - masked_loss: 2.6523\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5685 - masked_acc: 0.5115 - masked_loss: 2.5685"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 2.5685 - masked_acc: 0.5115 - masked_loss: 2.5685\n",
            "Epoch 11/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.3757 - masked_acc: 0.5411 - masked_loss: 2.3757"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 2.3848 - masked_acc: 0.5403 - masked_loss: 2.3848\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.5045 - masked_acc: 0.5263 - masked_loss: 2.5045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 2.5068 - masked_acc: 0.5260 - masked_loss: 2.5068\n",
            "Epoch 13/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.3388 - masked_acc: 0.5181 - masked_loss: 2.3388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 2.3501 - masked_acc: 0.5179 - masked_loss: 2.3501\n",
            "Epoch 14/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.1120 - masked_acc: 0.5380 - masked_loss: 2.1120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 2.1234 - masked_acc: 0.5372 - masked_loss: 2.1234\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1063 - masked_acc: 0.5655 - masked_loss: 2.1063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 2.1063 - masked_acc: 0.5655 - masked_loss: 2.1063\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9685 - masked_acc: 0.5863 - masked_loss: 1.9685"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 1.9685 - masked_acc: 0.5863 - masked_loss: 1.9685\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.7513 - masked_acc: 0.5914 - masked_loss: 1.7513"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 1.7513 - masked_acc: 0.5914 - masked_loss: 1.7513\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.8936 - masked_acc: 0.5739 - masked_loss: 1.8936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 1.8773 - masked_acc: 0.5782 - masked_loss: 1.8773\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5423 - masked_acc: 0.6553 - masked_loss: 1.5423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 1.5423 - masked_acc: 0.6553 - masked_loss: 1.5423\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0752 - masked_acc: 0.7263 - masked_loss: 1.0752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 36ms/step - loss: 1.0752 - masked_acc: 0.7263 - masked_loss: 1.0752\n",
            "Epoch 21/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3380 - masked_acc: 0.6397 - masked_loss: 1.3380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 1.3470 - masked_acc: 0.6419 - masked_loss: 1.3470\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4423 - masked_acc: 0.6518 - masked_loss: 1.4423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 1.4423 - masked_acc: 0.6518 - masked_loss: 1.4423\n",
            "Epoch 23/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.7027 - masked_acc: 0.8396 - masked_loss: 0.7027"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.7031 - masked_acc: 0.8412 - masked_loss: 0.7031\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.9422 - masked_acc: 0.7381 - masked_loss: 0.9422"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.9422 - masked_acc: 0.7381 - masked_loss: 0.9422\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8934 - masked_acc: 0.7357 - masked_loss: 0.8934"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.8934 - masked_acc: 0.7357 - masked_loss: 0.8934\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3957 - masked_acc: 0.9107 - masked_loss: 0.3957"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.3975 - masked_acc: 0.9116 - masked_loss: 0.3975\n",
            "Epoch 27/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3352 - masked_acc: 0.9562 - masked_loss: 0.3352"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.3321 - masked_acc: 0.9567 - masked_loss: 0.3321\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4391 - masked_acc: 0.9000 - masked_loss: 0.4391"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.4378 - masked_acc: 0.9010 - masked_loss: 0.4378\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2607 - masked_acc: 0.9523 - masked_loss: 0.2607"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 38ms/step - loss: 0.2607 - masked_acc: 0.9523 - masked_loss: 0.2607\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1911 - masked_acc: 0.9667 - masked_loss: 0.1911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.1897 - masked_acc: 0.9671 - masked_loss: 0.1897\n",
            "Epoch 31/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2096 - masked_acc: 0.9665 - masked_loss: 0.2096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.2076 - masked_acc: 0.9669 - masked_loss: 0.2076\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1374 - masked_acc: 0.9761 - masked_loss: 0.1374"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1374 - masked_acc: 0.9761 - masked_loss: 0.1374\n",
            "Epoch 33/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2021 - masked_acc: 0.9588 - masked_loss: 0.2021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.2002 - masked_acc: 0.9592 - masked_loss: 0.2002\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2193 - masked_acc: 0.9495 - masked_loss: 0.2193"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.2172 - masked_acc: 0.9500 - masked_loss: 0.2172\n",
            "Epoch 35/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0134 - masked_acc: 1.0000 - masked_loss: 0.0134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0133 - masked_acc: 1.0000 - masked_loss: 0.0133\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2152 - masked_acc: 0.9490 - masked_loss: 0.2152"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.2152 - masked_acc: 0.9490 - masked_loss: 0.2152\n",
            "Epoch 37/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1268 - masked_acc: 0.9710 - masked_loss: 0.1268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1256 - masked_acc: 0.9713 - masked_loss: 0.1256\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1082 - masked_acc: 0.9765 - masked_loss: 0.1082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 37ms/step - loss: 0.1082 - masked_acc: 0.9765 - masked_loss: 0.1082\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1522 - masked_acc: 0.9669 - masked_loss: 0.1522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1522 - masked_acc: 0.9669 - masked_loss: 0.1522\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1873 - masked_acc: 0.9534 - masked_loss: 0.1873"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1873 - masked_acc: 0.9534 - masked_loss: 0.1873\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0823 - masked_acc: 0.9807 - masked_loss: 0.0823"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0823 - masked_acc: 0.9807 - masked_loss: 0.0823\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1722 - masked_acc: 0.9584 - masked_loss: 0.1722"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.1722 - masked_acc: 0.9584 - masked_loss: 0.1722\n",
            "Epoch 43/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1925 - masked_acc: 0.9573 - masked_loss: 0.1925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.1906 - masked_acc: 0.9578 - masked_loss: 0.1906\n",
            "Epoch 44/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0451 - masked_acc: 0.9898 - masked_loss: 0.0451"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0443 - masked_acc: 0.9900 - masked_loss: 0.0443\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1248 - masked_acc: 0.9762 - masked_loss: 0.1248"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.1248 - masked_acc: 0.9762 - masked_loss: 0.1248\n",
            "Epoch 46/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.1251 - masked_acc: 0.9707 - masked_loss: 0.1251"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.1226 - masked_acc: 0.9713 - masked_loss: 0.1226\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1894 - masked_acc: 0.9529 - masked_loss: 0.1894"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 37ms/step - loss: 0.1894 - masked_acc: 0.9529 - masked_loss: 0.1894\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1541 - masked_acc: 0.9631 - masked_loss: 0.1541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1541 - masked_acc: 0.9631 - masked_loss: 0.1541\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1172 - masked_acc: 0.9668 - masked_loss: 0.1172"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1172 - masked_acc: 0.9668 - masked_loss: 0.1172\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1048 - masked_acc: 0.9762 - masked_loss: 0.1048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1048 - masked_acc: 0.9762 - masked_loss: 0.1048\n",
            "Epoch 51/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0659 - masked_acc: 0.9854 - masked_loss: 0.0659"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0653 - masked_acc: 0.9855 - masked_loss: 0.0653\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2037 - masked_acc: 0.9538 - masked_loss: 0.2037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.2037 - masked_acc: 0.9538 - masked_loss: 0.2037\n",
            "Epoch 53/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.1314 - masked_acc: 0.9658 - masked_loss: 0.1314"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.1288 - masked_acc: 0.9665 - masked_loss: 0.1288\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0437 - masked_acc: 0.9899 - masked_loss: 0.0437"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0433 - masked_acc: 0.9900 - masked_loss: 0.0433\n",
            "Epoch 55/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.1425 - masked_acc: 0.9668 - masked_loss: 0.1425"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.1580 - masked_acc: 0.9625 - masked_loss: 0.1580\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2139 - masked_acc: 0.9491 - masked_loss: 0.2139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 38ms/step - loss: 0.2139 - masked_acc: 0.9491 - masked_loss: 0.2139\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0240 - masked_acc: 0.9950 - masked_loss: 0.0240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0240 - masked_acc: 0.9950 - masked_loss: 0.0240\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2338 - masked_acc: 0.9430 - masked_loss: 0.2338"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.2315 - masked_acc: 0.9436 - masked_loss: 0.2315\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1364 - masked_acc: 0.9672 - masked_loss: 0.1364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1364 - masked_acc: 0.9672 - masked_loss: 0.1364\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0031 - masked_acc: 1.0000 - masked_loss: 0.0031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0031 - masked_acc: 1.0000 - masked_loss: 0.0031\n",
            "Epoch 61/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1112 - masked_acc: 0.9714 - masked_loss: 0.1112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.1101 - masked_acc: 0.9717 - masked_loss: 0.1101\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2126 - masked_acc: 0.9484 - masked_loss: 0.2126"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.2126 - masked_acc: 0.9484 - masked_loss: 0.2126\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0699 - masked_acc: 0.9808 - masked_loss: 0.0699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0699 - masked_acc: 0.9808 - masked_loss: 0.0699\n",
            "Epoch 64/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.2045 - masked_acc: 0.9521 - masked_loss: 0.2045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.2005 - masked_acc: 0.9531 - masked_loss: 0.2005\n",
            "Epoch 65/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2162 - masked_acc: 0.9596 - masked_loss: 0.2162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 37ms/step - loss: 0.2333 - masked_acc: 0.9550 - masked_loss: 0.2333\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.1479 - masked_acc: 0.6888 - masked_loss: 1.1479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 1.1460 - masked_acc: 0.6869 - masked_loss: 1.1460\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8348 - masked_acc: 0.7620 - masked_loss: 0.8348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.8348 - masked_acc: 0.7620 - masked_loss: 0.8348\n",
            "Epoch 68/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.6385 - masked_acc: 0.8079 - masked_loss: 0.6385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.6303 - masked_acc: 0.8117 - masked_loss: 0.6303\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6250 - masked_acc: 0.8065 - masked_loss: 0.6250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 36ms/step - loss: 0.6250 - masked_acc: 0.8065 - masked_loss: 0.6250\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4603 - masked_acc: 0.8753 - masked_loss: 0.4603"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.4559 - masked_acc: 0.8766 - masked_loss: 0.4559\n",
            "Epoch 71/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3432 - masked_acc: 0.9005 - masked_loss: 0.3432"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.3437 - masked_acc: 0.9015 - masked_loss: 0.3437\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4481 - masked_acc: 0.9022 - masked_loss: 0.4481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.4481 - masked_acc: 0.9022 - masked_loss: 0.4481\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3462 - masked_acc: 0.9246 - masked_loss: 0.3462"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.3462 - masked_acc: 0.9246 - masked_loss: 0.3462\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0592 - masked_acc: 0.9800 - masked_loss: 0.0592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0592 - masked_acc: 0.9800 - masked_loss: 0.0592\n",
            "Epoch 75/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1053 - masked_acc: 0.9757 - masked_loss: 0.1053"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.1043 - masked_acc: 0.9759 - masked_loss: 0.1043\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1192 - masked_acc: 0.9726 - masked_loss: 0.1192"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1192 - masked_acc: 0.9726 - masked_loss: 0.1192\n",
            "Epoch 77/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0814 - masked_acc: 0.9808 - masked_loss: 0.0814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0806 - masked_acc: 0.9810 - masked_loss: 0.0806\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1384 - masked_acc: 0.9678 - masked_loss: 0.1384"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 37ms/step - loss: 0.1384 - masked_acc: 0.9678 - masked_loss: 0.1384\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0994 - masked_acc: 0.9764 - masked_loss: 0.0994"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0994 - masked_acc: 0.9764 - masked_loss: 0.0994\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1176 - masked_acc: 0.9711 - masked_loss: 0.1176"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1176 - masked_acc: 0.9711 - masked_loss: 0.1176\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1815 - masked_acc: 0.9534 - masked_loss: 0.1815"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1815 - masked_acc: 0.9534 - masked_loss: 0.1815\n",
            "Epoch 82/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0971 - masked_acc: 0.9765 - masked_loss: 0.0971"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.0961 - masked_acc: 0.9767 - masked_loss: 0.0961\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2566 - masked_acc: 0.9300 - masked_loss: 0.2566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 0.2566 - masked_acc: 0.9300 - masked_loss: 0.2566\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0985 - masked_acc: 0.9712 - masked_loss: 0.0985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0975 - masked_acc: 0.9715 - masked_loss: 0.0975\n",
            "Epoch 85/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0924 - masked_acc: 0.9716 - masked_loss: 0.0924"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0906 - masked_acc: 0.9722 - masked_loss: 0.0906\n",
            "Epoch 86/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1474 - masked_acc: 0.9519 - masked_loss: 0.1474"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1460 - masked_acc: 0.9524 - masked_loss: 0.1460\n",
            "Epoch 87/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0476 - masked_acc: 0.9906 - masked_loss: 0.0476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 37ms/step - loss: 0.0466 - masked_acc: 0.9908 - masked_loss: 0.0466\n",
            "Epoch 88/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0814 - masked_acc: 0.9813 - masked_loss: 0.0814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0806 - masked_acc: 0.9814 - masked_loss: 0.0806\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1405 - masked_acc: 0.9671 - masked_loss: 0.1405"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1405 - masked_acc: 0.9671 - masked_loss: 0.1405\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0857 - masked_acc: 0.9764 - masked_loss: 0.0857"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0857 - masked_acc: 0.9764 - masked_loss: 0.0857\n",
            "Epoch 91/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1530 - masked_acc: 0.9571 - masked_loss: 0.1530"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.1515 - masked_acc: 0.9576 - masked_loss: 0.1515\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2096 - masked_acc: 0.9441 - masked_loss: 0.2096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.2096 - masked_acc: 0.9441 - masked_loss: 0.2096\n",
            "Epoch 93/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0389 - masked_acc: 0.9907 - masked_loss: 0.0389"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0385 - masked_acc: 0.9908 - masked_loss: 0.0385\n",
            "Epoch 94/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.1162 - masked_acc: 0.9707 - masked_loss: 0.1162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.1139 - masked_acc: 0.9713 - masked_loss: 0.1139\n",
            "Epoch 95/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0768 - masked_acc: 0.9815 - masked_loss: 0.0768"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0758 - masked_acc: 0.9819 - masked_loss: 0.0758\n",
            "Epoch 96/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1254 - masked_acc: 0.9673 - masked_loss: 0.1254"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 38ms/step - loss: 0.1241 - masked_acc: 0.9677 - masked_loss: 0.1241\n",
            "Epoch 97/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0665 - masked_acc: 0.9809 - masked_loss: 0.0665"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0658 - masked_acc: 0.9811 - masked_loss: 0.0658\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1552 - masked_acc: 0.9629 - masked_loss: 0.1552"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.1552 - masked_acc: 0.9629 - masked_loss: 0.1552\n",
            "Epoch 99/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1706 - masked_acc: 0.9530 - masked_loss: 0.1706"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.1689 - masked_acc: 0.9535 - masked_loss: 0.1689\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1087 - masked_acc: 0.9668 - masked_loss: 0.1087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.1087 - masked_acc: 0.9668 - masked_loss: 0.1087\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 60,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "ad41509a-cddd-49a1-c4a4-64341a5b2097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f21b015f640>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "8a09b826-659b-45f4-f411-0f3203e53939"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f21b01115e0>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('Bank.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "a48ed06d-a1ef-4090-99f3-747f8c030909"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_REGULAR  OM_PREDICTION\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2912272-0a9b-4ae4-91b7-08c80f23c06c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_REGULAR</th>\n",
              "      <th>OM_PREDICTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2912272-0a9b-4ae4-91b7-08c80f23c06c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2912272-0a9b-4ae4-91b7-08c80f23c06c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2912272-0a9b-4ae4-91b7-08c80f23c06c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_REGULAR'].values\n",
        "y_test2 = dc['OM_PREDICTION'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "c1289a6c-08f1-4903-8fe5-51e52da6ffe1"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31,)\n",
            "(31,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "711ee56f-8912-426a-a433-d91809646c56"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #%%time\n",
        " #for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "# print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('Bank_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "32ed3d20-383c-411f-cb1a-b17108464b0a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_REGULAR  OM_PREDICTION\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9212d65-7fad-4401-8905-56bbccc41df0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_REGULAR</th>\n",
              "      <th>OM_PREDICTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9212d65-7fad-4401-8905-56bbccc41df0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9212d65-7fad-4401-8905-56bbccc41df0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9212d65-7fad-4401-8905-56bbccc41df0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_REGULAR'].values\n",
        "y_test_pred2 = dd['OM_PREDICTION'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "8c2e79c0-ca97-4809-f4ca-78bb56db6a3f"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "317b437f-26c3-442c-ca7f-97ee70351985"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.500000\n",
            "Testing: Recall = 0.111111\n",
            "Testing: F1 Score = 0.181818\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[21  1]\n",
            " [ 8  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "44461297-0a90-490c-cfc0-296dca6993c7"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.95      0.82        22\n",
            "           1       0.50      0.11      0.18         9\n",
            "\n",
            "    accuracy                           0.71        31\n",
            "   macro avg       0.61      0.53      0.50        31\n",
            "weighted avg       0.66      0.71      0.64        31\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}