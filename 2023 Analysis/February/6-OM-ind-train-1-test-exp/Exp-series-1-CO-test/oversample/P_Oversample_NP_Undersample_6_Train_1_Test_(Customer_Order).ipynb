{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJnMTPsgYlc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "[link text](https://)  \n",
        "#Experiment with P Oversample , NP Undersample\n",
        "###6 OM - Dataset , Camping, Bank,  Library Management, Decider, OnlineStore, E-Commerce\n",
        "###1 OM - Testing - Customer-Order\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 337\n",
        "\n",
        "### P samples - 209\n",
        "### NP samples - 128 \n",
        "\n",
        "## Testing\n",
        "\n",
        "### Total instances - 8\n",
        "\n",
        "### P samples - 6\n",
        "### NP samples - 2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "# !pip install \"tensorflow-text>=2.10\"\n",
        "# !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('6-OM-CO-test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Dat from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "acaaa864-7710-4898-9fd8-17a32eaa1c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8787fe77-e764-463b-b35b-4268df2ef434\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8787fe77-e764-463b-b35b-4268df2ef434')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8787fe77-e764-463b-b35b-4268df2ef434 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8787fe77-e764-463b-b35b-4268df2ef434');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d6926e-e8c1-41de-827e-7ca18fd4e4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "d0549795-ea74-48d6-e3ca-ef50fa34d5ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 91, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "a373635e-f733-4e3b-e07e-921e3dcee5ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "91667408-c311-4a5c-abf4-bfa781eef0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 48  3]\n",
            "\n",
            "[ 2 48]\n",
            "[48  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "bde353ee-4295-4edb-dba4-3363482dd2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "dc861080-6c14-49ea-8dda-39ae7c784d79"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "9459e399-1d3e-46c8-bb20-de69825854e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "775843bc-6a9e-4196-b257-63b6e85bff67"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAATxUlEQVR4nO3cf7RdZX3n8fenCRBBwFHUYhINUyljWgUxg3ScDozimsDMInb6Y8HYFi01dVq6bHXaYmupxU5bO7Nq6wwzTGZJGZkBStF2xTZt1ClCrYIEf1BDBnulaBJFIBCBWiHB7/yxd/TkeuM9udnn3tzH92utu9bZez93n++++d7PffKcs0+qCklSW75joQuQJA3PcJekBhnuktQgw12SGmS4S1KDDHdJapDhPo+SXJnkVxe6jpkk+f4kd4859uwkOyZdkwSQ5ENJfnKh61hsmg/3vjEeTnLUtP33JjlnZHtVkkqydKDnfU2SD4/uq6rXV9Xbhjj/0Krqr6rqlCHOleTqJL8xxLm0OPS/T08kOWHa/k/0v1erFqi0b1tNh3vfUN8PFHD+wlYjNe/vgAv3bSR5IXD0wpXz7a3pcAd+HLgVuBq4aN/OJNcAzwXel+SxJL8I3NIf3t3v+75+7E8k2dbP/jcned7IeSrJ65P8bZLdSa5I5wXAlcD39efa3Y/fb0ab5HVJppI8lGRjkufMdu7pF5hkWZJ/2DdjSvIrSfYmOa7ffluS3+sfH5XkPyf5fJIv9ctET+mP7bfUkuT0ftb1aJI/SvKH02fjSd6U5P4kX0zy2n7feuDVwC/21/6+fv8vJdnZn+/uJK8Y/59Ri8Q1dL9z+1wEvHvfRpJ/3ffUI0m2J3nryLFlSf53kl19v9+e5NnTnyDJiUnuTPILk7yQJlRVs1/AFPDTwEuAPcCzR47dC5wzsr2Kboa/dGTfuv4cLwCWAm8BPjJyvIA/BZ5G98fiAWBtf+w1wIen1XM18Bv945cDDwKnA0cB/wW4ZZxzz3CdtwA/2D9+P/BZ4NyRYz/QP34HsBF4OnAs8D7gt/pjZwM7+sdHAp8D3gAcAfxb4ImR2s8G9gKX98fPA74C/KPp19lvnwJsB54z8rP+roXuD78G/V27FzgHuLv/fVkC7ACe1/fyqr5vXkg3qXwR8CXgVf33/1Tfj0f33/sS4Lj+2IeAnwROAj4DrF/o610MX83O3JP8c7rGuqGq7qALvH93kKd5PV34bauqvcBvAqeNzt6B366q3VX1eeAm4LQxz/1q4Kqq+nhVPQ68mW6mv2oO574ZOKt/veBFwDv77WXAPwVu6Wf964Gfr6qHqurR/noumOF8Z9L9MXtnVe2pqvcCH5s2Zg9weX98E/AYXYjP5Em6P2CrkxxRVfdW1WcP9IPRorZv9v5KYBuwc9+BqvpQVf1NVX2tqu4ErgPO6g/vAZ4BPL+qnqyqO6rqkZHzrqb7Hfi1qtowHxey2DUb7nT/JXx/VT3Yb1/LyNLMmJ4H/H7/38TdwENAgOUjY+4befwV4Kljnvs5dLNjAKrqMWDXHM99M92s6HTgb4AP0P3SnAlMVdUu4Jl0s6I7Rq7nL/r9M9W2s/ppU2/7tDG7+j94s9ZXVVPAzwFvBe5Pcv3oEpSacg3dJOo1jCzJACR5aZKbkjyQ5Mt0k6cTRr5vM3B9ki8k+Z0kR4x8+6vp/lDcOOkLaEWT4d6vI/8I3ez1viT3AT8PnJrk1H7Y9I/DnOnjMbcDP1VVTxv5ekpVfWSMMmb7uM0v0P3x2FfzMXQzl50H/I4D+wjdrPkHgJur6i66pZzz6IIfuiWgfwC+Z+Rajq+qmQL5i8DyaWv8Kw+inm+69qq6tqr2/W+qgLcfxPm0SFTV5+heWD0PeO+0w9fSLQuurKrj6V6XSv99e6rq16tqNfDPgH/D/uv3b6Xr4WuTLJnoRTSiyXAHXkW3FLCabinjNLp1wL/iGw3zJeAfj3zPA8DXpu27Enhzku8BSHJ8kh8es4YvASuSHHmA49cBr01yWrq3af4mcFtV3Tvm+b+uqr4C3AH8DN8I84/QzYxu7sd8DfifwDuSPKu/nuVJ/tUMp/wo3c/vkiRLk6wDzjiIkvb72SY5JcnL++v8Kt0fma8dxPm0uFwMvLyq/n7a/mOBh6rqq0nOYGSZNMm/TPLCPrgfoVumGe2RPcAPA8cA707SanYNptUf0EXAH1TV56vqvn1fwH8FXt2vTf8W8JZ+ieI/9AH5H4G/7vedWVV/TDfDvD7JI8CngXPHrOEvga3AfUkenH6wqj4I/CrwHrqZ8ncx8/r3uG6me3HzYyPbx/KNdwEB/BLdC8S39tfzQWZYJ6+qJ+heRL0Y2A38KN2Lu4+PWcu76NbXdyf5E7r19t+mm3ndBzyL7jUGNaiqPltVW2Y49NPA5UkeBS4Dbhg59p10Sy6P0K3V30y3VDN63n19+WzgKgP+W8v+y6rSzJLcBlxZVX+w0LVImp1/+TSjJGcl+c5+WeYiunfh/MVC1yVpPLOGe5Kr+htVPn2A40nyznQ349yZ5PThy9QCOAX4FN2yzJuAH6qqLy5oRQOzt9WycWbuVwNrv8Xxc4GT+6/1wH8/9LK00KpqQ1U9u6qeWlUvqqo/W+iaJuBq7G01atZwr6pb6N7ffSDrgHdX51bgaUlOHKpAaVLsbbVsiE9AXM7+N7js6Pd903/h+88dWQ9wzNF5yT95/oHeJbi4fHrXTPcBLU5H7pz+7rXF6VEefrCqDvUfZk69vYQlLzma4w7xqaWZjdvbg3y87bj624Y3AKw5dVl9bPNz5/PpJ+aUq//9QpcwmFW/PM79WYe/D9aNn5t91HBGe/u4PL1e6ueiaULG7e0h3i2zk/3vXlzB3O6ylA439rYWrSHCfSPw4/07C84Evtzauyr0bcve1qI167JMkuvoPpTqhHSf9/1rdHdCUlVXApvoPkdiiu7Do147qWKlIdnbatms4V5VF85yvOg+00RaVOxttcw7VCWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAaNFe5J1ia5O8lUkktnOP7cJDcl+USSO5OcN3yp0vDsbbVq1nBPsgS4AjgXWA1cmGT1tGFvAW6oqhcDFwD/behCpaHZ22rZODP3M4Cpqrqnqp4ArgfWTRtTwHH94+OBLwxXojQx9raatXSMMcuB7SPbO4CXThvzVuD9SX4WOAY4Z6YTJVkPrAd47vJxnlqaqIn09jKOHrxQ6WAN9YLqhcDVVbUCOA+4Jsk3nbuqNlTVmqpa88xnLBnoqaWJOujePoKj5r1Iabpxwn0nsHJke0W/b9TFwA0AVfVRYBlwwhAFShNkb6tZ44T77cDJSU5KciTdi0obp435PPAKgCQvoPsFeGDIQqUJsLfVrFnDvar2ApcAm4FtdO8c2Jrk8iTn98PeBLwuyaeA64DXVFVNqmhpCPa2WjbWq5pVtQnYNG3fZSOP7wJeNmxp0uTZ22qVd6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatBY4Z5kbZK7k0wlufQAY34kyV1Jtia5dtgypeHZ12rZ0tkGJFkCXAG8EtgB3J5kY1XdNTLmZODNwMuq6uEkz5pUwdIQ7Gu1bpyZ+xnAVFXdU1VPANcD66aNeR1wRVU9DFBV9w9bpjQ4+1pNGyfclwPbR7Z39PtGfTfw3Un+OsmtSdbOdKIk65NsSbLlgV1Pzq1iaRiD9TXs39t7eHwC5UoHZ9ZlmYM4z8nA2cAK4JYkL6yq3aODqmoDsAFgzanLaqDnliZlrL6G/Xv7uDzd3taCG2fmvhNYObK9ot83agewsar2VNXfAZ+h+6WQDlf2tZo2TrjfDpyc5KQkRwIXABunjfkTutkNSU6g++/sPcOVKQ3OvlbTZg33qtoLXAJsBrYBN1TV1iSXJzm/H7YZ2JXkLuAm4BeqatekipYOlX2t1o215l5Vm4BN0/ZdNvK4gDf2X9KiYF+rZd6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWiscE+yNsndSaaSXPotxv1gkkqyZrgSpcmxt9WqWcM9yRLgCuBcYDVwYZLVM4w7FngDcNvQRUqTYG+rZePM3M8Apqrqnqp6ArgeWDfDuLcBbwe+OmB90iTZ22rWOOG+HNg+sr2j3/d1SU4HVlbVn32rEyVZn2RLki0P7HryoIuVBjaR3t7D48NXKh2kQ35BNcl3AL8LvGm2sVW1oarWVNWaZz5jyaE+tTRRc+3tIzhq8sVJsxgn3HcCK0e2V/T79jkW+F7gQ0nuBc4ENvrCkxYBe1vNGifcbwdOTnJSkiOBC4CN+w5W1Zer6oSqWlVVq4BbgfOrastEKpaGY2+rWbOGe1XtBS4BNgPbgBuqamuSy5OcP+kCpUmxt9WypeMMqqpNwKZp+y47wNizD70saX7Y22qVd6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatBY4Z5kbZK7k0wluXSG429McleSO5P83yTPG75UaVj2tVo2a7gnWQJcAZwLrAYuTLJ62rBPAGuq6kXAjcDvDF2oNCT7Wq0bZ+Z+BjBVVfdU1RPA9cC60QFVdVNVfaXfvBVYMWyZ0uDsazVtnHBfDmwf2d7R7zuQi4E/n+lAkvVJtiTZ8sCuJ8evUhreYH0N+/f2Hh4fqERp7pYOebIkPwqsAc6a6XhVbQA2AKw5dVkN+dzSpMzW17B/bx+Xp9vbWnDjhPtOYOXI9op+336SnAP8CnBWVTl10eHOvlbTxlmWuR04OclJSY4ELgA2jg5I8mLgfwDnV9X9w5cpDc6+VtNmDfeq2gtcAmwGtgE3VNXWJJcnOb8f9p+ApwJ/lOSTSTYe4HTSYcG+VuvGWnOvqk3Apmn7Lht5fM7AdUkTZ1+rZd6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWiscE+yNsndSaaSXDrD8aOS/GF//LYkqwavVJoAe1utmjXckywBrgDOBVYDFyZZPW3YxcDDVfV84B3A24cuVBqava2WjTNzPwOYqqp7quoJ4Hpg3bQx64D/1T++EXhFkgxXpjQR9raatXSMMcuB7SPbO4CXHmhMVe1N8mXgGcCDo4OSrAfW95uPLznxbz89l6IPP288gWnXulhNQSvXcsoYYybW2x+sG1vo7VZ6Adq6lnF6e6xwH0xVbQA2ACTZUlVr5vP5J8VrOfwk2TKfz9dib7dyHdDetYwzbpxlmZ3AypHtFf2+GcckWQocD+wapwBpAdnbatY44X47cHKSk5IcCVwAbJw2ZiNwUf/4h4C/rKoarkxpIuxtNWvWZZl+nfESYDOwBLiqqrYmuRzYUlUbgXcB1ySZAh6i+yWZzYZDqPtw47Ucfma9Dnt7Vq1cB3wbXkuchEhSe7xDVZIaZLhLUoMWJNxnu+V7sUhyVZL7kyzq9zQnWZnkpiR3Jdma5A0LXdNcJVmW5GNJPtVfy6/P43Pb14eZVnp7Ln0972vu/S3fnwFeSXfTyO3AhVV117wWMoAk/wJ4DHh3VX3vQtczV0lOBE6sqo8nORa4A3jVIv03CXBMVT2W5Ajgw8AbqurWCT+vfX0YaqW359LXCzFzH+eW70Whqm6hewfFolZVX6yqj/ePHwW20d2ZuehU57F+84j+az5mMPb1YaiV3p5LXy9EuM90y/ei+2G3qv/UwxcDty1wKXOWZEmSTwL3Ax+oqvm4Fvv6MLfYe/tg+9oXVPV1SZ4KvAf4uap6ZKHrmauqerKqTqO74/SMJIt6aUGHroXePti+XohwH+eWb82zfh3vPcD/qar3LnQ9Q6iq3cBNwNp5eDr7+jDVWm+P29cLEe7j3PKtedS/WPMuYFtV/e5C13MokjwzydP6x0+he4Hz/83DU9vXh6FWensufT3v4V5Ve4F9t3xvA26oqq3zXccQklwHfBQ4JcmOJBcvdE1z9DLgx4CXJ/lk/3XeQhc1RycCNyW5ky5wP1BVfzrpJ7WvD1ut9PZB97UfPyBJDfIFVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGvT/AWQDpfj/B/VFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "76934d8b-3cf0-404a-e0d3-c30aab62de21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 198)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# # Setup the loop variables.\n",
        "# next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "# tokens = []\n",
        "\n",
        "# for n in range(10):\n",
        "#   # Run one step.\n",
        "#   next_token, done, state = decoder.get_next_token(\n",
        "#       ex_context, next_token, done, state, temperature=1.0)\n",
        "#   # Add the token to the output.\n",
        "#   tokens.append(next_token)\n",
        "\n",
        "# # Stack all the tokens together.\n",
        "# tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# # Convert the tokens back to a a string\n",
        "# result = decoder.tokens_to_text(tokens)\n",
        "# result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "8b12b7ab-a296-4c0d-f402-f41fd819331c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 198)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "fde14697-08b0-47a9-ac0e-082a3d0d433b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.288267, 'expected_acc': 0.005050505050505051}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "d65a12cc-b334-4f17-bf95-55ae56c41e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 2s 27ms/step - loss: 3.5075 - masked_acc: 0.5286 - masked_loss: 3.5075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 3.507453203201294,\n",
              " 'masked_acc': 0.5285714268684387,\n",
              " 'masked_loss': 3.507453203201294}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "79cd2685-44e1-45eb-bb13-03781ea0b34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.1505 - masked_acc: 0.9650 - masked_loss: 0.1505 - val_loss: 3.8504 - val_masked_acc: 0.6800 - val_masked_loss: 3.8504\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 0.2623 - masked_acc: 0.9300 - masked_loss: 0.2623 - val_loss: 3.9891 - val_masked_acc: 0.7100 - val_masked_loss: 3.9891\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.2997 - masked_acc: 0.9250 - masked_loss: 0.2997 - val_loss: 4.3361 - val_masked_acc: 0.7000 - val_masked_loss: 4.3361\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.1560 - masked_acc: 0.9750 - masked_loss: 0.1560 - val_loss: 4.8389 - val_masked_acc: 0.6700 - val_masked_loss: 4.8389\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.2128 - masked_acc: 0.9500 - masked_loss: 0.2128 - val_loss: 4.1220 - val_masked_acc: 0.7200 - val_masked_loss: 4.1220\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.1178 - masked_acc: 0.9800 - masked_loss: 0.1178 - val_loss: 4.4519 - val_masked_acc: 0.7000 - val_masked_loss: 4.4519\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.1359 - masked_acc: 0.9750 - masked_loss: 0.1359 - val_loss: 4.5281 - val_masked_acc: 0.7000 - val_masked_loss: 4.5281\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 5s 45ms/step - loss: 0.1515 - masked_acc: 0.9750 - masked_loss: 0.1515 - val_loss: 5.0488 - val_masked_acc: 0.6900 - val_masked_loss: 5.0488\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0991 - masked_acc: 0.9900 - masked_loss: 0.0991 - val_loss: 4.7902 - val_masked_acc: 0.6900 - val_masked_loss: 4.7902\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 50,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "56c9c96f-7f28-41b7-dafc-658c66f63b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa221fdd1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KkhXRASNG80_",
        "outputId": "79c7f1bd-aabe-4d98-8003-599481a95dbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa221f90940>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('co.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "8954a73c-fd6c-4442-d717-cc437b1c8259"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  module OM_name one sig class1_name extends Cla...              1\n",
              "1  module OM_name one sig class1_name extends Cla...              1\n",
              "2  module OM_name one sig class1_name extends Cla...              1\n",
              "3  module OM_name one sig class1_name extends Cla...              1\n",
              "4  module OM_name one sig class1_name extends Cla...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ac08990-4194-4760-ae14-9c2e7c33db13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ac08990-4194-4760-ae14-9c2e7c33db13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ac08990-4194-4760-ae14-9c2e7c33db13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ac08990-4194-4760-ae14-9c2e7c33db13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "e2a97b55-0dba-41c6-f4b6-bf5a9b69d0cf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8,)\n",
            "(8,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "99273f5a-0bc6-49f4-e0dd-0a79f3ce52a5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "# print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('co_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "c04be8f3-f654-405a-b62f-6f82ca762cbc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  module OM_name one sig class1_name extends Cla...              1\n",
              "1  module OM_name one sig class1_name extends Cla...              1\n",
              "2  module OM_name one sig class1_name extends Cla...              1\n",
              "3  module OM_name one sig class1_name extends Cla...              1\n",
              "4  module OM_name one sig class1_name extends Cla...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c60c158-126d-4d22-aa21-04dd2a10255f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name one sig class1_name extends Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c60c158-126d-4d22-aa21-04dd2a10255f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c60c158-126d-4d22-aa21-04dd2a10255f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c60c158-126d-4d22-aa21-04dd2a10255f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "850a25a3-defb-4fd3-d573-04ce72c31780"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "30dd3a0b-7986-45cf-8420-8150e8f32fe3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.750000\n",
            "Testing: Recall = 1.000000\n",
            "Testing: F1 Score = 0.857143\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[0 2]\n",
            " [0 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "7595e056-9131-4150-d28b-cb97336f2800"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}