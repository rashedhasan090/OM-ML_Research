{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJnMTPsgYlc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP Oversample\n",
        "###6 OM - Dataset , Camping,OnlineStore,  Library Management, Bank, Customer_order, E-Commerce\n",
        "###1 OM - Testing - Decider\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 376\n",
        "\n",
        "### P samples - 248\n",
        "### NP samples - 128\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 80\n",
        "\n",
        "### P samples - 12\n",
        "### NP samples - 68\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('6-OM-decider-test2.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "8d30920b-29d6-4f4e-b978-45d3bfc1fbae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79a27c96-b768-46b3-a607-9d7f07f1e212\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79a27c96-b768-46b3-a607-9d7f07f1e212')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79a27c96-b768-46b3-a607-9d7f07f1e212 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79a27c96-b768-46b3-a607-9d7f07f1e212');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "9e7db8e2-66d0-424e-b485-918dd4c631fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 67, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "0146fa50-c718-4747-94f5-9e3b23cf4fea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "be38536f-9022-4500-ebbb-ab2f5d75b60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 61  3]\n",
            "\n",
            "[ 2 63]\n",
            "[63  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "527dbac7-fe3f-4e0d-acc8-12f3fad6f8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "a5947d93-0854-4e66-b34b-d0076b47c146"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "fd436df7-b7d1-49d9-885d-2a48bb8c0b08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.       , 1.0000001], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "21f3b7ba-8a29-417d-c3a8-ed95e1dd8305"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "78c4f8b7-eec9-40e0-eb1a-174376de66a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 239)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "e6fb5e11-1303-4b19-d4e7-33addc21cc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 239)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "e6b37d30-30cb-44ae-db3c-877caab50a0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.4764633, 'expected_acc': 0.0041841004184100415}"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "d03e33a9-8b52-49e1-d935-ac583069c238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 1s 10ms/step - loss: 3.0465 - masked_acc: 0.5357 - masked_loss: 3.0465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 3.0464515686035156,\n",
              " 'masked_acc': 0.5357142686843872,\n",
              " 'masked_loss': 3.0464515686035156}"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "2c1182f1-1ecf-4625-815f-51b6094ded92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 1.9251 - masked_acc: 0.5550 - masked_loss: 1.9251 - val_loss: 2.9921 - val_masked_acc: 0.5357 - val_masked_loss: 2.9921\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 2.0143 - masked_acc: 0.5600 - masked_loss: 2.0143 - val_loss: 3.0368 - val_masked_acc: 0.5214 - val_masked_loss: 3.0368\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 2.0013 - masked_acc: 0.5700 - masked_loss: 2.0013 - val_loss: 3.1259 - val_masked_acc: 0.5214 - val_masked_loss: 3.1259\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 1.6470 - masked_acc: 0.5750 - masked_loss: 1.6470 - val_loss: 3.2306 - val_masked_acc: 0.5500 - val_masked_loss: 3.2306\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 1.6334 - masked_acc: 0.5850 - masked_loss: 1.6334 - val_loss: 3.1327 - val_masked_acc: 0.5286 - val_masked_loss: 3.1327\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 1.6709 - masked_acc: 0.6100 - masked_loss: 1.6709 - val_loss: 2.9257 - val_masked_acc: 0.5571 - val_masked_loss: 2.9257\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 1.3272 - masked_acc: 0.6700 - masked_loss: 1.3272 - val_loss: 3.0739 - val_masked_acc: 0.5714 - val_masked_loss: 3.0739\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 1.3193 - masked_acc: 0.6450 - masked_loss: 1.3193 - val_loss: 3.0601 - val_masked_acc: 0.6143 - val_masked_loss: 3.0601\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 1.3144 - masked_acc: 0.6750 - masked_loss: 1.3144 - val_loss: 2.9595 - val_masked_acc: 0.6429 - val_masked_loss: 2.9595\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.7817 - masked_acc: 0.7800 - masked_loss: 0.7817 - val_loss: 2.6381 - val_masked_acc: 0.6429 - val_masked_loss: 2.6381\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.9457 - masked_acc: 0.7450 - masked_loss: 0.9457 - val_loss: 2.8543 - val_masked_acc: 0.6643 - val_masked_loss: 2.8543\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 1.0296 - masked_acc: 0.7100 - masked_loss: 1.0296 - val_loss: 2.7753 - val_masked_acc: 0.6929 - val_masked_loss: 2.7753\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.4039 - masked_acc: 0.9250 - masked_loss: 0.4039 - val_loss: 2.9209 - val_masked_acc: 0.6857 - val_masked_loss: 2.9209\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.5841 - masked_acc: 0.8350 - masked_loss: 0.5841 - val_loss: 2.9484 - val_masked_acc: 0.7071 - val_masked_loss: 2.9484\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.5661 - masked_acc: 0.8650 - masked_loss: 0.5661 - val_loss: 2.5700 - val_masked_acc: 0.7643 - val_masked_loss: 2.5700\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.1929 - masked_acc: 0.9850 - masked_loss: 0.1929 - val_loss: 2.4496 - val_masked_acc: 0.7714 - val_masked_loss: 2.4496\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.1898 - masked_acc: 0.9800 - masked_loss: 0.1898 - val_loss: 2.4172 - val_masked_acc: 0.7786 - val_masked_loss: 2.4172\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.2480 - masked_acc: 0.9850 - masked_loss: 0.2480 - val_loss: 2.2742 - val_masked_acc: 0.7786 - val_masked_loss: 2.2742\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.0586 - masked_acc: 1.0000 - masked_loss: 0.0586 - val_loss: 2.4103 - val_masked_acc: 0.7786 - val_masked_loss: 2.4103\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.0566 - masked_acc: 0.9950 - masked_loss: 0.0566 - val_loss: 2.5564 - val_masked_acc: 0.7786 - val_masked_loss: 2.5564\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0863 - masked_acc: 0.9950 - masked_loss: 0.0863 - val_loss: 2.4236 - val_masked_acc: 0.7857 - val_masked_loss: 2.4236\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 3s 35ms/step - loss: 0.0234 - masked_acc: 1.0000 - masked_loss: 0.0234 - val_loss: 2.4984 - val_masked_acc: 0.7857 - val_masked_loss: 2.4984\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.0497 - masked_acc: 0.9950 - masked_loss: 0.0497 - val_loss: 2.4608 - val_masked_acc: 0.7786 - val_masked_loss: 2.4608\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0207 - masked_acc: 1.0000 - masked_loss: 0.0207 - val_loss: 2.5190 - val_masked_acc: 0.7786 - val_masked_loss: 2.5190\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0132 - masked_acc: 1.0000 - masked_loss: 0.0132 - val_loss: 2.5187 - val_masked_acc: 0.7786 - val_masked_loss: 2.5187\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.0122 - masked_acc: 1.0000 - masked_loss: 0.0122 - val_loss: 2.5384 - val_masked_acc: 0.7786 - val_masked_loss: 2.5384\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "025a77d4-575a-4168-a745-52dec1cea030"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbdc04a29a0>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "0d3a1bfa-cb65-48d0-cb21-82042756f518"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbdc2cd2550>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('decider.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "ec43fe15-8b67-47f6-e8a4-9edad7233d50"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b97ca644-c701-4c7a-a035-876c6209509f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b97ca644-c701-4c7a-a035-876c6209509f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b97ca644-c701-4c7a-a035-876c6209509f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b97ca644-c701-4c7a-a035-876c6209509f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "8c724408-2c27-4625-8c90-ca3a6acec9f1"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80,)\n",
            "(80,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "8a5694cc-391f-46e8-caf1-98a166f33dcf"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('decider_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "a23992b7-c50d-4699-cd57-efef42845d0e"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "1  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "2  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "3  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "4  moduleom_name:0,opendeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d842f0a-0447-4209-bba1-8dda39cf1147\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d842f0a-0447-4209-bba1-8dda39cf1147')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d842f0a-0447-4209-bba1-8dda39cf1147 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d842f0a-0447-4209-bba1-8dda39cf1147');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "d7709a16-77fc-45b6-ec2d-264acc7d0377"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "2f2f3d44-a038-4c5d-9f44-92b539466591"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.175439\n",
            "Testing: Recall = 0.833333\n",
            "Testing: F1 Score = 0.289855\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[21 47]\n",
            " [ 2 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "c1ea0e75-d991-4bd5-9b5a-1624ac411e96"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.31      0.46        68\n",
            "           1       0.18      0.83      0.29        12\n",
            "\n",
            "    accuracy                           0.39        80\n",
            "   macro avg       0.54      0.57      0.38        80\n",
            "weighted avg       0.80      0.39      0.44        80\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}