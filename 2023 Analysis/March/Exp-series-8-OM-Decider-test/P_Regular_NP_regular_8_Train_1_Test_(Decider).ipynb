{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJnMTPsgYlc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Regular , NP Regular \n",
        "###8 OM - Dataset , Camping,OnlineStore,  Library Management, Bank, Customer_order, E-Commerce, School Management, Student-course\n",
        "###1 OM - Testing - Decider\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 398\n",
        "\n",
        "### P samples - 85\n",
        "### NP samples - 313\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 80\n",
        "\n",
        "### P samples - 12\n",
        "### NP samples - 68\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('8-OM-decider-test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "315d2b58-b344-4a60-fd49-ad0ec09f493a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41315441-52ba-4fbd-8eb0-e1342197979a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41315441-52ba-4fbd-8eb0-e1342197979a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41315441-52ba-4fbd-8eb0-e1342197979a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41315441-52ba-4fbd-8eb0-e1342197979a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae03985-c323-4ed0-f2a9-668a2a9d46fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsAssociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsAssociationsrc=class6_namedst=Customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsAssociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsAssociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigCustomerLoanAssociationextendsAssociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\xe2\\x80\\x8b,Tableclass1_name:Attributec1_at1PrimaryKeyTableclass1_name:Attributec1_at2Tableclass2_name:Attributec2_at1PrimaryKeyTableclass3_name:Attributec3_at4Tableclass3_name:Attributec3_at5Tableclass3_name:Attributec3_at2Tableclass3_name:Attributec3_at2Tableclass4_name:Attributec4_at1PrimaryKeyTableclass4_name:Attributec4_at2Tableclass5_name:Attributec3_at1PrimaryKeyTableclass5_name:Attributec5_at1Tableclass6_name:Attributec6_at1PrimaryKeyTableclass6_name:Attributec6_at2Tableclass6_name:Attributec6_at3Tableclass7_name:Attributec7_at1Tableclass1_name:Attributec1_at1PrimaryKeyTableclass4_name:Attributec4_at1PrimaryKeyTableclass5_name:Attributec5_at1Tableclass6_name:Attributec6_at1PrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameTableName:class7_nameMappingStrategyforclass1_name:map_str2MappingStrategyforclass8_name:map_str2MappingStrategyforclass3_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass7_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type2AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name_0CREATETABLE`class5_name`(`c5_at1`c5_at1_typeNOTNULLPRIMARYKEY(`c5_at1`),);CREATETABLE`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typePRIMARYKEY(`c3_at1`),);CREATETABLE`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`),);CREATETABLE`class1_name`(`c1_at2`c4_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`),);CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typePRIMARYKEY(`c3_at1`),);CREATETABLE`assoc5`(`c3_at1`c3_at2_type`c1_at1`c1_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c3_at1`,`c1_at1`),);CREATETABLE`class4_name`(`c4_at2`c4_at2_type(64)`c6_at1`c6_at1_type`c4_at1`c4_at1_typeNOTNULLKEY`FK_class4_name_c6_at1_idx`(`c6_at1`)PRIMARYKEY(`c4_at1`),);CREATETABLE`assoc2`(`c6_at1`c6_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc2_c6_at1_idx`(`c6_at1`),KEY`FK_assoc2_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c6_at1`,`c3_at1`),);CREATETABLE`assoc3`(`c4_at1`c4_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc3_c4_at1_idx`(`c4_at1`)KEY`FK_assoc3_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c4_at1`,`c3_at1`),);CREATETABLE`assoc4`(`c5_at1`c5_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc4_c5_at1_idx`(`c5_at1`)KEY`FK_assoc4_c3_at1_idx`(`c3_at1`),PRIMARYKEY(`c5_at1`,`c3_at1`));CREATETABLE`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typePRIMARYKEY(`c3_at1`),);ALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`class4_name`ADDCONSTRAINT`FK_class4_name_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADE,\\xe2\\x80\\x8b'], shape=(1,), dtype=string)\n",
            "\n",
            "tf.Tensor([b'moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsAssociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsAssociationsrc=class6_namedst=Customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsAssociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsAssociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigCustomerLoanAssociationextendsAssociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\xe2\\x80\\x8b,Tableclass1_name:Attributec1_at1PrimaryKeyTableclass1_name:Attributec1_at2Tableclass2_name:Attributec2_at1PrimaryKeyTableclass3_name:Attributec3_at4Tableclass3_name:Attributec3_at5Tableclass3_name:Attributec3_at2Tableclass3_name:Attributec3_at2Tableclass4_name:Attributec4_at1PrimaryKeyTableclass4_name:Attributec4_at2Tableclass5_name:Attributec3_at1PrimaryKeyTableclass5_name:Attributec5_at1Tableclass6_name:Attributec6_at1PrimaryKeyTableclass6_name:Attributec6_at2Tableclass6_name:Attributec6_at3Tableclass7_name:Attributec7_at1Tableclass1_name:Attributec1_at1PrimaryKeyTableclass4_name:Attributec4_at1PrimaryKeyTableclass5_name:Attributec5_at1Tableclass6_name:Attributec6_at1PrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameTableName:class7_nameMappingStrategyforclass1_name:map_str2MappingStrategyforclass8_name:map_str2MappingStrategyforclass3_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass7_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type2AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name_0CREATETABLE`class5_name`(`c5_at1`c5_at1_typeNOTNULLPRIMARYKEY(`c5_at1`),);CREATETABLE`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typePRIMARYKEY(`c3_at1`),);CREATETABLE`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`),);CREATETABLE`class1_name`(`c1_at2`c4_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`),);CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typePRIMARYKEY(`c3_at1`),);CREATETABLE`assoc5`(`c3_at1`c3_at2_type`c1_at1`c1_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c3_at1`,`c1_at1`),);CREATETABLE`class4_name`(`c4_at2`c4_at2_type(64)`c6_at1`c6_at1_type`c4_at1`c4_at1_typeNOTNULLKEY`FK_class4_name_c6_at1_idx`(`c6_at1`)PRIMARYKEY(`c4_at1`),);CREATETABLE`assoc2`(`c6_at1`c6_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc2_c6_at1_idx`(`c6_at1`),KEY`FK_assoc2_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c6_at1`,`c3_at1`),);CREATETABLE`assoc3`(`c4_at1`c4_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc3_c4_at1_idx`(`c4_at1`)KEY`FK_assoc3_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c4_at1`,`c3_at1`),);CREATETABLE`assoc4`(`c5_at1`c5_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc4_c5_at1_idx`(`c5_at1`)KEY`FK_assoc4_c3_at1_idx`(`c3_at1`),PRIMARYKEY(`c5_at1`,`c3_at1`));CREATETABLE`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typePRIMARYKEY(`c3_at1`),);ALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`class4_name`ADDCONSTRAINT`FK_class4_name_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADE,\\xe2\\x80\\x8bNP'], shape=(1,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "mD0e-DWGQ2Vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f800cddc-652f-418a-b0e7-f0e2be1d3e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'class1,table2,obj1,atr1'\n",
            "b'class1,table2,obj1,atr1'\n"
          ]
        }
      ],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "UREvDg3sEKYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e1ea2e-ee7f-4706-a8c4-cb4031ef5ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table2,obj1,atr1\n",
            "[START] class1,table2,obj1,atr1 [END]\n"
          ]
        }
      ],
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "bc5f707b-ad07-48a2-9142-c3541fa8e193"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 17, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "ad2b9415-e063-45f3-b196-7c9505c35c74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "a06604d5-150d-46b2-e0c4-d7d4f5af7ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 165   3]\n",
            "\n",
            "[  2 166]\n",
            "[166   3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "f9833518-a61b-4fb3-c7d5-faf2414b8824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "0c4dc605-81da-41d7-c544-8cc0d79b8a2d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "d20c4bd8-92d2-47c5-efbc-32506ece9607"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "31cb7efe-06a9-4053-e600-ac52e6939e56"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "85dabd0e-e277-4494-dc3a-8e324192e560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 233)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "b2513498-b0e6-443b-dad7-78d95c4a1182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 233)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "1be1ddf0-599b-411c-85a3-d3677ab1d440"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.4510384, 'expected_acc': 0.004291845493562232}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "72be3a7e-9750-4b26-dff7-eb8c559bf16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 1s 13ms/step - loss: 3.6539 - masked_acc: 0.5143 - masked_loss: 3.6539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 3.653850793838501,\n",
              " 'masked_acc': 0.5142857432365417,\n",
              " 'masked_loss': 3.653850793838501}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "49282d1f-38df-4b14-b84f-ac050a7f7c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.0293 - masked_acc: 0.9950 - masked_loss: 0.0293 - val_loss: 2.9932 - val_masked_acc: 0.6857 - val_masked_loss: 2.9932\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0629 - masked_acc: 0.9900 - masked_loss: 0.0629 - val_loss: 3.0663 - val_masked_acc: 0.6929 - val_masked_loss: 3.0663\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0523 - masked_acc: 0.9900 - masked_loss: 0.0523 - val_loss: 2.8570 - val_masked_acc: 0.7071 - val_masked_loss: 2.8570\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.0672 - masked_acc: 0.9800 - masked_loss: 0.0672 - val_loss: 2.9416 - val_masked_acc: 0.6929 - val_masked_loss: 2.9416\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.0361 - masked_acc: 0.9900 - masked_loss: 0.0361 - val_loss: 2.9782 - val_masked_acc: 0.6786 - val_masked_loss: 2.9782\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0313 - masked_acc: 0.9950 - masked_loss: 0.0313 - val_loss: 2.9203 - val_masked_acc: 0.6857 - val_masked_loss: 2.9203\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 5s 52ms/step - loss: 0.0182 - masked_acc: 0.9950 - masked_loss: 0.0182 - val_loss: 3.0487 - val_masked_acc: 0.6857 - val_masked_loss: 3.0487\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.0272 - masked_acc: 0.9950 - masked_loss: 0.0272 - val_loss: 2.9092 - val_masked_acc: 0.7000 - val_masked_loss: 2.9092\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0291 - masked_acc: 0.9950 - masked_loss: 0.0291 - val_loss: 2.9365 - val_masked_acc: 0.7000 - val_masked_loss: 2.9365\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.0636 - masked_acc: 0.9850 - masked_loss: 0.0636 - val_loss: 3.3624 - val_masked_acc: 0.6643 - val_masked_loss: 3.3624\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0267 - masked_acc: 0.9950 - masked_loss: 0.0267 - val_loss: 3.0377 - val_masked_acc: 0.7000 - val_masked_loss: 3.0377\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "38rLdlmtQHCm",
        "outputId": "2f9aed54-6ea4-49de-b333-df708f5fa692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc22de6aa30>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "KkhXRASNG80_",
        "outputId": "c4518910-bbd8-4878-a572-9d7c24ee8c32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc22dddcf10>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('decider.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "5491fa02-e8f2-459e-c128-1671d8c74617"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14501ecb-db45-4768-bb8e-6e150192ef63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14501ecb-db45-4768-bb8e-6e150192ef63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14501ecb-db45-4768-bb8e-6e150192ef63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14501ecb-db45-4768-bb8e-6e150192ef63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "68226925-a9a7-44be-d157-5e7c46ca2284"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80,)\n",
            "(80,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "571da437-3e79-4552-8e81-06ed2f58400e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#    mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#    print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('decider_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "15d9743e-ecfc-4db6-a5e5-3a7aab77ff0c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "4  moduleom_name:0opendeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-102647c6-fd9c-4bb8-b542-533775635b1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-102647c6-fd9c-4bb8-b542-533775635b1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-102647c6-fd9c-4bb8-b542-533775635b1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-102647c6-fd9c-4bb8-b542-533775635b1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "660bdb29-c2c3-4605-86cb-6fbc75c20dc9"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "77966a66-edeb-4fce-f4d9-ab4c5f95f31f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 1.000000\n",
            "Testing: Recall = 0.583333\n",
            "Testing: F1 Score = 0.736842\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[68  0]\n",
            " [ 5  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "79d24cc4-8b06-43e9-cc3d-44b2db5af53e"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        68\n",
            "           1       1.00      0.58      0.74        12\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.97      0.79      0.85        80\n",
            "weighted avg       0.94      0.94      0.93        80\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}