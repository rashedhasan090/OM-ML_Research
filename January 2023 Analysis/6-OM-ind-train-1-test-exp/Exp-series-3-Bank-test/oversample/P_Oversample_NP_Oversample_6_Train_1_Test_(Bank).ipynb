{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "#Experiment with P Oversample , NP Oversample\n",
        "###6 OM - Dataset , Camping,OnlineStore,  Library Management, Decider, Customer_order, E-Commerce\n",
        "###1 OM - Testing - Bank\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 433\n",
        "\n",
        "### P samples - 286\n",
        "### NP samples - 147\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 32\n",
        "\n",
        "### P samples - 9\n",
        "### NP samples - 23 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('6-OM-Bank-test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "0d56c4b9-f599-43cc-89b4-3eda56a69d07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b4828b4-211a-4193-a994-975496abc766\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b4828b4-211a-4193-a994-975496abc766')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b4828b4-211a-4193-a994-975496abc766 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b4828b4-211a-4193-a994-975496abc766');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,â€‹OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "#print(example_text.numpy().decode())\n",
        "#print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        " #Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "1978ecb0-9c8b-4461-9174-c58419d18825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 148, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "e5a1aef2-1110-4f5d-dc40-6e351b1cac46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "42d4a2a5-6ed1-46c0-a15a-e70e221f53c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 25  3]\n",
            "\n",
            "[ 2 23]\n",
            "[23  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "b589e93a-2290-412e-8a71-144f8e79cce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "f8df96c7-4e14-46aa-9b06-979a1edfc6ef"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "b16896e8-859e-46a6-83a2-ef0b163ce504"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "ff7b91eb-4234-464f-a349-9b0251f250f2"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "085e788b-b051-4b20-ef50-10806ef6f2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 231)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "af421f63-00be-455e-d1ed-5a1b0d7cde11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 231)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "5af9355c-0d2b-40fa-d805-b91f9024ff03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.4424176, 'expected_acc': 0.004329004329004329}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "cbd37ba5-2acf-459d-d0a1-a78c4674a675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 1s 15ms/step - loss: 2.6868 - masked_acc: 0.6643 - masked_loss: 2.6868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 2.686814069747925,\n",
              " 'masked_acc': 0.6642857193946838,\n",
              " 'masked_loss': 2.686814069747925}"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "b05070a8-798f-47ca-8597-2b7a57359a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.3571 - masked_acc: 0.8900 - masked_loss: 0.3571 - val_loss: 3.0955 - val_masked_acc: 0.7214 - val_masked_loss: 3.0955\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.3994 - masked_acc: 0.8900 - masked_loss: 0.3994 - val_loss: 3.3307 - val_masked_acc: 0.7071 - val_masked_loss: 3.3307\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 3s 35ms/step - loss: 0.4735 - masked_acc: 0.8450 - masked_loss: 0.4735 - val_loss: 2.8585 - val_masked_acc: 0.7857 - val_masked_loss: 2.8585\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.4097 - masked_acc: 0.9000 - masked_loss: 0.4097 - val_loss: 2.8689 - val_masked_acc: 0.7429 - val_masked_loss: 2.8689\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.8123 - masked_acc: 0.7700 - masked_loss: 0.8123 - val_loss: 3.4581 - val_masked_acc: 0.6214 - val_masked_loss: 3.4581\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 4s 35ms/step - loss: 0.8807 - masked_acc: 0.7550 - masked_loss: 0.8807 - val_loss: 2.8964 - val_masked_acc: 0.7143 - val_masked_loss: 2.8964\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.4464 - masked_acc: 0.8600 - masked_loss: 0.4464 - val_loss: 2.7068 - val_masked_acc: 0.7571 - val_masked_loss: 2.7068\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.2432 - masked_acc: 0.9250 - masked_loss: 0.2432 - val_loss: 3.1018 - val_masked_acc: 0.7357 - val_masked_loss: 3.1018\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 0.4074 - masked_acc: 0.8850 - masked_loss: 0.4074 - val_loss: 2.7889 - val_masked_acc: 0.7714 - val_masked_loss: 2.7889\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 3s 35ms/step - loss: 0.4857 - masked_acc: 0.8550 - masked_loss: 0.4857 - val_loss: 2.9337 - val_masked_acc: 0.7500 - val_masked_loss: 2.9337\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.1668 - masked_acc: 0.9650 - masked_loss: 0.1668 - val_loss: 3.0923 - val_masked_acc: 0.7643 - val_masked_loss: 3.0923\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.1554 - masked_acc: 0.9650 - masked_loss: 0.1554 - val_loss: 2.9372 - val_masked_acc: 0.7643 - val_masked_loss: 2.9372\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.1790 - masked_acc: 0.9600 - masked_loss: 0.1790 - val_loss: 2.9081 - val_masked_acc: 0.7786 - val_masked_loss: 2.9081\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0964 - masked_acc: 0.9900 - masked_loss: 0.0964 - val_loss: 3.0522 - val_masked_acc: 0.7714 - val_masked_loss: 3.0522\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.1051 - masked_acc: 0.9750 - masked_loss: 0.1051 - val_loss: 2.9634 - val_masked_acc: 0.7786 - val_masked_loss: 2.9634\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "8663dcad-a73d-4e29-a624-babeb80c03ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb4982b1d90>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KkhXRASNG80_",
        "outputId": "fc77ccd6-f5e7-479e-f416-30f3a8133666"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb4b4dbdb80>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('Bank.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "d2b04c8f-4557-4f6e-d33b-5a067282c10f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3683dad-c1ad-4036-b9cb-73fa05e0407f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3683dad-c1ad-4036-b9cb-73fa05e0407f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3683dad-c1ad-4036-b9cb-73fa05e0407f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3683dad-c1ad-4036-b9cb-73fa05e0407f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "f2714278-91e1-41b2-b704-cf25c0cdf8f8"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31,)\n",
            "(31,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "5b17ed9b-ab53-40ce-862a-50c52ec4e214"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "# print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('Bank_Pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "06b70d87-0807-4102-a798-a752c4f39569"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63da1006-c7ac-4589-b195-a3b939972341\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63da1006-c7ac-4589-b195-a3b939972341')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63da1006-c7ac-4589-b195-a3b939972341 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63da1006-c7ac-4589-b195-a3b939972341');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "a1a40239-05e7-483a-cb2d-5215742118c3"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "2d3acecf-8032-4a6a-cb15-6be0abf266da"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.333333\n",
            "Testing: Recall = 0.888889\n",
            "Testing: F1 Score = 0.484848\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[ 6 16]\n",
            " [ 1  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "50d92ee7-1092-48c4-ce51-3aac00a85a5f"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.27      0.41        22\n",
            "           1       0.33      0.89      0.48         9\n",
            "\n",
            "    accuracy                           0.45        31\n",
            "   macro avg       0.60      0.58      0.45        31\n",
            "weighted avg       0.71      0.45      0.43        31\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}