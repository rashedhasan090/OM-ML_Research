{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJnMTPsgYlc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Regular , NP Regular \n",
        "###6 OM - Dataset , Decider,OnlineStore,  Library Management, Bank, Customer_order, Camping\n",
        "###1 OM - Testing - , E-Commerce\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 228\n",
        "\n",
        "### P samples - 46\n",
        "### NP samples - 182\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 148\n",
        "\n",
        "### P samples - 26\n",
        "### NP samples - 122\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('6-OM-ecomm-test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "cc82d08b-58e7-46f2-8494-6d251d5afb1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fd3701d-7e8e-4481-b7e5-a2fd256ff0ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fd3701d-7e8e-4481-b7e5-a2fd256ff0ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7fd3701d-7e8e-4481-b7e5-a2fd256ff0ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7fd3701d-7e8e-4481-b7e5-a2fd256ff0ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#  # print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "#print(example_text.numpy().decode())\n",
        "#print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cddab686-483f-4f91-d026-766d55e65956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "8f45a396-e297-4db6-d7ee-a86cab0842a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 181, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "#context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "#tokens = context_vocab[example_tokens[0].numpy()]\n",
        "#' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "f9dda94e-52b9-43ca-f957-820db99b6bcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "4e98a7ce-3332-45f6-9633-52edf07a1ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 166   3]\n",
            "\n",
            "[  2 167]\n",
            "[167   3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "b1fe01d6-dce0-44ec-ae67-b617aecce692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "307a7664-a287-47d9-b7b0-5a0a980ff00d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "667d10b7-dcdd-4e19-c13c-4592ee05194d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99999994, 1.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "a02359a1-24d4-4e73-d33c-b62f731c00a2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "2192060a-571b-4f09-a292-08d10bfd9923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 189)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "94409f44-fb2a-4fd7-e963-fe6f0e727225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 189)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "67b5de70-057f-4ce3-ad5c-e68a90348a96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.241747, 'expected_acc': 0.005291005291005291}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "63fe3139-f2bd-4df2-972d-5853ea3c5647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/70 [=============>................] - ETA: 1s - loss: 5.3209 - masked_acc: 0.0303 - masked_loss: 5.3209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/70 [==============================] - 33s 21ms/step - loss: 5.3221 - masked_acc: 0.0294 - masked_loss: 5.3221\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.3220696449279785,\n",
              " 'masked_acc': 0.029411764815449715,\n",
              " 'masked_loss': 5.3220696449279785}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "f07ca874-18bb-4993-a10d-92228529e550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3178 - masked_acc: 0.4950 - masked_loss: 3.3178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 29s 66ms/step - loss: 3.3178 - masked_acc: 0.4950 - masked_loss: 3.3178 - val_loss: 3.1474 - val_masked_acc: 0.5000 - val_masked_loss: 3.1474\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.2068 - masked_acc: 0.5000 - masked_loss: 3.2068"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 45ms/step - loss: 3.2244 - masked_acc: 0.5000 - masked_loss: 3.2244\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2381 - masked_acc: 0.5000 - masked_loss: 3.2381"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 3.2381 - masked_acc: 0.5000 - masked_loss: 3.2381\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.2630 - masked_acc: 0.5000 - masked_loss: 3.2630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 65ms/step - loss: 3.2604 - masked_acc: 0.5000 - masked_loss: 3.2604\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9598 - masked_acc: 0.5000 - masked_loss: 2.9598"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 2.9598 - masked_acc: 0.5000 - masked_loss: 2.9598\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.8736 - masked_acc: 0.5100 - masked_loss: 2.8736"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 67ms/step - loss: 2.8736 - masked_acc: 0.5100 - masked_loss: 2.8736\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6622 - masked_acc: 0.5050 - masked_loss: 2.6622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 51ms/step - loss: 2.6622 - masked_acc: 0.5050 - masked_loss: 2.6622\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6181 - masked_acc: 0.5050 - masked_loss: 2.6181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 57ms/step - loss: 2.6181 - masked_acc: 0.5050 - masked_loss: 2.6181\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4421 - masked_acc: 0.5050 - masked_loss: 2.4421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 59ms/step - loss: 2.4421 - masked_acc: 0.5050 - masked_loss: 2.4421\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3694 - masked_acc: 0.5250 - masked_loss: 2.3694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 2.3694 - masked_acc: 0.5250 - masked_loss: 2.3694\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1054 - masked_acc: 0.5150 - masked_loss: 2.1054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 73ms/step - loss: 2.1054 - masked_acc: 0.5150 - masked_loss: 2.1054\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9476 - masked_acc: 0.5400 - masked_loss: 1.9476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 1.9476 - masked_acc: 0.5400 - masked_loss: 1.9476\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.7705 - masked_acc: 0.5400 - masked_loss: 1.7705"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 64ms/step - loss: 1.7705 - masked_acc: 0.5400 - masked_loss: 1.7705\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4586 - masked_acc: 0.6350 - masked_loss: 1.4586"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 1.4586 - masked_acc: 0.6350 - masked_loss: 1.4586\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3483 - masked_acc: 0.5950 - masked_loss: 1.3483"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 1.3483 - masked_acc: 0.5950 - masked_loss: 1.3483\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.0259 - masked_acc: 0.7020 - masked_loss: 1.0259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 1.0265 - masked_acc: 0.7000 - masked_loss: 1.0265\n",
            "Epoch 17/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.8737 - masked_acc: 0.7626 - masked_loss: 0.8737"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 0.8750 - masked_acc: 0.7600 - masked_loss: 0.8750\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4969 - masked_acc: 0.9000 - masked_loss: 0.4969"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 63ms/step - loss: 0.4969 - masked_acc: 0.9000 - masked_loss: 0.4969\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4580 - masked_acc: 0.9300 - masked_loss: 0.4580"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.4580 - masked_acc: 0.9300 - masked_loss: 0.4580\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1978 - masked_acc: 0.9850 - masked_loss: 0.1978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.1978 - masked_acc: 0.9850 - masked_loss: 0.1978\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1344 - masked_acc: 0.9850 - masked_loss: 0.1344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 63ms/step - loss: 0.1344 - masked_acc: 0.9850 - masked_loss: 0.1344\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0901 - masked_acc: 0.9900 - masked_loss: 0.0901"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 0.0901 - masked_acc: 0.9900 - masked_loss: 0.0901\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0854 - masked_acc: 0.9900 - masked_loss: 0.0854"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 64ms/step - loss: 0.0854 - masked_acc: 0.9900 - masked_loss: 0.0854\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0613 - masked_acc: 0.9900 - masked_loss: 0.0613"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0613 - masked_acc: 0.9900 - masked_loss: 0.0613\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0365 - masked_acc: 0.9950 - masked_loss: 0.0365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 0.0365 - masked_acc: 0.9950 - masked_loss: 0.0365\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0348 - masked_acc: 0.9949 - masked_loss: 0.0348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 65ms/step - loss: 0.0346 - masked_acc: 0.9950 - masked_loss: 0.0346\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0535 - masked_acc: 0.9900 - masked_loss: 0.0535"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 0.0535 - masked_acc: 0.9900 - masked_loss: 0.0535\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0538 - masked_acc: 0.9900 - masked_loss: 0.0538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 65ms/step - loss: 0.0538 - masked_acc: 0.9900 - masked_loss: 0.0538\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0317 - masked_acc: 0.9950 - masked_loss: 0.0317"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 51ms/step - loss: 0.0317 - masked_acc: 0.9950 - masked_loss: 0.0317\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0606 - masked_acc: 0.9850 - masked_loss: 0.0606"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 52ms/step - loss: 0.0606 - masked_acc: 0.9850 - masked_loss: 0.0606\n",
            "Epoch 31/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0116 - masked_acc: 1.0000 - masked_loss: 0.0116"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 65ms/step - loss: 0.0116 - masked_acc: 1.0000 - masked_loss: 0.0116\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0325 - masked_acc: 0.9949 - masked_loss: 0.0325"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 0.0323 - masked_acc: 0.9950 - masked_loss: 0.0323\n",
            "Epoch 33/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0352 - masked_acc: 0.9899 - masked_loss: 0.0352"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0349 - masked_acc: 0.9900 - masked_loss: 0.0349\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0451 - masked_acc: 0.9900 - masked_loss: 0.0451"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0451 - masked_acc: 0.9900 - masked_loss: 0.0451\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0298 - masked_acc: 0.9900 - masked_loss: 0.0298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 54ms/step - loss: 0.0298 - masked_acc: 0.9900 - masked_loss: 0.0298\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0394 - masked_acc: 0.9900 - masked_loss: 0.0394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 55ms/step - loss: 0.0394 - masked_acc: 0.9900 - masked_loss: 0.0394\n",
            "Epoch 37/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0506 - masked_acc: 0.9848 - masked_loss: 0.0506"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0502 - masked_acc: 0.9850 - masked_loss: 0.0502\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0356 - masked_acc: 0.9900 - masked_loss: 0.0356"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 61ms/step - loss: 0.0356 - masked_acc: 0.9900 - masked_loss: 0.0356\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0168 - masked_acc: 0.9950 - masked_loss: 0.0168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0168 - masked_acc: 0.9950 - masked_loss: 0.0168\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0359 - masked_acc: 0.9900 - masked_loss: 0.0359"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 52ms/step - loss: 0.0359 - masked_acc: 0.9900 - masked_loss: 0.0359\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0287 - masked_acc: 0.9900 - masked_loss: 0.0287"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.0287 - masked_acc: 0.9900 - masked_loss: 0.0287\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0059 - masked_acc: 1.0000 - masked_loss: 0.0059"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0059 - masked_acc: 1.0000 - masked_loss: 0.0059\n",
            "Epoch 43/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0481 - masked_acc: 0.9848 - masked_loss: 0.0481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 63ms/step - loss: 0.0477 - masked_acc: 0.9850 - masked_loss: 0.0477\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0204 - masked_acc: 0.9950 - masked_loss: 0.0204"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0204 - masked_acc: 0.9950 - masked_loss: 0.0204\n",
            "Epoch 45/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0385 - masked_acc: 0.9899 - masked_loss: 0.0385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0382 - masked_acc: 0.9900 - masked_loss: 0.0382\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0187 - masked_acc: 0.9949 - masked_loss: 0.0187"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 61ms/step - loss: 0.0186 - masked_acc: 0.9950 - masked_loss: 0.0186\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0046 - masked_acc: 1.0000 - masked_loss: 0.0046"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0046 - masked_acc: 1.0000 - masked_loss: 0.0046\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0352 - masked_acc: 0.9900 - masked_loss: 0.0352"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0352 - masked_acc: 0.9900 - masked_loss: 0.0352\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0030 - masked_acc: 1.0000 - masked_loss: 0.0030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0030 - masked_acc: 1.0000 - masked_loss: 0.0030\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0445 - masked_acc: 0.9850 - masked_loss: 0.0445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0445 - masked_acc: 0.9850 - masked_loss: 0.0445\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0028 - masked_acc: 1.0000 - masked_loss: 0.0028"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0028 - masked_acc: 1.0000 - masked_loss: 0.0028\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0289 - masked_acc: 0.9848 - masked_loss: 0.0289"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0287 - masked_acc: 0.9850 - masked_loss: 0.0287\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0404 - masked_acc: 0.9850 - masked_loss: 0.0404"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0404 - masked_acc: 0.9850 - masked_loss: 0.0404\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0254 - masked_acc: 0.9900 - masked_loss: 0.0254"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 51ms/step - loss: 0.0254 - masked_acc: 0.9900 - masked_loss: 0.0254\n",
            "Epoch 55/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0044 - masked_acc: 1.0000 - masked_loss: 0.0044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0043 - masked_acc: 1.0000 - masked_loss: 0.0043\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0344 - masked_acc: 0.9900 - masked_loss: 0.0344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0344 - masked_acc: 0.9900 - masked_loss: 0.0344\n",
            "Epoch 57/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0235 - masked_acc: 0.9899 - masked_loss: 0.0235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0233 - masked_acc: 0.9900 - masked_loss: 0.0233\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0251 - masked_acc: 0.9900 - masked_loss: 0.0251"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 67ms/step - loss: 0.0251 - masked_acc: 0.9900 - masked_loss: 0.0251\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0137 - masked_acc: 0.9950 - masked_loss: 0.0137"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 8s 79ms/step - loss: 0.0137 - masked_acc: 0.9950 - masked_loss: 0.0137\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0385 - masked_acc: 0.9850 - masked_loss: 0.0385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 63ms/step - loss: 0.0385 - masked_acc: 0.9850 - masked_loss: 0.0385\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0283 - masked_acc: 0.9850 - masked_loss: 0.0283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 0.0283 - masked_acc: 0.9850 - masked_loss: 0.0283\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 52ms/step - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0016 - masked_acc: 1.0000 - masked_loss: 0.0016"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 60ms/step - loss: 0.0016 - masked_acc: 1.0000 - masked_loss: 0.0016\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0383 - masked_acc: 0.9900 - masked_loss: 0.0383"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0383 - masked_acc: 0.9900 - masked_loss: 0.0383\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1295 - masked_acc: 0.9800 - masked_loss: 0.1295"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 63ms/step - loss: 0.1295 - masked_acc: 0.9800 - masked_loss: 0.1295\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.6388 - masked_acc: 0.6313 - masked_loss: 1.6388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 1.6536 - masked_acc: 0.6300 - masked_loss: 1.6536\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2577 - masked_acc: 0.6550 - masked_loss: 1.2577"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 1.2577 - masked_acc: 0.6550 - masked_loss: 1.2577\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7988 - masked_acc: 0.7450 - masked_loss: 0.7988"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 58ms/step - loss: 0.7988 - masked_acc: 0.7450 - masked_loss: 0.7988\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5079 - masked_acc: 0.8500 - masked_loss: 0.5079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 0.5079 - masked_acc: 0.8500 - masked_loss: 0.5079\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3071 - masked_acc: 0.9100 - masked_loss: 0.3071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 63ms/step - loss: 0.3071 - masked_acc: 0.9100 - masked_loss: 0.3071\n",
            "Epoch 71/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1378 - masked_acc: 0.9697 - masked_loss: 0.1378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.1367 - masked_acc: 0.9700 - masked_loss: 0.1367\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1295 - masked_acc: 0.9650 - masked_loss: 0.1295"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 52ms/step - loss: 0.1295 - masked_acc: 0.9650 - masked_loss: 0.1295\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0910 - masked_acc: 0.9800 - masked_loss: 0.0910"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 55ms/step - loss: 0.0910 - masked_acc: 0.9800 - masked_loss: 0.0910\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0262 - masked_acc: 0.9950 - masked_loss: 0.0262"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0262 - masked_acc: 0.9950 - masked_loss: 0.0262\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0421 - masked_acc: 0.9850 - masked_loss: 0.0421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0421 - masked_acc: 0.9850 - masked_loss: 0.0421\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0045 - masked_acc: 1.0000 - masked_loss: 0.0045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0045 - masked_acc: 1.0000 - masked_loss: 0.0045\n",
            "Epoch 77/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0533 - masked_acc: 0.9798 - masked_loss: 0.0533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0528 - masked_acc: 0.9800 - masked_loss: 0.0528\n",
            "Epoch 78/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0181 - masked_acc: 0.9949 - masked_loss: 0.0181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 65ms/step - loss: 0.0179 - masked_acc: 0.9950 - masked_loss: 0.0179\n",
            "Epoch 79/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0289 - masked_acc: 0.9899 - masked_loss: 0.0289"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.0287 - masked_acc: 0.9900 - masked_loss: 0.0287\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0347 - masked_acc: 0.9850 - masked_loss: 0.0347"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0347 - masked_acc: 0.9850 - masked_loss: 0.0347\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0135 - masked_acc: 0.9950 - masked_loss: 0.0135"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0135 - masked_acc: 0.9950 - masked_loss: 0.0135\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0220 - masked_acc: 0.9900 - masked_loss: 0.0220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 0.0220 - masked_acc: 0.9900 - masked_loss: 0.0220\n",
            "Epoch 83/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0143 - masked_acc: 0.9949 - masked_loss: 0.0143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 61ms/step - loss: 0.0142 - masked_acc: 0.9950 - masked_loss: 0.0142\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0119 - masked_acc: 0.9950 - masked_loss: 0.0119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0119 - masked_acc: 0.9950 - masked_loss: 0.0119\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0268 - masked_acc: 0.9900 - masked_loss: 0.0268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 8s 80ms/step - loss: 0.0268 - masked_acc: 0.9900 - masked_loss: 0.0268\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0352 - masked_acc: 0.9800 - masked_loss: 0.0352"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0352 - masked_acc: 0.9800 - masked_loss: 0.0352\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0092 - masked_acc: 0.9950 - masked_loss: 0.0092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 61ms/step - loss: 0.0092 - masked_acc: 0.9950 - masked_loss: 0.0092\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0127 - masked_acc: 0.9950 - masked_loss: 0.0127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0127 - masked_acc: 0.9950 - masked_loss: 0.0127\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0196 - masked_acc: 0.9900 - masked_loss: 0.0196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0196 - masked_acc: 0.9900 - masked_loss: 0.0196\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0164 - masked_acc: 0.9950 - masked_loss: 0.0164"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0164 - masked_acc: 0.9950 - masked_loss: 0.0164\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0179 - masked_acc: 0.9900 - masked_loss: 0.0179"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0179 - masked_acc: 0.9900 - masked_loss: 0.0179\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0292 - masked_acc: 0.9850 - masked_loss: 0.0292"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 58ms/step - loss: 0.0292 - masked_acc: 0.9850 - masked_loss: 0.0292\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 51ms/step - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0147 - masked_acc: 0.9950 - masked_loss: 0.0147"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0147 - masked_acc: 0.9950 - masked_loss: 0.0147\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0194 - masked_acc: 0.9900 - masked_loss: 0.0194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 62ms/step - loss: 0.0194 - masked_acc: 0.9900 - masked_loss: 0.0194\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0143 - masked_acc: 0.9950 - masked_loss: 0.0143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0143 - masked_acc: 0.9950 - masked_loss: 0.0143\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0136 - masked_acc: 0.9950 - masked_loss: 0.0136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.0136 - masked_acc: 0.9950 - masked_loss: 0.0136\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0304 - masked_acc: 0.9800 - masked_loss: 0.0304"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.0304 - masked_acc: 0.9800 - masked_loss: 0.0304\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0147 - masked_acc: 0.9950 - masked_loss: 0.0147"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0147 - masked_acc: 0.9950 - masked_loss: 0.0147\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0138 - masked_acc: 0.9900 - masked_loss: 0.0138"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 63ms/step - loss: 0.0138 - masked_acc: 0.9900 - masked_loss: 0.0138\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "22a507ef-ba97-4df8-dd94-71bb2ef7d956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0bd5d5c7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "c14c02fa-504c-4d37-cc0a-18f34590923e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0bd3bfbd00>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('ecom.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "17ed0d9f-52ee-4415-e1bd-76d4f9f7e247"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a71ef59-c431-47a0-8136-41be14ccaf02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a71ef59-c431-47a0-8136-41be14ccaf02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a71ef59-c431-47a0-8136-41be14ccaf02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a71ef59-c431-47a0-8136-41be14ccaf02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "3282dc00-b463-4d4e-b90d-a86e91134bd4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(147,)\n",
            "(147,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "fd6501dc-1656-4680-918b-b5508fb747b4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #%%time\n",
        " #for t in inputs:\n",
        " #  mylist_res = model.translate([t])[0].numpy().decode()\n",
        " #  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        " #print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('ecom_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "0c02e4a5-8336-474d-a7fd-ab7a39ff05c7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0,opendeclarationonesigclass1_na...              0\n",
              "1  moduleom_name:0,opendeclarationonesigclass1_na...              0\n",
              "2  moduleom_name:0,opendeclarationonesigclass1_na...              0\n",
              "3  moduleom_name:0,opendeclarationonesigclass1_na...              0\n",
              "4  moduleom_name:0,opendeclarationonesigclass1_na...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9df54861-8416-425c-93bc-9271ceeb3750\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9df54861-8416-425c-93bc-9271ceeb3750')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9df54861-8416-425c-93bc-9271ceeb3750 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9df54861-8416-425c-93bc-9271ceeb3750');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "8ee6b4ac-8324-4d86-eb0e-6996eddebedb"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "4505ba6d-3e80-414a-ce09-5dee8e4a681f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 1.000000\n",
            "Testing: Recall = 0.120000\n",
            "Testing: F1 Score = 0.214286\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[122   0]\n",
            " [ 22   3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "6969c2c0-8bb8-4378-df67-456d71339674"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       122\n",
            "           1       1.00      0.12      0.21        25\n",
            "\n",
            "    accuracy                           0.85       147\n",
            "   macro avg       0.92      0.56      0.57       147\n",
            "weighted avg       0.87      0.85      0.80       147\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}