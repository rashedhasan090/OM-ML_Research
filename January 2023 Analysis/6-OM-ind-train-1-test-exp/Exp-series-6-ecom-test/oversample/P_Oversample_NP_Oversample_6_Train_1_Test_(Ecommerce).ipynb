{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP Undersample \n",
        "###6 OM - Dataset , Decider,OnlineStore,  Library Management, Bank, Customer_order, Camping\n",
        "###1 OM - Testing - , E-Commerce\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 222\n",
        "\n",
        "### P samples - 135\n",
        "### NP samples - 87\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 148\n",
        "\n",
        "### P samples - 26\n",
        "### NP samples - 122\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('6-OM-ecomm-test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "85211474-2cfa-49bb-dfcf-12f3957b4a06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "1  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "2  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "3  moduleOM_nameonesigclass1_nameextendsClassattr...  \n",
              "4  moduleOM_nameonesigclass1_nameextendsClassattr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef86f3d3-5f8c-4859-9be1-791d7320c6b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "      <td>moduleOM_nameonesigclass1_nameextendsClassattr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef86f3d3-5f8c-4859-9be1-791d7320c6b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef86f3d3-5f8c-4859-9be1-791d7320c6b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef86f3d3-5f8c-4859-9be1-791d7320c6b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa72cee-60cb-4157-f8b6-73d30d79ae6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tf.Tensor([b'moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsAssociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsAssociationsrc=class6_namedst=Customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsAssociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsAssociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigCustomerLoanAssociationextendsAssociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\xe2\\x80\\x8b,Tableclass1_name:Attributec1_at1PrimaryKeyTableclass1_name:Attributec1_at2Tableclass2_name:Attributec2_at1PrimaryKeyTableclass3_name:Attributec3_at4Tableclass3_name:Attributec3_at5Tableclass3_name:Attributec3_at2Tableclass3_name:Attributec3_at2Tableclass4_name:Attributec4_at1PrimaryKeyTableclass4_name:Attributec4_at2Tableclass5_name:Attributec3_at1PrimaryKeyTableclass5_name:Attributec5_at1Tableclass6_name:Attributec6_at1PrimaryKeyTableclass6_name:Attributec6_at2Tableclass6_name:Attributec6_at3Tableclass7_name:Attributec7_at1Tableclass1_name:Attributec1_at1PrimaryKeyTableclass4_name:Attributec4_at1PrimaryKeyTableclass5_name:Attributec5_at1Tableclass6_name:Attributec6_at1PrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameTableName:class7_nameMappingStrategyforclass8_name:map_str2MappingStrategyforclass3_name:map_str2MappingStrategyforclass5_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass7_name:map_str2AssociationStrategyforassoc5:assoc_type1AssociationStrategyforassoc1:assoc_type2AssociationStrategyforassoc2:assoc_type2AssociationStrategyforassoc3:assoc_type2,USEOM_name_0CREATETABLE`class5_name`(`c5_at1`c5_at1_typeNOTNULL`c3_at1`c3_at2_typePRIMARYKEY(`c5_at1`),);CREATETABLE`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typePRIMARYKEY(`c3_at1`),);CREATETABLE`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`),);CREATETABLE`class1_name`(`c1_at2`c4_at2_type(64)`c3_at1`c3_at2_type`c1_at1`c1_at1_typeKEY`FK_class1_name_c3_at1_idx`(`c3_at1`),PRIMARYKEY(`c1_at1`),);CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typePRIMARYKEY(`c3_at1`),);CREATETABLE`class4_name`(`c4_at2`c4_at2_type(64)`c4_at1`c4_at1_typeNOTNULLPRIMARYKEY(`c4_at1`),);CREATETABLE`assoc2`(`c6_at1`c6_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc2_c6_at1_idx`(`c6_at1`),KEY`FK_assoc2_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c6_at1`,`c3_at1`),);CREATETABLE`assoc3`(`c4_at1`c4_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc3_c4_at1_idx`(`c4_at1`)KEY`FK_assoc3_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c4_at1`,`c3_at1`),);CREATETABLE`assoc4`(`c5_at1`c5_at1_typeNOTNULL`c3_at1`c3_at2_typeKEY`FK_assoc4_c5_at1_idx`(`c5_at1`)KEY`FK_assoc4_c3_at1_idx`(`c3_at1`),PRIMARYKEY(`c5_at1`,`c3_at1`));CREATETABLE`assoc1`(`c6_at1`c6_at1_typeNOTNULL`c4_at1`c4_at1_typeNOTNULLKEY`FK_assoc1_c6_at1_idx`(`c6_at1`),KEY`FK_assoc1_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c6_at1`,`c4_at1`),);CREATETABLE`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typePRIMARYKEY(`c3_at1`),);ALTERTABLE`class1_name`ADDCONSTRAINT`FK_class1_name_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE,NP'], shape=(1,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        " # print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "f2fa3775-3c5e-46b1-b72f-3f9f8eb4c1ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 108, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "a9cf880e-bf55-4ead-94e1-dbb69e02e584"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "a788eaf8-0a1b-4054-8a32-99df71676041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 53  3]\n",
            "\n",
            "[ 2 53]\n",
            "[53  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "4cc083dd-7961-4291-8841-5b9b4d7605ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "0d2ae2ec-3bda-4d59-9dfa-eb5d460c762b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "11c0a869-5ac2-417b-82ac-85edef17525e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "605aaf51-f0bc-4cfe-f3c4-60a98eac1457"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "ad32a712-2f2c-4f73-fcba-d8f1b40a173c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 150)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "a79df743-38d8-4b8b-e7ff-ba0a64648ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 150)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "a1b388a9-5b94-4e28-d3f4-83924345c148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.0106354, 'expected_acc': 0.006666666666666667}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "3bdbda89-967d-4502-8594-f338138d0dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/70 [===============>..............] - ETA: 0s - loss: 5.1808 - masked_acc: 0.0000e+00 - masked_loss: 5.1808"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/70 [==============================] - 13s 8ms/step - loss: 5.1877 - masked_acc: 0.0000e+00 - masked_loss: 5.1877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.187736988067627,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 5.187736988067627}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "0c7f81d9-35f5-4ecb-9628-26b8cba8a388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.2352 - masked_acc: 0.4949 - masked_loss: 3.2352"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 30s 48ms/step - loss: 3.2312 - masked_acc: 0.4950 - masked_loss: 3.2312 - val_loss: 3.0099 - val_masked_acc: 0.5000 - val_masked_loss: 3.0099\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1358 - masked_acc: 0.5000 - masked_loss: 3.1358"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 3.1358 - masked_acc: 0.5000 - masked_loss: 3.1358\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1246 - masked_acc: 0.5000 - masked_loss: 3.1246"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 3.1246 - masked_acc: 0.5000 - masked_loss: 3.1246\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.0020 - masked_acc: 0.5000 - masked_loss: 3.0020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 2.9957 - masked_acc: 0.5000 - masked_loss: 2.9957\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7071 - masked_acc: 0.5000 - masked_loss: 2.7071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 2.7071 - masked_acc: 0.5000 - masked_loss: 2.7071\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7622 - masked_acc: 0.5050 - masked_loss: 2.7622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 58ms/step - loss: 2.7622 - masked_acc: 0.5050 - masked_loss: 2.7622\n",
            "Epoch 7/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.7548 - masked_acc: 0.5000 - masked_loss: 2.7548"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 2.7503 - masked_acc: 0.5000 - masked_loss: 2.7503\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5130 - masked_acc: 0.5100 - masked_loss: 2.5130"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 44ms/step - loss: 2.5130 - masked_acc: 0.5100 - masked_loss: 2.5130\n",
            "Epoch 9/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.5544 - masked_acc: 0.5152 - masked_loss: 2.5544"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 52ms/step - loss: 2.5536 - masked_acc: 0.5150 - masked_loss: 2.5536\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.2259 - masked_acc: 0.5051 - masked_loss: 2.2259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 44ms/step - loss: 2.2189 - masked_acc: 0.5050 - masked_loss: 2.2189\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2139 - masked_acc: 0.5300 - masked_loss: 2.2139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 52ms/step - loss: 2.2139 - masked_acc: 0.5300 - masked_loss: 2.2139\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.8942 - masked_acc: 0.5450 - masked_loss: 1.8942"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 45ms/step - loss: 1.8942 - masked_acc: 0.5450 - masked_loss: 1.8942\n",
            "Epoch 13/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.8385 - masked_acc: 0.5657 - masked_loss: 1.8385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 1.8355 - masked_acc: 0.5650 - masked_loss: 1.8355\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5778 - masked_acc: 0.5800 - masked_loss: 1.5778"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 1.5778 - masked_acc: 0.5800 - masked_loss: 1.5778\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3083 - masked_acc: 0.6500 - masked_loss: 1.3083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 1.3083 - masked_acc: 0.6500 - masked_loss: 1.3083\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1066 - masked_acc: 0.6750 - masked_loss: 1.1066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 1.1066 - masked_acc: 0.6750 - masked_loss: 1.1066\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8202 - masked_acc: 0.7850 - masked_loss: 0.8202"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 69ms/step - loss: 0.8202 - masked_acc: 0.7850 - masked_loss: 0.8202\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7094 - masked_acc: 0.7850 - masked_loss: 0.7094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 8s 78ms/step - loss: 0.7094 - masked_acc: 0.7850 - masked_loss: 0.7094\n",
            "Epoch 19/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3241 - masked_acc: 0.9394 - masked_loss: 0.3241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.3310 - masked_acc: 0.9350 - masked_loss: 0.3310\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3195 - masked_acc: 0.9550 - masked_loss: 0.3195"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.3195 - masked_acc: 0.9550 - masked_loss: 0.3195\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0968 - masked_acc: 0.9950 - masked_loss: 0.0968"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 51ms/step - loss: 0.0968 - masked_acc: 0.9950 - masked_loss: 0.0968\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1074 - masked_acc: 0.9850 - masked_loss: 0.1074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.1074 - masked_acc: 0.9850 - masked_loss: 0.1074\n",
            "Epoch 23/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0305 - masked_acc: 1.0000 - masked_loss: 0.0305"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0307 - masked_acc: 1.0000 - masked_loss: 0.0307\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0482 - masked_acc: 0.9899 - masked_loss: 0.0482"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 58ms/step - loss: 0.0480 - masked_acc: 0.9900 - masked_loss: 0.0480\n",
            "Epoch 25/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0571 - masked_acc: 0.9949 - masked_loss: 0.0571"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.0568 - masked_acc: 0.9950 - masked_loss: 0.0568\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0217 - masked_acc: 0.9950 - masked_loss: 0.0217"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0217 - masked_acc: 0.9950 - masked_loss: 0.0217\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0336 - masked_acc: 0.9950 - masked_loss: 0.0336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 54ms/step - loss: 0.0336 - masked_acc: 0.9950 - masked_loss: 0.0336\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0119 - masked_acc: 1.0000 - masked_loss: 0.0119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 40ms/step - loss: 0.0119 - masked_acc: 1.0000 - masked_loss: 0.0119\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0448 - masked_acc: 0.9900 - masked_loss: 0.0448"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.0448 - masked_acc: 0.9900 - masked_loss: 0.0448\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0089 - masked_acc: 1.0000 - masked_loss: 0.0089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 58ms/step - loss: 0.0324 - masked_acc: 0.9950 - masked_loss: 0.0324\n",
            "Epoch 31/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0090 - masked_acc: 1.0000 - masked_loss: 0.0090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.0089 - masked_acc: 1.0000 - masked_loss: 0.0089\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0264 - masked_acc: 0.9900 - masked_loss: 0.0264"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 0.0264 - masked_acc: 0.9900 - masked_loss: 0.0264\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0175 - masked_acc: 0.9950 - masked_loss: 0.0175"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0175 - masked_acc: 0.9950 - masked_loss: 0.0175\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0241 - masked_acc: 0.9950 - masked_loss: 0.0241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0241 - masked_acc: 0.9950 - masked_loss: 0.0241\n",
            "Epoch 35/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0295 - masked_acc: 0.9899 - masked_loss: 0.0295"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 59ms/step - loss: 0.0293 - masked_acc: 0.9900 - masked_loss: 0.0293\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0169 - masked_acc: 0.9949 - masked_loss: 0.0169"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.0168 - masked_acc: 0.9950 - masked_loss: 0.0168\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0055 - masked_acc: 1.0000 - masked_loss: 0.0055"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0055 - masked_acc: 1.0000 - masked_loss: 0.0055\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0233 - masked_acc: 0.9950 - masked_loss: 0.0233"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 58ms/step - loss: 0.0233 - masked_acc: 0.9950 - masked_loss: 0.0233\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0273 - masked_acc: 0.9900 - masked_loss: 0.0273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 44ms/step - loss: 0.0273 - masked_acc: 0.9900 - masked_loss: 0.0273\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0045 - masked_acc: 1.0000 - masked_loss: 0.0045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 45ms/step - loss: 0.0045 - masked_acc: 1.0000 - masked_loss: 0.0045\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0243 - masked_acc: 0.9900 - masked_loss: 0.0243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 54ms/step - loss: 0.0243 - masked_acc: 0.9900 - masked_loss: 0.0243\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0041 - masked_acc: 1.0000 - masked_loss: 0.0041"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0041 - masked_acc: 1.0000 - masked_loss: 0.0041\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0036 - masked_acc: 1.0000 - masked_loss: 0.0036"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0036 - masked_acc: 1.0000 - masked_loss: 0.0036\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0337 - masked_acc: 0.9950 - masked_loss: 0.0337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0337 - masked_acc: 0.9950 - masked_loss: 0.0337\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0041 - masked_acc: 1.0000 - masked_loss: 0.0041"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 7s 70ms/step - loss: 0.0041 - masked_acc: 1.0000 - masked_loss: 0.0041\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0314 - masked_acc: 0.9900 - masked_loss: 0.0314"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0314 - masked_acc: 0.9900 - masked_loss: 0.0314\n",
            "Epoch 47/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0038 - masked_acc: 1.0000 - masked_loss: 0.0038"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.0038 - masked_acc: 1.0000 - masked_loss: 0.0038\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0185 - masked_acc: 0.9950 - masked_loss: 0.0185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.0185 - masked_acc: 0.9950 - masked_loss: 0.0185\n",
            "Epoch 49/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0115 - masked_acc: 0.9949 - masked_loss: 0.0115"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 45ms/step - loss: 0.0115 - masked_acc: 0.9950 - masked_loss: 0.0115\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0032 - masked_acc: 1.0000 - masked_loss: 0.0032"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 39ms/step - loss: 0.0032 - masked_acc: 1.0000 - masked_loss: 0.0032\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0209 - masked_acc: 0.9950 - masked_loss: 0.0209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 50ms/step - loss: 0.0209 - masked_acc: 0.9950 - masked_loss: 0.0209\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0161 - masked_acc: 0.9950 - masked_loss: 0.0161"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 45ms/step - loss: 0.0161 - masked_acc: 0.9950 - masked_loss: 0.0161\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0026 - masked_acc: 1.0000 - masked_loss: 0.0026"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0026 - masked_acc: 1.0000 - masked_loss: 0.0026\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0245 - masked_acc: 0.9900 - masked_loss: 0.0245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0245 - masked_acc: 0.9900 - masked_loss: 0.0245\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0149 - masked_acc: 0.9950 - masked_loss: 0.0149"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0149 - masked_acc: 0.9950 - masked_loss: 0.0149\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0176 - masked_acc: 0.9950 - masked_loss: 0.0176"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.0176 - masked_acc: 0.9950 - masked_loss: 0.0176\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015\n",
            "Epoch 59/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0071 - masked_acc: 0.9949 - masked_loss: 0.0071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0071 - masked_acc: 0.9950 - masked_loss: 0.0071\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0195 - masked_acc: 0.9900 - masked_loss: 0.0195"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.0195 - masked_acc: 0.9900 - masked_loss: 0.0195\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0157 - masked_acc: 0.9950 - masked_loss: 0.0157"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0157 - masked_acc: 0.9950 - masked_loss: 0.0157\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0089 - masked_acc: 0.9950 - masked_loss: 0.0089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0089 - masked_acc: 0.9950 - masked_loss: 0.0089\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0230 - masked_acc: 0.9900 - masked_loss: 0.0230"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 57ms/step - loss: 0.0230 - masked_acc: 0.9900 - masked_loss: 0.0230\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0022 - masked_acc: 1.0000 - masked_loss: 0.0022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0022 - masked_acc: 1.0000 - masked_loss: 0.0022\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0162 - masked_acc: 0.9950 - masked_loss: 0.0162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0162 - masked_acc: 0.9950 - masked_loss: 0.0162\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0063 - masked_acc: 0.9949 - masked_loss: 0.0063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0063 - masked_acc: 0.9950 - masked_loss: 0.0063\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0150 - masked_acc: 0.9950 - masked_loss: 0.0150"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 40ms/step - loss: 0.0150 - masked_acc: 0.9950 - masked_loss: 0.0150\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.0810e-04 - masked_acc: 1.0000 - masked_loss: 8.0810e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 44ms/step - loss: 8.0810e-04 - masked_acc: 1.0000 - masked_loss: 8.0810e-04\n",
            "Epoch 69/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0134 - masked_acc: 0.9949 - masked_loss: 0.0134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0133 - masked_acc: 0.9950 - masked_loss: 0.0133\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 9.8474e-04 - masked_acc: 1.0000 - masked_loss: 9.8474e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 9.7773e-04 - masked_acc: 1.0000 - masked_loss: 9.7773e-04\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0231 - masked_acc: 0.9900 - masked_loss: 0.0231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 47ms/step - loss: 0.0231 - masked_acc: 0.9900 - masked_loss: 0.0231\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014\n",
            "Epoch 73/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0164 - masked_acc: 0.9949 - masked_loss: 0.0164"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0162 - masked_acc: 0.9950 - masked_loss: 0.0162\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0139 - masked_acc: 0.9950 - masked_loss: 0.0139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 54ms/step - loss: 0.0139 - masked_acc: 0.9950 - masked_loss: 0.0139\n",
            "Epoch 75/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0033 - masked_acc: 1.0000 - masked_loss: 0.0033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 44ms/step - loss: 0.0032 - masked_acc: 1.0000 - masked_loss: 0.0032\n",
            "Epoch 76/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0168 - masked_acc: 0.9949 - masked_loss: 0.0168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0166 - masked_acc: 0.9950 - masked_loss: 0.0166\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0053 - masked_acc: 0.9950 - masked_loss: 0.0053"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0053 - masked_acc: 0.9950 - masked_loss: 0.0053\n",
            "Epoch 78/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0141 - masked_acc: 0.9949 - masked_loss: 0.0141"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 40ms/step - loss: 0.0140 - masked_acc: 0.9950 - masked_loss: 0.0140\n",
            "Epoch 79/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0153 - masked_acc: 0.9899 - masked_loss: 0.0153"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 39ms/step - loss: 0.0152 - masked_acc: 0.9900 - masked_loss: 0.0152\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0090 - masked_acc: 0.9950 - masked_loss: 0.0090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 52ms/step - loss: 0.0090 - masked_acc: 0.9950 - masked_loss: 0.0090\n",
            "Epoch 81/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0126 - masked_acc: 0.9949 - masked_loss: 0.0126"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0125 - masked_acc: 0.9950 - masked_loss: 0.0125\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0052 - masked_acc: 0.9950 - masked_loss: 0.0052"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0052 - masked_acc: 0.9950 - masked_loss: 0.0052\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0157 - masked_acc: 0.9900 - masked_loss: 0.0157"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 57ms/step - loss: 0.0157 - masked_acc: 0.9900 - masked_loss: 0.0157\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0020 - masked_acc: 1.0000 - masked_loss: 0.0020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0020 - masked_acc: 1.0000 - masked_loss: 0.0020\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0202 - masked_acc: 0.9900 - masked_loss: 0.0202"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0202 - masked_acc: 0.9900 - masked_loss: 0.0202\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4661 - masked_acc: 0.8900 - masked_loss: 0.4661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 57ms/step - loss: 0.4661 - masked_acc: 0.8900 - masked_loss: 0.4661\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6652 - masked_acc: 0.5300 - masked_loss: 2.6652"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 2.6652 - masked_acc: 0.5300 - masked_loss: 2.6652\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5543 - masked_acc: 0.6300 - masked_loss: 1.5543"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 1.5543 - masked_acc: 0.6300 - masked_loss: 1.5543\n",
            "Epoch 89/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.9210 - masked_acc: 0.7677 - masked_loss: 0.9210"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 57ms/step - loss: 0.9133 - masked_acc: 0.7700 - masked_loss: 0.9133\n",
            "Epoch 90/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4078 - masked_acc: 0.8737 - masked_loss: 0.4078"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.4040 - masked_acc: 0.8750 - masked_loss: 0.4040\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2228 - masked_acc: 0.9400 - masked_loss: 0.2228"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 48ms/step - loss: 0.2228 - masked_acc: 0.9400 - masked_loss: 0.2228\n",
            "Epoch 92/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0559 - masked_acc: 0.9848 - masked_loss: 0.0559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 0.0562 - masked_acc: 0.9850 - masked_loss: 0.0562\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0260 - masked_acc: 0.9950 - masked_loss: 0.0260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0260 - masked_acc: 0.9950 - masked_loss: 0.0260\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0126 - masked_acc: 1.0000 - masked_loss: 0.0126"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 53ms/step - loss: 0.0126 - masked_acc: 1.0000 - masked_loss: 0.0126\n",
            "Epoch 95/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0215 - masked_acc: 0.9949 - masked_loss: 0.0215"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 44ms/step - loss: 0.0214 - masked_acc: 0.9950 - masked_loss: 0.0214\n",
            "Epoch 96/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0245 - masked_acc: 0.9899 - masked_loss: 0.0245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.0243 - masked_acc: 0.9900 - masked_loss: 0.0243\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0041 - masked_acc: 1.0000 - masked_loss: 0.0041"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 57ms/step - loss: 0.0041 - masked_acc: 1.0000 - masked_loss: 0.0041\n",
            "Epoch 98/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0229 - masked_acc: 0.9949 - masked_loss: 0.0229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0228 - masked_acc: 0.9950 - masked_loss: 0.0228\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0063 - masked_acc: 1.0000 - masked_loss: 0.0063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 42ms/step - loss: 0.0063 - masked_acc: 1.0000 - masked_loss: 0.0063\n",
            "Epoch 100/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0179 - masked_acc: 0.9949 - masked_loss: 0.0179"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 6s 56ms/step - loss: 0.0177 - masked_acc: 0.9950 - masked_loss: 0.0177\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "e71f8f3a-ad12-4abc-db88-17a44a52cc8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8d45fbcdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "e7de3434-e71f-47d5-a048-db9a70176628"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8d45fef850>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAucElEQVR4nO3deXxU9bn48c+TfQGSkECALAQRWUNYIqhURZQWrLi1iF5rlbr8umhdemtd2kqt3bVebW2v2Lq1LveKSwERryhuFRf2fZMtISsJWSBM1uf3x0zGgFkmIZPJzHner1dezFnmzHPmDPPMdz2iqhhjjHGusEAHYIwxJrAsERhjjMNZIjDGGIezRGCMMQ5nicAYYxwuItABdFZKSopmZWUFOgxjjAkqa9asOaSqA1rbFnSJICsri9WrVwc6DGOMCSoisr+tbVY1ZIwxDue3RCAiT4pIiYhsbmO7iMijIrJbRDaKyCR/xWKMMaZt/iwRPA3Mamf7bGCE5+8m4K9+jMWcIBRHlDc1tX5OtQ2NuOrdf/WNTT0clZuqemNw1TfS2Easxj/a+mwYN7+1Eajq+yKS1c4ulwDPqvsb6WMRSRSRwapa6K+YjFvZkVqu+funREeG8eDcHIYP6OPT8w5WHGPphgKWbCygsMLF3ReO5huT0hAR7z6VNfW8uaWIJRsLWHeggm+fOZTbLjiNqIjO/eZoalLW5R1myYZCXt9USESY8PXswczJGcL49ITjXrOo0sVdr2xka0EVv7k8m/NHpwJQ7arnl0u38tKafJrzXkSYcPaIFObkDOHM4cl8tLuMJRsLWL3vMPNOz+DHXxtJTGQ4qspr6w/yq9e3MbBvDHNyhjAnZzDpSXHe+FbvP8ySDQW8sbmQ6IhwLhrvjm/skH7e+HaXVLN4fQFLNhay99BRb8zJ8VE8cOk4ZmcPbvM9qDzmeS83FPDJnnImDU1kTs4QZo8bTP/4qE69nwCb8iu58+WNVNTUcWH2YC5u5b1slldew9KNhSzeUMD+sqPMGDWQOTlDGJeWwNvbilmyoYDtRdXcfN6p3HD2KYSHCY1Nyt8+2MOfV+5m1KC+XJwzhNnZg0npEw1AfWMTH+4+xJL1Bby1tZjUhBjmjHe/r6f4+BnsrNqGRv741k7+sWo/3z13ON+fPpyIcP/XiO8pPcLSjYUs2VBAYaWLmWNSuThnCNNOTTnu/4KrvpE/vLmD//ksj9ysJOaMH8JZpyaz6vMylmwo4N+fl5GTnuC97gP6RvslXvHnL0NPIliqquNa2bYU+K2qfuhZfhv4iap+qSVYRG7CXWogMzNz8v79bbZ5mBYaGpu44vFVZKXEc9+csSTERlJZU89VT3zM56VHiI0Kx1XfyN2zR3PuaQN4fZP7g7un9Girx6vz/JqekJFImMDaAxV8bWwqP/36GNYecH9pv7+zlLrGJoYmx3HqgD68vb2E0YP78eDc8ZQfrWPx+gJWbCvmaG2j+6ACOekJ3i+NokoXSzYUsHRjIQcrjhEdEcaMUQOpb1Te21lCfaOS2T+OOTmDuTgnjR3F1fzstc3UNjSSlhjL56VHufL0DL42bhA/fXUzhZXHuHrqUIYkxgLuJPjG5iIOVhzznld6UiyjB/fjra3FjBjYhwUXj+WfH+/njc1FTMhIRATWHagAIMrzJdKkSkOTEhMZxvmjU3HVNfLezlIampTIcEEQFKW+UQkTOHN4Mmeekkx4mPv5yzYVsulgJZdPTONHXxvp/Y//yd4ymjyFlvqmJlQhs38cXxmRwsd7ythTepSIMOErI1KYM34IF4xJZXthFUs2FrB8czFVx+q95zV6cF/m5Axh1rhBvLzmIH96ZxcpfaIZl5bgvU7NsbZ1rSdlJnLqwD6s2FZC+dE67/aRqX0Z2C+aD3YdYkpWf26feRoPv7WTT/eVc/aIFIqrXOwsPnLce9aoSmOT0i8mgpljBpF/uIZP95Wj+sU+J0pPiuXr491Jq09MBK97vly3FVa3un98dLjnSzeNxLhI/vOlDWwvqiY7LYFNByuZkJHIH6/I8VviKal2ce+rm3lrazEiMCWrP+lJcazYVkzlsXoS4yKZPW4Qc8YPIT46gv98aQO7So4wc0wqWwuqjvtcpiXGcs5pA1i7/zA7iqsJE/jlpeO4eurQLsUmImtUNbfVbcGQCFrKzc1V6zXkm5U7Spj/1GcADE6IYcHFY/nLyt1sK6zmiWtzGT2oL3e+vJF3d5R6nzN5aBK5WUmEtfIrMSkuklljB5OZHEdjk/L3D/fw4Js7vV8ag/rFeP/TNv/SfGtrMXe/spFDR9xfIn2iI7hg9EAGe76Y6xqaeH9nKbtKjnhfJyJMOOe0AVw0fjAzx6TSNyYSOL608e/dh2gu7U/ISOTheRMYkhjDf63YxePvfU6TQlZyHA9dMYHJQ5OOO4/m0sanew8z9ZT+TMxIRER4f2cpP160geKqWiLDhR99dSQ3en7t5pXXsHxzEeU1X3wZjhrUlwtGpxIf7S5YV9TU8eaWIvaV1Xj3GZwQw6xxgxjYN+a4GOobm/jzO7v588rd3mqitMRYLhg9kDjP8aIjwjhv5EDve6mqbCusZvGGApZsKDjuS6M5IWX2d5dYGpuUjz4/xOaDVd59LpkwhPsvHkdCXCSVx+r5vy1F7DnUetJPjo/ia2MHkeE5XkNjEx99Xsa2wiqmjxzIyEF9UVVeWXuQBYu3UF3bQN/oCH5xyVgum+guJe4oqmbFtmKO1DYAIMCkzCTOOW2A91dxUaWLNzYXUlJd+6UYVGHTwQpWfV5Gy5qdcWn9OGt4CuFhX/6MFlYc462txRytc//QSOkTze+/mc2MUaks2VDATz0/Gl7/4dk+l4R9tXxzIXe/somaukZumXEq35ycwaAE93Wva2jig12lLN7gLg3VeOJL7RfNH76ZwzmnDUBVWZdXwSd7ypkyLImJGUmEec5xR1E1SzYU8PXxgxk9uF+X4uutieBx4F1VfcGzvAOY3lHVkCUC39364jre3VHKk9flcueijXzu+TX5129NZuYYd/WJqrJ4QwGl1bXMGjfIW/Xhq+1FVSzfXMSZpyRzelZ/7we3pbIjtTz3yQFOS+3D9JEDiYkMP267qrKjuJo3NxczoG80s8cNIqmDqo/S6lqWby4kLEyYl5txXHF/zf5yPt5TzvxpWcRFda72s6Kmjqc/2sfXxg7q8n+4ztiQV8G7O0o5+7QUb0Lyhaqy9kAFK7eXMCK1z3EJqaU9pUd4c0sxwwfE89Wxg7o7fMBdZfg/nx5g3pRM0jwJvjuVVLtYtrGQo3WNzB43qMNf8676Rt7dUcKu4iNcfcbQ46rRdhZX89WH3+fXl2XzH1Mzuy3GP7+ziwf/byfZaQk8PC+HUwf2bXPfY3WNvL29mH2HjvKtM4aSGNf5ar6u6K2J4OvAzcCFwFTgUVWd0tExLRH45khtA7kPvMXlk9L59WXZuOobefy9PYxPT+C8UQMDHZ4xAdHUpIz6+XKuOyuLey4c3S3HbGxSpvxqBePSEvjbtblE9kAbRFe0lwj81lgsIi8A04EUEckH7gMiAVT1v4FluJPAbqAGmO+vWJxo+eYiXPVNXD4xDYCYyHBuvWBEgKMyJrDCwoSh/eOOa7g/WZ/tK6fsaB1X5Gb02iTQEX/2Grqqg+0K/MBfr+90r607SGb/uC/VjxvjdFkp8ezrxkSwfHMR0RFhTB/Z6uwNQSE405dpV1Gli39/fohLJ6b5XOdsjFMMS4lnf3lNt4wtaGpS3txSxDmnDWi1jSZYWCIIQf9afxBVuMxTLWSM+UJWcjx1DU0UVB7reOcObDxYSWGli1l+aojvKZYIQoyq8uq6g0zMTGRYSnygwzGm18lKcfeM23eopoM9O/bGZvdgxws8gxiDlSWCEPPCp3lsL6rmytMzAh2KMb1S8w+kvWUn106gqry5uYgzhyeTEBfZHaEFjCWCELKruJr7l27h7BEpzJ1sicCY1qT2jSEmMuykG4y3F1Wzr6yG2ePaniYkWFgiCBGu+kZueWEd8VERPHRFTqsDu4wx7i6kWcnxJ92FdPnmIkTwDs4MZpYIQsRvlm1je1E1D87N+dJ0BsaY4w3rhi6k72wvIXdokt8mgutJlghCQHGVi2dW7efbZw61UcPG+CArJZ4D5TU0dHFa8pq6BrYWVjFlWP9ujiwwLBGEgObJx84baUnAGF8MS46noUmPm7ivMzbmV9LYpEzKDI0Bm5YIQkBJlXvmxlAoohrTE7Kaew51sXpo7YHDAEy0RGB6i9JqFwADLREY45MvxhJ0MRHsr2BYSnyXbhDUG1kiCAEl1bWECST3sURgjC8G9IkmPir8uHtH+EpVWXfgcMhUC4ElgpBQWl1Lcp/oVm/UYYz5MhEhK6VrXUgPlNdQdrSOSUMTuz+wALFEEAJKqmutWsiYTspKiWdfF0YXN7cPWInA9Col1S5rKDamk4Ylx5NXXkNdQ+e6kK7dX0Gf6AhOS237LmTBxhJBCCipshKBMZ2VlRJPk0Le4c61E6w9cJicjISQqoq1RBDkGpuUQ0dqbTSxMZ00rAs9h2rqGtheVB1S1UJgiSDolR+to0lhYD8rERjTGan93D+eyo7U+fycDXmhNZCsmSWCIFfiGUMwwLqOGtMpcVHuO4odq2/0+TlfDCRL9EdIAWOJIMiVVLtHFVuJwJjOiY0MBzqXCNYdOMwpA+JJjAuNgWTNLBEEuVLP9BLWRmBM50RHuL/+aup8TwRbC6oYn5bgr5ACxhJBkCs9YvMMGdMVYWFCbGQ4Lh9LBK76RgqrXAxL6ePnyHqeJYIgV1Llom9MBDGeYq4xxnexUeEc87FEkH+4BlUYmhzn56h6niWCIGejio3putjIcJ+rhvZ75iXKtERgeht3IrD2AWO6IjbK96qh5gnqspLj/RlSQFgiCHKl1bXWY8iYLoqNDPe519CBsqP0jY4gKS7Sz1H1PEsEQUxV3fMM2RgCY7rEXTXU4NO++8tryEyOQyR0ppZoZokgiFXXNuCqb7ISgTFdFBMVzrF63yad219WE5LVQmCJIKiV2BgCY05KXGQ4Lh8aixublPzDNSHZUAyWCIJaafOoYus1ZEyXxEb51kZQUHGM+kZlaH9LBKaX8c4zZInAmC6J8bH7aHPX0aFWNWR6my9KBFY1ZExXxPnYfXR/uXuq6lAcTAaWCIJaSXUtURFh9IuNCHQoxgSl5u6jqtrufvvLaoiKCGNQv9D80eXXRCAis0Rkh4jsFpG7WtmeKSIrRWSdiGwUkQv9GU+oKalydx0Nxe5sxvSE2KhwGpuUusb2ew7tLztKZv84wkLormQt+S0RiEg48BgwGxgDXCUiY07Y7afA/6rqROBK4C/+iicUlR6xwWTGnIzmqahddR0lgpqQbSgG/5YIpgC7VXWPqtYBLwKXnLCPAv08jxOAAj/GE3LsXsXGnJzYqI7vSaCqHCivCdmGYvBvIkgD8los53vWtbQA+JaI5APLgFtaO5CI3CQiq0VkdWlpqT9iDUo2z5AxJ6e5RNDe6OLSI7XU1DWGbEMxBL6x+CrgaVVNBy4E/iEiX4pJVReqaq6q5g4YMKDHg+yNXPWNVB6rt66jxpwEX0oEB0J41tFm/uxuchDIaLGc7lnX0vXALABVXSUiMUAKUOLHuIJWXUMTL6/Np6aukWpXPWCDyYw5Gd42gnYSQSjPOtrMn4ngM2CEiAzDnQCuBP7jhH0OAOcDT4vIaCAGsLqfNny4u5S7X9nkXQ4TGDmobwAjMia4NZcI2htUdqDsKGECaYmxPRVWj/NbIlDVBhG5GXgTCAeeVNUtInI/sFpVFwM/Ap4QkdtxNxxfpx116HWwfYfcv0ze+/F0EuOiiAwX4qJsDIExXeW9gX07iWB/eQ1DEmOJigh0Tbr/+PVbRFWX4W4Ebrnu5y0ebwWm+TOGUHKgvIb4qHAy+4fmVLjG9DRf2gj2hfCso81CN8WFoPzDNWRYEjCm2/hSIsgvd/+/C2WWCILIAQd8II3pSd5E0EaJoLahkbKjdQxOCO1u2pYIgkTzoJZMSwTGdJuOqoaa7/kRqnMMNbNEECRKj9Tiqm+yRGBMN4qOCEOk7aqh4ir3VO+hPpWLJYIgkVd+DMASgTHdSETcM5C2mQg8JQKrGjK9QV65u+toRv/Q7ctsTCDEtXOXsiJPiSA1xKdysUQQJA54EkF6kpUIjOlOMZFtJ4KSKhdREWEkxkX2cFQ9yxJBkDhQXkNqv2hiPL0cjDHdo72qoaIqF4P6xYR8l21LBEEir7yGDCsNGNPt2qsaKq5ykRriDcVgiSBo5FnXUWP8IqaDxuLUEO86CpYIgkJtQyOFVS4bTGaMH8S2USJQVU+JwBKB6QUOHj6GqnUdNcYf4qJaLxFU1zZQU9cY8oPJwBJBUMg77B5DYCUCY7pfW72GShwymAwsEQSF5q6jViIwpvu11WuoqNIZ00uAJYKgkFdeQ1REmN2NzBg/aKvXUPP0EtZGYHqFA2U1ZCTFEhYW2n2ZjQmEWE/V0In3xCqyRGB6k7zDNv20Mf4SExWOKtQ2NB23vqTKRb+YCO8MpaHMEkEvp6ocKLMxBMb4S1s3pymqcoX8ZHPNLBH0cpXH6qmubbBEYIyfxLVxTwKnDCYDSwS9XvP00zbZnDH+0Tx/V03diYnAGYPJwBJBr7c+7zAAQ5MtERjjD81VQ64WJYKmJqWkutYR8wyBJYJerdpVzyNv72ZiZiIjU/sGOhxjQlJcVARwfNXQoaO1NDapI8YQAEQEOgDTtj+/s5tDR2r5+7W51nXUGD+JjXL/Hm5ZNdR8r+KBDkkEViLopfYeOsqT/97L3Mnp5GQkBjocY0JWTCu9hooq3WMInFIisETQS/3q9a1ER4Tz41kjAx2KMSGtuWqoZRtBcbVzBpOBJYJe6aPPD7FiWwm3zDiVgSF+r1RjAi22lV5DxZUuwgRS+kQFKqweZYmgF1q5vYToiDCum5YV6FCMCXneAWUtSwRVtaT0iSYi3Blfkc44yyCzIa+SMUP6ER0R+kPbjQm05ikkWlYNOWlUMVgi6HUam5TNBZXkpCcGOhRjHCEyXAgPk+Mai4urXI6qlrVE0MvsLjlCTV0j49MTAh2KMY4gIsRGhh/fRlDlYlCCMwaTgSWCXmdDfgUA461EYEyPaXnf4qO1DRyuqWdwQmyAo+o5lgh6mY35FfSNjuCUlPhAh2KMY8RGhnvbCPaVHQUgK9k5/wctEfQyG/MrGZeWYCOJjelB7qqhBgD2HXLfGjYrxTnze/k1EYjILBHZISK7ReSuNva5QkS2isgWEXnen/H0drUNjWwrrGJ8hrUPGNOTYqLCOVbvvjGNE0sEfptrSETCgceAmUA+8JmILFbVrS32GQHcDUxT1cMiMtBf8QSD7YXV1Deq9RgypofFRYbj8jQW7z10lNR+0cRHO2cqNn+WCKYAu1V1j6rWAS8Cl5ywz43AY6p6GEBVS/wYT6+30dtQbCUCY3pSbFQ4NfXNVUNHHVUagE6UCETkLCCr5XNU9dl2npIG5LVYzgemnrDPaZ5j/xsIBxao6nJfYwo1G/IrSY6PIi3ROb0VjOkNYiPDveMI9h46yswxqQGOqGf5lAhE5B/AcGA90NzZVoH2EoGvrz8CmA6kA++LSLaqVpzw+jcBNwFkZmae5Ev2XhvzKxifnoCINRQb05Nio8Jx1TdR5aqn7GgdWQ7rtedriSAXGKOq2oljHwQyWiyne9a1lA98oqr1wF4R2Yk7MXzWcidVXQgsBMjNze1MDEHjaG0Du0uOMHvc4ECHYozjNPca2nfIeQ3F4HsbwWZgUCeP/RkwQkSGiUgUcCWw+IR9XsNdGkBEUnBXFe3p5OuEhM0HK2lSyLEeQ8b0uOYBZXs9iWCYlQhalQJsFZFPgdrmlap6cVtPUNUGEbkZeBN3/f+TqrpFRO4HVqvqYs+2r4rIVtxVTj9W1bIunktQW7apEIDstMTABmKMA7kHlDV5E4HT7hHuayJY0JWDq+oyYNkJ637e4rECd3j+HOuxlbt5ZtV+rpqSyYC+zpnfxJjeonkG0u2F1QxJiPHetcwpfEoEqvqeiAwFRqjqChGJw/0r35ykv32whz+8uYNLJgzhgUvHBTocYxyp+Z4EWwurHNdQDD62EYjIjcAi4HHPqjTc9fvmJPzv6jweeH0bs8cN4qG5OYTbtBLGBERzieBAeY0lgnb8AJgGVAGo6i7A0aOAT9bO4mp+9tpmpp2azCNXTnTMnZCM6Y1iW1QFDXNYjyHwPRHUekYHAyAiEbjHEZgucNU38sMX1tEnOoKH500gKsKSgDGB1DIRWImgbe+JyD1ArIjMBF4ClvgvrND2m2Xb2F5UzYNX5DjqLkjG9FZxUS1KBJYI2nQXUApsAv4fsExV7/VbVCHszS1FPLNqP9d/ZRjnjbTaNWN6gxhPIggTyOzvrK6j0Inuo55un0+Ae2ZREXlOVa/2X2ihZ9XnZfzwhXWMT0/gzlkjAx2OMcajuWooLSnWkVW1vp5xhojcDeAZJfwysMtvUYWg1fvKuf6Zz8jsH8dT151OdIT1vjWmt2hOBE6bWqKZr4ngO0C2JxksBd5T1QV+iyrEbMyvYP5Tn5HaL4bnbpxKch8bNGZMb9LcRuDE9gHooGpIRCa1WHwE9ziCf+NuPJ6kqmv9GVwocNU38oPn19IvNpLnbphqjcPG9EL9YiPpGxPBhIzEQIcSEB21ETx0wvJhYIxnvQIz/BFUKPn7h3vJKz/GczdMZYjdZ8CYXikmMpxP77mAmEjntQ9AB4lAVc/rqUBCQWVNPbFR4d7GpqJKF4+t3M1Xx6Qy7dSUAEdnjGlPbJRz2+18vTFNAnAfcI5n1XvA/apa6a/AgkVFTR3LNhWxZEMBH+8tIz0plofmTmDKsP78fvl2GhqVe78+OtBhGmNMm3ztPvok7nsSXOFZvgZ4CrjcH0H1Rk1NSliLuYBUlZfXHuQXi7dQXdvAsJR4/t85w3l9UwHzFq7isglpvLLuIN+fPpyhDu2JYIwJDr4mguGq+o0Wy78QkfV+iKdXOVrbwIptxSzZUMB7O0sZMbAvc3KGcPaIFP70zi7e3FLMlKz+/OyiMYxL64eIcPOMU/nV61t54dM8BvaN5vvnnRro0zDGmHb5mgiOichXVPVDABGZBhzzX1j+cfhoHcu3FLF4fQGf7SunsYM7bzZvHpwQwxW5GWwtrOJ3y7fzu+UQFR7GPReO4vqvnHLcrKF9oiP4zeXjuXRCGv1iI+kT7etbbIwxgeHrt9R3gWc9bQXg7j10rX9C8o8nP9zLr5dto6FJGZYSz3VnZR03v0hrwsPCOOvUZCZnJnmrhfLKa3hvZylThvXntNS+bT536inJ3Rq/Mcb4i6+JoEpVc0SkH4CqVonIMD/G1e2y0xO4/ivDmJMzhLFD3NU4XZHRP45vnTG0m6MzxpjA8TURvAxMUtWqFusWAZO7PyT/OD2rP6dn9Q90GMYY0+t0NLJ4FDAWSBCRlj2E+gE2RNYYY0JARyWCkcBFQCIwp8X6auBGP8VkjDGmB3WUCOKA/wQWquqqHojHGGNMD+soEWTivhtZpIi8DbwBfKraQb9LY4wxQaPdGZZU9XeqOgO4ENiAezrqtSLyvIh8W0RSeyJIY4wx/uNTryFVrQZe9fwhImOA2cCzwNf8Fp0xxhi/a7dEICLfavF4WvNjVd0K1KqqJQFjjAlyHU2+fUeLx386Ydt3ujkWY4wxAdBRIpA2Hre2bIwxJgh1lAi0jcetLRtjjAlCHTUWjxKRjbh//Q/3PMazfIpfIzPGGNMjOkoEOUAqkHfC+gygyC8RGWOM6VEdVQ09DFSq6v6Wf0ClZ5sxxpgg11EiSFXVTSeu9KzL8ktExhhjelRHiSCxnW2x3RiHMcaYAOkoEawWkS/NMioiNwBrOjq4iMwSkR0isltE7mpnv2+IiIpIbschG2OM6U4dNRbfBrwqIlfzxRd/LhAFXNbeE0UkHHgMmAnkA5+JyGLPqOSW+/UFbgU+6XT0xhhjTlq7iUBVi4GzROQ8YJxn9euq+o4Px54C7FbVPQAi8iJwCbD1hP1+CfwO+HFnAjfGGNM9fJ10biWwspPHTuP4bqf5wNSWO4jIJCBDVV8XkTYTgYjcBNwEkJmZ2ckwjDHGtKejNgK/EZEw4I/AjzraV1UXqmququYOGDDA/8EZY4yD+DMRHMQ98KxZumdds764q5veFZF9wBnAYmswNsaYnuXPRPAZMEJEholIFHAlsLh5o6pWqmqKqmapahbwMXCxqq72Y0zGGGNO4LdEoKoNwM3Am8A24H9VdYuI3C8iF/vrdY0xxnSOT43FXaWqy4BlJ6z7eRv7TvdnLMYYY1oXsMZiY4wxvYMlAmOMcThLBMYY43CWCIwxxuEsERhjjMNZIjDGGIezRGCMMQ5nicAYYxzOEoExxjicJQJjjHE4SwTGGONwlgiMMcbhLBEYY4zDWSIwxhiHs0RgjDEOZ4nAGGMczhKBMcY4nCUCY4xxOEsExhjjcJYIjDHG4SwRGGOMw1kiMMYYh7NEYIwxDmeJwBhjHM4SgTHGOJwlAmOMcThLBMYY43CWCIwxxuEsERhjjMNZIjDGGIezRGCMMQ5nicAYYxzOEoExxjicXxOBiMwSkR0isltE7mpl+x0islVENorI2yIy1J/xGGOM+TK/JQIRCQceA2YDY4CrRGTMCbutA3JVdTywCPi9v+IxxhjTOn+WCKYAu1V1j6rWAS8Cl7TcQVVXqmqNZ/FjIN2P8RhjjGmFPxNBGpDXYjnfs64t1wNvtLZBRG4SkdUisrq0tLQbQzTGGNMrGotF5FtALvCH1rar6kJVzVXV3AEDBvRscMYYE+Ii/Hjsg0BGi+V0z7rjiMgFwL3Auapa68d4jDHGtMKfJYLPgBEiMkxEooArgcUtdxCRicDjwMWqWuLHWIwxxrTBbyUCVW0QkZuBN4Fw4ElV3SIi9wOrVXUx7qqgPsBLIgJwQFUv7uxr1dfXk5+fj8vl6sYzMF0VExNDeno6kZGRgQ7FGOMDf1YNoarLgGUnrPt5i8cXdMfr5Ofn07dvX7KysvAkFBMgqkpZWRn5+fkMGzYs0OEYY3zQKxqLT5bL5SI5OdmSQC8gIiQnJ1vpzJggEhKJALAk0IvYtTAmuIRMIjDGGNM1lgiMMcbhLBEEmYaGhkCHYIwJMX7tNRQIv1iyha0FVd16zDFD+nHfnLEd7nfppZeSl5eHy+Xi1ltv5aabbmL58uXcc889NDY2kpKSwttvv82RI0e45ZZbWL16NSLCfffdxze+8Q369OnDkSNHAFi0aBFLly7l6aef5rrrriMmJoZ169Yxbdo0rrzySm699VZcLhexsbE89dRTjBw5ksbGRn7yk5+wfPlywsLCuPHGGxk7diyPPvoor732GgBvvfUWf/nLX3j11Ve79T0yxgSvkEsEgfTkk0/Sv39/jh07xumnn84ll1zCjTfeyPvvv8+wYcMoLy8H4Je//CUJCQls2rQJgMOHD3d47Pz8fD766CPCw8Opqqrigw8+ICIighUrVnDPPffw8ssvs3DhQvbt28f69euJiIigvLycpKQkvv/971NaWsqAAQN46qmn+M53vuPX98EYE1xCLhH48svdXx599FHvL+28vDwWLlzIOeec4+1P379/fwBWrFjBiy++6H1eUlJSh8eeO3cu4eHhAFRWVnLttdeya9cuRIT6+nrvcb/73e8SERFx3Otdc801/POf/2T+/PmsWrWKZ599tpvO2BgTCkIuEQTKu+++y4oVK1i1ahVxcXFMnz6dCRMmsH37dp+P0bLb5Yn98OPj472Pf/azn3Heeefx6quvsm/fPqZPn97ucefPn8+cOXOIiYlh7ty53kRhjDFgjcXdprKykqSkJOLi4ti+fTsff/wxLpeL999/n7179wJ4q4ZmzpzJY4895n1uc9VQamoq27Zto6mpqd06/MrKStLS3DN6P/300971M2fO5PHHH/c2KDe/3pAhQxgyZAgPPPAA8+fP776TNsaEBEsE3WTWrFk0NDQwevRo7rrrLs444wwGDBjAwoULufzyy8nJyWHevHkA/PSnP+Xw4cOMGzeOnJwcVq5cCcBvf/tbLrroIs466ywGDx7c5mvdeeed3H333UycOPG4XkQ33HADmZmZjB8/npycHJ5//nnvtquvvpqMjAxGjx7tp3fAGBOsRFUDHUOn5Obm6urVq49bt23bNvuC68DNN9/MxIkTuf7663vk9eyaGNO7iMgaVc1tbZtVFjvA5MmTiY+P56GHHgp0KMaYXsgSgQOsWbMm0CEYY3oxayMwxhiHs0RgjDEOZ4nAGGMczhKBMcY4nCUCY4xxOEsEAdCnT59Ah2CMMV6h1330jbugaFP3HnNQNsz+bfcesxdoaGiweYeMMVYi6A533XXXcXMHLViwgAceeIDzzz+fSZMmkZ2dzb/+9S+fjnXkyJE2n/fss896p4+45pprACguLuayyy4jJyeHnJwcPvroI/bt28e4ceO8z3vwwQdZsGABANOnT+e2224jNzeXRx55hCVLljB16lQmTpzIBRdcQHFxsTeO+fPnk52dzfjx43n55Zd58sknue2227zHfeKJJ7j99tu7+rYZY3oLVQ2qv8mTJ+uJtm7d+qV1PWnt2rV6zjnneJdHjx6tBw4c0MrKSlVVLS0t1eHDh2tTU5OqqsbHx7d5rPr6+laft3nzZh0xYoSWlpaqqmpZWZmqql5xxRX68MMPq6pqQ0ODVlRU6N69e3Xs2LHeY/7hD3/Q++67T1VVzz33XP3e977n3VZeXu6N64knntA77rhDVVXvvPNOvfXWW4/br7q6Wk855RStq6tTVdUzzzxTN27c2Op5BPqaGGOOB6zWNr5XrV6gG0ycOJGSkhIKCgooLS0lKSmJQYMGcfvtt/P+++8TFhbGwYMHKS4uZtCgQe0eS1W55557vvS8d955h7lz55KSkgJ8ca+Bd955x3t/gfDwcBISEjq80U3z5HfgvuHNvHnzKCwspK6uznvvhLbumTBjxgyWLl3K6NGjqa+vJzs7u5PvljGmt7FE0E3mzp3LokWLKCoqYt68eTz33HOUlpayZs0aIiMjycrK+tI9BlrT1ee1FBERQVNTk3e5vXsb3HLLLdxxxx1cfPHFvPvuu94qpLbccMMN/PrXv2bUqFE2pbUxIcLaCLrJvHnzePHFF1m0aBFz586lsrKSgQMHEhkZycqVK9m/f79Px2nreTNmzOCll16irKwM+OJeA+effz5//etfAWhsbKSyspLU1FRKSkooKyujtraWpUuXtvt6zfc2eOaZZ7zr27pnwtSpU8nLy+P555/nqquu8vXtMcb0YpYIusnYsWOprq4mLS2NwYMHc/XVV7N69Wqys7N59tlnGTVqlE/Haet5Y8eO5d577+Xcc88lJyeHO+64A4BHHnmElStXkp2dzeTJk9m6dSuRkZH8/Oc/Z8qUKcycObPd116wYAFz585l8uTJ3monaPueCQBXXHEF06ZN8+kWm8aY3s/uR2A67aKLLuL222/n/PPPb3MfuybG9C7t3Y/ASgTGZxUVFZx22mnExsa2mwSMMcHFGosDZNOmTd6xAM2io6P55JNPAhRRxxITE9m5c2egwzDGdLOQSQSqiogEOgyfZWdns379+kCH4RfBVt1ojNOFRNVQTEwMZWVl9gXUC6gqZWVlxMTEBDoUY4yPQqJEkJ6eTn5+PqWlpYEOxeBOzOnp6YEOwxjjo5BIBJGRkd4RscYYYzrHr1VDIjJLRHaIyG4RuauV7dEi8j+e7Z+ISJY/4zHGGPNlfksEIhIOPAbMBsYAV4nImBN2ux44rKqnAg8Dv/NXPMYYY1rnzxLBFGC3qu5R1TrgReCSE/a5BGie12ARcL4EU9cfY4wJAf5sI0gD8los5wNT29pHVRtEpBJIBg613ElEbgJu8iweEZEdXYwp5cRjO4QTz9uJ5wzOPG8nnjN0/ryHtrUhKBqLVXUhsPBkjyMiq9saYh3KnHjeTjxncOZ5O/GcoXvP259VQweBjBbL6Z51re4jIhFAAlDmx5iMMcacwJ+J4DNghIgME5Eo4Epg8Qn7LAau9Tz+JvCO2qgwY4zpUX6rGvLU+d8MvAmEA0+q6hYRuR/3LdMWA38H/iEiu4Fy3MnCn066eilIOfG8nXjO4MzzduI5Qzeed9BNQ22MMaZ7hcRcQ8YYY7rOEoExxjicYxJBR9NdhAIRyRCRlSKyVUS2iMitnvX9ReQtEdnl+Tfk7jEpIuEisk5ElnqWh3mmLdntmcYkKtAxdjcRSRSRRSKyXUS2iciZDrnWt3s+35tF5AURiQm16y0iT4pIiYhsbrGu1Wsrbo96zn2jiEzq7Os5IhH4ON1FKGgAfqSqY4AzgB94zvMu4G1VHQG87VkONbcC21os/w542DN9yWHc05mEmkeA5ao6CsjBff4hfa1FJA34IZCrquNwd0S5ktC73k8Ds05Y19a1nQ2M8PzdBPy1sy/miESAb9NdBD1VLVTVtZ7H1bi/GNI4fiqPZ4BLAxKgn4hIOvB14G+eZQFm4J62BELznBOAc3D3vENV61S1ghC/1h4RQKxn7FEcUEiIXW9VfR93T8qW2rq2lwDPqtvHQKKIDO7M6zklEbQ23UVagGLpEZ6ZXCcCnwCpqlro2VQEpAYqLj/5L+BOoMmznAxUqGqDZzkUr/cwoBR4ylMl9jcRiSfEr7WqHgQeBA7gTgCVwBpC/3pD29f2pL/fnJIIHEVE+gAvA7epalXLbZ4BeyHTZ1hELgJKVHVNoGPpYRHAJOCvqjoROMoJ1UChdq0BPPXil+BOhEOAeL5chRLyuvvaOiUR+DLdRUgQkUjcSeA5VX3Fs7q4uajo+bckUPH5wTTgYhHZh7vKbwbuuvNET9UBhOb1zgfyVfUTz/Ii3IkhlK81wAXAXlUtVdV64BXcn4FQv97Q9rU96e83pyQCX6a7CHqeuvG/A9tU9Y8tNrWcyuNa4F89HZu/qOrdqpquqlm4r+s7qno1sBL3tCUQYucMoKpFQJ6IjPSsOh/YSghfa48DwBkiEuf5vDefd0hfb4+2ru1i4Nue3kNnAJUtqpB8o6qO+AMuBHYCnwP3BjoeP53jV3AXFzcC6z1/F+KuM38b2AWsAPoHOlY/nf90YKnn8SnAp8Bu4CUgOtDx+eF8JwCrPdf7NSDJCdca+AWwHdgM/AOIDrXrDbyAuw2kHnfp7/q2ri0guHtFfg5swt2jqlOvZ1NMGGOMwzmlasgYY0wbLBEYY4zDWSIwxhiHs0RgjDEOZ4nAGGMczhKBcTQRaRSR9S3+um2SNhHJajl7pA/7x4vICs/jD1sMkDLGr+yDZpzumKpOCHQQHmcCqzzTKBzVL+bOMcavrERgTCtEZJ+I/F5ENonIpyJyqmd9loi845n3/W0RyfSsTxWRV0Vkg+fvLM+hwkXkCc/8+f8nIrGtvNZwEVkP/BP4D9yTqOV4SigDe+aMjZNZIjBOF3tC1dC8FtsqVTUb+DPuGU4B/gQ8o6rjgeeARz3rHwXeU9Uc3HP+bPGsHwE8pqpjgQrgGycGoKqfe0ola3BPmf4McL2qTlDVUJsryPRCNrLYOJqIHFHVPq2s3wfMUNU9non8ilQ1WUQOAYNVtd6zvlBVU0SkFEhX1doWx8gC3lL3jUQQkZ8Akar6QBuxfKaqp4vIy8Ctqprf3edrTGusRGBM27SNx51R2+JxI620y4nIf3salUd4qohmAUtF5PYuvqYxnWKJwJi2zWvx7yrP449wz3IKcDXwgefx28D3wHv/5ARfX0RVv4t7IrVf4r7r1OueaqGHTyp6Y3xkvYaM08V6foU3W66qzV1Ik0RkI+5f9Vd51t2C+65gP8Z9h7D5nvW3AgtF5Hrcv/y/h3v2SF+dCzwLnA2815UTMaarrI3AmFZ42ghyVfVQoGMxxt+sasgYYxzOSgTGGONwViIwxhiHs0RgjDEOZ4nAGGMczhKBMcY4nCUCY4xxuP8P/bGOjQ79Vc8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('ecomm.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "377e0bd8-c302-4df3-ac5e-1ff772e979d0"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a2e7945-401a-4939-9c37-23374c6c4c68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a2e7945-401a-4939-9c37-23374c6c4c68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a2e7945-401a-4939-9c37-23374c6c4c68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a2e7945-401a-4939-9c37-23374c6c4c68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "b15d32b1-8f35-4f59-b17c-1efdc4a861d0"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(147,)\n",
            "(147,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "6f171731-6b14-4001-dba1-243e26e5ff71"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('ecomm_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "81d402d1-10bd-43bf-b94d-9b5d779cbda4"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "1  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "2  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "3  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "4  moduleom_name:0,opendeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d12caeb-c8bb-478e-88c0-4fa72db98fb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d12caeb-c8bb-478e-88c0-4fa72db98fb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d12caeb-c8bb-478e-88c0-4fa72db98fb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d12caeb-c8bb-478e-88c0-4fa72db98fb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "c7b6845c-1f7e-44d8-8125-a2c328e88328"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "fa736e5b-edff-4845-a6e6-580586d3f44c"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.181818\n",
            "Testing: Recall = 0.800000\n",
            "Testing: F1 Score = 0.296296\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[32 90]\n",
            " [ 5 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "29b285fc-b0ca-46a4-d6fe-9c68a19f4559"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.26      0.40       122\n",
            "           1       0.18      0.80      0.30        25\n",
            "\n",
            "    accuracy                           0.35       147\n",
            "   macro avg       0.52      0.53      0.35       147\n",
            "weighted avg       0.75      0.35      0.38       147\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
