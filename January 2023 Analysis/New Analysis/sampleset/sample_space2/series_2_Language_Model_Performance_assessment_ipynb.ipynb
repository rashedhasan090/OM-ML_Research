{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "[link text](https://)  \n",
        "#  series 2 : Language Model Performance assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGFTkuRvzWqc",
        "outputId": "f88ab4ef-86cc-4892-bc53-22bcae956844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text>=2.10\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text>=2.10) (0.12.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (15.0.6.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.3.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.2.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.3.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.51.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (21.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.29.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (5.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.1.21 keras-2.11.0 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text>=2.10\"\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "#### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('dummy_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "28d7a8f7-abca-4f79-a02c-d7601ec072ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                OM_Regular               OM_Prediction\n",
              "0  class1,table1,obj1,atr1  class1,table1,obj1,atr1,NP\n",
              "1  class1,table2,obj1,atr1  class1,table2,obj1,atr1,NP\n",
              "2  class1,table3,obj1,atr1  class1,table3,obj1,atr1,NP\n",
              "3  class1,table4,obj1,atr1  class1,table4,obj1,atr1,NP\n",
              "4  class1,table5,obj1,atr1  class1,table5,obj1,atr1,NP"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c94d3d4-f4e2-428a-b57f-a1d4d8f9c490\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class1,table1,obj1,atr1</td>\n",
              "      <td>class1,table1,obj1,atr1,NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>class1,table2,obj1,atr1</td>\n",
              "      <td>class1,table2,obj1,atr1,NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>class1,table3,obj1,atr1</td>\n",
              "      <td>class1,table3,obj1,atr1,NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>class1,table4,obj1,atr1</td>\n",
              "      <td>class1,table4,obj1,atr1,NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>class1,table5,obj1,atr1</td>\n",
              "      <td>class1,table5,obj1,atr1,NP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c94d3d4-f4e2-428a-b57f-a1d4d8f9c490')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c94d3d4-f4e2-428a-b57f-a1d4d8f9c490 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c94d3d4-f4e2-428a-b57f-a1d4d8f9c490');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTbSbBz55QtF",
        "outputId": "58d90e7a-e1a5-4e82-dc7a-0baf167e6c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class34,table25,obj23,atr15\n"
          ]
        }
      ],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH_dPY8TRp3c",
        "outputId": "7a5a8fff-b4ee-4028-85ee-d2c71d79a2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class34,table25,obj23,atr15,P\n"
          ]
        }
      ],
      "source": [
        "print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc6-NK1GtWQt",
        "outputId": "b6ef2535-9e75-4d4d-d635-579ce0df2f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'class4,table15,obj2,atr2'], shape=(1,), dtype=string)\n",
            "\n",
            "tf.Tensor([b'class4,table15,obj2,atr2,NP'], shape=(1,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD0e-DWGQ2Vo",
        "outputId": "49f2c90c-0071-4515-a97d-348721e41695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'class1,table2,obj1,atr1'\n",
            "b'class1,table2,obj1,atr1'\n"
          ]
        }
      ],
      "source": [
        "#example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  #text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  #pattern = '\\s+'\n",
        "  #re.split(pattern, text, maxsplit=2)\n",
        "  #text = tf.strings.regex_replace(text, '\\s+', '')\n",
        "  #tf.strings.split(text, sep=', ', maxsplit=2, name=None)\n",
        "  #tf.strings.split (text, sep='\\s+', maxsplit=2, name=None)\n",
        "  #text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  #tf.strings.split(text, ',')\n",
        "  #text = tf.strings.split(text, sep=None, maxsplit=-1, name=None)\n",
        "  #text.tf.strings.split(', ')\n",
        "\n",
        "  # Add spaces around punctuation.\n",
        "  #text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  #text = tf.strings.strip(text)\n",
        "\n",
        "  #text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  #return text\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'\\0')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UREvDg3sEKYa",
        "outputId": "13793d6e-c776-40be-c1ec-51d4259ba508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table2,obj1,atr1\n",
            "[START] class1,table2,obj1,atr1 [END]\n"
          ]
        }
      ],
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmsI1Yql8FYe",
        "outputId": "edeaac12-44a0-4b06-e334-4dab414e3795"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'class6,table8,obj1,atr1',\n",
              " 'class6,table7,obj1,atr1',\n",
              " 'class6,table6,obj1,atr1',\n",
              " 'class6,table5,obj1,atr1',\n",
              " 'class6,table4,obj1,atr1',\n",
              " 'class6,table3,obj1,atr1',\n",
              " 'class6,table2,obj1,atr1',\n",
              " 'class6,table18,obj1,atr1',\n",
              " 'class6,table17,obj1,atr1',\n",
              " 'class6,table16,obj1,atr1',\n",
              " 'class6,table15,obj1,atr1',\n",
              " 'class6,table14,obj1,atr1',\n",
              " 'class6,table12,obj1,atr1',\n",
              " 'class6,table10,obj1,atr1',\n",
              " 'class6,table1,obj1,atr1',\n",
              " 'class5,table9,obj1,atr1',\n",
              " 'class5,table8,obj1,atr1',\n",
              " 'class5,table7,obj1,atr1',\n",
              " 'class5,table6,obj1,atr1',\n",
              " 'class5,table4,obj1,atr1',\n",
              " 'class5,table3,obj1,atr1',\n",
              " 'class5,table17,obj1,atr1',\n",
              " 'class5,table16,obj1,atr1',\n",
              " 'class5,table15,obj1,atr1',\n",
              " 'class5,table14,obj1,atr1',\n",
              " 'class5,table13,obj1,atr1',\n",
              " 'class5,table12,obj1,atr1',\n",
              " 'class5,table11,obj1,atr1',\n",
              " 'class5,table1,obj1,atr1',\n",
              " 'class4,table9,obj2,atr2',\n",
              " 'class4,table8,obj2,atr2',\n",
              " 'class4,table6,obj2,atr2',\n",
              " 'class4,table5,obj2,atr2',\n",
              " 'class4,table4,obj2,atr2',\n",
              " 'class4,table3,obj2,atr2',\n",
              " 'class4,table18,obj2,atr2',\n",
              " 'class4,table17,obj2,atr2',\n",
              " 'class4,table15,obj2,atr2',\n",
              " 'class4,table14,obj2,atr2',\n",
              " 'class4,table13,obj2,atr2',\n",
              " 'class4,table12,obj2,atr2',\n",
              " 'class4,table11,obj2,atr2',\n",
              " 'class4,table10,obj2,atr2',\n",
              " 'class4,table1,obj2,atr2',\n",
              " 'class34,table25,obj23,atr15',\n",
              " 'class34,table24,obj23,atr14']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "context_text_processor.get_vocabulary()[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlC4xuZnKLBS",
        "outputId": "8865d370-e238-4105-c36c-8b3b7d464ca5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'class6,table8,obj1,atr1,np',\n",
              " 'class6,table7,obj1,atr1,np',\n",
              " 'class6,table6,obj1,atr1,np',\n",
              " 'class6,table5,obj1,atr1,np',\n",
              " 'class6,table4,obj1,atr1,np',\n",
              " 'class6,table3,obj1,atr1,np',\n",
              " 'class6,table2,obj1,atr1,np',\n",
              " 'class6,table18,obj1,atr1,np',\n",
              " 'class6,table17,obj1,atr1,np',\n",
              " 'class6,table16,obj1,atr1,np',\n",
              " 'class6,table15,obj1,atr1,np',\n",
              " 'class6,table14,obj1,atr1,np',\n",
              " 'class6,table12,obj1,atr1,np',\n",
              " 'class6,table10,obj1,atr1,np',\n",
              " 'class6,table1,obj1,atr1,np',\n",
              " 'class5,table9,obj1,atr1,np',\n",
              " 'class5,table8,obj1,atr1,np',\n",
              " 'class5,table7,obj1,atr1,np',\n",
              " 'class5,table6,obj1,atr1,np',\n",
              " 'class5,table4,obj1,atr1,np',\n",
              " 'class5,table3,obj1,atr1,np',\n",
              " 'class5,table17,obj1,atr1,np',\n",
              " 'class5,table16,obj1,atr1,np',\n",
              " 'class5,table15,obj1,atr1,np',\n",
              " 'class5,table14,obj1,atr1,np',\n",
              " 'class5,table13,obj1,atr1,np',\n",
              " 'class5,table12,obj1,atr1,np',\n",
              " 'class5,table11,obj1,atr1,np',\n",
              " 'class5,table1,obj1,atr1,np',\n",
              " 'class4,table9,obj2,atr2,np',\n",
              " 'class4,table8,obj2,atr2,np',\n",
              " 'class4,table6,obj2,atr2,np',\n",
              " 'class4,table5,obj2,atr2,np',\n",
              " 'class4,table4,obj2,atr2,np',\n",
              " 'class4,table3,obj2,atr2,np',\n",
              " 'class4,table18,obj2,atr2,np',\n",
              " 'class4,table17,obj2,atr2,np',\n",
              " 'class4,table15,obj2,atr2,np',\n",
              " 'class4,table14,obj2,atr2,np',\n",
              " 'class4,table13,obj2,atr2,np',\n",
              " 'class4,table12,obj2,atr2,np',\n",
              " 'class4,table11,obj2,atr2,np',\n",
              " 'class4,table10,obj2,atr2,np',\n",
              " 'class4,table1,obj2,atr2,np',\n",
              " 'class34,table25,obj23,atr15,p',\n",
              " 'class34,table24,obj23,atr14,p']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "target_text_processor.get_vocabulary()[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "ff2a5201-5738-4434-8335-d8a0c1497fe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 41, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "98g9rcxGQY0I",
        "outputId": "ca56b087-e94b-411f-c1c5-f11f9bd14bb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] class4,table15,obj2,atr2 [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "3237a533-3451-4fb0-e08d-5afe3c9650e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "967910b5-cf0a-47d6-fc8b-aaa2fef0b497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 17  3]\n",
            "\n",
            "[ 2 17]\n",
            "[17  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "da17be9f-459a-4c2d-ba58-ded6c86e6275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "    # Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y7hjPkNMmHh",
        "outputId": "c9241804-ecf5-405e-a29a-4e096706ece0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ],
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                  output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "d6b8ba02-6000-4be0-8c27-d9fc5b68a1e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Rqr8XGsAJlf6",
        "outputId": "05240eb0-d99e-42b6-bb06-bc4c8466c526"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATxklEQVR4nO3cf7RdZX3n8fenCRBBwFHUYhKFasqYVkHMIB2nA6O4GphZxE5/LBjboqWmLodZtnVscdVSi/1lp6u2trRMZomMzAClaF2xTRt1ilCrIMEfaMhgI0WSKAKBCIwVEvzOH3tHT6433pObfe7NfXy/1rqLs/d+7j7fffnez33ynLNPqgpJUlu+Z74LkCQNz3CXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4T6Hklye5Nfmu47pJPnhJHeOOfbMJNsnXZMEkOQjSX5uvutYaJoP974xHkpyxJT9dyc5a2T7hCSVZPFAz/vqJB8d3VdVr6uqtw1x/qFV1d9X1UlDnCvJlUl+c4hzaWHof58eT3LclP2f6n+vTpifyr57NR3ufUP9MFDAufNajNS+fwLO37uR5AXAkfNXzne3psMd+BngZuBK4IK9O5NcBTwb+ECSR5P8MnBTf3hXv++H+rE/m2RLP/vfmOQ5I+epJK9L8o9JdiW5LJ3nA5cDP9Sfa1c/fp8ZbZLXJtma5MEk65M8a6ZzT73AJEuS/PPeGVOSX02yJ8kx/fbbkvxh//iIJL+f5J4kX+mXiZ7UH9tnqSXJqf2s65Ekf5Hkz6fOxpO8Mcl9Sb6c5DX9vrXAq4Bf7q/9A/3+X0myoz/fnUlefiD/I7UgXEX3O7fXBcB79m4k+fd9Tz2cZFuSt44cW5LkfyXZ2ff7rUmeOfUJkhyf5PYkb5rkhTShqpr9ArYCrwdeDOwGnjly7G7grJHtE+hm+ItH9q3pz/F8YDHwFuBjI8cL+CvgKXR/LO4HVvfHXg18dEo9VwK/2T9+GfAAcCpwBPDHwE3jnHua67wJ+LH+8QeBLwBnjxz70f7xO4D1wFOBo4EPAL/THzsT2N4/Phz4IvAG4DDgPwKPj9R+JrAHuLQ/fg7wNeBfTL3OfvskYBvwrJGf9XPnuz/8GvR37W7gLODO/vdlEbAdeE7fyyf0ffMCuknlC4GvAK/sv//n+348sv/eFwPH9Mc+AvwccCLweWDtfF/vQvhqduae5N/QNdZ1VXUbXeD9pwM8zevowm9LVe0Bfhs4ZXT2DvxuVe2qqnuAG4BTxjz3q4ArquqTVfUY8Ga6mf4Jszj3jcAZ/esFLwTe2W8vAf4VcFM/618L/GJVPVhVj/TXc9405zud7o/ZO6tqd1W9D/jElDG7gUv74xuAR+lCfDpP0P0BW5nksKq6u6q+sL8fjBa0vbP3VwBbgB17D1TVR6rqs1X1jaq6HbgGOKM/vBt4GvC8qnqiqm6rqodHzruS7nfg16tq3VxcyELXbLjT/ZPwg1X1QL99NSNLM2N6DvBH/T8TdwEPAgGWjoy5d+Tx14Anj3nuZ9HNjgGoqkeBnbM89410s6JTgc8CH6L7pTkd2FpVO4Gn082Kbhu5nr/t909X247qp029bVPG7Oz/4M1YX1VtBX4BeCtwX5JrR5eg1JSr6CZRr2ZkSQYgyUuS3JDk/iRfpZs8HTfyfRuBa5N8KcnvJTls5NtfRfeH4vpJX0Armgz3fh35J+lmr/cmuRf4ReDkJCf3w6Z+HOZ0H4+5Dfj5qnrKyNeTqupjY5Qx08dtfonuj8femo+im7ns2O937N/H6GbNPwrcWFV30C3lnEMX/NAtAf0z8AMj13JsVU0XyF8Glk5Z419+APV827VX1dVVtfdfUwW8/QDOpwWiqr5I98LqOcD7phy+mm5ZcHlVHUv3ulT679tdVb9RVSuBfw38B/Zdv38rXQ9fnWTRRC+iEU2GO/BKuqWAlXRLGafQrQP+Pd9qmK8A3zfyPfcD35iy73LgzUl+ACDJsUl+YswavgIsS3L4fo5fA7wmySnp3qb528AtVXX3mOf/pqr6GnAb8J/5Vph/jG5mdGM/5hvA/wDekeQZ/fUsTfIj05zy43Q/v4uSLE6yBjjtAEra52eb5KQkL+uv8+t0f2S+cQDn08JyIfCyqvp/U/YfDTxYVV9Pchojy6RJ/l2SF/TB/TDdMs1oj+wGfgI4CnhPklazazCt/oAuAN5dVfdU1b17v4A/AV7Vr03/DvCWfoniv/YB+VvAP/T7Tq+qv6SbYV6b5GHgc8DZY9bwd8Bm4N4kD0w9WFUfBn4NeC/dTPm5TL/+Pa4b6V7c/MTI9tF8611AAL9C9wLxzf31fJhp1smr6nG6F1EvBHYBP0X34u5jY9byLrr19V1J3k+33v67dDOve4Fn0L3GoAZV1ReqatM0h14PXJrkEeAS4LqRY99Lt+TyMN1a/Y10SzWj593bl88ErjDgv7Psu6wqTS/JLcDlVfXu+a5F0sz8y6dpJTkjyff2yzIX0L0L52/nuy5J45kx3JNc0d+o8rn9HE+Sd6a7Gef2JKcOX6bmwUnAZ+iWZd4I/HhVfXl+SxqWva2WjTNzvxJY/R2Onw2s6L/WAn928GVpvlXVuqp6ZlU9uapeWFV/Pd81TcCV2Ntq1IzhXlU30b2/e3/WAO+pzs3AU5IcP1SB0qTY22rZEJ+AuJR9b3DZ3u/7tn/C9587shbgqCPz4n/5vP29S3Dh+Oyu6e4BWpiOuGfqO9cWrkd46IGqOtj/ObPq7UUsevGRHHOQTy1Nb9zeHuTjbcfV3za8DmDVyUvqExufPZdPPxHf9/61813CYFa8/pb5LmEwH67rvzjzqOGM9vYxeWq9xM9F04SM29tDvFtmB/vevbiM2d1lKR1q7G0tWEOE+3rgZ/p3FpwOfLW1d1Xou5a9rQVrxmWZJNfQfSjVcek+7/vX6e6EpKouBzbQfY7EVroPj3rNpIqVhmRvq2UzhntVnT/D8aL7TBNpQbG31TLvUJWkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkho0VrgnWZ3kziRbk1w8zfFnJ7khyaeS3J7knOFLlYZnb6tVM4Z7kkXAZcDZwErg/CQrpwx7C3BdVb0IOA/406ELlYZmb6tl48zcTwO2VtVdVfU4cC2wZsqYAo7pHx8LfGm4EqWJsbfVrMVjjFkKbBvZ3g68ZMqYtwIfTPJfgKOAs6Y7UZK1wFqAZy8d56mliZpIby/hyMELlQ7UUC+ong9cWVXLgHOAq5J827mral1VraqqVU9/2qKBnlqaqAPu7cM4Ys6LlKYaJ9x3AMtHtpf1+0ZdCFwHUFUfB5YAxw1RoDRB9raaNU643wqsSHJiksPpXlRaP2XMPcDLAZI8n+4X4P4hC5UmwN5Ws2YM96raA1wEbAS20L1zYHOSS5Oc2w97I/DaJJ8BrgFeXVU1qaKlIdjbatlYr2pW1QZgw5R9l4w8vgN46bClSZNnb6tV3qEqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUFjhXuS1UnuTLI1ycX7GfOTSe5IsjnJ1cOWKQ3PvlbLFs80IMki4DLgFcB24NYk66vqjpExK4A3Ay+tqoeSPGNSBUtDsK/VunFm7qcBW6vqrqp6HLgWWDNlzGuBy6rqIYCqum/YMqXB2ddq2jjhvhTYNrK9vd836vuB70/yD0luTrJ6uhMlWZtkU5JN9+98YnYVS8MYrK9h397ezWMTKFc6MDMuyxzAeVYAZwLLgJuSvKCqdo0Oqqp1wDqAVScvqYGeW5qUsfoa9u3tY/JUe1vzbpyZ+w5g+cj2sn7fqO3A+qraXVX/BHye7pdCOlTZ12raOOF+K7AiyYlJDgfOA9ZPGfN+utkNSY6j++fsXQPWKQ3NvlbTZgz3qtoDXARsBLYA11XV5iSXJjm3H7YR2JnkDuAG4E1VtXNSRUsHy75W68Zac6+qDcCGKfsuGXlcwC/1X9KCYF+rZd6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWiscE+yOsmdSbYmufg7jPuxJJVk1XAlSpNjb6tVM4Z7kkXAZcDZwErg/CQrpxl3NPAG4Jahi5Qmwd5Wy8aZuZ8GbK2qu6rqceBaYM00494GvB34+oD1SZNkb6tZ44T7UmDbyPb2ft83JTkVWF5Vf/2dTpRkbZJNSTbdv/OJAy5WGthEens3jw1fqXSADvoF1STfA/wB8MaZxlbVuqpaVVWrnv60RQf71NJEzba3D+OIyRcnzWCccN8BLB/ZXtbv2+to4AeBjyS5GzgdWO8LT1oA7G01a5xwvxVYkeTEJIcD5wHr9x6sqq9W1XFVdUJVnQDcDJxbVZsmUrE0HHtbzZox3KtqD3ARsBHYAlxXVZuTXJrk3EkXKE2Kva2WLR5nUFVtADZM2XfJfsaeefBlSXPD3larvENVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoPGCvckq5PcmWRrkounOf5LSe5IcnuS/5PkOcOXKg3LvlbLZgz3JIuAy4CzgZXA+UlWThn2KWBVVb0QuB74vaELlYZkX6t148zcTwO2VtVdVfU4cC2wZnRAVd1QVV/rN28Glg1bpjQ4+1pNGyfclwLbRra39/v250Lgb6Y7kGRtkk1JNt2/84nxq5SGN1hfw769vZvHBipRmr3FQ54syU8Bq4AzpjteVeuAdQCrTl5SQz63NCkz9TXs29vH5Kn2tubdOOG+A1g+sr2s37ePJGcBvwqcUVVOXXSos6/VtHGWZW4FViQ5McnhwHnA+tEBSV4E/Hfg3Kq6b/gypcHZ12rajOFeVXuAi4CNwBbguqranOTSJOf2w/4b8GTgL5J8Osn6/ZxOOiTY12rdWGvuVbUB2DBl3yUjj88auC5p4uxrtcw7VCWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAaNFe5JVie5M8nWJBdPc/yIJH/eH78lyQlDFypNgr2tVs0Y7kkWAZcBZwMrgfOTrJwy7ELgoap6HvAO4O1DFyoNzd5Wy8aZuZ8GbK2qu6rqceBaYM2UMWuA/9k/vh54eZIMV6Y0Efa2mrV4jDFLgW0j29uBl+xvTFXtSfJV4GnAA6ODkqwF1vabjy06/h8/N5uiDy1vAjiOKde6EH2x+08T1wKcNMaYifX2h+v6Bnq7mV6Atq5lnN4eK9wHU1XrgHUASTZV1aq5fP5J8VoOPUk2zeXztdjbrVwHtHct44wbZ1lmB7B8ZHtZv2/aMUkWA8cCO8cpQJpH9raaNU643wqsSHJiksOB84D1U8asBy7oH/848HdVVcOVKU2Eva1mzbgs068zXgRsBBYBV1TV5iSXApuqaj3wLuCqJFuBB+l+SWay7iDqPtR4LYeeGa/D3p5RK9cB34XXEichktQe71CVpAYZ7pLUoHkJ95lu+V4oklyR5L4kC/o9zUmWJ7khyR1JNid5w3zXNFtJliT5RJLP9NfyG3P43Pb1IaaV3p5NX8/5mnt/y/fngVfQ3TRyK3B+Vd0xp4UMIMm/BR4F3lNVPzjf9cxWkuOB46vqk0mOBm4DXrlA/58EOKqqHk1yGPBR4A1VdfOEn9e+PgS10tuz6ev5mLmPc8v3glBVN9G9g2JBq6ovV9Un+8ePAFvo7sxccKrzaL95WP81FzMY+/oQ1Epvz6av5yPcp7vle8H9sFvVf+rhi4Bb5reS2UuyKMmngfuAD1XVXFyLfX2IW+i9faB97Quq+qYkTwbeC/xCVT083/XMVlU9UVWn0N1xelqSBb20oIPXQm8faF/PR7iPc8u35li/jvde4H9X1fvmu54hVNUu4AZg9Rw8nX19iGqtt8ft6/kI93Fu+dYc6l+seRewpar+YL7rORhJnp7kKf3jJ9G9wPl/5+Cp7etDUCu9PZu+nvNwr6o9wN5bvrcA11XV5rmuYwhJrgE+DpyUZHuSC+e7pll6KfDTwMuSfLr/Ome+i5ql44EbktxOF7gfqqq/mvST2teHrFZ6+4D72o8fkKQG+YKqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkN+v/iPaYAJb9gQgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "ca371450-bca6-472f-facb-661284e07bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 105)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuehagxL-JBZ",
        "outputId": "a6b007a9-4169-4920-cabd-20d8c7413388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'class6,table5,obj1,atr1,np class34,table16,obj23,atr6,p class3,table12,obj1,atr1,np [START] class1,table7,obj1,atr1,np class6,table5,obj1,atr1,np class34,table23,obj23,atr13,p class2,table4,obj2,atr2,np class1,table17,obj1,atr1,np class2,table2,obj2,atr2,np'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ALTdqCMLGSY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "**Since the model's untrained, it outputs items from the vocabulary almost uniformly at random. **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "4f044fda-c98b-41e4-b81c-7096954eb130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 105)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FmzjGmprVmE"
      },
      "source": [
        "For training, you'll want to implement your own masked loss and accuracy functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "4bdf03d4-ee77-495e-c236-ae920754ac81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 4.65396, 'expected_acc': 0.009523809523809525}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "2f3ff266-aae0-468b-fbc1-5a94ec2d6026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/40 [===========>..................] - ETA: 0s - loss: 4.2704 - masked_acc: 0.0000e+00 - masked_loss: 4.2704"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 12s 12ms/step - loss: 4.2704 - masked_acc: 0.0000e+00 - masked_loss: 4.2704\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 4.270423889160156,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 4.270423889160156}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=40, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "f6dd12d6-6361-4ccd-8f93-7cf44b7abc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 3.1436 - masked_acc: 0.4949 - masked_loss: 3.1436"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 16s 21ms/step - loss: 3.1348 - masked_acc: 0.4950 - masked_loss: 3.1348 - val_loss: 2.4819 - val_masked_acc: 0.5000 - val_masked_loss: 2.4819\n",
            "Epoch 2/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 3.0121 - masked_acc: 0.5000 - masked_loss: 3.0121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.0026 - masked_acc: 0.5000 - masked_loss: 3.0026\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.8716 - masked_acc: 0.5000 - masked_loss: 2.8716"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.8716 - masked_acc: 0.5000 - masked_loss: 2.8716\n",
            "Epoch 4/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.4454 - masked_acc: 0.5000 - masked_loss: 2.4454"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.4398 - masked_acc: 0.5000 - masked_loss: 2.4398\n",
            "Epoch 5/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.1591 - masked_acc: 0.5000 - masked_loss: 2.1591"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.1498 - masked_acc: 0.5000 - masked_loss: 2.1498\n",
            "Epoch 6/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.5281 - masked_acc: 0.5612 - masked_loss: 1.5281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.5210 - masked_acc: 0.5650 - masked_loss: 1.5210\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7066 - masked_acc: 0.8000 - masked_loss: 0.7066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.7066 - masked_acc: 0.8000 - masked_loss: 0.7066\n",
            "Epoch 8/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.2250 - masked_acc: 0.9490 - masked_loss: 0.2250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.2283 - masked_acc: 0.9500 - masked_loss: 0.2283\n",
            "Epoch 9/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0491 - masked_acc: 1.0000 - masked_loss: 0.0491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0487 - masked_acc: 1.0000 - masked_loss: 0.0487\n",
            "Epoch 10/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0143 - masked_acc: 1.0000 - masked_loss: 0.0143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0143 - masked_acc: 1.0000 - masked_loss: 0.0143\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0096 - masked_acc: 1.0000 - masked_loss: 0.0096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0096 - masked_acc: 1.0000 - masked_loss: 0.0096\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0081 - masked_acc: 1.0000 - masked_loss: 0.0081"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0081 - masked_acc: 1.0000 - masked_loss: 0.0081\n",
            "Epoch 13/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0068 - masked_acc: 1.0000 - masked_loss: 0.0068"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0068 - masked_acc: 1.0000 - masked_loss: 0.0068\n",
            "Epoch 14/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0062 - masked_acc: 1.0000 - masked_loss: 0.0062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0062 - masked_acc: 1.0000 - masked_loss: 0.0062\n",
            "Epoch 15/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0053 - masked_acc: 1.0000 - masked_loss: 0.0053"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 0.0053 - masked_acc: 1.0000 - masked_loss: 0.0053\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0049 - masked_acc: 1.0000 - masked_loss: 0.0049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0049 - masked_acc: 1.0000 - masked_loss: 0.0049\n",
            "Epoch 17/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0042 - masked_acc: 1.0000 - masked_loss: 0.0042"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 0.0042 - masked_acc: 1.0000 - masked_loss: 0.0042\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0039 - masked_acc: 1.0000 - masked_loss: 0.0039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 0.0039 - masked_acc: 1.0000 - masked_loss: 0.0039\n",
            "Epoch 19/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0036 - masked_acc: 1.0000 - masked_loss: 0.0036"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0036 - masked_acc: 1.0000 - masked_loss: 0.0036\n",
            "Epoch 20/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0033 - masked_acc: 1.0000 - masked_loss: 0.0033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0033 - masked_acc: 1.0000 - masked_loss: 0.0033\n",
            "Epoch 21/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0030 - masked_acc: 1.0000 - masked_loss: 0.0030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0030 - masked_acc: 1.0000 - masked_loss: 0.0030\n",
            "Epoch 22/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0027 - masked_acc: 1.0000 - masked_loss: 0.0027"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0027 - masked_acc: 1.0000 - masked_loss: 0.0027\n",
            "Epoch 23/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0026 - masked_acc: 1.0000 - masked_loss: 0.0026"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 0.0026 - masked_acc: 1.0000 - masked_loss: 0.0026\n",
            "Epoch 24/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023\n",
            "Epoch 25/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0023 - masked_acc: 1.0000 - masked_loss: 0.0023\n",
            "Epoch 26/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0020 - masked_acc: 1.0000 - masked_loss: 0.0020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0020 - masked_acc: 1.0000 - masked_loss: 0.0020\n",
            "Epoch 27/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0019 - masked_acc: 1.0000 - masked_loss: 0.0019"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0019 - masked_acc: 1.0000 - masked_loss: 0.0019\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017\n",
            "Epoch 29/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0017 - masked_acc: 1.0000 - masked_loss: 0.0017\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0015 - masked_acc: 1.0000 - masked_loss: 0.0015\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0014 - masked_acc: 1.0000 - masked_loss: 0.0014\n",
            "Epoch 33/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0013 - masked_acc: 1.0000 - masked_loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0013 - masked_acc: 1.0000 - masked_loss: 0.0013\n",
            "Epoch 34/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0012 - masked_acc: 1.0000 - masked_loss: 0.0012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 0.0012 - masked_acc: 1.0000 - masked_loss: 0.0012\n",
            "Epoch 35/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011\n",
            "Epoch 37/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.0010 - masked_acc: 1.0000 - masked_loss: 0.0010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 9.9808e-04 - masked_acc: 1.0000 - masked_loss: 9.9808e-04\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 9.1805e-04 - masked_acc: 1.0000 - masked_loss: 9.1805e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 9.1786e-04 - masked_acc: 1.0000 - masked_loss: 9.1786e-04\n",
            "Epoch 39/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 8.7147e-04 - masked_acc: 1.0000 - masked_loss: 8.7147e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 8.7027e-04 - masked_acc: 1.0000 - masked_loss: 8.7027e-04\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 8.2832e-04 - masked_acc: 1.0000 - masked_loss: 8.2832e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 8.2714e-04 - masked_acc: 1.0000 - masked_loss: 8.2714e-04\n",
            "Epoch 41/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 7.8859e-04 - masked_acc: 1.0000 - masked_loss: 7.8859e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 7.8793e-04 - masked_acc: 1.0000 - masked_loss: 7.8793e-04\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 7.3327e-04 - masked_acc: 1.0000 - masked_loss: 7.3327e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 7.3229e-04 - masked_acc: 1.0000 - masked_loss: 7.3229e-04\n",
            "Epoch 43/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 6.9411e-04 - masked_acc: 1.0000 - masked_loss: 6.9411e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 6.9511e-04 - masked_acc: 1.0000 - masked_loss: 6.9511e-04\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 6.5102e-04 - masked_acc: 1.0000 - masked_loss: 6.5102e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 6.5137e-04 - masked_acc: 1.0000 - masked_loss: 6.5137e-04\n",
            "Epoch 45/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 6.0776e-04 - masked_acc: 1.0000 - masked_loss: 6.0776e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 6.0881e-04 - masked_acc: 1.0000 - masked_loss: 6.0881e-04\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.9323e-04 - masked_acc: 1.0000 - masked_loss: 5.9323e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 5.9323e-04 - masked_acc: 1.0000 - masked_loss: 5.9323e-04\n",
            "Epoch 47/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 5.4158e-04 - masked_acc: 1.0000 - masked_loss: 5.4158e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 5.4181e-04 - masked_acc: 1.0000 - masked_loss: 5.4181e-04\n",
            "Epoch 48/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 5.2168e-04 - masked_acc: 1.0000 - masked_loss: 5.2168e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 5.2272e-04 - masked_acc: 1.0000 - masked_loss: 5.2272e-04\n",
            "Epoch 49/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.8352e-04 - masked_acc: 1.0000 - masked_loss: 4.8352e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 4.8432e-04 - masked_acc: 1.0000 - masked_loss: 4.8432e-04\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.6185e-04 - masked_acc: 1.0000 - masked_loss: 4.6185e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 4.6204e-04 - masked_acc: 1.0000 - masked_loss: 4.6204e-04\n",
            "Epoch 51/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.3927e-04 - masked_acc: 1.0000 - masked_loss: 4.3927e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 4.3878e-04 - masked_acc: 1.0000 - masked_loss: 4.3878e-04\n",
            "Epoch 52/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 4.1461e-04 - masked_acc: 1.0000 - masked_loss: 4.1461e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 4.1375e-04 - masked_acc: 1.0000 - masked_loss: 4.1375e-04\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.9546e-04 - masked_acc: 1.0000 - masked_loss: 3.9546e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 3.9546e-04 - masked_acc: 1.0000 - masked_loss: 3.9546e-04\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.7227e-04 - masked_acc: 1.0000 - masked_loss: 3.7227e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.7206e-04 - masked_acc: 1.0000 - masked_loss: 3.7206e-04\n",
            "Epoch 55/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.4913e-04 - masked_acc: 1.0000 - masked_loss: 3.4913e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.4886e-04 - masked_acc: 1.0000 - masked_loss: 3.4886e-04\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 3.3352e-04 - masked_acc: 1.0000 - masked_loss: 3.3352e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.3352e-04 - masked_acc: 1.0000 - masked_loss: 3.3352e-04\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1610e-04 - masked_acc: 1.0000 - masked_loss: 3.1610e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.1610e-04 - masked_acc: 1.0000 - masked_loss: 3.1610e-04\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9648e-04 - masked_acc: 1.0000 - masked_loss: 2.9648e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.9648e-04 - masked_acc: 1.0000 - masked_loss: 2.9648e-04\n",
            "Epoch 59/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.8121e-04 - masked_acc: 1.0000 - masked_loss: 2.8121e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.8117e-04 - masked_acc: 1.0000 - masked_loss: 2.8117e-04\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6699e-04 - masked_acc: 1.0000 - masked_loss: 2.6699e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.6699e-04 - masked_acc: 1.0000 - masked_loss: 2.6699e-04\n",
            "Epoch 61/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.5179e-04 - masked_acc: 1.0000 - masked_loss: 2.5179e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.5175e-04 - masked_acc: 1.0000 - masked_loss: 2.5175e-04\n",
            "Epoch 62/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.3828e-04 - masked_acc: 1.0000 - masked_loss: 2.3828e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 2.3835e-04 - masked_acc: 1.0000 - masked_loss: 2.3835e-04\n",
            "Epoch 63/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.2976e-04 - masked_acc: 1.0000 - masked_loss: 2.2976e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 2.2941e-04 - masked_acc: 1.0000 - masked_loss: 2.2941e-04\n",
            "Epoch 64/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 2.1684e-04 - masked_acc: 1.0000 - masked_loss: 2.1684e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 2.1636e-04 - masked_acc: 1.0000 - masked_loss: 2.1636e-04\n",
            "Epoch 65/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 2.0237e-04 - masked_acc: 1.0000 - masked_loss: 2.0237e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 2.0177e-04 - masked_acc: 1.0000 - masked_loss: 2.0177e-04\n",
            "Epoch 66/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.9215e-04 - masked_acc: 1.0000 - masked_loss: 1.9215e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.9210e-04 - masked_acc: 1.0000 - masked_loss: 1.9210e-04\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.8508e-04 - masked_acc: 1.0000 - masked_loss: 1.8508e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.8508e-04 - masked_acc: 1.0000 - masked_loss: 1.8508e-04\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.7306e-04 - masked_acc: 1.0000 - masked_loss: 1.7306e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.7306e-04 - masked_acc: 1.0000 - masked_loss: 1.7306e-04\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.6286e-04 - masked_acc: 1.0000 - masked_loss: 1.6286e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.6286e-04 - masked_acc: 1.0000 - masked_loss: 1.6286e-04\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5641e-04 - masked_acc: 1.0000 - masked_loss: 1.5641e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 1.5641e-04 - masked_acc: 1.0000 - masked_loss: 1.5641e-04\n",
            "Epoch 71/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.4968e-04 - masked_acc: 1.0000 - masked_loss: 1.4968e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.4953e-04 - masked_acc: 1.0000 - masked_loss: 1.4953e-04\n",
            "Epoch 72/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.4076e-04 - masked_acc: 1.0000 - masked_loss: 1.4076e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 1.4064e-04 - masked_acc: 1.0000 - masked_loss: 1.4064e-04\n",
            "Epoch 73/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3185e-04 - masked_acc: 1.0000 - masked_loss: 1.3185e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.3212e-04 - masked_acc: 1.0000 - masked_loss: 1.3212e-04\n",
            "Epoch 74/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2601e-04 - masked_acc: 1.0000 - masked_loss: 1.2601e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.2606e-04 - masked_acc: 1.0000 - masked_loss: 1.2606e-04\n",
            "Epoch 75/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.1981e-04 - masked_acc: 1.0000 - masked_loss: 1.1981e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.1950e-04 - masked_acc: 1.0000 - masked_loss: 1.1950e-04\n",
            "Epoch 76/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.1289e-04 - masked_acc: 1.0000 - masked_loss: 1.1289e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.1247e-04 - masked_acc: 1.0000 - masked_loss: 1.1247e-04\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0860e-04 - masked_acc: 1.0000 - masked_loss: 1.0860e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.0860e-04 - masked_acc: 1.0000 - masked_loss: 1.0860e-04\n",
            "Epoch 78/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.0190e-04 - masked_acc: 1.0000 - masked_loss: 1.0190e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 1.0165e-04 - masked_acc: 1.0000 - masked_loss: 1.0165e-04\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.7264e-05 - masked_acc: 1.0000 - masked_loss: 9.7264e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 9.7264e-05 - masked_acc: 1.0000 - masked_loss: 9.7264e-05\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.2131e-05 - masked_acc: 1.0000 - masked_loss: 9.2131e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 9.2131e-05 - masked_acc: 1.0000 - masked_loss: 9.2131e-05\n",
            "Epoch 81/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 8.6909e-05 - masked_acc: 1.0000 - masked_loss: 8.6909e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 8.6794e-05 - masked_acc: 1.0000 - masked_loss: 8.6794e-05\n",
            "Epoch 82/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 8.2922e-05 - masked_acc: 1.0000 - masked_loss: 8.2922e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 8.2617e-05 - masked_acc: 1.0000 - masked_loss: 8.2617e-05\n",
            "Epoch 83/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 7.8254e-05 - masked_acc: 1.0000 - masked_loss: 7.8254e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 7.8307e-05 - masked_acc: 1.0000 - masked_loss: 7.8307e-05\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 7.4592e-05 - masked_acc: 1.0000 - masked_loss: 7.4592e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 7.4504e-05 - masked_acc: 1.0000 - masked_loss: 7.4504e-05\n",
            "Epoch 85/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 7.0029e-05 - masked_acc: 1.0000 - masked_loss: 7.0029e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 7.0058e-05 - masked_acc: 1.0000 - masked_loss: 7.0058e-05\n",
            "Epoch 86/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 6.6958e-05 - masked_acc: 1.0000 - masked_loss: 6.6958e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 6.7034e-05 - masked_acc: 1.0000 - masked_loss: 6.7034e-05\n",
            "Epoch 87/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 6.3893e-05 - masked_acc: 1.0000 - masked_loss: 6.3893e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 6.3795e-05 - masked_acc: 1.0000 - masked_loss: 6.3795e-05\n",
            "Epoch 88/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 6.0702e-05 - masked_acc: 1.0000 - masked_loss: 6.0702e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 6.0683e-05 - masked_acc: 1.0000 - masked_loss: 6.0683e-05\n",
            "Epoch 89/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 5.7184e-05 - masked_acc: 1.0000 - masked_loss: 5.7184e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 5.6991e-05 - masked_acc: 1.0000 - masked_loss: 5.6991e-05\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.4347e-05 - masked_acc: 1.0000 - masked_loss: 5.4347e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 5.4347e-05 - masked_acc: 1.0000 - masked_loss: 5.4347e-05\n",
            "Epoch 91/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 5.1217e-05 - masked_acc: 1.0000 - masked_loss: 5.1217e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 5.1258e-05 - masked_acc: 1.0000 - masked_loss: 5.1258e-05\n",
            "Epoch 92/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.8979e-05 - masked_acc: 1.0000 - masked_loss: 4.8979e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 4.8959e-05 - masked_acc: 1.0000 - masked_loss: 4.8959e-05\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.6485e-05 - masked_acc: 1.0000 - masked_loss: 4.6485e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 4.6485e-05 - masked_acc: 1.0000 - masked_loss: 4.6485e-05\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.4133e-05 - masked_acc: 1.0000 - masked_loss: 4.4133e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 4.4133e-05 - masked_acc: 1.0000 - masked_loss: 4.4133e-05\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.1728e-05 - masked_acc: 1.0000 - masked_loss: 4.1728e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 4.1728e-05 - masked_acc: 1.0000 - masked_loss: 4.1728e-05\n",
            "Epoch 96/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 3.9733e-05 - masked_acc: 1.0000 - masked_loss: 3.9733e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.9670e-05 - masked_acc: 1.0000 - masked_loss: 3.9670e-05\n",
            "Epoch 97/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 3.7714e-05 - masked_acc: 1.0000 - masked_loss: 3.7714e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 3.7685e-05 - masked_acc: 1.0000 - masked_loss: 3.7685e-05\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5586e-05 - masked_acc: 1.0000 - masked_loss: 3.5586e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 18ms/step - loss: 3.5586e-05 - masked_acc: 1.0000 - masked_loss: 3.5586e-05\n",
            "Epoch 99/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 3.4073e-05 - masked_acc: 1.0000 - masked_loss: 3.4073e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.4034e-05 - masked_acc: 1.0000 - masked_loss: 3.4034e-05\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2231e-05 - masked_acc: 1.0000 - masked_loss: 3.2231e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 17ms/step - loss: 3.2231e-05 - masked_acc: 1.0000 - masked_loss: 3.2231e-05\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 40,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "7e1cc66a-6e07-49b0-ef1b-69fa1c65672a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f98b7fc0100>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "49a691cc-4589-4117-dab6-0fab6449b3fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f98a1084f40>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "666a7f5f-e1f9-43df-c396-72964372ddce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'class4,table6,obj2,atr2,np '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#sample Dataset Library_Management_Dataset_1_input_prerp_each_class_and_entitities_sep_experiment \n",
        "\n",
        "\n",
        "\n",
        "result1 = model.translate(['class1,table6,obj1,atr1'])\n",
        "\n",
        "result2 = model.translate(['class4,table17,obj2,atr2'])\n",
        "\n",
        "result23 = model.translate(['class14,table2,obj1,atr1'])\n",
        "\n",
        "result222 = model.translate(['class17,table4,obj2,atr2'])\n",
        "#result1[0].numpy().decode()\n",
        "result222[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "Use that to generate the attention plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrGawQv2eiA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "1da3a4a6-359a-41f3-c6ab-4a910554d218"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model.plot_attention('class1,table10,obj1,atr1') # Are you still home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FUHFLEvSMbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438131b1-a587-4504-d53c-b08d26f8769c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected output:\n",
            " class34,table25,obj23,atr15,P\n"
          ]
        }
      ],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing existing samples"
      ],
      "metadata": {
        "id": "wmCM_ou4X9EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "wnNs8LbU66N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dummy_data_test_set.csv')"
      ],
      "metadata": {
        "id": "R_4M4qPQdG9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o23nQwO3SKk7",
        "outputId": "aada4e82-1955-434b-ac40-3a5b06f1dc44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                OM_Regular  OM_Prediction\n",
              "0  class1,table1,obj1,atr1              0\n",
              "1  class1,table2,obj1,atr1              0\n",
              "2  class1,table3,obj1,atr1              0\n",
              "3  class1,table4,obj1,atr1              0\n",
              "4  class1,table5,obj1,atr1              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a802cbb-fe57-4bd5-abbd-fa1bd60cb596\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class1,table1,obj1,atr1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>class1,table2,obj1,atr1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>class1,table3,obj1,atr1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>class1,table4,obj1,atr1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>class1,table5,obj1,atr1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a802cbb-fe57-4bd5-abbd-fa1bd60cb596')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a802cbb-fe57-4bd5-abbd-fa1bd60cb596 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a802cbb-fe57-4bd5-abbd-fa1bd60cb596');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df['OM_Regular'].values\n",
        "y_test = df['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "a3VgzasFdlTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test.dtype)\n",
        "print(\"y data type: \", y_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp0Z6jW5d9v9",
        "outputId": "845f2092-d08d-4bd5-c9e5-46271c106662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(122,)\n",
            "(122,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KL_C7GZ627i",
        "outputId": "fb694b09-fb2b-4e69-b1de-c84b27e039f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test"
      ],
      "metadata": {
        "id": "-qZlNac5eSDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PToqG3GiIUPM"
      },
      "source": [
        "The `translate` function works on batches, so if you have multiple texts to translate you can pass them all at once, which is much more efficient than translating them one at a time:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_train_pred = model.predict(X_train)"
      ],
      "metadata": {
        "id": "bNp4BPta5_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT68i4jYEQ7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010689df-72b5-48b3-c3a4-1f3ddad4b5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table1,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table3,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class1,table6,obj1,atr1,np \n",
            "class1,table7,obj1,atr1,np \n",
            "class1,table8,obj1,atr1,np \n",
            "class1,table9,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class1,table11,obj1,atr1,np \n",
            "class1,table12,obj1,atr1,np \n",
            "class1,table13,obj1,atr1,np \n",
            "class1,table14,obj1,atr1,np \n",
            "class1,table15,obj1,atr1,np \n",
            "class1,table16,obj1,atr1,np \n",
            "class1,table17,obj1,atr1,np \n",
            "class1,table1,obj18,atr1,np \n",
            "class2,table1,obj2,atr2,np \n",
            "class2,table2,obj2,atr2,np \n",
            "class2,table3,obj2,atr2,np \n",
            "class2,table4,obj2,atr2,np \n",
            "class2,table5,obj2,atr2,np \n",
            "class2,table6,obj2,atr2,np \n",
            "class2,table7,obj2,atr2,np \n",
            "class2,table8,obj2,atr2,np \n",
            "class2,table9,obj2,atr2,np \n",
            "class2,table10,obj2,atr2,np \n",
            "class2,table11,obj2,atr2,np \n",
            "class2,table12,obj2,atr2,np \n",
            "class2,table13,obj2,atr2,np \n",
            "class2,table14,obj2,atr2,np \n",
            "class2,table15,obj2,atr2,np \n",
            "class2,table16,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table1,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table3,obj1,atr1,np \n",
            "class3,table4,obj1,atr1,np \n",
            "class3,table5,obj1,atr1,np \n",
            "class3,table6,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table8,obj1,atr1,np \n",
            "class3,table9,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table11,obj1,atr1,np \n",
            "class3,table12,obj1,atr1,np \n",
            "class3,table13,obj1,atr1,np \n",
            "class3,table14,obj1,atr1,np \n",
            "class3,table15,obj1,atr1,np \n",
            "class3,table16,obj1,atr1,np \n",
            "class3,table17,obj1,atr1,np \n",
            "class3,table18,obj1,atr1,np \n",
            "class4,table1,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table3,obj2,atr2,np \n",
            "class4,table4,obj2,atr2,np \n",
            "class4,table5,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table8,obj2,atr2,np \n",
            "class4,table9,obj2,atr2,np \n",
            "class4,table10,obj2,atr2,np \n",
            "class4,table11,obj2,atr2,np \n",
            "class4,table12,obj2,atr2,np \n",
            "class4,table13,obj2,atr2,np \n",
            "class4,table14,obj2,atr2,np \n",
            "class4,table15,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table17,obj2,atr2,np \n",
            "class4,table18,obj2,atr2,np \n",
            "class5,table1,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class5,table3,obj1,atr1,np \n",
            "class5,table4,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class5,table6,obj1,atr1,np \n",
            "class5,table7,obj1,atr1,np \n",
            "class5,table8,obj1,atr1,np \n",
            "class5,table9,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class5,table11,obj1,atr1,np \n",
            "class5,table12,obj1,atr1,np \n",
            "class5,table13,obj1,atr1,np \n",
            "class5,table14,obj1,atr1,np \n",
            "class5,table15,obj1,atr1,np \n",
            "class5,table16,obj1,atr1,np \n",
            "class5,table17,obj1,atr1,np \n",
            "class6,table1,obj1,atr1,np \n",
            "class6,table2,obj1,atr1,np \n",
            "class6,table3,obj1,atr1,np \n",
            "class6,table4,obj1,atr1,np \n",
            "class6,table5,obj1,atr1,np \n",
            "class6,table6,obj1,atr1,np \n",
            "class6,table7,obj1,atr1,np \n",
            "class6,table8,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class6,table10,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class6,table12,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class6,table14,obj1,atr1,np \n",
            "class6,table15,obj1,atr1,np \n",
            "class6,table16,obj1,atr1,np \n",
            "class6,table17,obj1,atr1,np \n",
            "class6,table18,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table12,obj23,atr2,p \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table14,obj23,atr4,p \n",
            "class34,table15,obj23,atr5,p \n",
            "class34,table16,obj23,atr6,p \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table18,obj23,atr8,p \n",
            "class34,table19,obj23,atr9,p \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table21,obj23,atr11,p \n",
            "class34,table22,obj23,atr12,p \n",
            "class34,table23,obj23,atr13,p \n",
            "class34,table24,obj23,atr14,p \n",
            "class34,table25,obj23,atr15,p \n",
            "\n",
            "CPU times: user 16.4 s, sys: 587 ms, total: 17 s\n",
            "Wall time: 16.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for t in inputs:\n",
        "  mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Existing samples)"
      ],
      "metadata": {
        "id": "OCkpjZl3YOhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dg = pd.read_csv('dummy_data_test_set_prediction.csv')"
      ],
      "metadata": {
        "id": "scj5ksJ8f0nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred = dg['OM_Regular'].values\n",
        "y_test_pred = dg['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "5z16vFuixofS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Y-62gL5HYP",
        "outputId": "1681141c-690c-4f75-faa2-691a99555f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3fBkX6FRkNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test, y_test_pred) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, y_test_pred)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nflFqA_4-HB",
        "outputId": "289e80f8-e4d7-422e-eecc-bcffee15986d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 1.000000\n",
            "Testing: Recall = 0.733333\n",
            "Testing: F1 Score = 0.846154\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[107   0]\n",
            " [  4  11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSjhM_oPN7Tr",
        "outputId": "1a5de3ad-b384-4fc7-b058-b71d0aa2c498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       107\n",
            "           1       1.00      0.73      0.85        15\n",
            "\n",
            "    accuracy                           0.97       122\n",
            "   macro avg       0.98      0.87      0.91       122\n",
            "weighted avg       0.97      0.97      0.96       122\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('dummy_data_unseen.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "3eeb6407-97b9-4ab8-e0a3-feb9b7f498d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                OM_Regular  OM_Prediction\n",
              "0  table121,class221,obj31,atr1,obj32,atr2              0\n",
              "1  table122,class222,obj31,atr1,obj32,atr2              0\n",
              "2  table123,class223,obj31,atr1,obj32,atr2              0\n",
              "3  table124,class224,obj31,atr1,obj32,atr2              0\n",
              "4  table125,class225,obj31,atr1,obj32,atr2              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffb75ceb-b5ce-4bdf-9a25-f7f2777434fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table121,class221,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table122,class222,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table123,class223,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table124,class224,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table125,class225,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffb75ceb-b5ce-4bdf-9a25-f7f2777434fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffb75ceb-b5ce-4bdf-9a25-f7f2777434fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffb75ceb-b5ce-4bdf-9a25-f7f2777434fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = df['OM_Regular'].values\n",
        "y_test2 = df['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "843b34f7-e497-4d10-80a4-a82964359b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for t in inputs:\n",
        "  mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qjPTIDB-8UZ",
        "outputId": "ac2cc60b-a4f7-4d6b-e327-2c127bdd079d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class1,table1,obj1,atr1,np \n",
            "class1,table2,obj1,atr1,np \n",
            "class1,table3,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class1,table6,obj1,atr1,np \n",
            "class1,table7,obj1,atr1,np \n",
            "class1,table8,obj1,atr1,np \n",
            "class1,table9,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class1,table11,obj1,atr1,np \n",
            "class1,table12,obj1,atr1,np \n",
            "class1,table13,obj1,atr1,np \n",
            "class1,table14,obj1,atr1,np \n",
            "class1,table15,obj1,atr1,np \n",
            "class1,table16,obj1,atr1,np \n",
            "class1,table17,obj1,atr1,np \n",
            "class1,table1,obj18,atr1,np \n",
            "class2,table1,obj2,atr2,np \n",
            "class2,table2,obj2,atr2,np \n",
            "class2,table3,obj2,atr2,np \n",
            "class2,table4,obj2,atr2,np \n",
            "class2,table5,obj2,atr2,np \n",
            "class2,table6,obj2,atr2,np \n",
            "class2,table7,obj2,atr2,np \n",
            "class2,table8,obj2,atr2,np \n",
            "class2,table9,obj2,atr2,np \n",
            "class2,table10,obj2,atr2,np \n",
            "class2,table11,obj2,atr2,np \n",
            "class2,table12,obj2,atr2,np \n",
            "class2,table13,obj2,atr2,np \n",
            "class2,table14,obj2,atr2,np \n",
            "class2,table15,obj2,atr2,np \n",
            "class2,table16,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table1,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table3,obj1,atr1,np \n",
            "class3,table4,obj1,atr1,np \n",
            "class3,table5,obj1,atr1,np \n",
            "class3,table6,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table8,obj1,atr1,np \n",
            "class3,table9,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class3,table11,obj1,atr1,np \n",
            "class3,table12,obj1,atr1,np \n",
            "class3,table13,obj1,atr1,np \n",
            "class3,table14,obj1,atr1,np \n",
            "class3,table15,obj1,atr1,np \n",
            "class3,table16,obj1,atr1,np \n",
            "class3,table17,obj1,atr1,np \n",
            "class3,table18,obj1,atr1,np \n",
            "class4,table1,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table3,obj2,atr2,np \n",
            "class4,table4,obj2,atr2,np \n",
            "class4,table5,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table8,obj2,atr2,np \n",
            "class4,table9,obj2,atr2,np \n",
            "class4,table10,obj2,atr2,np \n",
            "class4,table11,obj2,atr2,np \n",
            "class4,table12,obj2,atr2,np \n",
            "class4,table13,obj2,atr2,np \n",
            "class4,table14,obj2,atr2,np \n",
            "class4,table15,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table17,obj2,atr2,np \n",
            "class4,table18,obj2,atr2,np \n",
            "class5,table1,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class5,table3,obj1,atr1,np \n",
            "class5,table4,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class5,table6,obj1,atr1,np \n",
            "class5,table7,obj1,atr1,np \n",
            "class5,table8,obj1,atr1,np \n",
            "class5,table9,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class5,table11,obj1,atr1,np \n",
            "class5,table12,obj1,atr1,np \n",
            "class5,table13,obj1,atr1,np \n",
            "class5,table14,obj1,atr1,np \n",
            "class5,table15,obj1,atr1,np \n",
            "class5,table16,obj1,atr1,np \n",
            "class5,table17,obj1,atr1,np \n",
            "class6,table1,obj1,atr1,np \n",
            "class6,table2,obj1,atr1,np \n",
            "class6,table3,obj1,atr1,np \n",
            "class6,table4,obj1,atr1,np \n",
            "class6,table5,obj1,atr1,np \n",
            "class6,table6,obj1,atr1,np \n",
            "class6,table7,obj1,atr1,np \n",
            "class6,table8,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class6,table10,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class6,table12,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class6,table14,obj1,atr1,np \n",
            "class6,table15,obj1,atr1,np \n",
            "class6,table16,obj1,atr1,np \n",
            "class6,table17,obj1,atr1,np \n",
            "class6,table18,obj1,atr1,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table12,obj23,atr2,p \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table14,obj23,atr4,p \n",
            "class34,table15,obj23,atr5,p \n",
            "class34,table16,obj23,atr6,p \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table18,obj23,atr8,p \n",
            "class34,table19,obj23,atr9,p \n",
            "class4,table6,obj2,atr2,np \n",
            "class34,table21,obj23,atr11,p \n",
            "class34,table22,obj23,atr12,p \n",
            "class34,table23,obj23,atr13,p \n",
            "class34,table24,obj23,atr14,p \n",
            "class34,table25,obj23,atr15,p \n",
            "\n",
            "CPU times: user 16.1 s, sys: 600 ms, total: 16.7 s\n",
            "Wall time: 15.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('dummy_data_unseen_prediction.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "98a39293-6f0f-4a1b-ae3e-376a72400fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    OM_Regular  OM_Prediction\n",
              "0  class1,table1,obj1,atr1,np               0\n",
              "1  class1,table2,obj1,atr1,np               0\n",
              "2  class1,table3,obj1,atr1,np               0\n",
              "3  class4,table6,obj2,atr2,np               0\n",
              "4  class4,table6,obj2,atr2,np               0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ce6d076-2cce-451d-bb57-429cf49a3f97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class1,table1,obj1,atr1,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>class1,table2,obj1,atr1,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>class1,table3,obj1,atr1,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>class4,table6,obj2,atr2,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>class4,table6,obj2,atr2,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ce6d076-2cce-451d-bb57-429cf49a3f97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ce6d076-2cce-451d-bb57-429cf49a3f97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ce6d076-2cce-451d-bb57-429cf49a3f97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "5dad03dc-908b-4130-c35c-f33d9e88b3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "713681b7-c0e1-4830-98eb-0d9bb81c6cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 1.000000\n",
            "Testing: Recall = 0.733333\n",
            "Testing: F1 Score = 0.846154\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[107   0]\n",
            " [  4  11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "1f6ec82a-19dc-4530-91ee-7e80b89e3463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       107\n",
            "           1       1.00      0.73      0.85        15\n",
            "\n",
            "    accuracy                           0.97       122\n",
            "   macro avg       0.98      0.87      0.91       122\n",
            "weighted avg       0.97      0.97      0.96       122\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples extended \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H3F2-mn7IWQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dx = pd.read_csv('dummy_data_unseen_extended.csv')"
      ],
      "metadata": {
        "id": "4PBeqFMtIazn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dx.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NzfdmWjAItwp",
        "outputId": "39963e27-552a-4fab-992f-485645d15ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                OM_Regular  OM_Prediction\n",
              "0  table121,class221,obj31,atr1,obj32,atr2              0\n",
              "1  table122,class222,obj31,atr1,obj32,atr2              0\n",
              "2  table123,class223,obj31,atr1,obj32,atr2              0\n",
              "3  table124,class224,obj31,atr1,obj32,atr2              0\n",
              "4  table125,class225,obj31,atr1,obj32,atr2              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94b563b4-148f-4930-b8b4-593973e70b62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table121,class221,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table122,class222,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table123,class223,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table124,class224,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table125,class225,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94b563b4-148f-4930-b8b4-593973e70b62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94b563b4-148f-4930-b8b4-593973e70b62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94b563b4-148f-4930-b8b4-593973e70b62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test3 = dx['OM_Regular'].values\n",
        "y_test3 = dx['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "H24W5gzGI4ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkMvlX1ZJK-S",
        "outputId": "911a5302-6a43-441d-9a31-ebb445e9aee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputg = X_test3"
      ],
      "metadata": {
        "id": "jhN_pT6GJd9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for t in inputg:\n",
        "  #mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3xkHEijJxmn",
        "outputId": "04a068cc-c44b-4d6a-ed5c-76e1eec18411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "\n",
            "CPU times: user 10.3 s, sys: 351 ms, total: 10.6 s\n",
            "Wall time: 10.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification Report (Unseen Extended samples)"
      ],
      "metadata": {
        "id": "HHRnQVxWK6X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dy = pd.read_csv('dummy_data_unseen_extended_prediction.csv')"
      ],
      "metadata": {
        "id": "5-GTg604LCVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dy.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g42wnY4kLwyC",
        "outputId": "fd2ce278-c777-44f2-be7f-47e482041e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    OM_Regular  OM_Prediction\n",
              "0  class4,table6,obj2,atr2,np               0\n",
              "1  class4,table6,obj2,atr2,np               0\n",
              "2  class4,table6,obj2,atr2,np               0\n",
              "3  class4,table6,obj2,atr2,np               0\n",
              "4  class4,table6,obj2,atr2,np               0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-818eb2b6-3726-44b4-9d91-e6be34e98355\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class4,table6,obj2,atr2,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>class4,table6,obj2,atr2,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>class4,table6,obj2,atr2,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>class4,table6,obj2,atr2,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>class4,table6,obj2,atr2,np</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-818eb2b6-3726-44b4-9d91-e6be34e98355')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-818eb2b6-3726-44b4-9d91-e6be34e98355 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-818eb2b6-3726-44b4-9d91-e6be34e98355');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred3 = dy['OM_Regular'].values\n",
        "y_test_pred3 = dy['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "3ohsM1IoLzIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EDtlK3HL93A",
        "outputId": "5783108f-ff0a-4ae7-b9d5-744fbaf638e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-qygf1jMHcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ValueError: Found input variables with inconsistent numbers of samples: [122, 155]"
      ],
      "metadata": {
        "id": "gXYSUeLQMZ4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples under samples\n"
      ],
      "metadata": {
        "id": "oewNFxyrSCHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dz = pd.read_csv('dummy_data_unseen_undersample.csv')"
      ],
      "metadata": {
        "id": "asSXqOK8SJeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dz.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3h8MVdk5SXIS",
        "outputId": "aaa7c478-b75f-46c0-dd9c-1e66efe292a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                OM_Regular  OM_Prediction\n",
              "0  table121,class221,obj31,atr1,obj32,atr2              0\n",
              "1  table122,class222,obj31,atr1,obj32,atr2              0\n",
              "2  table123,class223,obj31,atr1,obj32,atr2              0\n",
              "3  table124,class224,obj31,atr1,obj32,atr2              0\n",
              "4  table125,class225,obj31,atr1,obj32,atr2              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebf0b94b-11e1-4968-8d77-bbc2ab8c5628\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>table121,class221,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table122,class222,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>table123,class223,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>table124,class224,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>table125,class225,obj31,atr1,obj32,atr2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebf0b94b-11e1-4968-8d77-bbc2ab8c5628')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebf0b94b-11e1-4968-8d77-bbc2ab8c5628 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebf0b94b-11e1-4968-8d77-bbc2ab8c5628');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test4 = dz['OM_Regular'].values\n",
        "y_test4 = dz['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "nvtnoxuhS-RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHF26aXsTE5g",
        "outputId": "29920c79-6a2a-4dfa-d5a0-86050537b577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputop = X_test4"
      ],
      "metadata": {
        "id": "-Rnxlyu1TKdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for t in inputop:\n",
        "  #mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APWMDIcqTSxg",
        "outputId": "6140afab-70f6-4a14-fbeb-a0cb7065fda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "class4,table6,obj2,atr2,np \n",
            "\n",
            "CPU times: user 6.59 s, sys: 255 ms, total: 6.85 s\n",
            "Wall time: 6.51 s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wmCM_ou4X9EP",
        "OCkpjZl3YOhn",
        "Rc1aekzi9dLZ",
        "1t4_2FqbE9da",
        "H3F2-mn7IWQB",
        "HHRnQVxWK6X9",
        "oewNFxyrSCHi"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}