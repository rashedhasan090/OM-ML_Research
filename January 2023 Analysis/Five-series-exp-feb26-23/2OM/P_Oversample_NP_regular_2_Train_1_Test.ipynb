{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "[link text](https://)  \n",
        "#Experiment with P Regular , NP Regular \n",
        "###2 OM - Dataset & Camping\n",
        "###1 OM - Testing - Library Management \n",
        "### Total instances - 228 \n",
        "\n",
        "### P samples - 138 \n",
        "### NP samples - 90 \n",
        "\n",
        "Oversampling: Repeated P samples and 100 new samples from Ecommerce-OM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#!pip install \"tensorflow-text>=2.10\"\n",
        "#!pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('2-OM.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Dat from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "0f1ae019-0166-42bc-b9a8-4016b5a348bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6214959e-5dbf-4ff8-b3fc-b32b26488be3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6214959e-5dbf-4ff8-b3fc-b32b26488be3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6214959e-5dbf-4ff8-b3fc-b32b26488be3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6214959e-5dbf-4ff8-b3fc-b32b26488be3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  #print(example_context_strings[:5])\n",
        "  #print()\n",
        "  #print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  #text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  #pattern = '\\s+'\n",
        "  #re.split(pattern, text, maxsplit=2)\n",
        "  #text = tf.strings.regex_replace(text, '\\s+', '')\n",
        "  #tf.strings.split(text, sep=', ', maxsplit=2, name=None)\n",
        "  #tf.strings.split (text, sep='\\s+', maxsplit=2, name=None)\n",
        "  #text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  #tf.strings.split(text, ',')\n",
        "  #text = tf.strings.split(text, sep=None, maxsplit=-1, name=None)\n",
        "  #text.tf.strings.split(', ')\n",
        "\n",
        "  # Add spaces around punctuation.\n",
        "  #text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  #text = tf.strings.strip(text)\n",
        "\n",
        "  #text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  #return text\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'\\0')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "#print(example_text.numpy().decode())\n",
        "#print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "c15567cf-be14-4a6b-b752-b1d3357c22c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 32, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "98g9rcxGQY0I",
        "outputId": "3c59bcf6-eb6a-40e6-bbce-108dfc5e4b04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\u200b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass9_name:map_str3mappingstrategyoftableclass6_name:map_str3associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class10_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_class10_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "df5702c4-863d-4212-bd85-c7959e18ba51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAARFklEQVR4nO3dedBdd13H8feHdGHrIpSlJAE6Q4tEQJaSMnYGyqZt0RY3bEUWLWRcqijIWIUpUB1HxAGGoYpRENlaS2GcqHECSAF1KCZshTYUYlmalrHQvSxtSr/+cU+Yy0Pa5yY5z/bt+zVzZ+455/ec8z3J935ynt+95yZVhSSpl3ssdQGSpPEZ7pLUkOEuSQ0Z7pLUkOEuSQ0Z7pLUkOG+iJKckGTnUtchrSRJPprkxUtdx0pjuO+jJLdMPe5I8t2p5ectcW0/eDEM/6DcMVXbziQXJHnSUtaoXpJ8NcltSY6Ys/4zSSrJw5eotLstw30fVdV9dz+ArwM/N7XuPUtd3xxXD3UeAjwZ+CLwn0mesbRlqZmvAKfvXkjyGODeS1fO3ZvhPrIkByd5U5Krh8ebkhx8J2N/L8llSdYMP/dXSb6e5P+SvDXJvYZxJwxX3C9Pck2SbyT59b2trSZ2VtXZwN8Drxv2nyRvHPZ9U5LPJ3n0/vw56G7pXcALppZfCLxz90KSZw9X8jcluTLJa6a23TPJu5Ncm+SGJFuTPGjuAZIcmeSSJK9YyBPpwHAf3yuZXB0/DvhJYD3wqrmDkpwNvAh4alXtBP4COGb4uUcAq4Gzp37kwcBhw/ozgHOT/Nh+1PkB4AlJ7gP8NPCU4fiHAc8Frt2Pfevu6WLg0CSPSrIKOA1499T2bzMJ/8OBZwO/leQ5w7YXMum9tcD9gd8Evju98yRHAR8D3lJVr1+40+jBcB/f84Bzquqaqvom8Frg+VPbk+QNTAL1aVX1zSQBNgB/UFXXVdXNwJ8zeXHstmvY766q2gzcAjxyP+q8GgiTF9ouJlM2Pw6kqrZX1Tf2Y9+6+9p99f4sYDtw1e4NVfXRqvp8Vd1RVZcA5wFPHTbvYhLqj6iq71fVp6rqpqn9rgMuAl5dVRsX40RWugOWuoCGHgJ8bWr5a8O63Q5nEuS/UlU3DusewGRu8lOTnAcmwbtq6ueurarbp5a/A9x3P+pcDRRwQ1V9JMlbgHOBhyX5APCHc15c0izeBXwcOIqpKRmAJMcx+Q310cBBwMHA+6Z+bi1wfpLDmVzxv7Kqdg3bnwfsAC5c4Prb8Mp9fFcDD5tafuiwbrfrgZ8F/iHJ8cO6bzH5FfQnqurw4XHY8CboQvl54NNV9W2AqnpzVT2RyRXSMYBzmtprVfU1Jm+snsxk6m/ae4FNwNqqOgx4K5OLGIbfSF9bVeuAn2LyGpmev38Nk9fJe4cpH83DcB/fecCrkjxg+FjY2fzwvCNV9VEmVyIfSLK+qu4A/g54Y5IHAiRZneRnxixseON0dZJXAy8G/mRY/6QkxyU5kMm86PeAO8Y8tu5WzgCevvvCYcohwHVV9b0k64Ff3b0hydOSPGYI7puYTNNM9+Au4JeB+wDvTGJ2zcM/oPH9GbANuAT4PPDpYd0PqaoPAb8B/EuSJwB/xOTXzouT3AR8mP2bU5/2kCS3MJmn3wo8Bjihqj44bD+UyT8u1zOZRroW8A0r7ZOq+t+q2raHTb8NnJPkZiYXPRdMbXswkymXm5jM1X+MyVTN9H5vA34BeBDwdgP+rsX/rEOS+vFfPklqaN5wT/L24eaWL9zJ9iR5c5Idw80FTxi/TGl89rY6m+XK/R3AiXex/STg6OGxAfib/S9LWhTvwN5WU/OGe1V9HLjuLoacCrxzuLX9YuDwJEeOVaC0UOxtdTbGTUyrgSunlncO637kDsckG5hcAbGKVU+8N4eOcPild8xjv7PUJYzmy19YyI/WL56b7rj2W1X1gP3czd2+t7X83Mz1M/X2ot6hOtw2vBHg0NyvjmvypYRbtnxuqUsYzcnHHD//oBVgy83v+Nr8o8bTtbe1/Hy4Lpypt8f4tMxVTG4b3m0NU98nIa1g9rZWrDHCfRPwguGTBU8GbvRLp9SEva0Va95pmSTnAScAR2TyX8S9GjgQoKreCmxm8j0SO5h8mdVef8+4tBTsbXU2b7hX1enzbC/gd0arSFok9rY68w5VSWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWpopnBPcmKSy5PsSHLWHrY/NMlFST6T5JIkJ49fqjQ+e1tdzRvuSVYB5wInAeuA05OsmzPsVcAFVfV44DTgr8cuVBqbva3OZrlyXw/sqKorquo24Hzg1DljCjh0eH4YcPV4JUoLxt5WWwfMMGY1cOXU8k7guDljXgN8MMnvAvcBnrmnHSXZAGwAuCf33ttapbHZ22prrDdUTwfeUVVrgJOBdyX5kX1X1caqOraqjj2Qg0c6tLSg7G2tSLOE+1XA2qnlNcO6aWcAFwBU1SeAewJHjFGgtIDsbbU1S7hvBY5OclSSg5i8qbRpzpivA88ASPIoJi+Ab45ZqLQA7G21NW+4V9XtwJnAFmA7k08OXJrknCSnDMNeDrwkyeeA84AXVVUtVNHSGOxtdTbLG6pU1WZg85x1Z089vww4ftzSpIVnb6sr71CVpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqaKZwT3JiksuT7Ehy1p2MeW6Sy5JcmuS945Ypjc++VmcHzDcgySrgXOBZwE5ga5JNVXXZ1JijgT8Gjq+q65M8cKEKlsZgX6u7Wa7c1wM7quqKqroNOB84dc6YlwDnVtX1AFV1zbhlSqOzr9XaLOG+GrhyannnsG7aMcAxSf47ycVJTtzTjpJsSLItybZd3LpvFUvjGK2vwd7W8jPvtMxe7Odo4ARgDfDxJI+pqhumB1XVRmAjwKG5X410bGmhzNTXYG9r+Znlyv0qYO3U8pph3bSdwKaq2lVVXwG+xORFIS1X9rVamyXctwJHJzkqyUHAacCmOWP+mcnVDUmOYPLr7BXjlSmNzr5Wa/OGe1XdDpwJbAG2AxdU1aVJzklyyjBsC3BtksuAi4BXVNW1C1W0tL/sa3U305x7VW0GNs9Zd/bU8wJeNjykFcG+VmfeoSpJDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDc0U7klOTHJ5kh1JzrqLcb+YpJIcO16J0sKxt9XVvOGeZBVwLnASsA44Pcm6PYw7BHgp8Mmxi5QWgr2tzma5cl8P7KiqK6rqNuB84NQ9jPtT4HXA90asT1pI9rbamiXcVwNXTi3vHNb9QJInAGur6t/uakdJNiTZlmTbLm7d62KlkdnbauuA/d1BknsAbwBeNN/YqtoIbAQ4NPer/T22tJDsba1ks1y5XwWsnVpeM6zb7RDg0cBHk3wVeDKwyTeetALY22prlnDfChyd5KgkBwGnAZt2b6yqG6vqiKp6eFU9HLgYOKWqti1IxdJ47G21NW+4V9XtwJnAFmA7cEFVXZrknCSnLHSB0kKxt9XZTHPuVbUZ2Dxn3dl3MvaE/S9LWhz2trryDlVJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGZgr3JCcmuTzJjiRn7WH7y5JcluSSJP+R5GHjlyqNy75WZ/OGe5JVwLnAScA64PQk6+YM+wxwbFU9FrgQ+MuxC5XGZF+ru1mu3NcDO6rqiqq6DTgfOHV6QFVdVFXfGRYvBtaMW6Y0Ovtarc0S7quBK6eWdw7r7swZwL/vaUOSDUm2Jdm2i1tnr1Ia32h9Dfa2lp8DxtxZkl8DjgWeuqftVbUR2AhwaO5XYx5bWijz9TXY21p+Zgn3q4C1U8trhnU/JMkzgVcCT60qL1203NnXam2WaZmtwNFJjkpyEHAasGl6QJLHA38LnFJV14xfpjQ6+1qtzRvuVXU7cCawBdgOXFBVlyY5J8kpw7DXA/cF3pfks0k23cnupGXBvlZ3M825V9VmYPOcdWdPPX/myHVJC86+VmfeoSpJDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDc0U7klOTHJ5kh1JztrD9oOT/NOw/ZNJHj56pdICsLfV1bzhnmQVcC5wErAOOD3JujnDzgCur6pHAG8EXjd2odLY7G11NsuV+3pgR1VdUVW3AecDp84Zcyrwj8PzC4FnJMl4ZUoLwt5WWwfMMGY1cOXU8k7guDsbU1W3J7kRuD/wrelBSTYAG4bFWz9cF35hX4peblYdyRHMOdeV68tdzuWRM4yxt+9al16AXucyS2/PFO6jqaqNwEaAJNuq6tjFPP5C8VyWnyTbFvN4HXu7y3lAv3OZZdws0zJXAWunltcM6/Y4JskBwGHAtbMUIC0he1ttzRLuW4GjkxyV5CDgNGDTnDGbgBcOz38J+EhV1XhlSgvC3lZb807LDPOMZwJbgFXA26vq0iTnANuqahPwNuBdSXYA1zF5kcxn437Uvdx4LsvPvOdhb8+ry3nA3fBc4kWIJPXjHaqS1JDhLkkNLUm4z3fL90qR5O1Jrkmyoj/TnGRtkouSXJbk0iQvXeqa9lWSeyb5nySfG87ltYt4bPt6menS2/vS14s+5z7c8v0l4FlMbhrZCpxeVZctaiEjSPIU4BbgnVX16KWuZ18lORI4sqo+neQQ4FPAc1bo30mA+1TVLUkOBP4LeGlVXbzAx7Wvl6Euvb0vfb0UV+6z3PK9IlTVx5l8gmJFq6pvVNWnh+c3A9uZ3Jm54tTELcPigcNjMa5g7OtlqEtv70tfL0W47+mW7xX3h93V8K2Hjwc+ucSl7LMkq5J8FrgG+FBVLca52NfL3Erv7b3ta99Q1Q8kuS/wfuD3q+qmpa5nX1XV96vqcUzuOF2fZEVPLWj/dejtve3rpQj3WW751iIb5vHeD7ynqj6w1PWMoapuAC4CTlyEw9nXy1S33p61r5ci3Ge55VuLaHiz5m3A9qp6w1LXsz+SPCDJ4cPzezF5g/OLi3Bo+3oZ6tLb+9LXix7uVXU7sPuW7+3ABVV16WLXMYYk5wGfAB6ZZGeSM5a6pn10PPB84OlJPjs8Tl7qovbRkcBFSS5hErgfqqp/XeiD2tfLVpfe3uu+9usHJKkh31CVpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIb+H1VymZsi3O0OAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "e7bc9f0c-3177-4b18-9ea3-d6165c85954d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 30  3]\n",
            "\n",
            "[ 2 29]\n",
            "[29  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "b6d46eff-0fc7-4edb-ec9a-6c8f2941bcbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "8b7d4bcf-a335-49c6-b288-9fa7d08c27b6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "14713edd-33e5-4835-a9a9-3c59494438b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.99999994], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "09c1feb6-d85e-4e3f-af06-f86c04c76264"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "2280a186-16af-4270-f2be-00ff28e9f960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 92)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuehagxL-JBZ",
        "outputId": "9f62cde5-5412-4d73-9524-508adaf0e188"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass10_name:map_str2mappingstrategyoftableclass9_name:map_str3associationstrategyforassoc1:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c5_at1`c5_at1_type`c1_at1`c1_at1_typenotnullkey`fk_class1_name_c5_at1_idx`(`c5_at1`),primarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class1_name`addconstraint`fk_class1_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass10_name:map_str2mappingstrategyoftableclass9_name:map_str3associationstrategyforassoc1:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at2:c2_at2_typetable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class3_nameattributec3_at2:c3_at2_typetable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class4_nameattributec4_at2:c4_at2_typetable:class4_nameattributec4_at3:c4_at3_typetable:class4_nameattributec4_at4:c4_at4_typetable:class5_nameattributec5_at1:c5_at1_typeprimarykeytable:class5_nameattributec5_at2:c5_at2_typetable:class6_nameattributec6_at1:c6_at1_typeprimarykeytable:class6_nameattributec6_at2:c6_at2_typetablename:class6_nametable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class6_nameattributec6_at1:c6_at1_typeprimarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_namemappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2associationstrategyforassoc2:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`assoc1`(`c6_at1`c6_at1_typenotnull,`c4_at1`c4_at1_typenotnull,key`fk_assoc1_c6_at1_idx`(`c6_at1`),fk_assoc1_c4_at1_idx`(`c4_at1`),primarykey(`c6_at1`,`c4_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull,primarykey(`c3_at1`));createtable`class5_name`(`c5_at2`c5_at2_type,`c5_at1`c5_at1_type,`c4_at1`c4_at1_typenotnull,key`fk_class5_name_c4_at1_idx`(`c4_at1`),primarykey(`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type(64),`c2_at1`c2_at1_typenotnull,primarykey(`c2_at1`));createtable`assoc3`(`c4_at1`c4_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc3_c4_at1_idx`(`c4_at1`),key`fk_assoc3_c1_at1_idx`(`c1_at1`),primarykey(`c4_at1`,`c1_at1`));createtable`class6_name`(`c6_at3`c6_at3_type,`c6_at2`c6_at2_type,`c6_at1`c6_at1_typenotnull,`c2_at1`c2_at1_type,key`fk_class6_name_c2_at1_idx`(`c2_at1`),primarykey(`c6_at1`));createtable`class1_name`(`c3_at1`c3_at1_type,`c1_at2`c1_at2_type,`c1_at1`c1_at1_typenotnull,key`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`));createtable`class4_name`(`c4_at2`c4_at2_type(64),`c4_at4`c4_at4_type,`c4_at3`c4_at3_type,`c4_at1`c4_at1_typenotnull,primarykey(`c4_at1`));altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`class5_name`addconstraint`fk_class5_name_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc3_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`class6_name`addconstraint`fk_class6_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade;altertable`class1_name`addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at2:c2_at2_typetable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class3_nameattributec3_at2:c3_at2_typetable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class4_nameattributec4_at2:c4_at2_typetable:class4_nameattributec4_at3:c4_at3_typetable:class4_nameattributec4_at4:c4_at4_typetable:class5_nameattributec5_at1:c5_at1_typeprimarykeytable:class5_nameattributec5_at2:c5_at2_typetable:class6_nameattributec6_at1:c6_at1_typeprimarykeytable:class6_nameattributec6_at2:c6_at2_typetablename:class6_nametable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class6_nameattributec6_at1:c6_at1_typeprimarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_namemappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2mappingstrategyoftableclass6_name:map_str2mappingstrategyoftableclass4_name:map_str1mappingstrategyoftableclass5_name:map_str1associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`assoc1`(`c6_at1`c6_at1_typenotnull,`c4_at1`c4_at1_typenotnull,key`fk_assoc1_c6_at1_idx`(`c6_at1`),fk_assoc1_c4_at1_idx`(`c4_at1`),primarykey(`c6_at1`,`c4_at1`));createtable`assoc4`(`c3_at1`c3_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc4_c3_at1_idx`(`c3_at1`),key`fk_assoc4_c1_at1_idx`(`c1_at1`),primarykey(`c3_at1`,`c1_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull,primarykey(`c3_at1`));createtable`class5_name`(`c5_at2`c5_at2_type,`c5_at1`c5_at1_type,`c4_at1`c4_at1_typenotnull,key`fk_class5_name_c4_at1_idx`(`c4_at1`),primarykey(`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type(64),`c2_at1`c2_at1_typenotnull,primarykey(`c2_at1`));createtable`assoc3`(`c4_at1`c4_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc3_c4_at1_idx`(`c4_at1`),key`fk_assoc3_c1_at1_idx`(`c1_at1`),primarykey(`c4_at1`,`c1_at1`));createtable`class6_name`(`c6_at3`c6_at3_type,`c6_at2`c6_at2_type,`c6_at1`c6_at1_typenotnull,primarykey(`c6_at1`));createtable`class1_name`(`c1_at2`c1_at2_type,`c1_at1`c1_at1_typenotnull,primarykey(`c1_at1`));createtable`assoc2`(`c6_at1`c6_at1_typenotnull,`c2_at1`c2_at1_typenotnull,key`fk_assoc2_c6_at1_idx`(`c6_at1`),key`fk_assoc2_c2_at1_idx`(`c2_at1`),primarykey(`c6_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type(64),`c4_at4`c4_at4_type,`c4_at3`c4_at3_type,`c4_at1`c4_at1_typenotnull,primarykey(`c4_at1`));altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`assoc4`addconstraint`fk_assoc4_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc4_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`class5_name`addconstraint`fk_class5_name_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc3_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`assoc2`addconstraint`fk_assoc2_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc2_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass10_name:map_str2mappingstrategyoftableclass9_name:map_str3associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass9_name:map_str3mappingstrategyoftableclass6_name:map_str3associationstrategyforassoc4:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullkey`fk_class8_name_c7_at1_idx`(`c7_at1`)primarykey(`c7_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c5_at1`c5_at1_type`c1_at1`c1_at1_typenotnullkey`fk_class1_name_c5_at1_idx`(`c5_at1`),primarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class10_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class8_name`addconstraint`fk_class8_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascade;altertable`class1_name`addconstraint`fk_class1_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_class10_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str1mappingstrategyoftableclass8_name:map_str1mappingstrategyoftableclass10_name:map_str1associationstrategyforassoc4:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c5_at1`c5_at1_type`c1_at1`c1_at1_typenotnullkey`fk_class1_name_c5_at1_idx`(`c5_at1`),primarykey(`c1_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at2`c7_at2_type(64)`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c10_at1`c10_at1_type`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class1_name`addconstraint`fk_class1_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass10_name:map_str2associationstrategyforassoc1:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c5_at1`c5_at1_type`c2_at1`c2_at1_typenotnullkey`fk_class2_name_c5_at1_idx`(`c5_at1`),primarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c5_at1`c5_at1_type`c1_at1`c1_at1_typenotnullkey`fk_class1_name_c5_at1_idx`(`c5_at1`),primarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class2_name`addconstraint`fk_class2_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class1_name`addconstraint`fk_class1_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at2:c2_at2_typetable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class3_nameattributec3_at2:c3_at2_typetable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class4_nameattributec4_at2:c4_at2_typetable:class4_nameattributec4_at3:c4_at3_typetable:class4_nameattributec4_at4:c4_at4_typetable:class5_nameattributec5_at1:c5_at1_typeprimarykeytable:class5_nameattributec5_at2:c5_at2_typetable:class6_nameattributec6_at1:c6_at1_typeprimarykeytable:class6_nameattributec6_at2:c6_at2_typetablename:class6_nametable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class6_nameattributec6_at1:c6_at1_typeprimarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_namemappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2mappingstrategyoftableclass4_name:map_str1mappingstrategyoftableclass5_name:map_str1associationstrategyforassoc2:assoc_type1associationstrategyforassoc3:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2,useom_name_0createtable`assoc1`(`c6_at1`c6_at1_typenotnull,`c4_at1`c4_at1_typenotnull,key`fk_assoc1_c6_at1_idx`(`c6_at1`),fk_assoc1_c4_at1_idx`(`c4_at1`),primarykey(`c6_at1`,`c4_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull,primarykey(`c3_at1`));createtable`class2_name`(`c2_at2`c2_at2_type(64),`c2_at1`c2_at1_typenotnull,primarykey(`c2_at1`));createtable`class6_name`(`c6_at3`c6_at3_type,`c6_at2`c6_at2_type,`c6_at1`c6_at1_typenotnull,`c2_at1`c2_at1_type,key`fk_class6_name_c2_at1_idx`(`c2_at1`),primarykey(`c6_at1`));createtable`class1_name`(`c4_at1`c4_at1_type,`c3_at1`c3_at1_type,`c1_at2`c1_at2_type,`c1_at1`c1_at1_typenotnull,key`fk_class1_name_c4_at1_idx`(`c4_at1`),key`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`));createtable`class4_name`(`c4_at5`c4_at5_type(64),`c4_at2`c4_at2_type(64),`c5_at2`c5_at2_type,`c5_at1`c5_at1_type,`c4_at4`c4_at4_type,`c4_at3`c4_at3_type,`c4_at1`c4_at1_typenotnull,primarykey(`c4_at1`));altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`class6_name`addconstraint`fk_class6_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade;altertable`class1_name`addconstraint`fk_class1_name_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass10_name:map_str2mappingstrategyoftableclass9_name:map_str3associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class9_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`class9_name`addconstraint`fk_class9_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "56ae553c-5d66-46af-c7ea-e9b226e6992e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 92)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "fe59d8d1-6d56-4ed2-fe52-77e56191c199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 4.5217886, 'expected_acc': 0.010869565217391304}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "846fd3f6-813d-4424-ec67-a31783035153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/60 [=======>......................] - ETA: 0s - loss: 4.3454 - masked_acc: 0.0000e+00 - masked_loss: 4.3454"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/60 [==============================] - 7s 3ms/step - loss: 4.3454 - masked_acc: 0.0000e+00 - masked_loss: 4.3454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 4.345358371734619,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 4.345358371734619}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=60, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "da8f979a-92dd-4495-db2a-b1a60a6b9cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1483 - masked_acc: 0.4950 - masked_loss: 3.1483"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 17s 24ms/step - loss: 3.1483 - masked_acc: 0.4950 - masked_loss: 3.1483 - val_loss: 3.7719 - val_masked_acc: 0.5000 - val_masked_loss: 3.7719\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.8518 - masked_acc: 0.5051 - masked_loss: 2.8518"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 2.8491 - masked_acc: 0.5050 - masked_loss: 2.8491\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2878 - masked_acc: 0.5300 - masked_loss: 2.2878"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 2.2878 - masked_acc: 0.5300 - masked_loss: 2.2878\n",
            "Epoch 4/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.8963 - masked_acc: 0.5714 - masked_loss: 1.8963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 1.8992 - masked_acc: 0.5700 - masked_loss: 1.8992\n",
            "Epoch 5/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.0501 - masked_acc: 0.7071 - masked_loss: 1.0501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 1.0464 - masked_acc: 0.7100 - masked_loss: 1.0464\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4104 - masked_acc: 0.9091 - masked_loss: 0.4104"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.4064 - masked_acc: 0.9100 - masked_loss: 0.4064\n",
            "Epoch 7/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0966 - masked_acc: 0.9848 - masked_loss: 0.0966"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0958 - masked_acc: 0.9850 - masked_loss: 0.0958\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0344 - masked_acc: 0.9949 - masked_loss: 0.0344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0342 - masked_acc: 0.9950 - masked_loss: 0.0342\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0576 - masked_acc: 0.9850 - masked_loss: 0.0576"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0576 - masked_acc: 0.9850 - masked_loss: 0.0576\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0371 - masked_acc: 0.9900 - masked_loss: 0.0371"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0371 - masked_acc: 0.9900 - masked_loss: 0.0371\n",
            "Epoch 11/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0238 - masked_acc: 0.9949 - masked_loss: 0.0238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0234 - masked_acc: 0.9950 - masked_loss: 0.0234\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0331 - masked_acc: 0.9900 - masked_loss: 0.0331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0331 - masked_acc: 0.9900 - masked_loss: 0.0331\n",
            "Epoch 13/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0299 - masked_acc: 0.9899 - masked_loss: 0.0299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0296 - masked_acc: 0.9900 - masked_loss: 0.0296\n",
            "Epoch 14/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0197 - masked_acc: 0.9949 - masked_loss: 0.0197"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0193 - masked_acc: 0.9950 - masked_loss: 0.0193\n",
            "Epoch 15/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0216 - masked_acc: 0.9949 - masked_loss: 0.0216"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0213 - masked_acc: 0.9950 - masked_loss: 0.0213\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0286 - masked_acc: 0.9899 - masked_loss: 0.0286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0284 - masked_acc: 0.9900 - masked_loss: 0.0284\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0184 - masked_acc: 0.9950 - masked_loss: 0.0184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 43ms/step - loss: 0.0184 - masked_acc: 0.9950 - masked_loss: 0.0184\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0173 - masked_acc: 0.9950 - masked_loss: 0.0173"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0173 - masked_acc: 0.9950 - masked_loss: 0.0173\n",
            "Epoch 19/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0265 - masked_acc: 0.9898 - masked_loss: 0.0265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0260 - masked_acc: 0.9900 - masked_loss: 0.0260\n",
            "Epoch 20/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0174 - masked_acc: 0.9949 - masked_loss: 0.0174"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0171 - masked_acc: 0.9950 - masked_loss: 0.0171\n",
            "Epoch 21/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0398 - masked_acc: 0.9847 - masked_loss: 0.0398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0391 - masked_acc: 0.9850 - masked_loss: 0.0391\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0130 - masked_acc: 0.9949 - masked_loss: 0.0130"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0128 - masked_acc: 0.9950 - masked_loss: 0.0128\n",
            "Epoch 23/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0029 - masked_acc: 1.0000 - masked_loss: 0.0029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0029 - masked_acc: 1.0000 - masked_loss: 0.0029\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0333 - masked_acc: 0.9848 - masked_loss: 0.0333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0330 - masked_acc: 0.9850 - masked_loss: 0.0330\n",
            "Epoch 25/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0096 - masked_acc: 0.9949 - masked_loss: 0.0096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0094 - masked_acc: 0.9950 - masked_loss: 0.0094\n",
            "Epoch 26/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0275 - masked_acc: 0.9898 - masked_loss: 0.0275"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0270 - masked_acc: 0.9900 - masked_loss: 0.0270\n",
            "Epoch 27/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0175 - masked_acc: 0.9899 - masked_loss: 0.0175"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0174 - masked_acc: 0.9900 - masked_loss: 0.0174\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0109 - masked_acc: 0.9950 - masked_loss: 0.0109"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.0109 - masked_acc: 0.9950 - masked_loss: 0.0109\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0156 - masked_acc: 0.9950 - masked_loss: 0.0156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0156 - masked_acc: 0.9950 - masked_loss: 0.0156\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0213 - masked_acc: 0.9899 - masked_loss: 0.0213"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0211 - masked_acc: 0.9900 - masked_loss: 0.0211\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0208 - masked_acc: 0.9900 - masked_loss: 0.0208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0208 - masked_acc: 0.9900 - masked_loss: 0.0208\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0083 - masked_acc: 0.9949 - masked_loss: 0.0083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0186 - masked_acc: 0.9900 - masked_loss: 0.0186\n",
            "Epoch 33/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 9.3135e-04 - masked_acc: 1.0000 - masked_loss: 9.3135e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 9.3199e-04 - masked_acc: 1.0000 - masked_loss: 9.3199e-04\n",
            "Epoch 34/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0207 - masked_acc: 0.9898 - masked_loss: 0.0207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0203 - masked_acc: 0.9900 - masked_loss: 0.0203\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0241 - masked_acc: 0.9900 - masked_loss: 0.0241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0241 - masked_acc: 0.9900 - masked_loss: 0.0241\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.8719e-04 - masked_acc: 1.0000 - masked_loss: 7.8719e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 7.8719e-04 - masked_acc: 1.0000 - masked_loss: 7.8719e-04\n",
            "Epoch 37/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0269 - masked_acc: 0.9899 - masked_loss: 0.0269"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0267 - masked_acc: 0.9900 - masked_loss: 0.0267\n",
            "Epoch 38/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0026 - masked_acc: 1.0000 - masked_loss: 0.0026"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0025 - masked_acc: 1.0000 - masked_loss: 0.0025\n",
            "Epoch 39/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0194 - masked_acc: 0.9899 - masked_loss: 0.0194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0192 - masked_acc: 0.9900 - masked_loss: 0.0192\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0201 - masked_acc: 0.9900 - masked_loss: 0.0201"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0201 - masked_acc: 0.9900 - masked_loss: 0.0201\n",
            "Epoch 41/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0191 - masked_acc: 0.9898 - masked_loss: 0.0191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0187 - masked_acc: 0.9900 - masked_loss: 0.0187\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0131 - masked_acc: 0.9949 - masked_loss: 0.0131"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0130 - masked_acc: 0.9950 - masked_loss: 0.0130\n",
            "Epoch 43/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0162 - masked_acc: 0.9898 - masked_loss: 0.0162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0159 - masked_acc: 0.9900 - masked_loss: 0.0159\n",
            "Epoch 44/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0067 - masked_acc: 0.9949 - masked_loss: 0.0067"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0066 - masked_acc: 0.9950 - masked_loss: 0.0066\n",
            "Epoch 45/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0168 - masked_acc: 0.9898 - masked_loss: 0.0168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0165 - masked_acc: 0.9900 - masked_loss: 0.0165\n",
            "Epoch 46/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0181 - masked_acc: 0.9898 - masked_loss: 0.0181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0178 - masked_acc: 0.9900 - masked_loss: 0.0178\n",
            "Epoch 47/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 4.2797e-04 - masked_acc: 1.0000 - masked_loss: 4.2797e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 4.2756e-04 - masked_acc: 1.0000 - masked_loss: 4.2756e-04\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0264 - masked_acc: 0.9800 - masked_loss: 0.0264"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0264 - masked_acc: 0.9800 - masked_loss: 0.0264\n",
            "Epoch 49/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0075 - masked_acc: 0.9949 - masked_loss: 0.0075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0073 - masked_acc: 0.9950 - masked_loss: 0.0073\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0219 - masked_acc: 0.9850 - masked_loss: 0.0219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0219 - masked_acc: 0.9850 - masked_loss: 0.0219\n",
            "Epoch 51/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0119 - masked_acc: 0.9949 - masked_loss: 0.0119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0116 - masked_acc: 0.9950 - masked_loss: 0.0116\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0093 - masked_acc: 0.9950 - masked_loss: 0.0093"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0093 - masked_acc: 0.9950 - masked_loss: 0.0093\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0111 - masked_acc: 0.9950 - masked_loss: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0111 - masked_acc: 0.9950 - masked_loss: 0.0111\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0116 - masked_acc: 0.9899 - masked_loss: 0.0116"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0115 - masked_acc: 0.9900 - masked_loss: 0.0115\n",
            "Epoch 55/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0087 - masked_acc: 0.9949 - masked_loss: 0.0087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0085 - masked_acc: 0.9950 - masked_loss: 0.0085\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0120 - masked_acc: 0.9949 - masked_loss: 0.0120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 21ms/step - loss: 0.0119 - masked_acc: 0.9950 - masked_loss: 0.0119\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0136 - masked_acc: 0.9950 - masked_loss: 0.0136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0136 - masked_acc: 0.9950 - masked_loss: 0.0136\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0128 - masked_acc: 0.9949 - masked_loss: 0.0128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0127 - masked_acc: 0.9950 - masked_loss: 0.0127\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0153 - masked_acc: 0.9900 - masked_loss: 0.0153"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0153 - masked_acc: 0.9900 - masked_loss: 0.0153\n",
            "Epoch 60/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0078 - masked_acc: 0.9949 - masked_loss: 0.0078"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0076 - masked_acc: 0.9950 - masked_loss: 0.0076\n",
            "Epoch 61/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0114 - masked_acc: 0.9949 - masked_loss: 0.0114"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0112 - masked_acc: 0.9950 - masked_loss: 0.0112\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0167 - masked_acc: 0.9900 - masked_loss: 0.0167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0167 - masked_acc: 0.9900 - masked_loss: 0.0167\n",
            "Epoch 63/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0237 - masked_acc: 0.9848 - masked_loss: 0.0237"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0235 - masked_acc: 0.9850 - masked_loss: 0.0235\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.9152 - masked_acc: 0.8250 - masked_loss: 0.9152"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.9152 - masked_acc: 0.8250 - masked_loss: 0.9152\n",
            "Epoch 65/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 2.4139 - masked_acc: 0.5306 - masked_loss: 2.4139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 2.4150 - masked_acc: 0.5300 - masked_loss: 2.4150\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2875 - masked_acc: 0.6667 - masked_loss: 1.2875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 1.2769 - masked_acc: 0.6700 - masked_loss: 1.2769\n",
            "Epoch 67/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.2228 - masked_acc: 0.9490 - masked_loss: 0.2228"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.2185 - masked_acc: 0.9500 - masked_loss: 0.2185\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0333 - masked_acc: 0.9900 - masked_loss: 0.0333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0333 - masked_acc: 0.9900 - masked_loss: 0.0333\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0243 - masked_acc: 0.9900 - masked_loss: 0.0243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0243 - masked_acc: 0.9900 - masked_loss: 0.0243\n",
            "Epoch 70/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0174 - masked_acc: 0.9949 - masked_loss: 0.0174"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0171 - masked_acc: 0.9950 - masked_loss: 0.0171\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0172 - masked_acc: 0.9950 - masked_loss: 0.0172"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0172 - masked_acc: 0.9950 - masked_loss: 0.0172\n",
            "Epoch 72/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0280 - masked_acc: 0.9848 - masked_loss: 0.0280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0277 - masked_acc: 0.9850 - masked_loss: 0.0277\n",
            "Epoch 73/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0050 - masked_acc: 1.0000 - masked_loss: 0.0050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0050 - masked_acc: 1.0000 - masked_loss: 0.0050\n",
            "Epoch 74/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0140 - masked_acc: 0.9949 - masked_loss: 0.0140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0137 - masked_acc: 0.9950 - masked_loss: 0.0137\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0263 - masked_acc: 0.9850 - masked_loss: 0.0263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0263 - masked_acc: 0.9850 - masked_loss: 0.0263\n",
            "Epoch 76/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0163 - masked_acc: 0.9898 - masked_loss: 0.0163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0160 - masked_acc: 0.9900 - masked_loss: 0.0160\n",
            "Epoch 77/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0140 - masked_acc: 0.9949 - masked_loss: 0.0140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0139 - masked_acc: 0.9950 - masked_loss: 0.0139\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0142 - masked_acc: 0.9900 - masked_loss: 0.0142"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0142 - masked_acc: 0.9900 - masked_loss: 0.0142\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0134 - masked_acc: 0.9950 - masked_loss: 0.0134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 39ms/step - loss: 0.0134 - masked_acc: 0.9950 - masked_loss: 0.0134\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0131 - masked_acc: 0.9950 - masked_loss: 0.0131"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0131 - masked_acc: 0.9950 - masked_loss: 0.0131\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0115 - masked_acc: 0.9900 - masked_loss: 0.0115"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0115 - masked_acc: 0.9900 - masked_loss: 0.0115\n",
            "Epoch 82/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0201 - masked_acc: 0.9847 - masked_loss: 0.0201"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0197 - masked_acc: 0.9850 - masked_loss: 0.0197\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0111 - masked_acc: 0.9950 - masked_loss: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0111 - masked_acc: 0.9950 - masked_loss: 0.0111\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0063 - masked_acc: 0.9949 - masked_loss: 0.0063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0062 - masked_acc: 0.9950 - masked_loss: 0.0062\n",
            "Epoch 85/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0107 - masked_acc: 0.9949 - masked_loss: 0.0107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0106 - masked_acc: 0.9950 - masked_loss: 0.0106\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0208 - masked_acc: 0.9850 - masked_loss: 0.0208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0208 - masked_acc: 0.9850 - masked_loss: 0.0208\n",
            "Epoch 87/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0037 - masked_acc: 1.0000 - masked_loss: 0.0037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0037 - masked_acc: 1.0000 - masked_loss: 0.0037\n",
            "Epoch 88/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0199 - masked_acc: 0.9898 - masked_loss: 0.0199"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0196 - masked_acc: 0.9900 - masked_loss: 0.0196\n",
            "Epoch 89/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0117 - masked_acc: 0.9899 - masked_loss: 0.0117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 30ms/step - loss: 0.0116 - masked_acc: 0.9900 - masked_loss: 0.0116\n",
            "Epoch 90/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0108 - masked_acc: 0.9898 - masked_loss: 0.0108"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0106 - masked_acc: 0.9900 - masked_loss: 0.0106\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0093 - masked_acc: 0.9950 - masked_loss: 0.0093"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0093 - masked_acc: 0.9950 - masked_loss: 0.0093\n",
            "Epoch 92/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0104 - masked_acc: 0.9949 - masked_loss: 0.0104"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0102 - masked_acc: 0.9950 - masked_loss: 0.0102\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0118 - masked_acc: 0.9900 - masked_loss: 0.0118"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0118 - masked_acc: 0.9900 - masked_loss: 0.0118\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0086 - masked_acc: 0.9950 - masked_loss: 0.0086"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0086 - masked_acc: 0.9950 - masked_loss: 0.0086\n",
            "Epoch 95/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0116 - masked_acc: 0.9949 - masked_loss: 0.0116"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.0114 - masked_acc: 0.9950 - masked_loss: 0.0114\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0111 - masked_acc: 0.9950 - masked_loss: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0111 - masked_acc: 0.9950 - masked_loss: 0.0111\n",
            "Epoch 97/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0106 - masked_acc: 0.9898 - masked_loss: 0.0106"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0104 - masked_acc: 0.9900 - masked_loss: 0.0104\n",
            "Epoch 98/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0134 - masked_acc: 0.9899 - masked_loss: 0.0134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0132 - masked_acc: 0.9900 - masked_loss: 0.0132\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0125 - masked_acc: 0.9900 - masked_loss: 0.0125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0125 - masked_acc: 0.9900 - masked_loss: 0.0125\n",
            "Epoch 100/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0069 - masked_acc: 0.9949 - masked_loss: 0.0069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0068 - masked_acc: 0.9950 - masked_loss: 0.0068\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 60,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "422e7cf0-13c9-4f0f-f366-ac0f2496aa97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fafdffe4bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2WklEQVR4nO3deZhcZbnv/e9d89BD9ZTOPEFICOkMkCCIgMBBwO0RBTEoioCSIyKyxeMGnEBftx7de8tG5IjIGF9QMExhEgUCITImISMJISQBOmN3p+fumu/zR1WaTqeHSuhKdXXdn+uqK1WrVq11r1656lfPGp5HVBVjjDGFy5HrAowxxuSWBYExxhQ4CwJjjClwFgTGGFPgLAiMMabAuXJdwMGqrKzUiRMn5roMY4zJKytWrKhX1are3su7IJg4cSLLly/PdRnGGJNXROS9vt6zQ0PGGFPgLAiMMabAWRAYY0yBy7tzBMaYwRGLxaitrSUcDue6FDOIfD4fY8eOxe12Z/wZCwJjClRtbS3FxcVMnDgREcl1OWYQqCoNDQ3U1tYyadKkjD9nh4aMKVDhcJiKigoLgWFERKioqDjoVp4FgTEFzEJg+DmUfWpBYIwxBc6CwBiTM0VFRbkuwZDFIBARn4i8LiKrRWS9iPy0l3kuEZE6EVmVfnwjW/UYY4zpXTZbBBHgdFWdBcwGzhaRE3qZ7wFVnZ1+3JHFeowxQ5Sq8v3vf58ZM2ZQU1PDAw88AMDOnTs55ZRTmD17NjNmzOCll14ikUhwySWXdM1700035bj6/Je1y0c1NQZmW/qlO/2wcTGNGYJ++vh63trRMqjLnD66hBv+5zEZzfvwww+zatUqVq9eTX19PfPmzeOUU07h/vvv56yzzuKHP/whiUSCjo4OVq1axfbt21m3bh0ATU1Ng1p3IcrqOQIRcYrIKmAP8A9Vfa2X2c4XkTUiskhExmWzHmPM0LRs2TK+9KUv4XQ6qa6u5tRTT+WNN95g3rx53H333dx4442sXbuW4uJiJk+ezJYtW7jqqqv429/+RklJSa7Lz3tZvaFMVRPAbBEJAY+IyAxVXddtlseBP6tqRET+F3AvcHrP5YjIAmABwPjx47NZsjEFKdNf7ofbKaecwtKlS3nyySe55JJLuOaaa7j44otZvXo1zzzzDLfddhsPPvggd911V65LzWuH5aohVW0ClgBn95jeoKqR9Ms7gOP6+PztqjpXVedWVfXanbYxJo+dfPLJPPDAAyQSCerq6li6dCnHH3887733HtXV1Vx++eV84xvfYOXKldTX15NMJjn//PP5+c9/zsqVK3Ndft7LWotARKqAmKo2iYgfOBP4VY95RqnqzvTLzwIbslWPMWbo+vznP88rr7zCrFmzEBF+/etfM3LkSO69917+4z/+A7fbTVFREQsXLmT79u1ceumlJJNJAH75y1/muPr8J6lzullYsMhMUod6nKRaHg+q6s9E5GfAclVdLCK/JBUAcWAvcIWqbuxvuXPnzlUbmMaYj27Dhg0cffTRuS7DZEFv+1ZEVqjq3N7mz+ZVQ2uAOb1M/0m359cD12erBmOMMQOzO4uNMabAWRAYY0yBsyAwxpgCZ0FgjDEFzoLAGGMKnAWBMcYUOAsCY8ywsW3bNmbMmHHIn+9vfISPuuyhzILAGGMKXFY7nTPG5Imnr4Ndawd3mSNr4Jz/0+8s27Zt4+yzz+aEE07g5ZdfZt68eVx66aXccMMN7Nmzh/vuuw+Aq6++mnA4jN/v5+6772bq1KmsX7+eSy+9lGg0SjKZ5KGHHsLtdncte8uWLZx//vncfvvtlJeXc+WVV1JXV0cgEOCPf/wj06ZNY+vWrXz5y1+mra2Nc889N+NNC4fDXHHFFSxfvhyXy8VvfvMbTjvttF5rGj16NF/84hepra0lkUjw4x//mPnz5x/a3zRLLAiMMTm1efNm/vrXv3LXXXcxb9487r//fpYtW8bixYv5xS9+wcKFC3nppZdwuVw8++yz/OAHP+Chhx7itttu4+qrr+aiiy4iGo2SSCTYvXs3AG+//TYXXngh99xzD7NmzeKMM87gtttuY8qUKbz22mt861vf4vnnn+fqq6/miiuu4OKLL+bWW2/NuOZbb70VEWHt2rVs3LiRT33qU2zatKnXmp566ilGjx7Nk08+CUBzc3NW/o4fhQWBMWbAX+7ZNGnSJGpqagA45phjOOOMMxARampq2LZtG83NzXzta1/jnXfeQUSIxWIAnHjiifz7v/87tbW1nHfeeUyZMgWAuro6zj33XB5++GGmT59OW1sbL7/8MhdccEHXOiORVKfH//znP3nooYcA+OpXv8q1116bUc3Lli3jqquuAmDatGlMmDCBTZs29VpTTU0N3/ve97j22mv5zGc+w8knnzw4f7hBZOcIjDE55fV6u547HI6u1w6Hg3g8zo9//GNOO+001q1bx+OPP044HAbgy1/+MosXL8bv9/PpT3+a559/HoDS0lLGjx/PsmXLAEgmk4RCIVatWtX12LDhw46ORWTQtqW3mo466ihWrlxJTU0NP/rRj/jZz342aOsbLAUTBJ3trWxe/U9i0cjAMxtjhozm5mbGjBkDwD333NM1fcuWLUyePJnvfOc7nHvuuaxZswYAj8fDI488wsKFC7n//vspKSlh0qRJ/PWvfwVS4yOvXr0agJNOOom//OUvAF3nIzJx8sknd82/adMm3n//faZOndprTTt27CAQCPCVr3yF73//+0Ny/ISCCYL1z93HkY98mh3vrht4ZmPMkPFv//ZvXH/99cyZM4d4PN41/cEHH2TGjBnMnj2bdevWcfHFF3e9FwwGeeKJJ7jppptYvHgx9913H3feeSezZs3imGOO4bHHHgPg5ptv5tZbb6Wmpobt27dnXNO3vvUtkskkNTU1zJ8/n3vuuQev19trTWvXruX4449n9uzZ/PSnP+VHP/rR4P1xBknWxiPIlkMdj2DTyhc4avG5vPnxW5nzqa9koTJj8ouNRzB8Hex4BAXTIqiemBqTNbJ7U44rMcaYoaVgrhoqLa+ikWIcjVtyXYoxZghbu3YtX/3qV/eb5vV6ee2113JUUfYVTBAA7HGNIdj2Xq7LMMYMYTU1NaxatSrXZRxWBXNoCKAlOJ6qaG2uyzDGmCGloIIgHprMCPbS2d6a61KMMWbIyFoQiIhPRF4XkdUisl5EftrLPF4ReUBENovIayIyMVv1AHhGpO483Ln1rWyuxhhj8ko2WwQR4HRVnQXMBs4WkRN6zPN1oFFVjwRuAn6VxXooHTsNgKbaDQPMaYwxhSNrQaApbemX7vSj500L5wL3pp8vAs6Qwbzfu4eRk/ZdQvpOtlZhjMmS/sYKyIYXXniBz3zmM4f02YHGLvgoy86GrJ4jEBGniKwC9gD/UNWe11+NAT4AUNU40AxUZKueopIy6gnhtEtIjTGmS1YvH1XVBDBbRELAIyIyQ1UPuo8HEVkALAAYP378R6qpzj2Govb3P9IyjBlufvX6r9i4d+OgLnNa+TSuPb7v3jyvu+46xo0bx5VXXgnAjTfeiMvlYsmSJTQ2NhKLxfj5z3+e0TgBL7zwAjfccAOhUIi1a9fyxS9+kZqaGm6++WY6Ozt59NFHOeKII3j88cf5+c9/TjQapaKigvvuu4/q6mpefPFFrr76aiDVCd3SpUv3W/4bb7zBggULWLRoEU1NTVxzzTW0tbVRWVnJPffcw6hRo1ixYgWXXXYZAJ/61Kcy/jvt3buXyy67jC1bthAIBLj99tuZOXNmrzW1tbUxf/58WlpaiMfj/P73vx+U3kwPy1VDqtoELAHO7vHWdmAcgIi4gFKgoZfP366qc1V1blVV1UeqpTU4gRExu4TUmFybP38+Dz74YNfrBx98kK997Ws88sgjrFy5kiVLlvC9732PTLvBWb16NbfddhsbNmzgT3/6E5s2beL111/nG9/4BrfccgsAn/jEJ3j11Vd58803ufDCC/n1r38NwH/+539y6623smrVKl566SX8fn/Xcl9++WW++c1v8thjjzF+/HiuuuoqFi1a1PXF/8Mf/hCASy+9lFtuuaWrQ7tM3XDDDcyZM4c1a9bwi1/8oqvPpN5quv/++znrrLNYtWoVq1evZvbs2Qe1rr5krUUgIlVATFWbRMQPnMmBJ4MXA18DXgG+ADyvWe78KFE2mcqmp2ht3ktxaXk2V2VM3ujvl3u2zJkzhz179rBjxw7q6uooKytj5MiRfPe732Xp0qU4HA62b9/O7t27GTly5IDLmzdvHqNGjQLgiCOO6PpVXlNTw5IlSwCora1l/vz57Ny5k2g0yqRJk4BUL6TXXHMNF110Eeeddx5jx44FUn32LFiwgL///e+MHj2adevWsW7dOs4880wAEokEo0aNoqmpiaamJk455RQgNbbB008/ndHfYdmyZV1jIpx++uk0NDTQ0tLSa03z5s3jsssuIxaL8bnPfW7QgiCbLYJRwBIRWQO8QeocwRMi8jMR+Wx6njuBChHZDFwDXJfFegDwVqcuId29zS4hNSbXLrjgAhYtWsQDDzzA/Pnzue+++6irq2PFihWsWrWK6urqrvEHBjLQuAYAV111Fd/+9rdZu3Ytf/jDH7qWfd1113HHHXfQ2dnJSSedxMaNqcNko0aNwufz8eabbwKpLqyPOeaYrnEN1q5dy9///vdB+3t011tNp5xyCkuXLmXMmDFccsklLFy4cFDWlbUWgaquAeb0Mv0n3Z6HgQt6zpNNobGpHvmaazfCrE8czlUbY3qYP38+l19+OfX19bz44os8+OCDjBgxArfbzZIlS3jvvcHtEqb72Ab33ntv1/R3332XmpoaampqeOONN9i4cSOhUIhQKMSdd97JmWeeSTAY5OMf/zh1dXW88sornHjiicRiMTZt2sQxxxxDKBRi2bJlfOITnziksQ1+/OMf88ILL1BZWUlJSUmvNfn9fsaOHcvll19OJBJh5cqV+3W/fagK6s5igFGTpgMQ3WOXkBqTa8cccwytra2MGTOGUaNGcdFFF7F8+XJqampYuHAh06ZNG9T13XjjjVxwwQUcd9xxVFZWdk3/7//+b2bMmMHMmTNxu92cc845Xe9VV1fzxBNPcOWVV/Lmm2+yaNEirr32WmbNmsXs2bN5+eWXAbj77ru58sormT17dsbnNfbVtGLFCmbOnMl1113XFVC91fTCCy8wa9Ys5syZwwMPPNB1MvmjKpjxCLrbc+Mk3iudx7zvPjjwzMYMUzYewfBl4xFkoM4zlmK7hNQYY4AC64Z6n7aiiRy194Vcl2GMOUj5NlbAM888w7XX7n9F1qRJk3jkkUdyVFHvCjIItHwyZXsX09xYT2lZ5cAfMGaYUlWy2KvLoMu3sQLOOusszjrrrMO6zkM53F+Qh4a86V5Id29dn+NKjMkdn89HQ0PDIX1xmKFJVWloaMDn8x3U5wqyRVA6OhUErbu2AKfmthhjcmTs2LHU1tZSV1eX61LMIPL5fF03xGWqIIOgcuyRAMT22rCVpnC53e6uO2tNYSvIQ0MloQpa1Y80f5DrUowxJucKMggA6p3VeNp35LoMY4zJuYINgmbvSEoiu3JdhjHG5FzBBkEkOJrKxO5cl2GMMTlXsEGgJWMppZ22lsZcl2KMMTlVsEHgrpgAQP32d3NciTHG5FbBBkFwxEQAmnfa+MXGmMJWsEFQMSZ1L0G43u4lMMYUtsINgupxRNVJssl6ITXGFLaCDQKH00mdoxJ36/Zcl2KMMTlVsEEA0OQeSTC8M9dlGGNMThV0EHT4R1Ees3sJjDGFraCDIF4ylkrdSywayXUpxhiTM1kLAhEZJyJLROQtEVkvIgeMsiwinxSRZhFZlX78JFv19MZVNh6nKHU7th3O1RpjzJCSzW6o48D3VHWliBQDK0TkH6r6Vo/5XlLVz2Sxjj75KicC0LjjXUZPnJqLEowxJuey1iJQ1Z2qujL9vBXYAIzJ1voORWj0ZAA69mzNcSXGGJM7h+UcgYhMBOYAvY0wfaKIrBaRp0XkmD4+v0BElovI8sEcTalqTCoI4o12L4ExpnBlPQhEpAh4CPhXVW3p8fZKYIKqzgJuAR7tbRmqeruqzlXVuVVVVYNWm88fpJ4QzpbaQVumMcbkm6wGgYi4SYXAfar6cM/3VbVFVdvSz58C3CJSmc2aetrrGoGv0+4lMMYUrmxeNSTAncAGVf1NH/OMTM+HiByfrqchWzX1ps03klDUBqgxxhSubF41dBLwVWCtiKxKT/sBMB5AVW8DvgBcISJxoBO4UFU1izUdIBocQ1Xrq2gyiTgK+rYKY0yByloQqOoyQAaY53fA77JVQ0ZC4/HvjrK3fiflI4bURU3GGHNYFPxPYG/FeAAabIAaY0yBKvggKK6eCEBbnV1CaowpTAUfBIHS1OWosfa9Oa7EGGNyo+CDIFhaAUCysznHlRhjTG4UfBAUFYcAUAsCY0yBKvggcLpctKofifS86dkYYwpDwQcBQLsEcUYtCIwxhcmCAOh0FOGKtea6DGOMyQkLAiDsDOKxIDDGFCgLAiDiKsabaMt1GcYYkxMWBEDcXYQ/aUFgjClMGfc1JCIfByZ2/4yqLsxCTYddwlNCUNtzXYYxxuRERkEgIn8CjgBWAYn0ZAWGRRAkvSUUaYf1QGqMKUiZtgjmAtMPdxfRh4v4SnFJkvb2FoLpG8yMMaZQZPrzdx0wMpuF5JL4SgFob2nMcSXGGHP4ZdoiqATeEpHXgci+iar62axUdZi5giEAOloaYMyk3BZjjDGHWaZBcGM2i8g1T7AMgHCrtQiMMYUnoyBQ1RdFZAIwRVWfFZEA4MxuaYePJ90iiLRZEBhjCk9G5whE5HJgEfCH9KQxwKNZqumw85eUAxDraMptIcYYkwOZniy+ktRg9C0AqvoOMCJbRR1ugXQQJCwIjDEFKNMgiKhqdN8LEXGRuo+gTyIyTkSWiMhbIrJeRK7uZR4Rkd+KyGYRWSMixx5c+YOjyAanMcYUsEyD4EUR+QHgF5Ezgb8Cjw/wmTjwPVWdDpwAXCki03vMcw4wJf1YAPw+48oHkc8fJKouCFtX1MaYwpNpEFwH1AFrgf8FPKWqP+zvA6q6U1VXpp+3AhtInVvo7lxgoaa8CoREZNTBbMBgaZUgDhuTwBhTgDK+fFRVfwL8EUBEnCJyn6pelMmHRWQiMAd4rcdbY4APur2uTU/b2ePzC0i1GBg/fnyGJR+cDgnisiAwxhSgTFsE40TkegAR8QAPAe9k8kERKUrP/6+qekjftKp6u6rOVdW5VVVVh7KIAXU6i3DbmATGmAKUaRBcBtSkw+AJ4EVVvXGgD4mIm1QI3KeqD/cyy3ZgXLfXY9PTDruIM4gnbl1RG2MKT79BICLHpq/kmQPcDMwn1RJ4caArfEREgDuBDar6mz5mWwxcnL566ASgWVV39jFvVsXcxTYmgTGmIA10juC/erxuBKanpytwej+fPQn4KrBWRFalp/0AGA+gqrcBTwGfBjYDHcClB1H7oIq7i/EnbUwCY0zh6TcIVPW0Q12wqi4DZIB5lNTNajmX9JRQZIPTGGMKUKZdTJSKyG9EZHn68V8iUprt4g4n9ZUSkAixaGTgmY0xZhjJ9GTxXUAr8MX0owW4O1tF5cK+MQnamvfmuBJjjDm8Mr2P4AhVPb/b6592O+4/LDj9qSDoaN1LWVVO7mkzxpicyLRF0Ckin9j3QkROAjqzU1JuuNNjEnS0WIsg3+3Y9jZv3PRFIuGOXJdiTF7ItEXwTWBht/MCjcDXslNSbniKUkFgYxLkv+0r/8a85mfYumU9k6bPy3U5xgx5mQZBi6rOEpESAFVtEZFhNaajNx0EsXYLgnyXiKSu/oq0NeW2EGPyRKaHhh6CVAB06yZiUXZKyo1ASToIOqwr6nyn0XQQtDflthBj8kS/LQIRmQYcA5SKyHnd3ioBfNks7HALlKTHJLDBafJfrCP9T1Nu6zAmTwx0aGgq8BkgBPzPbtNbgcuzVFNOFJeUkVRBw9YiyHeSDoJEh/Uma0wmBgqCAPC/gdtV9ZXDUE/OOJxOWvEhEfvyyHf7gsBC3ZjMDBQE40mNRuYWkeeAp4HX011DDDvtUoTTgiDvOePpIIhYt+LGZKLfk8Wq+itVPZ1Ux3CrSXVHvVJE7heRi0Wk+nAUebh0OoK4bEyCvOeMp25xcVioG5ORjC4fTQ81+Uj6QXrs4XOAhcBZWavuMOt0FuGJWxDkO1ciHQRR61bcmEwMNB7BV7o9P2nfc1V9C4io6rAJAYCoqwhvwnogzXfuZBjAWnfGZGig+wiu6fb8lh7vXTbIteRc3F1MwAanyXv7gsBGnDMmMwMFgfTxvLfXeS/hKSZgYxLkPc++ILDWnTEZGSgItI/nvb3Oe0lvKUXagSaTuS7FfAReTQWBjThnTGYGOlk8TUTWkPr1f0T6OenXk7NaWQ6IrwSXJGlvbyFYHMp1OeYQ+UgHgVrvo8ZkYqAgmAVUAx/0mD4O2JWVinLI4Q8B0NbcYEGQx/waAYEiCwJjMjLQoaGbgGZVfa/7A2hOvzesOAPpwWlsTIK8FY2EcUuCDvXilZiNSWBMBgYKgmpVXdtzYnraxP4+KCJ3icgeEVnXx/ufFJFmEVmVfvwk46qzxJMenCbSal1R56vO9tQlo3sd5QC0t9i+NGYgAwVBqJ/3/AN89h7g7AHmeUlVZ6cfPxtg3qzzFqe+PCLt1iLIV+F0R3MtrlRvsp02JoExAxooCJaLyAG9jIrIN4AV/X1QVZcCefWN6isKARBrt87K8lWkI9Ui6PRVpf611p0xAxroZPG/Ao+IyEV8+MU/F/AAnx+E9Z8oIquBHcD/VtX1vc0kIguABQDjx48fhNX2LlhaCUDCWgR5K9qZuoks5h8BrRC2oUeNGVC/QaCqu4GPi8hpwIz05CdV9flBWPdKYIKqtonIp4FHgSl91HE7cDvA3Llzs3b/Qmn5CJIqJNvrs7UKk2X7goDikbDHWnfGZCLTTueWAEsGc8XdhrxEVZ8Skf8rIpWqmrNvYZfbQ5MEcXRaiyBfxdNB4CodnXptQ48aM6BMxywedCIyUkQk/fz4dC0NuapnnxZHKe5wzsswhygeSQWBrzwVBMmwdUVtzEAyahEcChH5M/BJoFJEaoEbADeAqt4GfAG4QkTiQCdw4VAY8KbdGcIbtePK+SoRTnUrUVwxBoCkjVJmzICyFgSq+qUB3v8d8Ltsrf9QhT1lhDp73kht8kUymgqCYGklYXWDjVJmzIBydmhoqIp5yyhO2q/IfKXpIPAGi2mXAI6oBYExA7Eg6CHhryCkLSQTiVyXYg6BRlNdSgSCJXRIEKeNUmbMgCwIepBgJS5J0tpkl5DmI4m2E1E3TpeLsCOA24YeNWZAFgQ9uIpSN5W17B12nasWBIl30ileACKuIhulzJgMWBD04CkZAUD73t05rsQcCkesgzA+AGLOIL6E9T5qzEAsCHoIlFUD0Nm8J8eVmEPhTHQScaSCIO4utlHKjMmABUEPReUjAYi1WBDkI2eik6ikgiDpKSKAtQiMGYgFQQ+hilQQJKy/obzkSnQSc6Z6SE96SwjaGNTGDMiCoAdfoIgO9SId1s1EPvIkw8TSh4bEV4JTlI5262bCmP5YEPSiyVGKq9OCIB95kmESrlSLQLwlgI1SZsxALAh60e4sxWP9DeUlbzJMwhkAwJUeg7rTxqA2pl8WBL3ocIXwx5pyXYY5BF7CJN09gqC9KYcVGTP0WRD0Iuotpzhh/Q3lI7+G0fShIW8wBEDUxi02pl8WBL1I+MopVQuCfJOIx/FJDPUEAfDuG4O6w04WG9MfC4JeaKACv0TpaLMwyCed6YHrxZM6NOQvLgMg0dmUq5KMyQsWBL1wFlUB0Nxg/Q3lk3BXEKRaBIF0ENgoZcb0z4KgF/v6G2qz/obySiQdBI50EBQVh0iqoBYExvTLgqAXvlAqCDqaLAjySaQj1dOo05cKAofTSTs+xEYpM6ZfFgS9CKY7notax3N5JdqZ+sJ3eYu6pnXYKGXGDMiCoBclFaMA628o38Q6Uz2NutItAoBORxBXzILAmP5kLQhE5C4R2SMi6/p4X0TktyKyWUTWiMix2arlYJWUlhNTJ2pBkFfi4dQXvtv/YYsg7AjitsFpjOlXNlsE9wBn9/P+OcCU9GMB8Pss1nJQxOGgWYpxWn9DeSURSbUIPP7irmlRVxHehI1JYEx/shYEqroU6K+Tl3OBhZryKhASkVHZqudgtTpCuCPW31A+SaaDwBv4sEUQcwXx2eA0xvQrl+cIxgAfdHtdm552ABFZICLLRWR5XV3dYSmu3W39DeWbZDT1he8PfNgiSHiKCVgQGNOvvDhZrKq3q+pcVZ1bVVV1WNYZ8ZQRjDcdlnWZQRLtBMAX/DAIku4iAtqZq4qMyQu5DILtwLhur8empw0JcW+Z9TeUZzTWTlwdeDy+D6f5SglIhFg0ksPKjBnachkEi4GL01cPnQA0q+rOHNazn2SgkhLa7Qskj0isg068iOPD/9biTbUOOlqbclSVMUOfK1sLFpE/A58EKkWkFrgBcAOo6m3AU8Cngc1AB3Bptmo5FI5gJQDNe3dTOXJ8jqsxmXDEOgiLj+Lu0/ypMQnaWxoprajOTWHGDHFZCwJV/dIA7ytwZbbW/1G5ilPdTLQ27LQgyBOOeCcR8e03zRUIAdDZaqOUGdOXvDhZnAve0lSLoL3R+hvKF85EJxHH/kHgSY9J0Nlq94QY0xcLgj4Ey0YCEGk5PJermo/Onegg5vDvNy1QmmrZRVvsLnFj+mJB0Ifi8lQQxFstCPKFOxEm1qNFUFyeOi8Qa7MWgTF9sSDoQ6iimqQKyTYLgnzhSYaJO/dvEZSUp1oESes3ypg+WRD0weX20CzFODosCPKFRztJuPYPAq8vQId6kU7rLsSYvlgQ9KPZEcITtkMK+cKrERKuwAHTm6UEZ9iCwJi+WBD0o81djj9qlx3mC7+GUfeBQdDuLMETtSAwpi8WBP2IeMopilsQ5ANNJvET6TUIOl2l+GLWXYgxfbEg6EfMX0lZsinXZZgMRMIdOEShlyCIeMoIJmwAe2P6YkHQDw1WEZQwne021OFQt28fiSd4wHsJb4gStSAwpi8WBP1wFaeuQW+s25HjSsxAwh2pL3qn98AgSPrLKaGdeCx6uMsyJi9YEPTDE0oFQWv9kOkd2/Qh2pEal9jRSxA4ghUAtDTapcDG9MaCoB+BstEAdDbuynElZiCRzlQQ9NYicBalgqB1r/UbZUxvLAj6UVyRGkI52mxBMNTF0kHg8h0YBN7iVAeCHc3WIjCmNxYE/QhVpVoEiVb7JTnUxdMD17t9RQe85ytNDW8atiAwplcWBP3w+YO0EMDRYf3UDHXxcCoIPIHiA94rKkv1NxRrtf1oTG8sCAbQLCFcnfYFMtQlIqlDQ17/gUFQku6BNNlu3YUY0xsLggG0usrxRe0LZKjTaKpF4A0ceGgoECwhqi600+4SN6Y3FgQDCHvLKYpbPzVDXbKtnqQKJWVVB7wnDgdNUoLTgsCYXlkQDCDmqySUtCAY6hztu2mUEtweb6/vtztKcEebDm9RxuSJrAaBiJwtIm+LyGYRua6X9y8RkToRWZV+fCOb9RyKZKCKUtqJRsK5LsX0w9u5hyZnRZ/vd7hKrOM5Y/qQtSAQESdwK3AOMB34kohM72XWB1R1dvpxR7bqOVSO4tQVJ031O3NcielPMFpPm7vvIIh4QgQSFgTG9CabLYLjgc2qukVVo8BfgHOzuL6s8JSmxi5usW4mhrRQooGIf0Sf78e8ZRQnreM5Y3qTzSAYA3zQ7XVtelpP54vIGhFZJCLjeluQiCwQkeUisryu7vDeFOQvSwVB+15rEQxViXiccm0iEazuc56kr4wSbSOZSBzGyozJD7k+Wfw4MFFVZwL/AO7tbSZVvV1V56rq3KqqA68KyabiilR2RZqsm4mhqnHPdpyiOIpH9jmPBCpwSZLWZrtyyJieshkE24Huv/DHpqd1UdUGVY2kX94BHJfFeg5JqCrV31CidU+OKzF9aapLNTw9Zb01OFOcQet4zpi+ZDMI3gCmiMgkEfEAFwKLu88gIqO6vfwssCGL9RySYHGIDvUi7dZPzVDVVl8LQKB8dJ/zeEpSQdDeZIFuTE+ubC1YVeMi8m3gGcAJ3KWq60XkZ8ByVV0MfEdEPgvEgb3AJdmq56NocoRwdVoQDFXRxtTAQaXV4/ucx1eSOpEcbrEgMKanrAUBgKo+BTzVY9pPuj2/Hrg+mzUMhlZnGd6IdTMxVCVaUifyy0eM7XOeYCgVBNEW24/G9JTrk8V5ocNTTlHM7i4eqhztu9lLCR6vr895itMdzyWs4zljDmBBkIGor5IS62ZiyPJ27qHJUd7vPMWl5cTVgXZYEBjTkwVBBpKBSkLaQiIez3UpphfBaD1tnv4vK3Y4nbRIEY6wBboxPVkQZMBRNAKnKE0Ndi/BUFQabyDsG/j+klZHCe6IBYExPVkQZMBVYt1MDFWZ3FW8T4ezFK/1QGrMASwIMrCvm4k2axEMOY31O3BJEkdJ33cV7xN2lxKIW39DxvRkQZCBoorUfW+RJutvaKhp2p26q9gd6vuu4n1inhBB63jOmANYEGSgtCp1fXrcupkYctobUkEQqOj7ruJ9kr4yQtqCJpPZLsuYvGJBkIGS0nLC6kaa3st1KaaHSGOqlRYa0fddxV0CFXgkTke7tQqM6c6CIAPicLAxcBwT6l6wboyHmERz+q7i6l57MN+PI93xXIt1PGfMfiwIMhQ/+nOMpJ5NK57PdSmmG0f7LhoHuKt4H3dxJQBtjXaIz5juLAgyNPXU+UTUTdMbD+S6FNONp7NuwLuK9/GVpu41aK/7YIA5jSksFgQZKi4t562ij3FE3bN2h/EQUhSto9VTmdG8E2d8nGaCJFf/JctVGZNfLAgOQnL656mikY2v/z3XpZi00ngDkQzuKgbwB4vZMPJzzGx9iT3bt2a5MmPyhwXBQTj61AvoUC9tK+zw0FCw767ieAZ3Fe8z7lNX4UDZ8vQtWazMmPxiQXAQAkWlbCg+kSkNzxOPRXNdTsFrrN+Zuqu4n7GKexoz+WjWBD7GlNpFRMIdWazOmPxhQXCQHDXnUU4L61961G5MyrGm3e8D4Ckb+Gay7hwfW0AFzaz9x5+yUZYxeceC4CAdffL5tKmfWUsvJ/7TSupvnMAbN11Aw+7aw17Lrg82E4tGDvt6h4r2hlQngP7ygbuX6G7GyZ/jAxlN0eq7s1GWMXnHguAg+QJF1P7Ln3h1yjUsH/MVtpZ+jFlNz+P8/cd449HfdbUSEvE427dsYMWTd/Dq77/JK3+4kvod+9+ZrMkkLU2HNlDKyqfvpuqOubz3qxPZuv61PudLJhLD9ia4SGMqCEpHDHwzWXcOp5PtR32FafENLF98m7XsTMETVc11DQdl7ty5unz58lyXsZ/3Nq6k46ErOTr2Fi0E8GoMr8S63o+oGwdJ4jhZNfpCyo77HI0rH2PCzr8xWndTT4hd3ol0BMbgirYQiDbgSXSwp+pEQvMuYOqxpyGODzN77dLHmPrcZbzvmkBZop5ibWfF5G8y87zvEywOAbC79l22PH0LU7c/hE8j1Lon0FR0JDp6DiNrzmD81Dkkk0neWbmExlWLccQ6KP3Yl7vWVb/jPd75x+24Gt/FM/M8ZpxyHk5XZkNcJxMJ1rzwV2JrHkKOOIPjPrNgv/q3b1lPPBKmbNREikvK9nuvL7FohPc3rqBh06vorrUEW7cwNrKZEm0ndv0OvL5AhnsrpbV5L3t+ezpHJLbylnsG7k//kilzTjmoZXSvrX7nNtqb6gm3NoAqxSMmUDFqAkUlZYe0zJ7LX7/0YVz+IkZOmknFyHEZ/c1yJRaNkEwm8Hh8Q7rOQiMiK1R1bq/vZTMIRORs4GbACdyhqv+nx/teYCFwHNAAzFfVbf0tcygGAaS+/FY89juSO1aRdAfAHcBRPJKKo05g/LTjqNv+Ljsf/QnHNj+HQ5S4OnjLfyztI+fhbHqPUNtmyuN7aHOU0OYuRxGmhtfikTi7qOS9ylMJzDwXty/A+CcvYrdzFOXffpZEPMq2e7/Jse1LAWikhL3OSibEt+FAWR08kUhwDEUt7zA6soVyUv3s7KUEgHJaiKuDOE58EuN9xxiaPKOZ3rkClyRpVT/F0sluKthadTqSjOGONOKMdxB3FxP3hlBfGXiCiDeIxjoZ8+6DjNMddKoHv0TZ6Doazv532vdsw7/qbqZH13b93TrUS52zimbPKDqDo1GXH4l34oh34oq14Y81EUg0U53Y0xWubepnh3sczUVHIJNPZe5nrzikfRaPRVnx6G+Zsv5mymmhnhBNzgraPZWgSTyJDryJdpLiJOIsIuoKEvOESPgrkaJKtG0Pofo3mRTdhK9b8HfXoV46xE9YfIQdQTrcZUS8FSS8IZD0l2QyjivSiDeyF3cyTGPVPCrmns+kGSfw5pN/YOya3zFaP+wWo4Ugu1xjaAmMJxaajKOoCqevGIe3iFjTdti9nlDLJtzJMJ2uUiLuUmKBEWj5ZPzVU3C6vbTv3IQ2vIunbTv+aD3F8b24NMGuwJF0VszAM+ponN4gTrcXp8eP2xfE4wvidHlobdhOe/37xJt34/CX4g2NxBsopemdf1L0wQscFV6LR1Kt0Ki62O0YQV3gCCLlU3EEK1PbLQ4cngCuQCmeonLi4RY6d78Le1OX9Tqqp1MyYSYkkzSueYqqXUsJJRp4r2g2iYmnUnHUCcTC7UTam0jGIniLKwiWj0IEdq58Gv+2Z5nUuZ4d7vE0VhyLZ9IJBCrHESipwOMLUrtmCWz6O+NbVtDsqqC+6kSKpp2GO1hKpKWOaEsD3tJqJsw8mdKKahLxeNePJklECUw7k6M+djZeX4APNq9h19olJJpqkUA5ruIqPEUVuP1FuH1FePxBXB4/bo8Xp8tNPBYlFgkT6Wih8f11RHduwN28laTDQ9JTjPpK8U84jiPmfori0nKSiQRb1r1C/epnKJo0lxknn3tI/99zEgQi4gQ2AWcCtcAbwJdU9a1u83wLmKmq3xSRC4HPq+r8/pY7VIMgU1vXv0b95hVMPuGzVFSP7XfelqYG3n7xAVxvP8609uX4JXWl0g6pxnP5P6gcPQFIHWJat+wx2rYux9H8Pv6OHXSEpjL+rO8wetK0ruVpMsmObRvYsepZeO+fiCZh6llM+fjncTgcbHh2IcUbHyAUq2Pb6HMYe/oCqsdNYd2Sv+Ba9Semdq6mXfy0OYqJiB9/sp1ibaFYO3DIh/+P3nFNoXn2Amr+x1dY/fQdTF79X1TS1FX7+5Pm4yofR7xpO7TsxNO+g+LwTioTu/FojLB4iYiXsATocIeIuEPEisbgHncsI48+kdETjx7UX5qtzXtZ//jNOBo24w3voShaTxIHUWeQqCuIQxN44m34Eu0Eky2EtBmPJIiqk63uI2msmINjxNG4iyvxFKXucu5s+IB4Yy201yHxDpyxdtyxFvyxJkrijRRra9f6E+KgVYppc4ZQcXJkdCMuSRJWNz6J8Y7zSNo+9l1cvmLat69H6t8m2LaNysh2Rmj9fn97gCaK2O6ZTNRVhC/WTCDRQkWiniLp3G++sLrZ7aymzVVBp7cSRKhse5txiVqccmjfC1sdE9lddSIaKId4FOKdeFvep6pjM6OTOwdcbod6AQjIh+e+4urgHc/RtPtHMb5lJSPYO2Ad7zvGsKt0DkVt2zgi+vZ+LfR9GilhS/FxBMJ7ODK6Ebf0fgj1fccYipKtlNNCTJ0kcOCTGGF10yH+rh9Xhyqpwm6pxEGSgHYQJNz1Y3GrazJViV2EaAPgldEXc+KCQ7v0OVdBcCJwo6qelX59PYCq/rLbPM+k53lFRFzALqBK+ykq34PgUHW2t/L2y48T3ryUcWddzZjJR+e6pC7JRIJwZxsdbS0kE3GqRk3Y74u6tXkv65/8v/hHHknNqRfgcDpzWO1Hp8kkLc178fr8+PzBQV9+c8NuNr20CH3vZTzT/4VZZ1zYZ/BFwh20NtUTbmsh3N5MccVIRoyedMD8mkyyt24HddveIh4LUzlhOiNGT+p1X3S0NbNr20bi0U4SsQjxSJhEtIN4pA2NRfGVjaJkxARKq8bQ3tJIa30t4dYGRk2dR/XYI/rcrnBHG53trSSTCTSRIBLuoLO1gXDrXlweP5Xjp1ExYgyqyq7332HP5pVoMsbk4/+F0rLKru14/+03qd+6Bre/GE9RCJfHR2dzA5GW3SQjHYyadQbjjqzZ72/0/obldDTuIta2l0S4ldDk4zhy9ildhzvbW5vY8uYSkvEYvpJKAqEqmndtpW3zq3j3vEnCFYCpZ3PUSefh8XjZ9PozdLz1DM5oCzr2eEbOPJ0xk2fQ0lhHy97ddDbXEQu3EQ+3k4i0k4xH0XgEknHE6UFcHhyeIKGxUxlz5Ex8gaIP/06d7Wxe8RytG56jpG4FHYGxyORPMnHuOV0//g5FroLgC8DZqvqN9OuvAh9T1W93m2ddep7a9Ot30/PU91jWAmBB+uVU4O1DLKsSqB9wruGnELe7ELcZCnO7C3Gb4eC3e4Kq9nobfmZn/3JMVW8Hbv+oyxGR5X0l4nBWiNtdiNsMhbndhbjNMLjbnc1T+tuB7tf1jU1P63We9KGhUlInjY0xxhwm2QyCN4ApIjJJRDzAhcDiHvMsBr6Wfv4F4Pn+zg8YY4wZfFk7NKSqcRH5NvAMqctH71LV9SLyM2C5qi4G7gT+JCKbgb2kwiKbPvLhpTxViNtdiNsMhbndhbjNMIjbnXc3lBljjBlcdtufMcYUOAsCY4wpcAUTBCJytoi8LSKbReS6XNeTDSIyTkSWiMhbIrJeRK5OTy8XkX+IyDvpfz96BzhDkIg4ReRNEXki/XqSiLyW3ucPpC9aGDZEJCQii0Rko4hsEJETC2Ffi8h30/+/14nIn0XENxz3tYjcJSJ70vdb7ZvW6/6VlN+mt3+NiBx7MOsqiCBId3dxK3AOMB34kohMz21VWREHvqeq04ETgCvT23kd8JyqTgGeS78ejq4GNnR7/SvgJlU9EmgEvp6TqrLnZuBvqjoNmEVq24f1vhaRMcB3gLmqOoPUhSgXMjz39T3A2T2m9bV/zwGmpB8LgN8fzIoKIgiA44HNqrpFVaPAX4BD67lpCFPVnaq6Mv28ldQXwxhS23pverZ7gc/lpMAsEpGxwL8Ad6RfC3A6sCg9y7DabhEpBU4hdeUdqhpV1SYKYF+TutrRn773KADsZBjua1VdCgd0rNTX/j0XWKgprwIhERmV6boKJQjGAB90e12bnjZsichEYA7wGlCtqjvTb+0CMh/kN3/8N/BvwL7BBSqAJlWNp18Pt30+CagD7k4fDrtDRIIM832tqtuB/wTeJxUAzcAKhve+7q6v/fuRvuMKJQgKiogUAQ8B/6qq+3WNmL5hb1hdMywinwH2qOqKXNdyGLmAY4Hfq+ocoJ0eh4GG6b4uI/XrdxIwGghy4OGTgjCY+7dQgiCT7i6GBRFxkwqB+1T14fTk3fuaiel/9+Sqviw5CfisiGwjddjvdFLHz0Ppwwcw/PZ5LVCrqvuGp1tEKhiG+77+H8BWVa1T1RjwMKn9P5z3dXd97d+P9B1XKEGQSXcXeS99XPxOYIOq/qbbW9278vga8Njhri2bVPV6VR2rqhNJ7dvnVfUiYAmprktgmG23qu4CPhCRqelJZwBvMcz3NalDQieISCD9/33fdg/bfd1DX/t3MXBx+uqhE4DmboeQBqaqBfEAPk1qoJx3gR/mup4sbeMnSDUV1wCr0o9Pkzpe/hzwDvAsUJ7rWrP4N/gk8ET6+WTgdWAz8FfAm+v6BnlbZwPL0/v7UaCsEPY18FNgI7AO+BPgHY77GvgzqfMgMVItwK/3tX8BIXVl5LvAWlJXVWW8LutiwhhjClyhHBoyxhjTBwsCY4wpcBYExhhT4CwIjDGmwFkQGGNMgbMgMAVNRBIisqrbY9A6aRORid17jsxg/qCIPJt+vqzbDVLGZJX9RzOFrlNVZ+e6iLQTgVfS3Si064d95xiTVdYiMKYXIrJNRH4tImtF5HUROTI9faKIPJ/u8/05ERmfnl4tIo+IyOr04+PpRTlF5I/p/vP/LiL+XtZ1hIisAv5/4MukOlGblW6hjDg8W2wKmQWBKXT+HoeG5nd7r1lVa4DfkerdFOAW4F5VnQncB/w2Pf23wIuqOotUnz/r09OnALeq6jFAE3B+zwJU9d10q2QFqS7T7wW+rqqzVXW49RVkhiC7s9gUNBFpU9WiXqZvA05X1S3pjvx2qWqFiNQDo1Q1lp6+U1UrRaQOGKuqkW7LmAj8Q1ODiCAi1wJuVf15H7W8oarzROQh4GpVrR3s7TWmN9YiMKZv2sfzgxHp9jxBL+flROS29EnlKelDRGcDT4jIdw9xncYcFAsCY/o2v9u/r6Sfv0yqh1OAi4CX0s+fA66ArrGTSzNdiap+k1RHav8fqRGnnkwfFrrpI1VvTIbsqiFT6PzpX+H7/E1V911CWiYia0j9qv9SetpVpEYF+z6pEcIuTU+/GrhdRL5O6pf/FaR6jszUqcBC4GTgxUPZEGMOlZ0jMKYX6XMEc1W1Pte1GJNtdmjIGGMKnLUIjDGmwFmLwBhjCpwFgTHGFDgLAmOMKXAWBMYYU+AsCIwxpsD9P8CSj34IvWY4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "c0b1cfb9-563b-415f-86f7-571fea081570"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fafa8573f10>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('lbm_sample.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "2fee1fe9-e35a-4618-bce4-eef9503839ef"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1182b928-8f30-47ed-86a3-399b7cbd929a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1182b928-8f30-47ed-86a3-399b7cbd929a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1182b928-8f30-47ed-86a3-399b7cbd929a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1182b928-8f30-47ed-86a3-399b7cbd929a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "f4671263-723c-44b1-a3cc-76b0f7137fcd"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "0e4081e0-c860-42af-8043-29946ce08b67"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#for t in inputs:\n",
        " # mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f8621d-555b-499b-dd8b-262084c09cc1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 7.63 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('lbm_sample_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "e8d07711-070f-4c3f-b443-423df2fdb8d7"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "4  moduleom_name:0opendeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b28c64c-777f-4620-b449-75dca7c8ad01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b28c64c-777f-4620-b449-75dca7c8ad01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b28c64c-777f-4620-b449-75dca7c8ad01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b28c64c-777f-4620-b449-75dca7c8ad01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "ab6d0603-83a0-40c7-bcf3-4d632da4dd62"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "88d731fa-a046-4745-da24-0c092298111e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.000000\n",
            "Testing: Recall = 0.000000\n",
            "Testing: F1 Score = 0.000000\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[85  0]\n",
            " [15  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "38088f85-19b6-4562-e100-2bc660c0d5db"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92        85\n",
            "           1       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.85       100\n",
            "   macro avg       0.42      0.50      0.46       100\n",
            "weighted avg       0.72      0.85      0.78       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}