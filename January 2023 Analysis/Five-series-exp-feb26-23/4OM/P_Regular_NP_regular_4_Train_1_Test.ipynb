{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "[link text](https://)  \n",
        "#Experiment with P Regular , NP Regular \n",
        "###4 OM - Dataset, Camping, Bank, Customer-Order\n",
        "###1 OM - Testing - Library Management \n",
        "\n",
        "### Total instances - 145 \n",
        "\n",
        "### P samples - 34\n",
        "### NP samples - 111"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGFTkuRvzWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a82464-108b-4da1-cd45-5a2835d0d73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-text>=2.10 in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text>=2.10) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text>=2.10) (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (23.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (23.1.21)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.30.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.19.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (15.0.6.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install \"tensorflow-text>=2.10\"\n",
        "#!pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('4-OM.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Dat from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "92d895cf-3d04-4ff6-cefa-d4e567157077"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc1b82f2-9a50-4350-82ca-33a580b102a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc1b82f2-9a50-4350-82ca-33a580b102a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc1b82f2-9a50-4350-82ca-33a580b102a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc1b82f2-9a50-4350-82ca-33a580b102a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  #print(example_context_strings[:5])\n",
        "  #print()\n",
        "  #print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "#print(example_text.numpy())\n",
        "#print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  #text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  #pattern = '\\s+'\n",
        "  #re.split(pattern, text, maxsplit=2)\n",
        "  #text = tf.strings.regex_replace(text, '\\s+', '')\n",
        "  #tf.strings.split(text, sep=', ', maxsplit=2, name=None)\n",
        "  #tf.strings.split (text, sep='\\s+', maxsplit=2, name=None)\n",
        "  #text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  #tf.strings.split(text, ',')\n",
        "  #text = tf.strings.split(text, sep=None, maxsplit=-1, name=None)\n",
        "  #text.tf.strings.split(', ')\n",
        "\n",
        "  # Add spaces around punctuation.\n",
        "  #text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  #text = tf.strings.strip(text)\n",
        "\n",
        "  #text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  #return text\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'\\0')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "#print(example_text.numpy().decode())\n",
        "#print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "5fb71a7c-c004-4683-dc37-1a8fa5de1369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 85, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "98g9rcxGQY0I",
        "outputId": "c57a2b9b-cbf8-40aa-e3a5-476870a7c531"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] moduleom_name:0,opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsclassattrset=c2_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsclassattrset=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsclassattrset=c4_at1+c4_at2id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsclassattrset=c5_at1+c3_at1id=c5_at1noparentisabstract=no}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsclassattrset=c7_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsassociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsassociationsrc=class6_namedst=customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsassociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsassociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigcustomerloanassociationextendsassociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\u200b,tablename:class5_nametablename:class8_nametablename:class7_nametablename:class1_nametablename:class3_nametablename:class4_nametablename:class6_nametableclass1_name:attributec1_at1primarykeytableclass1_name:attributec1_at2tableclass2_name:attributec2_at1primarykeytableclass3_name:attributec3_at4tableclass3_name:attributec3_at5tableclass3_name:attributec3_at2tableclass3_name:attributec3_at2tableclass4_name:attributec4_at1primarykeytableclass4_name:attributec4_at2tableclass5_name:attributec3_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeytableclass6_name:attributec6_at2tableclass6_name:attributec6_at3tableclass7_name:attributec7_at1tableclass1_name:attributec1_at1primarykeytableclass4_name:attributec4_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeymappingstrategyforclass8_name:map_str2mappingstrategyforclass6_name:map_str2mappingstrategyforclass7_name:map_str2associationstrategyforassoc1:assoc_type1associationstrategyforassoc2:assoc_type1associationstrategyforassoc5:assoc_type1associationstrategyforassoc3:assoc_type2,useom_name_0createtable`class5_name`(`c5_at1`c5_at1_typenotnull`c3_at1`c3_at2_typekey`fk_class5_name_c3_at1_idx`(`c3_at1`)primarykey(`c5_at1`),);createtable`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`),);createtable`class1_name`(`c1_at2`c4_at2_type(64)`c3_at1`c3_at2_type`c1_at1`c1_at1_typekey`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`),);createtable`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c6_at1`c6_at1_type`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typekey`fk_class3_name_c6_at1_idx`(`c6_at1`)primarykey(`c3_at1`),);createtable`class4_name`(`c4_at2`c4_at2_type(64)`c6_at1`c6_at1_type`c4_at1`c4_at1_typenotnullkey`fk_class4_name_c6_at1_idx`(`c6_at1`)primarykey(`c4_at1`),);createtable`assoc3`(`c4_at1`c4_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc3_c4_at1_idx`(`c4_at1`)key`fk_assoc3_c3_at1_idx`(`c3_at1`)primarykey(`c4_at1`,`c3_at1`),);createtable`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typeprimarykey(`c3_at1`),);altertable`class5_name`addconstraint`fk_class5_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`class1_name`addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`class3_name`addconstraint`fk_class3_name_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,altertable`class4_name`addconstraint`fk_class4_name_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,\\u200b [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "e966df7b-bdf6-42dd-f9b1-9b6be888f4eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "165063c3-92be-4fed-9989-ea49bf656fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 17  3]\n",
            "\n",
            "[ 2 16]\n",
            "[16  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "f3f8e781-c25e-450a-ee20-137c6b13d4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y7hjPkNMmHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "9fe8155c-84d8-4638-fe4b-b658fd434f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "fbae9142-cf9c-432b-e9d6-451de1617c32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "913926d0-7cd5-4a5b-ff7d-1817c8856fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "236e1c06-0e28-419b-dc6f-604251fd2b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 108)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuehagxL-JBZ",
        "outputId": "38e9d9af-b6f7-4c6e-c6ed-c5c95f1ed002"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'moduleom_nameonesigclass1_nameextendsclassattrset=c1_at1+c1_at2attrset=c1_at1+c1_at2isabstract=nonoparentonesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassid=integerisabstract=nonoparentonesigc2_at1extendsc2_at1_typeonesigc2_at1extendsc2_at1_typeonesigassoc1extendsassociationsrc=class1_namedst=class2_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpconesigclass3_nameextendsclassattrset=c3_at1oneparentparentinclass1_nameisabstract=noattrset=c1_at1+c1_at2onesigc3_at1extendsc3_at1_typepredshowrunshowfor16,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at2:c1_at2_typetable:class3_nameattributec3_at1:c3_at1_typetable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class3_nameattributec1_at1:c1_at1_typeforeignkeytable:class3_nameparentclassclass1_nametablename:class1_nametablename:class2_nametablename:class3_nameassociationtableassoc1source:class1_nameassociationtableassoc1destination:class2_nameonetomanyassociationsource>destinationmappingstrategyoftableclass1_name:map_str2mappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2associationmappingstrategy:ownassociationtable,useom_name_0tablestructurefortableclass2_namecreatetable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`)tablestructurefortableclass1_namecreatetable`class1_name``c1_at3`c1_at3_type(64)`c1_at2`c1_at2_type`c3_at1`int`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`)tablestructurefortableclass1_namecreatetable`assoc1``c2_at1`c2_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc1_c2_at1_idx`(`c2_at1`)key`fk_assoc1_c1_at1_idx`(`c1_at1`)primarykey(`c2_at1`,`c1_at1`)altertable`assoc1`addconstraint`fk_assoc1_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0,opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsclassattrset=c2_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsclassattrset=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsclassattrset=c4_at1+c4_at2id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsclassattrset=c5_at1+c3_at1id=c5_at1noparentisabstract=no}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsclassattrset=c7_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsassociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsassociationsrc=class6_namedst=customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsassociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsassociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigcustomerloanassociationextendsassociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\xe2\\x80\\x8b,tableclass1_name:attributec1_at1primarykeytableclass1_name:attributec1_at2tableclass2_name:attributec2_at1primarykeytableclass3_name:attributec3_at4tableclass3_name:attributec3_at5tableclass3_name:attributec3_at2tableclass3_name:attributec3_at2tableclass4_name:attributec4_at1primarykeytableclass4_name:attributec4_at2tableclass5_name:attributec3_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeytableclass6_name:attributec6_at2tableclass6_name:attributec6_at3tableclass7_name:attributec7_at1tableclass1_name:attributec1_at1primarykeytableclass4_name:attributec4_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_nametablename:class7_namemappingstrategyforclass1_name:map_str2mappingstrategyforclass8_name:map_str2mappingstrategyforclass3_name:map_str2mappingstrategyforclass5_name:map_str2mappingstrategyforclass6_name:map_str2mappingstrategyforclass7_name:map_str2associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc5:assoc_type2,useom_name_0createtable`class5_name`(`c5_at1`c5_at1_typenotnull`c3_at1`c3_at2_typeprimarykey(`c5_at1`),);createtable`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`),);createtable`class1_name`(`c1_at2`c4_at2_type(64)`c1_at1`c1_at1_typeprimarykey(`c1_at1`),);createtable`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`assoc5`(`c3_at1`c3_at2_type`c1_at1`c1_at1_typekey`fk_assoc5_c3_at1_idx`(`c3_at1`)key`fk_assoc5_c1_at1_idx`(`c1_at1`)primarykey(`c3_at1`,`c1_at1`),);createtable`class4_name`(`c4_at2`c4_at2_type(64)`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`),);createtable`assoc2`(`c6_at1`c6_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc2_c6_at1_idx`(`c6_at1`),key`fk_assoc2_c3_at1_idx`(`c3_at1`)primarykey(`c6_at1`,`c3_at1`),);createtable`assoc3`(`c4_at1`c4_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc3_c4_at1_idx`(`c4_at1`)key`fk_assoc3_c3_at1_idx`(`c3_at1`)primarykey(`c4_at1`,`c3_at1`),);createtable`assoc4`(`c5_at1`c5_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc4_c5_at1_idx`(`c5_at1`)key`fk_assoc4_c3_at1_idx`(`c3_at1`),primarykey(`c5_at1`,`c3_at1`));createtable`assoc1`(`c6_at1`c6_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc1_c6_at1_idx`(`c6_at1`),key`fk_assoc1_c4_at1_idx`(`c4_at1`)primarykey(`c6_at1`,`c4_at1`),);createtable`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typeprimarykey(`c3_at1`),);altertable`assoc5`addconstraint`fk_assoc5_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade,altertable`assoc2`addconstraint`fk_assoc2_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`assoc4`addconstraint`fk_assoc4_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascade,altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,n\\xe2\\x80\\x8bp moduleom_name:0,opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsclassattrset=c2_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsclassattrset=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsclassattrset=c4_at1+c4_at2id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsclassattrset=c5_at1+c3_at1id=c5_at1noparentisabstract=no}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsclassattrset=c7_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsassociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsassociationsrc=class6_namedst=customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsassociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsassociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigcustomerloanassociationextendsassociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\xe2\\x80\\x8b,tableclass1_name:attributec1_at1primarykeytableclass1_name:attributec1_at2tableclass2_name:attributec2_at1primarykeytableclass3_name:attributec3_at4tableclass3_name:attributec3_at5tableclass3_name:attributec3_at2tableclass3_name:attributec3_at2tableclass4_name:attributec4_at1primarykeytableclass4_name:attributec4_at2tableclass5_name:attributec3_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeytableclass6_name:attributec6_at2tableclass6_name:attributec6_at3tableclass7_name:attributec7_at1tableclass1_name:attributec1_at1primarykeytableclass4_name:attributec4_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_nametablename:class7_namemappingstrategyforclass8_name:map_str2mappingstrategyforclass3_name:map_str2mappingstrategyforclass5_name:map_str2mappingstrategyforclass6_name:map_str2mappingstrategyforclass7_name:map_str2associationstrategyforassoc5:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`class5_name`(`c5_at1`c5_at1_typenotnull`c3_at1`c3_at2_typeprimarykey(`c5_at1`),);createtable`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`),);createtable`class1_name`(`c1_at2`c4_at2_type(64)`c3_at1`c3_at2_type`c1_at1`c1_at1_typekey`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`),);createtable`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`class4_name`(`c4_at2`c4_at2_type(64)`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`),);createtable`assoc2`(`c6_at1`c6_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc2_c6_at1_idx`(`c6_at1`),key`fk_assoc2_c3_at1_idx`(`c3_at1`)primarykey(`c6_at1`,`c3_at1`),);createtable`assoc3`(`c4_at1`c4_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc3_c4_at1_idx`(`c4_at1`)key`fk_assoc3_c3_at1_idx`(`c3_at1`)primarykey(`c4_at1`,`c3_at1`),);createtable`assoc4`(`c5_at1`c5_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc4_c5_at1_idx`(`c5_at1`)key`fk_assoc4_c3_at1_idx`(`c3_at1`),primarykey(`c5_at1`,`c3_at1`));createtable`assoc1`(`c6_at1`c6_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc1_c6_at1_idx`(`c6_at1`),key`fk_assoc1_c4_at1_idx`(`c4_at1`)primarykey(`c6_at1`,`c4_at1`),);createtable`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typeprimarykey(`c3_at1`),);altertable`class1_name`addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`assoc2`addconstraint`fk_assoc2_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`assoc4`addconstraint`fk_assoc4_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascade,altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0,opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsclassattrset=c2_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsclassattrset=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsclassattrset=c4_at1+c4_at2id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsclassattrset=c5_at1+c3_at1id=c5_at1noparentisabstract=no}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsclassattrset=c7_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsassociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsassociationsrc=class6_namedst=customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsassociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsassociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigcustomerloanassociationextendsassociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\xe2\\x80\\x8b,tablename:class5_nametablename:class8_nametableclass1_name:attributec1_at1primarykeytableclass1_name:attributec1_at2tableclass2_name:attributec2_at1primarykeytableclass3_name:attributec3_at4tableclass3_name:attributec3_at5tableclass3_name:attributec3_at2tableclass3_name:attributec3_at2tableclass4_name:attributec4_at1primarykeytableclass4_name:attributec4_at2tableclass5_name:attributec3_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeytableclass6_name:attributec6_at2tableclass6_name:attributec6_at3tableclass7_name:attributec7_at1tableclass1_name:attributec1_at1primarykeytableclass4_name:attributec4_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeymappingstrategyforclass8_name:map_str2mappingstrategyforclass6_name:map_str2mappingstrategyforclass7_name:map_str2associationstrategyforassoc2:assoc_type1associationstrategyforassoc5:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`class5_name`(`c5_at1`c5_at1_typenotnull`c3_at1`c3_at2_typekey`fk_class5_name_c3_at1_idx`(`c3_at1`)primarykey(`c5_at1`),);createtable`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`),);createtable`class1_name`(`c1_at2`c4_at2_type(64)`c3_at1`c3_at2_type`c1_at1`c1_at1_typekey`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`),);createtable`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c6_at1`c6_at1_type`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typekey`fk_class3_name_c6_at1_idx`(`c6_at1`)primarykey(`c3_at1`),);createtable`class4_name`(`c4_at2`c4_at2_type(64)`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`),);createtable`assoc3`(`c4_at1`c4_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc3_c4_at1_idx`(`c4_at1`)key`fk_assoc3_c3_at1_idx`(`c3_at1`)primarykey(`c4_at1`,`c3_at1`),);createtable`assoc1`(`c6_at1`c6_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc1_c6_at1_idx`(`c6_at1`),key`fk_assoc1_c4_at1_idx`(`c4_at1`)primarykey(`c6_at1`,`c4_at1`),);createtable`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typeprimarykey(`c3_at1`),);altertable`class5_name`addconstraint`fk_class5_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`class1_name`addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`class3_name`addconstraint`fk_class3_name_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at2:c2_at2_typetable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class3_nameattributec3_at2:c3_at2_typetable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class4_nameattributec4_at2:c4_at2_typetable:class4_nameattributec4_at3:c4_at3_typetable:class4_nameattributec4_at4:c4_at4_typetable:class5_nameattributec5_at1:c5_at1_typeprimarykeytable:class5_nameattributec5_at2:c5_at2_typetable:class6_nameattributec6_at1:c6_at1_typeprimarykeytable:class6_nameattributec6_at2:c6_at2_typetablename:class6_nametable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class6_nameattributec6_at1:c6_at1_typeprimarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_namemappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2associationstrategyforassoc2:assoc_type1associationstrategyforassoc3:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2,useom_name_0createtable`assoc1`(`c6_at1`c6_at1_typenotnull,`c4_at1`c4_at1_typenotnull,key`fk_assoc1_c6_at1_idx`(`c6_at1`),fk_assoc1_c4_at1_idx`(`c4_at1`),primarykey(`c6_at1`,`c4_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull,primarykey(`c3_at1`));createtable`class5_name`(`c5_at2`c5_at2_type,`c5_at1`c5_at1_type,`c4_at1`c4_at1_typenotnull,key`fk_class5_name_c4_at1_idx`(`c4_at1`),primarykey(`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type(64),`c2_at1`c2_at1_typenotnull,primarykey(`c2_at1`));createtable`class6_name`(`c6_at3`c6_at3_type,`c6_at2`c6_at2_type,`c6_at1`c6_at1_typenotnull,`c2_at1`c2_at1_type,key`fk_class6_name_c2_at1_idx`(`c2_at1`),primarykey(`c6_at1`));createtable`class1_name`(`c4_at1`c4_at1_type,`c3_at1`c3_at1_type,`c1_at2`c1_at2_type,`c1_at1`c1_at1_typenotnull,key`fk_class1_name_c4_at1_idx`(`c4_at1`),key`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`));createtable`class4_name`(`c4_at2`c4_at2_type(64),`c4_at4`c4_at4_type,`c4_at3`c4_at3_type,`c4_at1`c4_at1_typenotnull,primarykey(`c4_at1`));altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`class5_name`addconstraint`fk_class5_name_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`class6_name`addconstraint`fk_class6_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade;altertable`class1_name`addconstraint`fk_class1_name_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,p moduleom_nameonesigclass1_nameextendsclassattrset=c1_at1+c1_at2attrset=c1_at1+c1_at2isabstract=nonoparentonesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassid=integerisabstract=nonoparentonesigc2_at1extendsc2_at1_typeonesigc2_at1extendsc2_at1_typeonesigassoc1extendsassociationsrc=class1_namedst=class2_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpconesigclass3_nameextendsclassattrset=c3_at1oneparentparentinclass1_nameisabstract=noattrset=c1_at1+c1_at2onesigc3_at1extendsc3_at1_typepredshowrunshowfor16.om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at2:c1_at2_typetable:class3_nameattributec3_at1:c3_at1_typetable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class3_nameattributec1_at1:c1_at1_typeforeignkeytable:class3_nameparentclassclass1_nametablename:class1_nametablename:class2_nametablename:class3_nameassociationtableassoc1source:class1_nameassociationtableassoc1destination:class2_nameonetomanyassociationsource>destinationmappingstrategyoftableclass1_name:map_str2mappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2associationmappingstrategy:ownassociationtable,useom_name_0tablestructurefortableclass2_namecreatetable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`orderid`)tablestructurefortableclass1_namecreatetable`class1_name``c1_at3`c1_at3_type(64)`c1_at2`c1_at2_type`c3_at1`int`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`)tablestructurefortableclass1_namecreatetable`assoc1``c2_at1`c2_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc1_c2_at1_idx`(`c2_at1`)key`fk_assoc1_c1_at1_idx`(`c1_at1`)primarykey(`c2_at1`,`c1_at1`)altertable`assoc1`addconstraint`fk_assoc1_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0,opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,onesigclass2_nameextendsclassattrset=c2_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc2_at1extendsc2_at1_type,onesigclass3_nameextendsclassattrset=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,onesigclass4_nameextendsclassattrset=c4_at1+c4_at2id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,onesigclass5_nameextendsclassattrset=c5_at1+c3_at1id=c5_at1noparentisabstract=no}onesigc5_at1extendsc5_at1_type,onesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,onesigclass7_nameextendsclassattrset=c7_at1oneparentparentinclass5_nameid=c3_at1isabstract=no}onesigc7_at1extendsc7_at1_type,onesigassoc1extendsassociationsrc=class6_namedst=class4_name,src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc2extendsassociationsrc=class6_namedst=customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc3extendsassociationsrc=class3_namedst=class4_name,src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigassoc4extendsassociationsrc=class3_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigcustomerloanassociationextendsassociation{}{src=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}predshowrunshow\\xe2\\x80\\x8b,tablename:class5_nametablename:class8_nametableclass1_name:attributec1_at1primarykeytableclass1_name:attributec1_at2tableclass2_name:attributec2_at1primarykeytableclass3_name:attributec3_at4tableclass3_name:attributec3_at5tableclass3_name:attributec3_at2tableclass3_name:attributec3_at2tableclass4_name:attributec4_at1primarykeytableclass4_name:attributec4_at2tableclass5_name:attributec3_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeytableclass6_name:attributec6_at2tableclass6_name:attributec6_at3tableclass7_name:attributec7_at1tableclass1_name:attributec1_at1primarykeytableclass4_name:attributec4_at1primarykeytableclass5_name:attributec5_at1tableclass6_name:attributec6_at1primarykeymappingstrategyforclass8_name:map_str2mappingstrategyforclass3_name:map_str2mappingstrategyforclass6_name:map_str2mappingstrategyforclass7_name:map_str2associationstrategyforassoc1:assoc_type1associationstrategyforassoc5:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`class5_name`(`c5_at1`c5_at1_typenotnull`c3_at1`c3_at2_typekey`fk_class5_name_c3_at1_idx`(`c3_at1`)primarykey(`c5_at1`),);createtable`class2_name`(`c7_at1`c7_at1_type`c5_at1`c5_at1_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`class6_name`(`c6_at3`c6_at3_type(64)`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`),);createtable`class1_name`(`c1_at2`c4_at2_type(64)`c3_at1`c3_at2_type`c1_at1`c1_at1_typekey`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`),);createtable`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at5`c3_at5_type`c3_at4`c3_at4_type`c3_at1`c3_at2_typeprimarykey(`c3_at1`),);createtable`class4_name`(`c4_at2`c4_at2_type(64)`c6_at1`c6_at1_type`c4_at1`c4_at1_typenotnullkey`fk_class4_name_c6_at1_idx`(`c6_at1`)primarykey(`c4_at1`),);createtable`assoc2`(`c6_at1`c6_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc2_c6_at1_idx`(`c6_at1`),key`fk_assoc2_c3_at1_idx`(`c3_at1`)primarykey(`c6_at1`,`c3_at1`));createtable`assoc3`(`c4_at1`c4_at1_typenotnull`c3_at1`c3_at2_typekey`fk_assoc3_c4_at1_idx`(`c4_at1`)key`fk_assoc3_c3_at1_idx`(`c3_at1`)primarykey(`c4_at1`,`c3_at1`),);createtable`class8_name`(`c5_at1`c5_at1_type`c3_at1`c3_at2_type`c2_at1`c2_at1_typeprimarykey(`c3_at1`),);altertable`class5_name`addconstraint`fk_class5_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`class1_name`addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`class4_name`addconstraint`fk_class4_name_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,altertable`assoc2`addconstraint`fk_assoc2_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at2:c2_at2_typetable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class3_nameattributec3_at2:c3_at2_typetable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class4_nameattributec4_at2:c4_at2_typetable:class4_nameattributec4_at3:c4_at3_typetable:class4_nameattributec4_at4:c4_at4_typetable:class5_nameattributec5_at1:c5_at1_typeprimarykeytable:class5_nameattributec5_at2:c5_at2_typetable:class6_nameattributec6_at1:c6_at1_typeprimarykeytable:class6_nameattributec6_at2:c6_at2_typetablename:class6_nametable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class6_nameattributec6_at1:c6_at1_typeprimarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_namemappingstrategyoftableclass1_name:map_str2mappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2mappingstrategyoftableclass4_name:map_str1mappingstrategyoftableclass5_name:map_str1associationstrategyforassoc2:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2\\xe2\\x80\\x8b,useom_name_0createtable`assoc1`(`c6_at1`c6_at1_typenotnull,`c4_at1`c4_at1_typenotnull,key`fk_assoc1_c6_at1_idx`(`c6_at1`),fk_assoc1_c4_at1_idx`(`c4_at1`),primarykey(`c6_at1`,`c4_at1`));createtable`assoc4`(`c3_at1`c3_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc4_c3_at1_idx`(`c3_at1`),key`fk_assoc4_c1_at1_idx`(`c1_at1`),primarykey(`c3_at1`,`c1_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull,primarykey(`c3_at1`));createtable`class2_name`(`c2_at2`c2_at2_type(64),`c2_at1`c2_at1_typenotnull,primarykey(`c2_at1`));createtable`assoc3`(`c4_at1`c4_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc3_c4_at1_idx`(`c4_at1`),key`fk_assoc3_c1_at1_idx`(`c1_at1`),primarykey(`c4_at1`,`c1_at1`));createtable`class6_name`(`c6_at3`c6_at3_type,`c6_at2`c6_at2_type,`c6_at1`c6_at1_typenotnull,`c2_at1`c2_at1_type,key`fk_class6_name_c2_at1_idx`(`c2_at1`),primarykey(`c6_at1`));createtable`class1_name`(`c1_at2`c1_at2_type,`c1_at1`c1_at1_typenotnull,primarykey(`c1_at1`));createtable`class4_name`(`c4_at5`c4_at5_type(64),`c4_at2`c4_at2_type(64),`c5_at2`c5_at2_type,`c5_at1`c5_at1_type,`c4_at4`c4_at4_type,`c4_at3`c4_at3_type,`c4_at1`c4_at1_typenotnull,primarykey(`c4_at1`));altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`assoc4`addconstraint`fk_assoc4_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc4_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc3_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`class6_name`addconstraint`fk_class6_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade,p moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\xe2\\x80\\x8b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str1mappingstrategyoftableclass8_name:map_str1mappingstrategyoftableclass10_name:map_str1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`assoc5`(`c6_at1`c6_at1_typenotnull`c1_at1`c1_at1_typenotnullkey`fk_assoc5_c6_at1_idx`(`c6_at1`),key`fk_assoc5_c1_at1_idx`(`c1_at1`),primarykey(`c5_at1`,`c1_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c1_at1`c1_at1_typenotnullprimarykey(`c1_at1`));createtable`assoc1`(`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc1_c3_at1_idx`(`c3_at1`),key`fk_assoc1_c2_at1_idx`(`c2_at1`),primarykey(`c3_at1`,`c2_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at2`c7_at2_type(64)`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c10_at1`c10_at1_type`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnullprimarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_assoc5_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc5_c6_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascadealtertable`assoc1`addconstraint`fk_assoc1_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc1_c3_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,np moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30,om_name_solution:0table:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class1_nameattributec1_at2:c1_at2_typetable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at2:c2_at2_typetable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class3_nameattributec3_at2:c3_at2_typetable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class4_nameattributec4_at2:c4_at2_typetable:class4_nameattributec4_at3:c4_at3_typetable:class4_nameattributec4_at4:c4_at4_typetable:class5_nameattributec5_at1:c5_at1_typeprimarykeytable:class5_nameattributec5_at2:c5_at2_typetable:class6_nameattributec6_at1:c6_at1_typeprimarykeytable:class6_nameattributec6_at2:c6_at2_typetablename:class6_nametable:class1_nameattributec1_at1:c1_at1_typeprimarykeytable:class2_nameattributec2_at1:c1_at1_typeprimarykeytable:class3_nameattributec3_at1:c3_at1_typeprimarykeytable:class4_nameattributec4_at1:c4_at1_typeprimarykeytable:class6_nameattributec6_at1:c6_at1_typeprimarykeytablename:class1_nametablename:class2_nametablename:class3_nametablename:class4_nametablename:class5_nametablename:class6_namemappingstrategyoftableclass2_name:map_str2mappingstrategyoftableclass3_name:map_str2mappingstrategyoftableclass6_name:map_str2mappingstrategyoftableclass4_name:map_str1mappingstrategyoftableclass5_name:map_str1associationstrategyforassoc4:assoc_type1associationstrategyforassoc1:assoc_type2associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2,useom_name_0createtable`assoc1`(`c6_at1`c6_at1_typenotnull,`c4_at1`c4_at1_typenotnull,key`fk_assoc1_c6_at1_idx`(`c6_at1`),fk_assoc1_c4_at1_idx`(`c4_at1`),primarykey(`c6_at1`,`c4_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull,primarykey(`c3_at1`));createtable`class2_name`(`c2_at2`c2_at2_type(64),`c2_at1`c2_at1_typenotnull,primarykey(`c2_at1`));createtable`assoc3`(`c4_at1`c4_at1_typenotnull,`c1_at1`c1_at1_typenotnull,key`fk_assoc3_c4_at1_idx`(`c4_at1`),key`fk_assoc3_c1_at1_idx`(`c1_at1`),primarykey(`c4_at1`,`c1_at1`));createtable`class6_name`(`c6_at3`c6_at3_type,`c6_at2`c6_at2_type,`c6_at1`c6_at1_typenotnull,primarykey(`c6_at1`));createtable`class1_name`(`c3_at1`c3_at1_type,`c1_at2`c1_at2_type,`c1_at1`c1_at1_typenotnull,key`fk_class1_name_c3_at1_idx`(`c3_at1`),primarykey(`c1_at1`));createtable`assoc2`(`c6_at1`c6_at1_typenotnull,`c2_at1`c2_at1_typenotnull,key`fk_assoc2_c6_at1_idx`(`c6_at1`),key`fk_assoc2_c2_at1_idx`(`c2_at1`),primarykey(`c6_at1`,`c2_at1`));createtable`class4_name`(`c4_at5`c4_at5_type(64),`c4_at2`c4_at2_type(64),`c5_at2`c5_at2_type,`c5_at1`c5_at1_type,`c4_at4`c4_at4_type,`c4_at3`c4_at3_type,`c4_at1`c4_at1_typenotnull,primarykey(`c4_at1`));altertable`assoc1`addconstraint`fk_assoc1_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc1_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade;altertable`assoc3`addconstraint`fk_assoc3_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc3_c1_at1`foreignkey(`c1_at1`)references`class1_name`(`c1_at1`)ondeletecascadeonupdatecascade;altertable`class1_name`addconstraint`fk_class1_name_c3_at1`foreignkey(`c3_at1`)references`class3_name`(`c3_at1`)ondeletecascadeonupdatecascade;altertable`assoc2`addconstraint`fk_assoc2_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade,addconstraint`fk_assoc2_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascade,np'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "3ff383b4-17b7-4074-ec5d-4521664fb99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 108)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "9c54281e-9b12-4d61-ee8d-1988a1058c28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 4.6821313, 'expected_acc': 0.009259259259259259}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "1e786ba7-c77e-4874-a562-063034b044da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/60 [===============>..............] - ETA: 0s - loss: 4.8607 - masked_acc: 0.0000e+00 - masked_loss: 4.8607"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/60 [==============================] - 6s 6ms/step - loss: 4.8601 - masked_acc: 0.0000e+00 - masked_loss: 4.8601\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 4.860110282897949,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 4.860110282897949}"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=60, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "5ee51161-5583-4bb7-c7ff-29b0af2cc146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0220 - masked_acc: 0.9899 - masked_loss: 0.0220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 60 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 46ms/step - loss: 0.0218 - masked_acc: 0.9900 - masked_loss: 0.0218 - val_loss: 5.6084 - val_masked_acc: 0.5147 - val_masked_loss: 5.6084\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0177 - masked_acc: 0.9900 - masked_loss: 0.0177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 5s 49ms/step - loss: 0.0177 - masked_acc: 0.9900 - masked_loss: 0.0177\n",
            "Epoch 3/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0330 - masked_acc: 0.9798 - masked_loss: 0.0330"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0327 - masked_acc: 0.9800 - masked_loss: 0.0327\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0121 - masked_acc: 0.9949 - masked_loss: 0.0121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0120 - masked_acc: 0.9950 - masked_loss: 0.0120\n",
            "Epoch 5/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0235 - masked_acc: 0.9796 - masked_loss: 0.0235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0230 - masked_acc: 0.9800 - masked_loss: 0.0230\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0142 - masked_acc: 0.9850 - masked_loss: 0.0142"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0142 - masked_acc: 0.9850 - masked_loss: 0.0142\n",
            "Epoch 7/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0184 - masked_acc: 0.9898 - masked_loss: 0.0184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 29ms/step - loss: 0.0180 - masked_acc: 0.9900 - masked_loss: 0.0180\n",
            "Epoch 8/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0286 - masked_acc: 0.9847 - masked_loss: 0.0286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0280 - masked_acc: 0.9850 - masked_loss: 0.0280\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0223 - masked_acc: 0.9900 - masked_loss: 0.0223"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0223 - masked_acc: 0.9900 - masked_loss: 0.0223\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0399 - masked_acc: 0.9747 - masked_loss: 0.0399"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0395 - masked_acc: 0.9750 - masked_loss: 0.0395\n",
            "Epoch 11/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0229 - masked_acc: 0.9899 - masked_loss: 0.0229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 25ms/step - loss: 0.0227 - masked_acc: 0.9900 - masked_loss: 0.0227\n",
            "Epoch 12/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0261 - masked_acc: 0.9898 - masked_loss: 0.0261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0256 - masked_acc: 0.9900 - masked_loss: 0.0256\n",
            "Epoch 13/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0218 - masked_acc: 0.9848 - masked_loss: 0.0218"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0216 - masked_acc: 0.9850 - masked_loss: 0.0216\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0178 - masked_acc: 0.9850 - masked_loss: 0.0178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0178 - masked_acc: 0.9850 - masked_loss: 0.0178\n",
            "Epoch 15/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0190 - masked_acc: 0.9898 - masked_loss: 0.0190"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0186 - masked_acc: 0.9900 - masked_loss: 0.0186\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0123 - masked_acc: 0.9950 - masked_loss: 0.0123"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0123 - masked_acc: 0.9950 - masked_loss: 0.0123\n",
            "Epoch 17/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0198 - masked_acc: 0.9848 - masked_loss: 0.0198"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0196 - masked_acc: 0.9850 - masked_loss: 0.0196\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0384 - masked_acc: 0.9747 - masked_loss: 0.0384"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0380 - masked_acc: 0.9750 - masked_loss: 0.0380\n",
            "Epoch 19/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0165 - masked_acc: 0.9898 - masked_loss: 0.0165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0162 - masked_acc: 0.9900 - masked_loss: 0.0162\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0124 - masked_acc: 0.9950 - masked_loss: 0.0124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0124 - masked_acc: 0.9950 - masked_loss: 0.0124\n",
            "Epoch 21/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0286 - masked_acc: 0.9899 - masked_loss: 0.0286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0283 - masked_acc: 0.9900 - masked_loss: 0.0283\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0173 - masked_acc: 0.9900 - masked_loss: 0.0173"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0173 - masked_acc: 0.9900 - masked_loss: 0.0173\n",
            "Epoch 23/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0198 - masked_acc: 0.9848 - masked_loss: 0.0198"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0196 - masked_acc: 0.9850 - masked_loss: 0.0196\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0225 - masked_acc: 0.9798 - masked_loss: 0.0225"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0223 - masked_acc: 0.9800 - masked_loss: 0.0223\n",
            "Epoch 25/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0278 - masked_acc: 0.9847 - masked_loss: 0.0278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0272 - masked_acc: 0.9850 - masked_loss: 0.0272\n",
            "Epoch 26/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0152 - masked_acc: 0.9949 - masked_loss: 0.0152"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0149 - masked_acc: 0.9950 - masked_loss: 0.0149\n",
            "Epoch 27/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0223 - masked_acc: 0.9847 - masked_loss: 0.0223"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0218 - masked_acc: 0.9850 - masked_loss: 0.0218\n",
            "Epoch 28/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0140 - masked_acc: 0.9898 - masked_loss: 0.0140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0137 - masked_acc: 0.9900 - masked_loss: 0.0137\n",
            "Epoch 29/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0300 - masked_acc: 0.9796 - masked_loss: 0.0300"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0294 - masked_acc: 0.9800 - masked_loss: 0.0294\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0132 - masked_acc: 0.9949 - masked_loss: 0.0132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0131 - masked_acc: 0.9950 - masked_loss: 0.0131\n",
            "Epoch 31/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0258 - masked_acc: 0.9798 - masked_loss: 0.0258"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0255 - masked_acc: 0.9800 - masked_loss: 0.0255\n",
            "Epoch 32/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0185 - masked_acc: 0.9898 - masked_loss: 0.0185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0181 - masked_acc: 0.9900 - masked_loss: 0.0181\n",
            "Epoch 33/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0216 - masked_acc: 0.9899 - masked_loss: 0.0216"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0214 - masked_acc: 0.9900 - masked_loss: 0.0214\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0071 - masked_acc: 0.9950 - masked_loss: 0.0071"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0071 - masked_acc: 0.9950 - masked_loss: 0.0071\n",
            "Epoch 35/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0416 - masked_acc: 0.9798 - masked_loss: 0.0416"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0412 - masked_acc: 0.9800 - masked_loss: 0.0412\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0117 - masked_acc: 0.9899 - masked_loss: 0.0117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 27ms/step - loss: 0.0116 - masked_acc: 0.9900 - masked_loss: 0.0116\n",
            "Epoch 37/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0268 - masked_acc: 0.9898 - masked_loss: 0.0268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 45ms/step - loss: 0.0263 - masked_acc: 0.9900 - masked_loss: 0.0263\n",
            "Epoch 38/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0220 - masked_acc: 0.9847 - masked_loss: 0.0220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0216 - masked_acc: 0.9850 - masked_loss: 0.0216\n",
            "Epoch 39/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0218 - masked_acc: 0.9847 - masked_loss: 0.0218"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0214 - masked_acc: 0.9850 - masked_loss: 0.0214\n",
            "Epoch 40/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0185 - masked_acc: 0.9949 - masked_loss: 0.0185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0239 - masked_acc: 0.9900 - masked_loss: 0.0239\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0166 - masked_acc: 0.9900 - masked_loss: 0.0166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 25ms/step - loss: 0.0166 - masked_acc: 0.9900 - masked_loss: 0.0166\n",
            "Epoch 42/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0147 - masked_acc: 0.9847 - masked_loss: 0.0147"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0144 - masked_acc: 0.9850 - masked_loss: 0.0144\n",
            "Epoch 43/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0229 - masked_acc: 0.9847 - masked_loss: 0.0229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0225 - masked_acc: 0.9850 - masked_loss: 0.0225\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0239 - masked_acc: 0.9848 - masked_loss: 0.0239"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0237 - masked_acc: 0.9850 - masked_loss: 0.0237\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0287 - masked_acc: 0.9850 - masked_loss: 0.0287"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0287 - masked_acc: 0.9850 - masked_loss: 0.0287\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0181 - masked_acc: 0.9848 - masked_loss: 0.0181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0179 - masked_acc: 0.9850 - masked_loss: 0.0179\n",
            "Epoch 47/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0391 - masked_acc: 0.9848 - masked_loss: 0.0391"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0387 - masked_acc: 0.9850 - masked_loss: 0.0387\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0412 - masked_acc: 0.9899 - masked_loss: 0.0412"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0495 - masked_acc: 0.9850 - masked_loss: 0.0495\n",
            "Epoch 49/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.9510 - masked_acc: 0.7245 - masked_loss: 0.9510"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.9409 - masked_acc: 0.7250 - masked_loss: 0.9409\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5796 - masked_acc: 0.8300 - masked_loss: 0.5796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.5796 - masked_acc: 0.8300 - masked_loss: 0.5796\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2243 - masked_acc: 0.9150 - masked_loss: 0.2243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.2243 - masked_acc: 0.9150 - masked_loss: 0.2243\n",
            "Epoch 52/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.1336 - masked_acc: 0.9643 - masked_loss: 0.1336"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.1310 - masked_acc: 0.9650 - masked_loss: 0.1310\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0520 - masked_acc: 0.9700 - masked_loss: 0.0520"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0520 - masked_acc: 0.9700 - masked_loss: 0.0520\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0301 - masked_acc: 0.9798 - masked_loss: 0.0301"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0298 - masked_acc: 0.9800 - masked_loss: 0.0298\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0188 - masked_acc: 0.9900 - masked_loss: 0.0188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0188 - masked_acc: 0.9900 - masked_loss: 0.0188\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0165 - masked_acc: 0.9950 - masked_loss: 0.0165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0165 - masked_acc: 0.9950 - masked_loss: 0.0165\n",
            "Epoch 57/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0185 - masked_acc: 0.9847 - masked_loss: 0.0185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0245 - masked_acc: 0.9800 - masked_loss: 0.0245\n",
            "Epoch 58/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0138 - masked_acc: 0.9898 - masked_loss: 0.0138"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0136 - masked_acc: 0.9900 - masked_loss: 0.0136\n",
            "Epoch 59/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0377 - masked_acc: 0.9745 - masked_loss: 0.0377"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0370 - masked_acc: 0.9750 - masked_loss: 0.0370\n",
            "Epoch 60/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0149 - masked_acc: 0.9899 - masked_loss: 0.0149"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0239 - masked_acc: 0.9850 - masked_loss: 0.0239\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0116 - masked_acc: 0.9950 - masked_loss: 0.0116"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0116 - masked_acc: 0.9950 - masked_loss: 0.0116\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0399 - masked_acc: 0.9750 - masked_loss: 0.0399"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0399 - masked_acc: 0.9750 - masked_loss: 0.0399\n",
            "Epoch 63/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0148 - masked_acc: 0.9899 - masked_loss: 0.0148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0147 - masked_acc: 0.9900 - masked_loss: 0.0147\n",
            "Epoch 64/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0191 - masked_acc: 0.9847 - masked_loss: 0.0191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0187 - masked_acc: 0.9850 - masked_loss: 0.0187\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0221 - masked_acc: 0.9900 - masked_loss: 0.0221"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0221 - masked_acc: 0.9900 - masked_loss: 0.0221\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0207 - masked_acc: 0.9848 - masked_loss: 0.0207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0205 - masked_acc: 0.9850 - masked_loss: 0.0205\n",
            "Epoch 67/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0197 - masked_acc: 0.9898 - masked_loss: 0.0197"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0193 - masked_acc: 0.9900 - masked_loss: 0.0193\n",
            "Epoch 68/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0166 - masked_acc: 0.9898 - masked_loss: 0.0166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0163 - masked_acc: 0.9900 - masked_loss: 0.0163\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0267 - masked_acc: 0.9850 - masked_loss: 0.0267"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0267 - masked_acc: 0.9850 - masked_loss: 0.0267\n",
            "Epoch 70/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0131 - masked_acc: 0.9949 - masked_loss: 0.0131"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0128 - masked_acc: 0.9950 - masked_loss: 0.0128\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0203 - masked_acc: 0.9900 - masked_loss: 0.0203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0203 - masked_acc: 0.9900 - masked_loss: 0.0203\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0212 - masked_acc: 0.9850 - masked_loss: 0.0212"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0212 - masked_acc: 0.9850 - masked_loss: 0.0212\n",
            "Epoch 73/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0172 - masked_acc: 0.9898 - masked_loss: 0.0172"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0168 - masked_acc: 0.9900 - masked_loss: 0.0168\n",
            "Epoch 74/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0243 - masked_acc: 0.9848 - masked_loss: 0.0243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0241 - masked_acc: 0.9850 - masked_loss: 0.0241\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0179 - masked_acc: 0.9900 - masked_loss: 0.0179"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0179 - masked_acc: 0.9900 - masked_loss: 0.0179\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0241 - masked_acc: 0.9850 - masked_loss: 0.0241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0241 - masked_acc: 0.9850 - masked_loss: 0.0241\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0225 - masked_acc: 0.9850 - masked_loss: 0.0225"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0225 - masked_acc: 0.9850 - masked_loss: 0.0225\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0226 - masked_acc: 0.9800 - masked_loss: 0.0226"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 26ms/step - loss: 0.0226 - masked_acc: 0.9800 - masked_loss: 0.0226\n",
            "Epoch 79/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0220 - masked_acc: 0.9847 - masked_loss: 0.0220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0216 - masked_acc: 0.9850 - masked_loss: 0.0216\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0203 - masked_acc: 0.9900 - masked_loss: 0.0203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0203 - masked_acc: 0.9900 - masked_loss: 0.0203\n",
            "Epoch 81/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0156 - masked_acc: 0.9949 - masked_loss: 0.0156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0155 - masked_acc: 0.9950 - masked_loss: 0.0155\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0112 - masked_acc: 0.9950 - masked_loss: 0.0112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 31ms/step - loss: 0.0112 - masked_acc: 0.9950 - masked_loss: 0.0112\n",
            "Epoch 83/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0219 - masked_acc: 0.9848 - masked_loss: 0.0219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 32ms/step - loss: 0.0217 - masked_acc: 0.9850 - masked_loss: 0.0217\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0259 - masked_acc: 0.9800 - masked_loss: 0.0259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0259 - masked_acc: 0.9800 - masked_loss: 0.0259\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0192 - masked_acc: 0.9900 - masked_loss: 0.0192"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0192 - masked_acc: 0.9900 - masked_loss: 0.0192\n",
            "Epoch 86/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0166 - masked_acc: 0.9898 - masked_loss: 0.0166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 22ms/step - loss: 0.0163 - masked_acc: 0.9900 - masked_loss: 0.0163\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0251 - masked_acc: 0.9850 - masked_loss: 0.0251"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 33ms/step - loss: 0.0251 - masked_acc: 0.9850 - masked_loss: 0.0251\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0165 - masked_acc: 0.9900 - masked_loss: 0.0165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0165 - masked_acc: 0.9900 - masked_loss: 0.0165\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0159 - masked_acc: 0.9950 - masked_loss: 0.0159"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0159 - masked_acc: 0.9950 - masked_loss: 0.0159\n",
            "Epoch 90/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0342 - masked_acc: 0.9848 - masked_loss: 0.0342"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0339 - masked_acc: 0.9850 - masked_loss: 0.0339\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0200 - masked_acc: 0.9800 - masked_loss: 0.0200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0200 - masked_acc: 0.9800 - masked_loss: 0.0200\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0119 - masked_acc: 0.9950 - masked_loss: 0.0119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0119 - masked_acc: 0.9950 - masked_loss: 0.0119\n",
            "Epoch 93/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0194 - masked_acc: 0.9949 - masked_loss: 0.0194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0242 - masked_acc: 0.9900 - masked_loss: 0.0242\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0219 - masked_acc: 0.9850 - masked_loss: 0.0219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 28ms/step - loss: 0.0219 - masked_acc: 0.9850 - masked_loss: 0.0219\n",
            "Epoch 95/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0188 - masked_acc: 0.9848 - masked_loss: 0.0188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 41ms/step - loss: 0.0187 - masked_acc: 0.9850 - masked_loss: 0.0187\n",
            "Epoch 96/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0187 - masked_acc: 0.9898 - masked_loss: 0.0187"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 3s 34ms/step - loss: 0.0183 - masked_acc: 0.9900 - masked_loss: 0.0183\n",
            "Epoch 97/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0209 - masked_acc: 0.9899 - masked_loss: 0.0209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0207 - masked_acc: 0.9900 - masked_loss: 0.0207\n",
            "Epoch 98/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0115 - masked_acc: 0.9898 - masked_loss: 0.0115"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0112 - masked_acc: 0.9900 - masked_loss: 0.0112\n",
            "Epoch 99/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0214 - masked_acc: 0.9899 - masked_loss: 0.0214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 23ms/step - loss: 0.0212 - masked_acc: 0.9900 - masked_loss: 0.0212\n",
            "Epoch 100/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0238 - masked_acc: 0.9898 - masked_loss: 0.0238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 2s 24ms/step - loss: 0.0233 - masked_acc: 0.9900 - masked_loss: 0.0233\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 60,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "15b52458-c817-418a-c462-a0775891bc0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbb7bf56d90>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "e5070944-d15f-415f-88fb-342b22122f7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbb7bf7a880>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('lbm_sample.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "e46f1962-b51b-4786-91a5-a4713cc95264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae309e0b-f563-4eec-a22e-ed6e97f3354c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae309e0b-f563-4eec-a22e-ed6e97f3354c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae309e0b-f563-4eec-a22e-ed6e97f3354c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae309e0b-f563-4eec-a22e-ed6e97f3354c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "06e87b74-a56e-4891-80ea-8b9102fb0cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "a19ae94b-9272-4b18-ba01-976e7b559a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "#for t in inputs:\n",
        "#  mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('lbm_sample_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "cb689177-5538-4061-ca25-9a15a47806a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "3  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "4  moduleom_name:0opendeclarationonesigclass1_nam...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf309a8c-c7c4-442c-8d40-bc01c4d50453\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf309a8c-c7c4-442c-8d40-bc01c4d50453')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf309a8c-c7c4-442c-8d40-bc01c4d50453 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf309a8c-c7c4-442c-8d40-bc01c4d50453');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "27bf5f86-8ac6-40d6-efb8-4507951fb16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "ac8beda6-499b-4837-b97f-5afa053bc316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.153061\n",
            "Testing: Recall = 1.000000\n",
            "Testing: F1 Score = 0.265487\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[ 2 83]\n",
            " [ 0 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "d47a86f0-2889-4f25-87ea-e31ae75645ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.02      0.05        85\n",
            "           1       0.15      1.00      0.27        15\n",
            "\n",
            "    accuracy                           0.17       100\n",
            "   macro avg       0.58      0.51      0.16       100\n",
            "weighted avg       0.87      0.17      0.08       100\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}