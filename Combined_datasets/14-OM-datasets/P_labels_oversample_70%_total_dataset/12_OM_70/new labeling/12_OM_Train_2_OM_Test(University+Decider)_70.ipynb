{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# 12_OM_Train_2_OM_Test(University+Decider)-70\n",
        "\n",
        "# P oversample increased to 70%\n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###10 OM Dataset -  Camping,  Bank, , E-Commerce,  Traffic Controller, Library Management, School OM, Store OM, Student-course , Canteen OM, Hospital Management , Online Store, Customer Order\n",
        "\n",
        "###2 OM - Testing - University (Unseen)  , Decider (Unseen)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 70% - 30%\n",
        "\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "\n",
        "### Total instances - 30829\n",
        "\n",
        "### P samples - 21580 P \n",
        "### NP samples -  9248 NP\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 111\n",
        "\n",
        "### P samples - 25\n",
        "### NP samples - 80\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "# !pip install \"tensorflow-text>=2.10\"\n",
        "# !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_excel('12_OM_70_label.xlsx')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "6b8d367c-60a8-460c-8119-a07eeb13f7ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  module OM_name:0, open Declaration onesigclass...   \n",
              "1  module OM_name:0, open Declaration onesigclass...   \n",
              "2  module OM_name:0, open Declaration onesigclass...   \n",
              "3  module OM_name:0, open Declaration onesigclass...   \n",
              "4  module OM_name:0, open Declaration onesigclass...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  P, module OM_name:0, open Declaration onesigcl...  \n",
              "1  P, module OM_name:0, open Declaration onesigcl...  \n",
              "2  P, module OM_name:0, open Declaration onesigcl...  \n",
              "3  P, module OM_name:0, open Declaration onesigcl...  \n",
              "4  P, module OM_name:0, open Declaration onesigcl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7bc1d56-9e39-4d2f-a567-b7c5fc178249\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name:0, open Declaration onesigclass...</td>\n",
              "      <td>P, module OM_name:0, open Declaration onesigcl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name:0, open Declaration onesigclass...</td>\n",
              "      <td>P, module OM_name:0, open Declaration onesigcl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name:0, open Declaration onesigclass...</td>\n",
              "      <td>P, module OM_name:0, open Declaration onesigcl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name:0, open Declaration onesigclass...</td>\n",
              "      <td>P, module OM_name:0, open Declaration onesigcl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name:0, open Declaration onesigclass...</td>\n",
              "      <td>P, module OM_name:0, open Declaration onesigcl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7bc1d56-9e39-4d2f-a567-b7c5fc178249')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7bc1d56-9e39-4d2f-a567-b7c5fc178249 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7bc1d56-9e39-4d2f-a567-b7c5fc178249');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# # example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "# example_text = tf.constant('module OM_name:0 open Declaration one sig class1_name  extends  Class attr Set=c1_at1+c1_at2id=c1_at1 no parent is Abstract=No} one sig c1_at1 extends c1_at1_type one sig c1_at2 extends c1_at2_type one sig class2_name  extends  Class attr Set=c2_at1+c2_at2id=c2_at1 no parent is Abstract=No} one sig c2_at1 extends c2_at1_type one sig c2_at2 extends c2_at2_type one sig class3_name  extends  Class attr Set=c3_at1+c3_at2id=c3_at1 no parent is Abstract=No} one sig c3_at1 extends c3_at1_type one sig c3_at2 extends c3_at2_type one sig class4_name  extends  Class attr Set=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1 no parent is Abstract=No} one sig c4_at1 extends c4_at1_type one sig c4_at2 extends c4_at2_type one sig c4_at3 extends c4_at3_type one sig c4_at4 extends c4_at4_type one sig class5_name  extends  Class attr Set=c5_at1+c5_at2 one parent parent in class4_nameid=c4_at1isAbstract=No} one sig c5_at1 extends c5_at1_type one sig c5_at2 extends c5_at2_type one sig class6_name  extends  Class attr Set=c6_at1+c6_at2+c6_at3id=c6_at1 no parent is Abstract=No} one sig c6_at1 extends c6_at1_type one sig c6_at2 extends c6_at2_type one sig c6_at3 extends c6_at3_type one sig assoc1  extends  Association src=class6_namedst=class4_name src_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc} one sig assoc2  extends  Association src=class1_namedst=class5_name src_multiplicity=src_mlpc dst_multiplicity=dst_mlpc} one sig assoc3  extends  Association src=class4_namedst=class1_name src_multiplicity=src_mlpc dst_multiplicity=dst_mlpc} one sig assoc4  extends  Association src=class3_namedst=class1_name src_multiplicity=src_mlpc dst_multiplicity=dst_mlpc} pred show run show for30​,Mapping Strategy of Table class4_name:map_str2Mapping Strategy of Table class5_name:map_str2Mapping Strategy of Table class7_name:map_str2Mapping Strategy of Table class8_name:map_str2Mapping Strategy of Table class6_name:map_str3Association Strategy for assoc4:assoc_type1Association Strategy for assoc1:assoc_type2Association Strategy for assoc2:assoc_type2Association Strategy for assoc3:assoc_type2Association Strategy for assoc4:assoc_type2,USEOM_name_0  CREATE TABLE `assoc2`(`c7_at1`c7_at1_type NOT NULL`c4_at1`c4_at1_type NOT NULL  KEY  `FK_assoc2_c7_at1_idx`(`c7_at1`) KEY `FK_assoc2_c4_at1_idx`(`c4_at1`) PRIMARY  KEY (`c7_at1`,`c4_at1`));  CREATE TABLE `class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_type NOT NULL PRIMARY  KEY (`c2_at1`));  CREATE TABLE `class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_type NOT NULL PRIMARY  KEY (`c7_at1`));  CREATE TABLE `class1_name`(`c1_at2`c1_at2_type`c5_at1`c5_at1_type`c1_at1`c1_at1_type NOT NULL  KEY  `FK_class1_name_c5_at1_idx`(`c5_at1`), PRIMARY  KEY (`c1_at1`));  CREATE TABLE `class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_type NOT NULL  KEY  `FK_class10_name_c7_at1_idx`(`c7_at1`), PRIMARY  KEY (`c7_at1`));  CREATE TABLE `class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_type NOT NULL  KEY  `FK_class9_name_c7_at1_idx`(`c7_at1`), PRIMARY  KEY (`c7_at1`));  CREATE TABLE `assoc1`(`c3_at1`c3_at1_type NOT NULL`c2_at1`c2_at1_type NOT NULL  KEY  `FK_assoc1_c3_at1_idx`(`c3_at1`), KEY `FK_assoc1_c2_at1_idx`(`c2_at1`), PRIMARY  KEY (`c3_at1`,`c2_at1`));  CREATE TABLE `class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_type NOT NULL PRIMARY  KEY (`c4_at1`));  CREATE TABLE `class7_name`(`c7_at1`c7_at1_type NOT NULL PRIMARY  KEY (`c7_at1`));  CREATE TABLE `class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_type NOT NULL PRIMARY  KEY (`c6_at1`));  CREATE TABLE `class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_type NOT NULL PRIMARY  KEY (`c3_at1`));  CREATE TABLE `assoc4`(`c6_at1`c6_at1_type NOT NULL`c2_at1`c2_at1_type NOT NULL  KEY  `FK_assoc4_c6_at1_idx`(`c6_at1`) KEY `FK_assoc4_c2_at1_idx`(`c2_at1`) PRIMARY  KEY (`c6_at1`,`c2_at1`));  CREATE TABLE `assoc3`(`c7_at1`c7_at1_type NOT NULL`c6_at1`c6_at1_type NOT NULL  KEY  `FK_assoc3_c7_at1_idx`(`c7_at1`), KEY `FK_assoc3_c6_at1_idx`(`c6_at1`), PRIMARY  KEY (`c7_at1`,`c6_at1`)); ALTER TABLE `assoc2`ADD CONSTRAINT `FK_assoc2_c7_at1`  FOREIGN  KEY  (`c7_at1`) REFERENCES `class7_name`(`c7_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ADD CONSTRAINT `FK_assoc2_c4_at1`  FOREIGN  KEY  (`c4_at1`) REFERENCES `class4_name`(`c4_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ALTER TABLE `class1_name`ADD CONSTRAINT `FK_class1_name_c5_at1`  FOREIGN  KEY  (`c5_at1`) REFERENCES `class5_name`(`c5_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ALTER TABLE `class10_name`ADD CONSTRAINT `FK_class10_name_c7_at1`  FOREIGN  KEY  (`c7_at1`) REFERENCES `class7_name`(`c7_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ALTER TABLE `class9_name`ADD CONSTRAINT `FK_class9_name_c7_at1`  FOREIGN  KEY  (`c7_at1`) REFERENCES `class7_name`(`c7_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ALTER TABLE `assoc1`ADD CONSTRAINT `FK_assoc1_c3_at1`  FOREIGN  KEY  (`c3_at1`) REFERENCES `class3_name`(`c3_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ADD CONSTRAINT `FK_assoc1_c3_at1`  FOREIGN  KEY  (`c2_at1`) REFERENCES `class2_name`(`c2_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ALTER TABLE `assoc4`ADD CONSTRAINT `FK_assoc4_c6_at1`  FOREIGN  KEY  (`c6_at1`) REFERENCES `class6_name`(`c6_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ADD CONSTRAINT `FK_assoc4_c2_at1`  FOREIGN  KEY  (`c2_at1`) REFERENCES `class2_name`(`c2_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ALTER TABLE `assoc3`ADD CONSTRAINT `FK_assoc3_c7_at1`  FOREIGN  KEY  (`c7_at1`) REFERENCES `class7_name`(`c7_at1`) ON DELETE CASCADE  ON UPDATE CASCADE ADD CONSTRAINT `FK_assoc3_c6_at1`  FOREIGN  KEY  (`c6_at1`) REFERENCES `class6_name`(`c6_at1`) ON DELETE CASCADE  ON UPDATE CASCADE​')\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "# context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# # Here are the first 10 words from the vocabulary:\n",
        "# context_text_processor.get_vocabulary()[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "# target_text_processor = tf.keras.layers.TextVectorization(\n",
        "#     standardize=tf_lower_and_split_punct,\n",
        "#     max_tokens=max_vocab_size,\n",
        "#     ragged=True)\n",
        "\n",
        "# target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "# target_text_processor.get_vocabulary()[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "93c7fe6f-6045-4665-da25-8f590f188644"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[116, 120, 336, 118, 119, 328, 367, 23, 358, 6, 346, 373, 23, 359, 6,\n",
              "  348, 22, 10, 393, 60, 384, 366, 23, 334, 6, 345, 22, 10, 392, 60, 383,\n",
              "  333, 23, 129, 6, 344, 365, 23, 129, 353, 60, 382, 364, 23, 129, 352, 22,\n",
              "  10, 395, 60, 381, 363, 23, 356, 6, 343, 362, 23, 115, 6, 342, 22, 10,\n",
              "  227, 391, 60, 387, 361, 23, 357, 6, 341, 22, 10, 389, 60, 385, 22, 10,\n",
              "  390, 60, 386, 360, 23, 115, 349, 372, 23, 115, 351, 371, 23, 115, 350,\n",
              "  370, 23, 130, 6, 347, 22, 10, 227, 394, 60, 388, 369, 23, 130, 354, 368,\n",
              "  23, 130, 672, 47, 17, 331, 47, 17, 561, 47, 17, 332, 47, 17, 440, 47,\n",
              "  17, 577, 47, 17, 516, 47, 17, 416, 47, 17, 569, 47, 17, 498, 47, 17,\n",
              "  503, 47, 17, 726, 484, 2, 487, 18, 2, 450, 70, 2, 448, 70, 2, 555, 61,\n",
              "  2, 497, 2, 524, 70, 2, 562, 61, 2, 509, 2, 521, 61, 2, 478, 18, 2, 573,\n",
              "  452, 2, 453, 18, 2, 449, 472, 2, 468, 2, 446, 338, 61, 2, 376, 2, 377,\n",
              "  2, 474, 481, 2, 482, 2, 455, 2, 523, 61, 2, 493, 2, 621, 70, 2, 732, 70,\n",
              "  2, 565, 269, 61, 2, 375, 2, 374, 2, 584, 70, 2, 579, 70, 2, 572, 335,\n",
              "  61, 2, 379, 2, 380, 2, 447, 21, 485, 39, 16, 486, 12, 2, 26, 14, 242,\n",
              "  15, 8, 7, 13, 43, 21, 495, 39, 16, 496, 12, 2, 264, 14, 263, 15, 8, 7,\n",
              "  13, 43, 21, 507, 39, 16, 508, 12, 2, 264, 14, 263, 15, 8, 7, 13, 30, 21,\n",
              "  470, 39, 16, 477, 12, 2, 42, 14, 176, 15, 8, 7, 13, 30, 21, 441, 39, 16,\n",
              "  451, 12, 2, 26, 14, 242, 15, 8, 7, 13, 30, 21, 466, 39, 16, 467, 12, 2,\n",
              "  102, 14, 103, 15, 8, 7, 13, 30, 21, 339, 39, 16, 330, 12, 2, 102, 14,\n",
              "  103, 15, 8, 7, 13, 8, 39, 16, 238, 12, 2, 42, 14, 176, 15, 8, 7, 13, 30,\n",
              "  21, 417, 39, 16, 473, 12, 2, 24, 14, 410, 15, 8, 7, 13, 8, 39, 16, 454,\n",
              "  12, 2, 325, 14, 324, 15, 8, 7, 13, 30, 21, 491, 39, 16, 402, 12, 2, 102,\n",
              "  14, 103, 15, 8, 7, 13, 30, 21, 340, 39, 16, 231, 12, 2, 229, 14, 228,\n",
              "  15, 8, 7, 13, 30, 39, 16, 355, 12, 2, 102, 14, 103, 15, 8, 7, 13, 30,\n",
              "  21, 337, 39, 16, 378, 12, 2, 102, 14, 103, 15, 8, 7, 13, 8, 39, 16, 231,\n",
              "  12, 2, 229, 14, 228, 15, 8, 7, 13, 8, 117]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "2e754784-6c0f-4a41-badf-51eb653ff629"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "96c82a94-9177-4736-a744-dca219e974c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[116 120 336 118 119 328 367  23 358   6]\n",
            "\n",
            "[116 176 120 338 118 119 330 369  23 360]\n",
            "[176 120 338 118 119 330 369  23 360   6]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "c4ef31b5-4c00-4e80-ece8-f0e6cf364abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 529)\n",
            "Encoder output, shape (batch, s, units): (1, 529, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "c51fddf4-e2ae-4a78-a79f-98c8efb34c79"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 529, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 529, 256)\n",
            "Attention result, shape (batch, t, units): (1, 529, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 529, 529)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "297cc8c8-a5d7-4a4b-838a-15acfa20c415"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.99999994, 1.        , 0.9999999 , 0.99999994,\n",
              "       0.9999999 , 0.99999994, 0.9999999 , 0.9999999 , 1.        ,\n",
              "       1.0000001 , 1.        , 1.        , 0.9999999 , 1.        ,\n",
              "       1.0000001 , 0.9999999 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.0000001 , 0.9999999 , 1.0000001 ,\n",
              "       1.0000001 , 1.        , 1.        , 1.        , 1.0000001 ,\n",
              "       1.        , 1.        , 0.9999999 , 0.9999999 , 0.99999994,\n",
              "       1.0000001 , 1.        , 1.        , 0.9999999 , 0.99999994,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.9999999 ,\n",
              "       0.99999994, 0.99999994, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.9999999 , 1.        ,\n",
              "       1.0000001 , 1.        , 0.9999999 , 0.9999999 , 0.99999994,\n",
              "       1.0000001 , 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.99999994, 1.        , 0.9999999 ,\n",
              "       1.        , 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       0.99999994, 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.99999994, 1.        , 1.        , 1.        , 0.9999999 ,\n",
              "       0.99999994, 1.        , 1.        , 0.9999999 , 0.99999994,\n",
              "       0.9999999 , 1.0000001 , 0.9999999 , 0.99999994, 1.        ,\n",
              "       1.        , 0.9999999 , 0.99999994, 1.0000001 , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.99999994, 1.        ,\n",
              "       1.        , 1.0000001 , 0.9999999 , 0.99999994, 1.        ,\n",
              "       1.        , 0.9999999 , 0.99999994, 1.        , 1.        ,\n",
              "       1.        , 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.0000001 ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99999994, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.9999999 , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9999999 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.9999999 , 1.        , 0.99999994,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9999999 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99999994,\n",
              "       1.        , 1.        , 1.0000001 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99999994, 1.        , 1.0000001 , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.9999999 , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.9999999 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.0000001 , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.99999994, 1.        ,\n",
              "       0.99999994, 1.        , 0.9999999 , 1.        , 0.99999994,\n",
              "       0.99999994, 1.        , 1.0000001 , 1.0000001 , 1.        ,\n",
              "       0.9999999 , 1.        , 1.        , 0.99999994, 1.        ,\n",
              "       0.99999994, 1.        , 0.9999999 , 1.        , 0.99999994,\n",
              "       1.        , 1.        , 1.        , 1.0000001 , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.9999999 , 1.        , 0.9999999 , 1.        , 0.99999994,\n",
              "       1.        , 1.        , 1.        , 1.0000001 , 1.        ,\n",
              "       0.9999999 , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.99999994, 1.        , 0.9999999 , 1.        , 0.99999994,\n",
              "       1.        , 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.9999999 , 1.        , 0.99999994, 0.99999994, 1.        ,\n",
              "       0.99999994, 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.9999999 , 1.        , 0.99999994, 1.        , 1.        ,\n",
              "       1.        , 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.9999999 , 1.        , 0.99999994, 0.9999999 , 1.0000001 ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9999999 , 1.        , 0.9999999 , 1.        ,\n",
              "       0.99999994, 1.        , 1.        , 1.        , 1.0000001 ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99999994, 1.        , 0.9999999 , 1.        ,\n",
              "       0.99999994, 0.9999999 , 1.0000001 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.99999994, 1.        , 1.0000001 ,\n",
              "       1.        , 0.9999999 , 1.        , 0.99999994, 1.        ,\n",
              "       1.        , 1.        , 1.0000001 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9999999 , 1.        , 0.99999994, 1.        ,\n",
              "       1.        , 1.        , 1.0000001 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9999999 , 1.        , 0.99999994, 1.        ,\n",
              "       1.        , 1.        , 1.0000001 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9999999 , 1.        , 0.99999994, 1.        ,\n",
              "       1.0000001 , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.9999999 ,\n",
              "       1.        , 0.99999994, 1.        , 1.        , 1.        ,\n",
              "       1.0000001 , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.99999994, 1.        , 0.99999994, 1.        , 0.9999999 ,\n",
              "       1.        , 0.99999994, 1.        , 1.        , 0.99999994,\n",
              "       1.0000001 , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.9999999 ,\n",
              "       1.        , 0.99999994, 1.        , 1.0000001 , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.9999999 , 1.        , 0.99999994,\n",
              "       0.99999994, 1.        , 1.        , 1.0000001 , 1.        ,\n",
              "       0.9999999 , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.9999999 , 1.        , 0.99999994,\n",
              "       0.9999999 , 1.0000001 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.9999999 , 1.        , 0.99999994, 0.9999999 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "7f9a060b-c135-41ae-acd5-f9654ca546d2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzTUlEQVR4nO3de3hU1b3/8c+emcxMQsJFA+EiGAUtUBQwCA03RVOiIopWQfApyFNRkVgx3ooXIt5Qj3KoLUKlgj2ncEJRVI4gFiNRLPhDbh5FwSIilJIEVEJIMpPMzPr9ERkdkwCJgZXg+/U8+3nI2mvvvfZK+PJhXyaOMcYIAADAEpftAQAAgJ82wggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIauQ4jh566CHbw2hwN9xwg1JTU+u9bWJiYsMOCECDys/Pl+M4eumll2wPBXVAGDkOnnvuOTmOo379+tW4/pNPPtFDDz2knTt31rjtiy++eHwH+K3ly5eflIHDtrKyMj300EPKz8+3PRTghHvxxRflOI4cx9F7771Xbb0xRh07dpTjOLr88sstjBCNEWHkOFiwYIFSU1O1bt06bd++vdr6Tz75RNOmTWsUYWTatGk1risvL9cDDzxwQsZxIs2dO1fbtm07rscoKyvTtGnTCCP4SfP7/Vq4cGG19nfeeUf/+te/5PP5LIwKjRVhpIF98cUXWrNmjWbMmKHWrVtrwYIFtodUL36/Xx6Px/YwGlxcXBxFEDgBLrvsMi1evFihUCimfeHChUpLS1Pbtm0tjQyNEWGkgS1YsECtWrXSsGHDdM0111QLIy+++KKuvfZaSdKQIUOilzPz8/OVmpqqLVu26J133om2X3jhhdFtDxw4oMmTJ6tjx47y+Xzq0qWLnnzySUUikWifnTt3ynEcPf3003r++efVuXNn+Xw+nX/++frggw+i/W644QbNmjVLkqLHchwnur6mZ0Y2bdqkSy+9VM2bN1diYqIuvvhivf/++9XOz3Ec/eMf/1B2drZat26tZs2a6aqrrtK+ffuOOHdLly6V4zj6v//7v2jbyy+/LMdxdPXVV8f07datm0aNGhXT9te//lVpaWmKj4/XKaecouuuu067d++O6VPTMyNfffWVfv3rX6t58+Zq2bKlxo0bpw8//FCO49R4lWrPnj0aMWKEEhMT1bp1a911110Kh8OSqua/devWkqRp06ZF5/XwXBYUFGj8+PE67bTT5PP51K5dO1155ZU1XiUDmrLRo0frq6++0sqVK6NtFRUVeumllzRmzJhq/Z9++mn1799fp556quLj45WWllbjcx8rV67UwIED1bJlSyUmJupnP/uZ7rvvviOOJRgM6vLLL1eLFi20Zs2aH39yaHAn3399LVuwYIGuvvpqeb1ejR49WrNnz9YHH3yg888/X5I0ePBg/fa3v9Wzzz6r++67T926dZNU9Y/rzJkzddtttykxMVH333+/JCklJUVS1aX/Cy64QHv27NHNN9+sTp06ac2aNZoyZYr27t2rmTNnxoxj4cKFKikp0c033yzHcfTUU0/p6quv1o4dOxQXF6ebb75Z//73v7Vy5Ur993//91HPa8uWLRo0aJCaN2+ue+65R3FxcfrTn/6kCy+8UO+8806152Nuu+02tWrVSjk5Odq5c6dmzpyprKwsLVq0qNZjDBw4UI7j6N1339W5554rSVq9erVcLlfMved9+/Zp69atysrKirY99thjevDBBzVy5EjdeOON2rdvn/7whz9o8ODB2rRpk1q2bFnjMSORiIYPH65169Zp4sSJ6tq1q1577TWNGzeuxv7hcFiZmZnq16+fnn76ab311lt65pln1LlzZ02cOFGtW7fW7NmzNXHiRF111VXREHX4fH71q19py5Ytuu2225SamqqioiKtXLlSu3btqveDtUBjlJqaqvT0dP3P//yPLr30UknSG2+8oeLiYl133XV69tlnY/r//ve/1xVXXKHrr79eFRUVys3N1bXXXqvXX39dw4YNk1RVhy6//HKde+65evjhh+Xz+bR9+3b94x//qHUc5eXluvLKK7V+/Xq99dZb0VqMRsagwaxfv95IMitXrjTGGBOJRMxpp51mbr/99ph+ixcvNpLMqlWrqu3j5z//ubnggguqtT/yyCOmWbNm5rPPPotp/93vfmfcbrfZtWuXMcaYL774wkgyp556qvn666+j/V577TUjyfzv//5vtG3SpEmmth8BSSYnJyf69YgRI4zX6zWff/55tO3f//63SUpKMoMHD462zZ8/30gyGRkZJhKJRNvvuOMO43a7zYEDB2o83vfPf+TIkdGvzzvvPHPttdcaSebTTz81xhizZMkSI8l8+OGHxhhjdu7cadxut3nsscdi9vXRRx8Zj8cT0z5u3Dhz+umnR79++eWXjSQzc+bMaFs4HDYXXXSRkWTmz58fs60k8/DDD8ccp3fv3iYtLS369b59+6rNnzHGfPPNN0aS+Y//+I8jzgHQlB2uAR988IH54x//aJKSkkxZWZkxxphrr73WDBkyxBhjzOmnn26GDRsW3e5wn8MqKipMjx49zEUXXRRt+8///E8jyezbt6/W469atcpIMosXLzYlJSXmggsuMMnJyWbTpk0NeJZoaNymaUALFixQSkqKhgwZIqnqVseoUaOUm5sbvYxfX4sXL9agQYPUqlUr7d+/P7pkZGQoHA7r3Xffjek/atQotWrVKvr1oEGDJEk7duyo87HD4bD+/ve/a8SIETrzzDOj7e3atdOYMWP03nvv6eDBgzHb3HTTTTG3fQYNGqRwOKwvv/zyiMcaNGiQVq9eLUkqKSnRhx9+qJtuuknJycnR9tWrV6tly5bq0aOHJGnJkiWKRCIaOXJkzNy0bdtWZ511llatWlXr8VasWKG4uDhNmDAh2uZyuTRp0qRat7nllluqjflY5jU+Pl5er1f5+fn65ptvjtofaOpGjhyp8vJyvf766yopKdHrr79e4y0aqervx2HffPONiouLNWjQIG3cuDHafvgK52uvvRZze7omxcXFGjp0qLZu3ar8/Hz16tXrR58Pjh/CSAMJh8PKzc3VkCFD9MUXX2j79u3avn27+vXrp8LCQuXl5f2o/f/zn//UihUr1Lp165glIyNDklRUVBTTv1OnTjFfHw4m9flHcN++fSorK9PPfvazauu6deumSCRS7dmM+h5/0KBB2rt3r7Zv3641a9bIcRylp6fHhJTVq1drwIABcrmqfnz/+c9/yhijs846q9r8fPrpp9Xm5vu+/PJLtWvXTgkJCTHtXbp0qbG/3++PPhPy/XM7lnn1+Xx68skn9cYbbyglJUWDBw/WU089pYKCgqNuCzRFh2vUwoULtWTJEoXDYV1zzTU19n399df1i1/8Qn6/X6ecckr0lmdxcXG0z6hRozRgwADdeOONSklJ0XXXXae//e1vNQaTyZMn64MPPtBbb72ln//858ftHNEweGakgbz99tvau3evcnNzlZubW239ggULNHTo0HrvPxKJ6Je//KXuueeeGtefffbZMV+73e4a+xlj6j2Guqjv8QcOHChJevfdd7Vjxw6dd955atasmQYNGqRnn31Whw4d0qZNm/TYY49Ft4lEInIcR2+88UaNx23IDyqr7byO1eTJkzV8+HC9+uqrevPNN/Xggw9q+vTpevvtt9W7d+8GGiXQeIwZM0YTJkxQQUGBLr300hqf31q9erWuuOIKDR48WM8995zatWunuLg4zZ8/P+b14Pj4eL377rtatWqVli1bphUrVmjRokW66KKL9Pe//z3m7+eVV16p3NxcPfHEE/qv//qv6H9e0DgRRhrIggUL1KZNm+gbKt+3ZMkSvfLKK5ozZ47i4+Njbl/8UG3rOnfurEOHDkWvhDSEI43j+1q3bq2EhIQaP59j69atcrlc6tixY4OMqVOnTurUqZNWr16tHTt2RG8vDR48WNnZ2Vq8eLHC4bAGDx4c3aZz584yxuiMM86oFsqO5vTTT9eqVatUVlYWc3Wkps+HOVZHm9fOnTvrzjvv1J133ql//vOf6tWrl5555hn99a9/rfcxgcbqqquu0s0336z333+/1gfYX375Zfn9fr355psxr97Pnz+/Wl+Xy6WLL75YF198sWbMmKHHH39c999/v1atWhVTH0eMGKGhQ4fqhhtuUFJSkmbPnt3wJ4cGQ1RsAOXl5VqyZIkuv/xyXXPNNdWWrKwslZSUaOnSpZKkZs2aSap6VfeHmjVrVmP7yJEjtXbtWr355pvV1h04cKDau/zH4kjj+D63262hQ4fqtddei3kFtbCwUAsXLtTAgQPVvHnzOh+/NoMGDdLbb7+tdevWRcNIr169lJSUpCeeeCL62t9hV199tdxut6ZNm1btyosxRl999VWtx8rMzFRlZaXmzp0bbYtEIjWGymN1ONT8cF7LysoUCARi2jp37qykpCQFg8F6Hw9ozBITEzV79mw99NBDGj58eI193G63HMeJebZu586devXVV2P6ff3119W2PfwsSE1/h8aOHatnn31Wc+bM0b333lv/k8Bxx5WRBrB06VKVlJToiiuuqHH9L37xi+gHoI0aNUq9evWS2+3Wk08+qeLiYvl8Pl100UVq06aN0tLSNHv2bD366KPq0qWL2rRpo4suukh33323li5dqssvv1w33HCD0tLSVFpaqo8++kgvvfSSdu7cqeTk5DqN+/A/6L/97W+VmZkpt9ut6667rsa+jz76aPT9/ltvvVUej0d/+tOfFAwG9dRTT9Vtwo5i0KBBWrBggRzHid62cbvd6t+/v958801deOGF8nq90f6dO3fWo48+qilTpmjnzp0aMWKEkpKS9MUXX+iVV17RTTfdpLvuuqvGY40YMUJ9+/bVnXfeqe3bt6tr165aunRptOgd69Wj74uPj1f37t21aNEinX322TrllFPUo0cPhUIhXXzxxRo5cqS6d+8uj8ejV155RYWFhbXOO3AyqO1V+cOGDRumGTNm6JJLLtGYMWNUVFSkWbNmqUuXLjGfO/Twww/r3Xff1bBhw3T66aerqKhIzz33nE477bRorfihrKwsHTx4UPfff79atGhx1M8kgSU2X+U5WQwfPtz4/X5TWlpaa58bbrjBxMXFmf379xtjjJk7d64588wzjdvtjnnNt6CgwAwbNswkJSUZSTGv+ZaUlJgpU6aYLl26GK/Xa5KTk03//v3N008/bSoqKowx373aW9Pro/rB66ahUMjcdtttpnXr1sZxnJjXfH/Y1xhjNm7caDIzM01iYqJJSEgwQ4YMMWvWrInp8/3X+r7v8Ot2Nb3O/ENbtmwxkky3bt1i2h999FEjyTz44IM1bvfyyy+bgQMHmmbNmplmzZqZrl27mkmTJplt27ZF+/zw1V5jql7FHTNmjElKSjItWrQwN9xwg/nHP/5hJJnc3NyYbZs1a1btuDk5OdVekV6zZo1JS0szXq83Opf79+83kyZNMl27djXNmjUzLVq0MP369TN/+9vfjjonQFNRWw34oR++2vvCCy+Ys846y/h8PtO1a1czf/78an+38vLyzJVXXmnat29vvF6vad++vRk9enTMRx58/9Xe77vnnnuMJPPHP/6xgc4UDckx5gQ90Qg0Ia+++qquuuoqvffeexowYIDt4QDASY0wgp+88vLymM84CIfDGjp0qNavX6+CgoKYdQCAhsczI/jJu+2221ReXq709HQFg0EtWbJEa9as0eOPP04QAYATgCsj+MlbuHChnnnmGW3fvl2BQEBdunTRxIkTY373DQDg+Knzq73vvvuuhg8frvbt28txnGqvXtUkPz9f5513XvQ3zdb0m1ABW8aMGaMNGzaouLhYwWBQW7ZsIYg0MOoGgCOpcxgpLS1Vz549j/lzGL744gsNGzZMQ4YM0ebNmzV58mTdeOONNX5eBoCTE3UDwJH8qNs0juPolVde0YgRI2rtc++992rZsmX6+OOPo23XXXedDhw4oBUrVtT30ACaKOoGgB867g+wrl27ttpHmGdmZmry5Mm1bhMMBmM+TS8Siejrr7/WqaeeWq8PoQLw4xhjVFJSovbt25+Q3/FB3QBODsdaO457GCkoKFBKSkpMW0pKig4ePFjtlcrDpk+frmnTph3voQGoo927d+u000477sehbgAnl6PVjkb5au+UKVOUnZ0d/bq4uFidOnXSGc9ny/tpskJ+6dRPIgp7pbIUl8I+qeyMSp195xYdyjxHYZ+j+P0h+T/8UnuuO0sdlv1bX45sr0hc1f5OW1Wm3bdEFNndTKd8LEU8UtjvKHlTib7+eZIqE6VQvFTZwqjzX/bp83GtVdkyrBZbPAqcKqW+/JV2XXGqKlsYtV5vtK+Po85PfqKDGd10sJNL7grJUy7F7w8rFO/oq56Ozuy9W1980EmeUqn1pkoduLFUHZoXa+eq09Vsr1HxWY5a/ny/vtl6quRIoRYh3do3X8+vzJBJCcjljih00CfjSE6lI3mMup61R58XJauixKv4XXGqbG4UX+go2EIKnR5Q0ka/Wmyv1O5LXFKckSvgkqfYJeNI4eYRhRPC6rRU2n2JS60+dqsyQQq0lkKJYTXb5ZYTkg6dUyH/Dq/cQcldIZW1NzJuyV/o6JRPK1V0Xpxabo+opGPV96HFjogOneZSeduIjNtI8RFd2uNjfVF6ioanfKj/+OASxf3Lq/j90qFORndnLlVRKEnv7e+izz5vL3epW/4iR5W9Duml81/QW6Vna/5fLtWh7hVSqUfugKNmZx/QVad/qFWFZ+tfW9sq7huXnLD099/8QXtCjq5//zeKBD1yHXJLYUejh7ynyohbr/1vf1W2MHIFHfmLpGvHva0RSR9p7lcD9M6eLoqsaamK80rl9oR1xRkf69Vl/RXuXK5QmUdOwK2/XPoneRXWK8Xn6Y3d3RX6oKXKzqjUw/1fVVguzXjhV6pMkmSkcIL022Gv61/BU/R/xR30+b5T5WxLlKdMKu8e0NKBc7Q2cLqeXnyVQp3L5d8Sr8oEyd3toIZ0/Fybv26vfR+myPe1VNYjoNcHztH6QAflvH+lHE9E7r1+nTdgmwpKkzSozed6eckgVSRHFL/Hpcpm0l3XvqLB8V/qxs9GafeXrXXWfwW049oEtez8jfq13qUV27rJcRmFy+IUv9uj34x8U5c0+1T//U1frS7qrJKVKSrvUyavL6Q7uuXpxW299f9GP6+kpCQ7ReEY1FY3BuoyeRRncWTAT1dIlXpPy49aO457GGnbtq0KCwtj2goLC9W8efNaP8PB5/PF/ObGw1zxPrl9fhm/5ImLyImT3D6X5JNc8W55HK88cX45cY48npA8Lq/cPr88rqrtnG9/nYnHE5E7ISL5/XJ7JccjyevI46mU2+tXxCcZnxT2G3ncPrn8frniw3J7PXL7JY+7an9hv5Enzsjld6LHdvtccjuSOyx54sJSnFO1vlnVftwhyRPnljshpLhmVeNze6v24U6o6iNHcsWH5E/0yOX3yyRILndErspvw4inKozENfPKleCXK+SV2xensN/I7XPk9kuRBFWde5xbrvhvw4hccgerwojxR2Tiw/LESa54l9xetyI+yeVX1bn63HLc367zeeWW5HYkl78qjLh9TtV5+OLkiYtEvw+H/+yK/y6MeBPjFCev4hM9csX75fZ75fZV7Ss+0SN/KE6ecp9c8X65wm65fY4iCSElJrkU73jk9vmrziHikUtV8+RPjJPn0Ldz6nfJCUlJSS4lhhy5EvySyyNXqCqM+BLj5Iq45fZXfc9cjiO3T/InxikxySVfME7uBJ8cn1+uhLDcnrB8iXFy+/0yCUYu45HjuJWY5JJXRr5wVX/j88sV71ZCklthueT2+RXxS4pIxi/FJ3rki4tTXMgrd6lfjt8vd1hyxVeNNd7jkdvvVyTBRLd1J1TImxgnT/Dbc/N91z8hzi1XvF9OXEQuv19xzbzyyFc1Vp9fLn/V3Ee+PXZSgqvq5y7eL49HVftL8MmbGCdXgl+Oy8iYOLl9HvkTPUpKdMlXGSdPadXPtyshIrevUvGJHnkSqv7ynKjbHQ1ZNzyKk8chjABWfPtU6tFqx3G/+Zuenq68vLyYtpUrVyo9Pf14HxpAE0XdAH5a6hxGDh06pM2bN2vz5s2Sql7B27x5s3bt2iWp6lLp2LFjo/1vueUW7dixQ/fcc4+2bt2q5557Tn/72990xx13NMwZAGj0qBsAjqTOYWT9+vXq3bu3evfuLUnKzs5W7969NXXqVEnS3r17owVGks444wwtW7ZMK1euVM+ePfXMM8/oz3/+szIzMxvoFAA0dtQNAEdS52dGLrzwQh3po0lq+pTECy+8UJs2barroQCcJKgbAI7k+H9gAAAAwBEQRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYFW9wsisWbOUmpoqv9+vfv36ad26dUfsP3PmTP3sZz9TfHy8OnbsqDvuuEOBQKBeAwbQNFE3ANSmzmFk0aJFys7OVk5OjjZu3KiePXsqMzNTRUVFNfZfuHChfve73yknJ0effvqpXnjhBS1atEj33Xffjx48gKaBugHgSOocRmbMmKEJEyZo/Pjx6t69u+bMmaOEhATNmzevxv5r1qzRgAEDNGbMGKWmpmro0KEaPXr0Uf9XBODkQd0AcCR1CiMVFRXasGGDMjIyvtuBy6WMjAytXbu2xm369++vDRs2RIvIjh07tHz5cl122WW1HicYDOrgwYMxC4CmiboB4Gg8dem8f/9+hcNhpaSkxLSnpKRo69atNW4zZswY7d+/XwMHDpQxRqFQSLfccssRL7dOnz5d06ZNq8vQADRS1A0AR3Pc36bJz8/X448/rueee04bN27UkiVLtGzZMj3yyCO1bjNlyhQVFxdHl927dx/vYQJoRKgbwE9Lna6MJCcny+12q7CwMKa9sLBQbdu2rXGbBx98UL/+9a914403SpLOOecclZaW6qabbtL9998vl6t6HvL5fPL5fHUZGoBGiroB4GjqdGXE6/UqLS1NeXl50bZIJKK8vDylp6fXuE1ZWVm1wuF2uyVJxpi6jhdAE0PdAHA0dboyIknZ2dkaN26c+vTpo759+2rmzJkqLS3V+PHjJUljx45Vhw4dNH36dEnS8OHDNWPGDPXu3Vv9+vXT9u3b9eCDD2r48OHR4gLg5EbdAHAkdQ4jo0aN0r59+zR16lQVFBSoV69eWrFiRfThtF27dsX8j+aBBx6Q4zh64IEHtGfPHrVu3VrDhw/XY4891nBnAaBRo24AOJI6hxFJysrKUlZWVo3r8vPzYw/g8SgnJ0c5OTn1ORSAkwR1A0Bt+N00AADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsqlcYmTVrllJTU+X3+9WvXz+tW7fuiP0PHDigSZMmqV27dvL5fDr77LO1fPnyeg0YQNNE3QBQG09dN1i0aJGys7M1Z84c9evXTzNnzlRmZqa2bdumNm3aVOtfUVGhX/7yl2rTpo1eeukldejQQV9++aVatmzZEOMH0ARQNwAcSZ3DyIwZMzRhwgSNHz9ekjRnzhwtW7ZM8+bN0+9+97tq/efNm6evv/5aa9asUVxcnCQpNTX1x40aQJNC3QBwJHW6TVNRUaENGzYoIyPjux24XMrIyNDatWtr3Gbp0qVKT0/XpEmTlJKSoh49eujxxx9XOByu9TjBYFAHDx6MWQA0TdQNAEdTpzCyf/9+hcNhpaSkxLSnpKSooKCgxm127Nihl156SeFwWMuXL9eDDz6oZ555Ro8++mitx5k+fbpatGgRXTp27FiXYQJoRKgbAI7muL9NE4lE1KZNGz3//PNKS0vTqFGjdP/992vOnDm1bjNlyhQVFxdHl927dx/vYQJoRKgbwE9LnZ4ZSU5OltvtVmFhYUx7YWGh2rZtW+M27dq1U1xcnNxud7StW7duKigoUEVFhbxeb7VtfD6ffD5fXYYGoJGibgA4mjpdGfF6vUpLS1NeXl60LRKJKC8vT+np6TVuM2DAAG3fvl2RSCTa9tlnn6ldu3Y1FhQAJxfqBoCjqfNtmuzsbM2dO1d/+ctf9Omnn2rixIkqLS2NPiU/duxYTZkyJdp/4sSJ+vrrr3X77bfrs88+07Jly/T4449r0qRJDXcWABo16gaAI6nzq72jRo3Svn37NHXqVBUUFKhXr15asWJF9OG0Xbt2yeX6LuN07NhRb775pu644w6de+656tChg26//Xbde++9DXcWABo16gaAI6lzGJGkrKwsZWVl1bguPz+/Wlt6erref//9+hwKwEmCugGgNvxuGgAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVtUrjMyaNUupqany+/3q16+f1q1bd0zb5ebmynEcjRgxoj6HBdDEUTsA1KTOYWTRokXKzs5WTk6ONm7cqJ49eyozM1NFRUVH3G7nzp266667NGjQoHoPFkDTRe0AUJs6h5EZM2ZowoQJGj9+vLp37645c+YoISFB8+bNq3WbcDis66+/XtOmTdOZZ5551GMEg0EdPHgwZgHQtB3v2kHdAJquOoWRiooKbdiwQRkZGd/twOVSRkaG1q5dW+t2Dz/8sNq0aaPf/OY3x3Sc6dOnq0WLFtGlY8eOdRkmgEbmRNQO6gbQdNUpjOzfv1/hcFgpKSkx7SkpKSooKKhxm/fee08vvPCC5s6de8zHmTJlioqLi6PL7t276zJMAI3Miagd1A2g6fIcz52XlJTo17/+tebOnavk5ORj3s7n88nn8x3HkQFozOpTO6gbQNNVpzCSnJwst9utwsLCmPbCwkK1bdu2Wv/PP/9cO3fu1PDhw6NtkUik6sAej7Zt26bOnTvXZ9wAmhBqB4AjqdNtGq/Xq7S0NOXl5UXbIpGI8vLylJ6eXq1/165d9dFHH2nz5s3R5YorrtCQIUO0efNm7ukCPxHUDgBHUufbNNnZ2Ro3bpz69Omjvn37aubMmSotLdX48eMlSWPHjlWHDh00ffp0+f1+9ejRI2b7li1bSlK1dgAnN2oHgNrUOYyMGjVK+/bt09SpU1VQUKBevXppxYoV0QfTdu3aJZeLD3YFEIvaAaA29XqANSsrS1lZWTWuy8/PP+K2L774Yn0OCeAkQO0AUBP+GwIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwKp6hZFZs2YpNTVVfr9f/fr107p162rtO3fuXA0aNEitWrVSq1atlJGRccT+AE5e1A4ANalzGFm0aJGys7OVk5OjjRs3qmfPnsrMzFRRUVGN/fPz8zV69GitWrVKa9euVceOHTV06FDt2bPnRw8eQNNB7QBQmzqHkRkzZmjChAkaP368unfvrjlz5ighIUHz5s2rsf+CBQt06623qlevXuratav+/Oc/KxKJKC8vr9ZjBINBHTx4MGYB0LQd79pB3QCarjqFkYqKCm3YsEEZGRnf7cDlUkZGhtauXXtM+ygrK1NlZaVOOeWUWvtMnz5dLVq0iC4dO3asyzABNDInonZQN4Cmq05hZP/+/QqHw0pJSYlpT0lJUUFBwTHt495771X79u1jitIPTZkyRcXFxdFl9+7ddRkmgEbmRNQO6gbQdHlO5MGeeOIJ5ebmKj8/X36/v9Z+Pp9PPp/vBI4MQGN2LLWDugE0XXUKI8nJyXK73SosLIxpLywsVNu2bY+47dNPP60nnnhCb731ls4999y6jxRAk0XtAHAkdbpN4/V6lZaWFvMA2eEHytLT02vd7qmnntIjjzyiFStWqE+fPvUfLYAmidoB4EjqfJsmOztb48aNU58+fdS3b1/NnDlTpaWlGj9+vCRp7Nix6tChg6ZPny5JevLJJzV16lQtXLhQqamp0fvDiYmJSkxMbMBTAdCYUTsA1KbOYWTUqFHat2+fpk6dqoKCAvXq1UsrVqyIPpi2a9cuuVzfXXCZPXu2KioqdM0118TsJycnRw899NCPGz2AJoPaAaA29XqANSsrS1lZWTWuy8/Pj/l6586d9TkEgJMQtQNATfjdNAAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsKpeYWTWrFlKTU2V3+9Xv379tG7duiP2X7x4sbp27Sq/369zzjlHy5cvr9dgATRt1A4ANalzGFm0aJGys7OVk5OjjRs3qmfPnsrMzFRRUVGN/desWaPRo0frN7/5jTZt2qQRI0ZoxIgR+vjjj3/04AE0HdQOALWpcxiZMWOGJkyYoPHjx6t79+6aM2eOEhISNG/evBr7//73v9cll1yiu+++W926ddMjjzyi8847T3/84x9/9OABNB3UDgC18dSlc0VFhTZs2KApU6ZE21wulzIyMrR27doat1m7dq2ys7Nj2jIzM/Xqq6/WepxgMKhgMBj9uri4WJIUKQ8qHAwo7EihyojCjhQOuhSWFCmvVMhUKFQZUNjlKBQKKRSpUDgYUChStV0kUrW/UCigcFlEkYBb4QopEtG32wQUrohTOCiFXVIkYBQKBxUJBBQpDytc4VE4IIXC3+4vYBSqNIoEnO+OHXRJFZJTIYUqwwp5nKr1pVX7CQelUGWlwmVBVXqqxheuqNpHuKyqjxwpUh5S4FBIkUBApiwguSOKlBsZR3IqHcljVFlaoUhZQJHyiMLBsCIBo3DQUTggRcq+O1ak3CWFjBRwKRxwyThSxBtRxBVWqFKKlLsUrnAr7JEiASniCSscdMsJSZHyCoWDESkoqaJqToxbCgedqvMIhqu+F99+Hw7/OVIekXEbSRFVHKpUZWmFyg+FFCkPKByIKBys2lf5oZACocqq+SkPyAm4q86hLKBDJRGVl4aq5rq8Qir3yPl2ngKHKr+b04BLTlgqKYnoUMipmpOgRwq4pbCj4KFKVUYiCgcCiviMFHQUDkqBQ5U65EQUPFT1/YgEA1Xz5glXtQUC386vR07ArUMlEXn1Xf+qcVWqrCSssEzV9zIgyUgRt1R+KKRgsOrcw2UBOQGPnKAUKQ+opCSi8kAoeoxw0FHYLaksoIrvn9v3+pcFwlVzVBmRE5AqSysUKg1WjScYUCTw7ffBU3XsknAkOq+hUECRgEvhsqAqDlUqUhaQ4zJVP9dBjwKHQioxVecWKv323MoCCodDKj8UUqisQpJkjKlLyYg6EbWjtroRUqVUv2ED+JFCqpR0DLXD1MGePXuMJLNmzZqY9rvvvtv07du3xm3i4uLMwoULY9pmzZpl2rRpU+txcnJyjKrKBwsLSyNadu/eXZeScUJrB3WDhaXxLkerHXW6MnKiTJkyJeZ/RAcOHNDpp5+uXbt2qUWLFhZHdvI4ePCgOnbsqN27d6t58+a2h3NSOJnn1BijkpIStW/f3vZQakXdODFO5p9zW07mOT3W2lGnMJKcnCy3263CwsKY9sLCQrVt27bGbdq2bVun/pLk8/nk8/mqtbdo0eKk+0bZ1rx5c+a0gZ2sc/pj/kE/EbWDunFinaw/5zadrHN6LLWjTg+wer1epaWlKS8vL9oWiUSUl5en9PT0GrdJT0+P6S9JK1eurLU/gJMPtQPAkdT5Nk12drbGjRunPn36qG/fvpo5c6ZKS0s1fvx4SdLYsWPVoUMHTZ8+XZJ0++2364ILLtAzzzyjYcOGKTc3V+vXr9fzzz/fsGcCoFGjdgCoTZ3DyKhRo7Rv3z5NnTpVBQUF6tWrl1asWKGUlBRJ0q5du+RyfXfBpX///lq4cKEeeOAB3XfffTrrrLP06quvqkePHsd8TJ/Pp5ycnBovwaJ+mNOGx5we2YmuHXw/jg/mteExp5JjTD3f1QMAAGgA/G4aAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBVow8js2bNUmpqqvx+v/r166d169bZHlKjNX36dJ1//vlKSkpSmzZtNGLECG3bti2mTyAQ0KRJk3TqqacqMTFRv/rVr6p9yuWuXbs0bNgwJSQkqE2bNrr77rsVCoVO5Kk0Wk888YQcx9HkyZOjbcxp40TtODbUjeOPunEMjvH3XFmRm5trvF6vmTdvntmyZYuZMGGCadmypSksLLQ9tEYpMzPTzJ8/33z88cdm8+bN5rLLLjOdOnUyhw4diva55ZZbTMeOHU1eXp5Zv369+cUvfmH69+8fXR8KhUyPHj1MRkaG2bRpk1m+fLlJTk42U6ZMsXFKjcq6detMamqqOffcc83tt98ebWdOGx9qx7Gjbhxf1I1j06jDSN++fc2kSZOiX4fDYdO+fXszffp0i6NqOoqKiowk88477xhjjDlw4ICJi4szixcvjvb59NNPjSSzdu1aY4wxy5cvNy6XyxQUFET7zJ492zRv3twEg8ETewKNSElJiTnrrLPMypUrzQUXXBAtKsxp40TtqD/qRsOhbhy7RnubpqKiQhs2bFBGRka0zeVyKSMjQ2vXrrU4sqajuLhYknTKKadIkjZs2KDKysqYOe3atas6deoUndO1a9fqnHPOiX4qpiRlZmbq4MGD2rJlywkcfeMyadIkDRs2LGbuJOa0MaJ2/DjUjYZD3Th2df44+BNl//79CofDMd8ISUpJSdHWrVstjarpiEQimjx5sgYMGBD9+OyCggJ5vV61bNkypm9KSooKCgqifWqa88Prfopyc3O1ceNGffDBB9XWMaeND7Wj/qgbDYe6UTeNNozgx5k0aZI+/vhjvffee7aH0qTt3r1bt99+u1auXCm/3297OMBxRd1oGNSNumu0t2mSk5PldrurPV1cWFiotm3bWhpV05CVlaXXX39dq1at0mmnnRZtb9u2rSoqKnTgwIGY/t+f07Zt29Y454fX/dRs2LBBRUVFOu+88+TxeOTxePTOO+/o2WeflcfjUUpKCnPayFA76oe60XCoG3XXaMOI1+tVWlqa8vLyom2RSER5eXlKT0+3OLLGyxijrKwsvfLKK3r77bd1xhlnxKxPS0tTXFxczJxu27ZNu3btis5penq6PvroIxUVFUX7rFy5Us2bN1f37t1PzIk0IhdffLE++ugjbd68Obr06dNH119/ffTPzGnjQu2oG+pGw6Nu1IPtJ2iPJDc31/h8PvPiiy+aTz75xNx0002mZcuWMU8X4zsTJ040LVq0MPn5+Wbv3r3RpaysLNrnlltuMZ06dTJvv/22Wb9+vUlPTzfp6enR9YdfJxs6dKjZvHmzWbFihWnduvVJ+zpZfXz/qXhjmNPGiNpx7KgbJwZ148gadRgxxpg//OEPplOnTsbr9Zq+ffua999/3/aQGi1JNS7z58+P9ikvLze33nqradWqlUlISDBXXXWV2bt3b8x+du7caS699FITHx9vkpOTzZ133mkqKytP8Nk0Xj8sKsxp40TtODbUjRODunFkjjHG2LkmAwAA0IifGQEAAD8NhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABY9f8BaM0lQmFXJj8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "5a8a0e2c-370e-4181-9269-ff01b1c9d6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 529, 256)\n",
            "input target tokens shape: (batch, t) (1, 529)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 529, 1692)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "716f661a-2c4a-4e8f-e630-df1338c5cc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 529)\n",
            "Target tokens, shape: (batch, t) (1, 529)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 529, 1692)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer='Adam',\n",
        "#               # loss=masked_loss, \n",
        "#               metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuP3_LFENMJG"
      },
      "outputs": [],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rJITfxEsHKR"
      },
      "outputs": [],
      "source": [
        "model.evaluate(val_ds, steps=60, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQd_esVVoSf3"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 60,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=9)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38rLdlmtQHCm"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkhXRASNG80_"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd "
      ],
      "metadata": {
        "id": "v5yBqPbaRQNF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_excel('2-OM-test-set.xlsx')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "74998612-9eaa-4a27-f0ec-f2c51371faa3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "1  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "2  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "3  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "4  module OM_name:0 ,open Declaration one sig cla...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b879c3cc-bec1-45ab-8cb7-e146ee44b580\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b879c3cc-bec1-45ab-8cb7-e146ee44b580')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b879c3cc-bec1-45ab-8cb7-e146ee44b580 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b879c3cc-bec1-45ab-8cb7-e146ee44b580');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"X data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "20f67e14-9e7e-40d7-a374-4ad1ff8f8972"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(111,)\n",
            "(111,)\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "5b6aa90b-91dd-4596-924c-628c455ec248"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()\n",
        "\n",
        "# import time\n",
        "\n",
        "# # Increase the time parameter\n",
        "# time_limit = 7  # in seconds\n",
        "\n",
        "# for t in inputs:\n",
        "#     start_time = time.time()\n",
        "#     output = \"\"\n",
        "#     while True:\n",
        "#         partial_output = model.translate([t], max_length=len(output) + 10)[0].numpy().decode()\n",
        "#         output += partial_output\n",
        "#         if time.time() - start_time > time_limit:\n",
        "#             break\n",
        "#     output = output.replace(' ', '')\n",
        "#     print(output)\n",
        "\n",
        "# print()\n",
        "\n"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_excel('2-OM-test-set-pred.xlsx')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "id": "v9M2iW1MGjfM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f92f7dd6-98f4-4648-8352-bc839e519e63"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  p,moduleom_name:0,opendeclarationonesigclass1_...              1\n",
              "1  namemappingstrategyforclass1_name:map_str2mapp...              1\n",
              "2  p,moduleom_name:0,opendeclarationonesigclass1_...              1\n",
              "3  ameclass3_nametablenameclass4_nametablenamecla...              1\n",
              "4  p,moduleom_name:0,opendeclarationonesigclass1_...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4258786d-0a18-444e-8722-3a78761f4211\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p,moduleom_name:0,opendeclarationonesigclass1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>namemappingstrategyforclass1_name:map_str2mapp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p,moduleom_name:0,opendeclarationonesigclass1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ameclass3_nametablenameclass4_nametablenamecla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p,moduleom_name:0,opendeclarationonesigclass1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4258786d-0a18-444e-8722-3a78761f4211')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4258786d-0a18-444e-8722-3a78761f4211 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4258786d-0a18-444e-8722-3a78761f4211');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "id": "Wy2Fvt1fHYJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa858f8-2658-4107-91a4-44592c46401b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1\n",
            " 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "id": "w7RY4modHkts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fffc7c4-02a3-4eb9-aae3-8744bd053491"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.200000\n",
            "Testing: Recall = 0.909091\n",
            "Testing: F1 Score = 0.327869\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[ 9 80]\n",
            " [ 2 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "id": "nd3P-TGIIN6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb8bff1-fdba-465e-a4f6-c7bd4a95ecdc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.10      0.18        89\n",
            "           1       0.20      0.91      0.33        22\n",
            "\n",
            "    accuracy                           0.26       111\n",
            "   macro avg       0.51      0.51      0.25       111\n",
            "weighted avg       0.70      0.26      0.21       111\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}