{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# 13_OM_Train_1_OM_Test(University)-70\n",
        "\n",
        "# P oversample increased to 70%\n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###13 OM Dataset -  Camping,  Bank, , E-Commerce,  Traffic Controller, Library Management, School OM, Store OM, Student-course , Canteen OM, Hospital Management , Decider (Unseen) , Online Store, Customer Order\n",
        "\n",
        "###1 OM - Testing - University (Unseen)  \n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 70% - 30%\n",
        "\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "\n",
        "### Total instances - 30940\n",
        "\n",
        "### P samples - 21658 P \n",
        "### NP samples -  9282 NP\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 31\n",
        "\n",
        "### P samples - 10\n",
        "### NP samples - 21\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DGFTkuRvzWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d514c4f-58ed-42b2-c971-5d8ff2c7eaae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text>=2.10\n",
            "  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text>=2.10) (0.13.0)\n",
            "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text>=2.10) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.10) (3.2.2)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text>=2.10\"\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_excel('dummy.xlsx')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "5bf7f221-7d52-43b7-ec63-3d67c071af05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  module OM_name 0;open Declarationone sig class...   \n",
              "1  module OM_name 0;open Declarationone sig class...   \n",
              "2  module OM_name 0;open Declarationone sig class...   \n",
              "3  module OM_name 0;open Declarationone sig class...   \n",
              "4  module OM_name 0;open Declarationone sig class...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  P, module OM_name 0;open Declarationone sig cl...  \n",
              "1  P, module OM_name 0;open Declarationone sig cl...  \n",
              "2  P, module OM_name 0;open Declarationone sig cl...  \n",
              "3  P, module OM_name 0;open Declarationone sig cl...  \n",
              "4  P, module OM_name 0;open Declarationone sig cl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-303dcda3-6dc5-40f7-a313-3c837234538f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name 0;open Declarationone sig class...</td>\n",
              "      <td>P, module OM_name 0;open Declarationone sig cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name 0;open Declarationone sig class...</td>\n",
              "      <td>P, module OM_name 0;open Declarationone sig cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name 0;open Declarationone sig class...</td>\n",
              "      <td>P, module OM_name 0;open Declarationone sig cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name 0;open Declarationone sig class...</td>\n",
              "      <td>P, module OM_name 0;open Declarationone sig cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name 0;open Declarationone sig class...</td>\n",
              "      <td>P, module OM_name 0;open Declarationone sig cl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-303dcda3-6dc5-40f7-a313-3c837234538f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-303dcda3-6dc5-40f7-a313-3c837234538f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-303dcda3-6dc5-40f7-a313-3c837234538f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cTbSbBz55QtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8869ea-fe05-481f-9a62-dce73dd2a309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc, }one sig assoc2extendsAssociationsrc=class6_namedst=Customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc |\n"
          ]
        }
      ],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lH_dPY8TRp3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f2cf87-6c46-43c0-9ac3-4c31d1e80608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc |\n"
          ]
        }
      ],
      "source": [
        "print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14de71d0-bb86-4fb1-816c-056fede1abb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc, }one sig assoc2extendsAssociationsrc=class6_namedst=Customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc |'], shape=(1,), dtype=string)\n",
            "\n",
            "tf.Tensor([b'NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc |'], shape=(1,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mD0e-DWGQ2Vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6a80fd-188a-4935-d2e0-b7994fe68541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,\\xe2\\x80\\x8bOM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE'\n",
            "b'moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,\\xe2\\x80\\x8bOM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE'\n"
          ]
        }
      ],
      "source": [
        "example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "#example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  # text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "# def tf_lower_and_split_punct(text):\n",
        "#   # Split accented characters.\n",
        "#   text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "#   text = tf.strings.lower(text)\n",
        "#   # Keep space, a to z, and select punctuation.\n",
        "#   text = tf.strings.regex_replace(text, '', '')\n",
        "#   # Add spaces around punctuation.\n",
        "#   text = tf.strings.regex_replace(text, '', r'')\n",
        "#   # Strip whitespace.\n",
        "#   text = tf.strings.strip(text)\n",
        "\n",
        "#   text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  \n",
        "#   # Remove spaces between tokens\n",
        "#   text = tf.strings.regex_replace(text, ' ', '')\n",
        "  \n",
        "#   return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UREvDg3sEKYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b399a07-d761-4fe0-b7ba-7814c886f337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE\n",
            "[START] moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE [END]\n"
          ]
        }
      ],
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc26d38-de9a-4f4e-b9a9-25e0a8a30984"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'sig',\n",
              " 'extends',\n",
              " '=',\n",
              " 'no',\n",
              " 'parentisAbstract',\n",
              " 'No}one',\n",
              " 'ClassattrSet',\n",
              " 'c2_at1',\n",
              " '|',\n",
              " 'module',\n",
              " 'class1_name',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'one',\n",
              " 'class4_name',\n",
              " 'class3_name',\n",
              " 'class2_name',\n",
              " 'c3_at6_typeone',\n",
              " 'c3_at6',\n",
              " 'c3_at5_typeone',\n",
              " 'c3_at5',\n",
              " 'c3_at4_typeone',\n",
              " 'c3_at4',\n",
              " 'c3_at3_typeone',\n",
              " 'c3_at3',\n",
              " 'c3_at2_typeone',\n",
              " 'c3_at2',\n",
              " 'c3_at1_typeone',\n",
              " 'c3_at1+c3_at2+c3_at3+c3_at4c3_at5+c3_at6id=c3_at1no',\n",
              " 'c3_at1',\n",
              " 'c2_at2_typeone',\n",
              " 'c2_at1_typeone',\n",
              " 'c2_at1+c2_at2id=c2_at1no',\n",
              " 'c1_at2_typeone',\n",
              " 'c1_at2',\n",
              " 'c1_at1_typeone',\n",
              " 'c1_at1+c1_at2id=c1_at1no',\n",
              " 'c1_at1',\n",
              " 'OM_name',\n",
              " 'Declarationone',\n",
              " '0;open',\n",
              " '}one',\n",
              " 'src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,',\n",
              " 'parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,',\n",
              " 'parentisAbstract=No}onesigc5_at1extendsc5_at1_type,',\n",
              " 'parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,',\n",
              " 'parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,',\n",
              " 'parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,',\n",
              " 'open',\n",
              " 'onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type,',\n",
              " 'onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1',\n",
              " 'onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1',\n",
              " 'onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1',\n",
              " 'onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1',\n",
              " 'onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type,',\n",
              " 'attr',\n",
              " 'assoc2extendsAssociationsrc=class6_namedst=Customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc',\n",
              " 'assoc1extendsAssociationsrc=class6_namedst=class4_name,',\n",
              " 'Set',\n",
              " 'OM_name:0,',\n",
              " 'Declaration',\n",
              " 'Class',\n",
              " '=c1_at1+c1_at2id=c1_at1']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "context_text_processor.get_vocabulary()[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jlC4xuZnKLBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556dbe33-8c6b-4e1e-f1fb-f839eefe9063"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'sig',\n",
              " 'extends',\n",
              " '=',\n",
              " 'no',\n",
              " 'parentisAbstract',\n",
              " 'No}one',\n",
              " 'ClassattrSet',\n",
              " 'c2_at1',\n",
              " 'module',\n",
              " 'class1_name',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'one',\n",
              " 'class4_name',\n",
              " 'class3_name',\n",
              " 'class2_name',\n",
              " 'c3_at6_typeone',\n",
              " 'c3_at6',\n",
              " 'c3_at5_typeone',\n",
              " 'c3_at5',\n",
              " 'c3_at4_typeone',\n",
              " 'c3_at4',\n",
              " 'c3_at3_typeone',\n",
              " 'c3_at3',\n",
              " 'c3_at2_typeone',\n",
              " 'c3_at2',\n",
              " 'c3_at1_typeone',\n",
              " 'c3_at1+c3_at2+c3_at3+c3_at4c3_at5+c3_at6id=c3_at1no',\n",
              " 'c3_at1',\n",
              " 'c2_at2_typeone',\n",
              " 'c2_at1_typeone',\n",
              " 'c2_at1+c2_at2id=c2_at1no',\n",
              " 'c1_at2_typeone',\n",
              " 'c1_at2',\n",
              " 'c1_at1_typeone',\n",
              " 'c1_at1+c1_at2id=c1_at1no',\n",
              " 'c1_at1',\n",
              " 'P,',\n",
              " 'OM_name',\n",
              " 'Declarationone',\n",
              " '0;open',\n",
              " '|',\n",
              " 'src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc',\n",
              " 'parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type,',\n",
              " 'parentisAbstract=No}onesigc5_at1extendsc5_at1_type,',\n",
              " 'parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type,',\n",
              " 'parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type,',\n",
              " 'parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type,',\n",
              " 'open',\n",
              " 'onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type,',\n",
              " 'onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1',\n",
              " 'onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1',\n",
              " 'onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1',\n",
              " 'onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1',\n",
              " 'onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type,',\n",
              " 'attr',\n",
              " 'assoc1extendsAssociationsrc=class6_namedst=class4_name,',\n",
              " 'Set',\n",
              " 'OM_name:0,',\n",
              " 'NP,',\n",
              " 'Declaration',\n",
              " 'Class',\n",
              " '=c1_at1+c1_at2id=c1_at1']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "target_text_processor.get_vocabulary()[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "787705fc-5613-402b-9ea8-654c4a542144"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[13, 11, 61, 50, 62, 15, 2, 12, 3, 63, 57, 60, 64, 5, 49, 56, 55, 5, 48,\n",
              "  54, 5, 47, 53, 5, 46, 52, 5, 45, 51, 15, 2, 59, 44, 43, 2, 58, 10, 14]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "98g9rcxGQY0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "bd16647f-d3f9-4f2b-e2ae-bce56eb01a31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc, }one sig assoc2extendsAssociationsrc=class6_namedst=Customersrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "44edd3b9-4c26-4055-f63a-b0853a3cdd0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "e6539eb9-184f-490f-cec3-bd364edef540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13 11 61 50 62 15  2 12  3 63]\n",
            "\n",
            "[12 61 10 60 50 62 14  2 11  3]\n",
            "[61 10 60 50 62 14  2 11  3 63]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "e40342e4-145b-4d82-9268-d8b1866f42b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 38)\n",
            "Encoder output, shape (batch, s, units): (1, 38, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "74d1c318-57c6-493c-e856-6ed7c2ddc376"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 38, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 35, 256)\n",
            "Attention result, shape (batch, t, units): (1, 35, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 35, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "be2f2d13-8231-4c73-c992-34c77f7b602a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.99999994, 0.99999994, 1.        , 1.        ,\n",
              "       0.99999994, 1.        , 0.99999994, 0.99999994, 0.9999998 ,\n",
              "       0.99999994, 0.9999999 , 0.9999999 , 1.        , 1.        ,\n",
              "       0.9999998 , 1.0000001 , 0.99999994, 1.        , 0.9999998 ,\n",
              "       1.        , 1.        , 0.99999994, 0.99999994, 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.9999999 , 1.        ,\n",
              "       1.        , 0.99999994, 1.        , 0.99999994, 0.9999999 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "dd07c20a-66b1-4ae6-e591-4e847212e557"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "27ed6dc2-0b50-4126-ad2d-2b19fe28fad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 38, 256)\n",
            "input target tokens shape: (batch, t) (1, 35)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 35, 65)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "6431e9d9-b66c-45e8-abb3-374f9520008f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 38)\n",
            "Target tokens, shape: (batch, t) (1, 35)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 35, 65)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "d0257f02-2998-4bfa-fc04-c64eed4e7b12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 4.1743875, 'expected_acc': 0.015384615384615385}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "cad3389f-fbfc-4f13-b5de-2ea5a2c9aeb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 4/70 [>.............................] - ETA: 3s - loss: 4.2238 - masked_acc: 0.0461 - masked_loss: 4.2238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/70 [==============================] - 22s 15ms/step - loss: 4.2238 - masked_acc: 0.0461 - masked_loss: 4.2238\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 4.223755359649658,\n",
              " 'masked_acc': 0.04614661633968353,\n",
              " 'masked_loss': 4.223755359649658}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "f42d165d-0587-42f0-b7a6-aab7b744124c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5096 - masked_acc: 0.8966 - masked_loss: 0.5096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 50s 309ms/step - loss: 0.5096 - masked_acc: 0.8966 - masked_loss: 0.5096 - val_loss: 0.0097 - val_masked_acc: 1.0000 - val_masked_loss: 0.0097\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0067 - masked_acc: 1.0000 - masked_loss: 0.0067"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 27s 266ms/step - loss: 0.0067 - masked_acc: 1.0000 - masked_loss: 0.0067\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0028 - masked_acc: 1.0000 - masked_loss: 0.0028"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 27s 269ms/step - loss: 0.0028 - masked_acc: 1.0000 - masked_loss: 0.0028\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0016 - masked_acc: 1.0000 - masked_loss: 0.0016"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 256ms/step - loss: 0.0016 - masked_acc: 1.0000 - masked_loss: 0.0016\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 260ms/step - loss: 0.0011 - masked_acc: 1.0000 - masked_loss: 0.0011\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.3345e-04 - masked_acc: 1.0000 - masked_loss: 7.3345e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 261ms/step - loss: 7.3345e-04 - masked_acc: 1.0000 - masked_loss: 7.3345e-04\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.4958e-04 - masked_acc: 1.0000 - masked_loss: 5.4958e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 30s 299ms/step - loss: 5.4958e-04 - masked_acc: 1.0000 - masked_loss: 5.4958e-04\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.2141e-04 - masked_acc: 1.0000 - masked_loss: 4.2141e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 261ms/step - loss: 4.2141e-04 - masked_acc: 1.0000 - masked_loss: 4.2141e-04\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3878e-04 - masked_acc: 1.0000 - masked_loss: 3.3878e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 262ms/step - loss: 3.3878e-04 - masked_acc: 1.0000 - masked_loss: 3.3878e-04\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7627e-04 - masked_acc: 1.0000 - masked_loss: 2.7627e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 262ms/step - loss: 2.7627e-04 - masked_acc: 1.0000 - masked_loss: 2.7627e-04\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2848e-04 - masked_acc: 1.0000 - masked_loss: 2.2848e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 258ms/step - loss: 2.2848e-04 - masked_acc: 1.0000 - masked_loss: 2.2848e-04\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9308e-04 - masked_acc: 1.0000 - masked_loss: 1.9308e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 27s 266ms/step - loss: 1.9308e-04 - masked_acc: 1.0000 - masked_loss: 1.9308e-04\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.6443e-04 - masked_acc: 1.0000 - masked_loss: 1.6443e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 260ms/step - loss: 1.6443e-04 - masked_acc: 1.0000 - masked_loss: 1.6443e-04\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4265e-04 - masked_acc: 1.0000 - masked_loss: 1.4265e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 264ms/step - loss: 1.4265e-04 - masked_acc: 1.0000 - masked_loss: 1.4265e-04\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2307e-04 - masked_acc: 1.0000 - masked_loss: 1.2307e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 256ms/step - loss: 1.2307e-04 - masked_acc: 1.0000 - masked_loss: 1.2307e-04\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0856e-04 - masked_acc: 1.0000 - masked_loss: 1.0856e-04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 259ms/step - loss: 1.0856e-04 - masked_acc: 1.0000 - masked_loss: 1.0856e-04\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.5880e-05 - masked_acc: 1.0000 - masked_loss: 9.5880e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 263ms/step - loss: 9.5880e-05 - masked_acc: 1.0000 - masked_loss: 9.5880e-05\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.4627e-05 - masked_acc: 1.0000 - masked_loss: 8.4627e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 259ms/step - loss: 8.4627e-05 - masked_acc: 1.0000 - masked_loss: 8.4627e-05\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.5640e-05 - masked_acc: 1.0000 - masked_loss: 7.5640e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 258ms/step - loss: 7.5640e-05 - masked_acc: 1.0000 - masked_loss: 7.5640e-05\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 6.7790e-05 - masked_acc: 1.0000 - masked_loss: 6.7790e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 259ms/step - loss: 6.7790e-05 - masked_acc: 1.0000 - masked_loss: 6.7790e-05\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 6.0918e-05 - masked_acc: 1.0000 - masked_loss: 6.0918e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 261ms/step - loss: 6.0918e-05 - masked_acc: 1.0000 - masked_loss: 6.0918e-05\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.5224e-05 - masked_acc: 1.0000 - masked_loss: 5.5224e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 26s 259ms/step - loss: 5.5224e-05 - masked_acc: 1.0000 - masked_loss: 5.5224e-05\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.0022e-05 - masked_acc: 1.0000 - masked_loss: 5.0022e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 27s 266ms/step - loss: 5.0022e-05 - masked_acc: 1.0000 - masked_loss: 5.0022e-05\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.5352e-05 - masked_acc: 1.0000 - masked_loss: 4.5352e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 31s 307ms/step - loss: 4.5352e-05 - masked_acc: 1.0000 - masked_loss: 4.5352e-05\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.1399e-05 - masked_acc: 1.0000 - masked_loss: 4.1399e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 4.1399e-05 - masked_acc: 1.0000 - masked_loss: 4.1399e-05\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7871e-05 - masked_acc: 1.0000 - masked_loss: 3.7871e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 246ms/step - loss: 3.7871e-05 - masked_acc: 1.0000 - masked_loss: 3.7871e-05\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4617e-05 - masked_acc: 1.0000 - masked_loss: 3.4617e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 244ms/step - loss: 3.4617e-05 - masked_acc: 1.0000 - masked_loss: 3.4617e-05\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1924e-05 - masked_acc: 1.0000 - masked_loss: 3.1924e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 3.1924e-05 - masked_acc: 1.0000 - masked_loss: 3.1924e-05\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9207e-05 - masked_acc: 1.0000 - masked_loss: 2.9207e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 245ms/step - loss: 2.9207e-05 - masked_acc: 1.0000 - masked_loss: 2.9207e-05\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6980e-05 - masked_acc: 1.0000 - masked_loss: 2.6980e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 246ms/step - loss: 2.6980e-05 - masked_acc: 1.0000 - masked_loss: 2.6980e-05\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4928e-05 - masked_acc: 1.0000 - masked_loss: 2.4928e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 244ms/step - loss: 2.4928e-05 - masked_acc: 1.0000 - masked_loss: 2.4928e-05\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3053e-05 - masked_acc: 1.0000 - masked_loss: 2.3053e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 239ms/step - loss: 2.3053e-05 - masked_acc: 1.0000 - masked_loss: 2.3053e-05\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1278e-05 - masked_acc: 1.0000 - masked_loss: 2.1278e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 243ms/step - loss: 2.1278e-05 - masked_acc: 1.0000 - masked_loss: 2.1278e-05\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9798e-05 - masked_acc: 1.0000 - masked_loss: 1.9798e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 253ms/step - loss: 1.9798e-05 - masked_acc: 1.0000 - masked_loss: 1.9798e-05\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.8331e-05 - masked_acc: 1.0000 - masked_loss: 1.8331e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 247ms/step - loss: 1.8331e-05 - masked_acc: 1.0000 - masked_loss: 1.8331e-05\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.7057e-05 - masked_acc: 1.0000 - masked_loss: 1.7057e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 253ms/step - loss: 1.7057e-05 - masked_acc: 1.0000 - masked_loss: 1.7057e-05\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5875e-05 - masked_acc: 1.0000 - masked_loss: 1.5875e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 246ms/step - loss: 1.5875e-05 - masked_acc: 1.0000 - masked_loss: 1.5875e-05\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4764e-05 - masked_acc: 1.0000 - masked_loss: 1.4764e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 247ms/step - loss: 1.4764e-05 - masked_acc: 1.0000 - masked_loss: 1.4764e-05\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3795e-05 - masked_acc: 1.0000 - masked_loss: 1.3795e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 253ms/step - loss: 1.3795e-05 - masked_acc: 1.0000 - masked_loss: 1.3795e-05\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2840e-05 - masked_acc: 1.0000 - masked_loss: 1.2840e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 245ms/step - loss: 1.2840e-05 - masked_acc: 1.0000 - masked_loss: 1.2840e-05\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2013e-05 - masked_acc: 1.0000 - masked_loss: 1.2013e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 1.2013e-05 - masked_acc: 1.0000 - masked_loss: 1.2013e-05\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1226e-05 - masked_acc: 1.0000 - masked_loss: 1.1226e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 1.1226e-05 - masked_acc: 1.0000 - masked_loss: 1.1226e-05\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0500e-05 - masked_acc: 1.0000 - masked_loss: 1.0500e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 243ms/step - loss: 1.0500e-05 - masked_acc: 1.0000 - masked_loss: 1.0500e-05\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.8423e-06 - masked_acc: 1.0000 - masked_loss: 9.8423e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 240ms/step - loss: 9.8423e-06 - masked_acc: 1.0000 - masked_loss: 9.8423e-06\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.2123e-06 - masked_acc: 1.0000 - masked_loss: 9.2123e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 243ms/step - loss: 9.2123e-06 - masked_acc: 1.0000 - masked_loss: 9.2123e-06\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.6263e-06 - masked_acc: 1.0000 - masked_loss: 8.6263e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 247ms/step - loss: 8.6263e-06 - masked_acc: 1.0000 - masked_loss: 8.6263e-06\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.0903e-06 - masked_acc: 1.0000 - masked_loss: 8.0903e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 247ms/step - loss: 8.0903e-06 - masked_acc: 1.0000 - masked_loss: 8.0903e-06\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.5955e-06 - masked_acc: 1.0000 - masked_loss: 7.5955e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 7.5955e-06 - masked_acc: 1.0000 - masked_loss: 7.5955e-06\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.1287e-06 - masked_acc: 1.0000 - masked_loss: 7.1287e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 246ms/step - loss: 7.1287e-06 - masked_acc: 1.0000 - masked_loss: 7.1287e-06\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 6.6969e-06 - masked_acc: 1.0000 - masked_loss: 6.6969e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 243ms/step - loss: 6.6969e-06 - masked_acc: 1.0000 - masked_loss: 6.6969e-06\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 6.3003e-06 - masked_acc: 1.0000 - masked_loss: 6.3003e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 241ms/step - loss: 6.3003e-06 - masked_acc: 1.0000 - masked_loss: 6.3003e-06\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.9311e-06 - masked_acc: 1.0000 - masked_loss: 5.9311e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 246ms/step - loss: 5.9311e-06 - masked_acc: 1.0000 - masked_loss: 5.9311e-06\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.5803e-06 - masked_acc: 1.0000 - masked_loss: 5.5803e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 238ms/step - loss: 5.5803e-06 - masked_acc: 1.0000 - masked_loss: 5.5803e-06\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.2401e-06 - masked_acc: 1.0000 - masked_loss: 5.2401e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 242ms/step - loss: 5.2401e-06 - masked_acc: 1.0000 - masked_loss: 5.2401e-06\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.9456e-06 - masked_acc: 1.0000 - masked_loss: 4.9456e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 4.9456e-06 - masked_acc: 1.0000 - masked_loss: 4.9456e-06\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.6607e-06 - masked_acc: 1.0000 - masked_loss: 4.6607e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 252ms/step - loss: 4.6607e-06 - masked_acc: 1.0000 - masked_loss: 4.6607e-06\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.3941e-06 - masked_acc: 1.0000 - masked_loss: 4.3941e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 4.3941e-06 - masked_acc: 1.0000 - masked_loss: 4.3941e-06\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.1376e-06 - masked_acc: 1.0000 - masked_loss: 4.1376e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 4.1376e-06 - masked_acc: 1.0000 - masked_loss: 4.1376e-06\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.9104e-06 - masked_acc: 1.0000 - masked_loss: 3.9104e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 254ms/step - loss: 3.9104e-06 - masked_acc: 1.0000 - masked_loss: 3.9104e-06\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6818e-06 - masked_acc: 1.0000 - masked_loss: 3.6818e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 253ms/step - loss: 3.6818e-06 - masked_acc: 1.0000 - masked_loss: 3.6818e-06\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4772e-06 - masked_acc: 1.0000 - masked_loss: 3.4772e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 247ms/step - loss: 3.4772e-06 - masked_acc: 1.0000 - masked_loss: 3.4772e-06\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2896e-06 - masked_acc: 1.0000 - masked_loss: 3.2896e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 3.2896e-06 - masked_acc: 1.0000 - masked_loss: 3.2896e-06\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1013e-06 - masked_acc: 1.0000 - masked_loss: 3.1013e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 245ms/step - loss: 3.1013e-06 - masked_acc: 1.0000 - masked_loss: 3.1013e-06\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9255e-06 - masked_acc: 1.0000 - masked_loss: 2.9255e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 2.9255e-06 - masked_acc: 1.0000 - masked_loss: 2.9255e-06\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7687e-06 - masked_acc: 1.0000 - masked_loss: 2.7687e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 23s 233ms/step - loss: 2.7687e-06 - masked_acc: 1.0000 - masked_loss: 2.7687e-06\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6100e-06 - masked_acc: 1.0000 - masked_loss: 2.6100e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 243ms/step - loss: 2.6100e-06 - masked_acc: 1.0000 - masked_loss: 2.6100e-06\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4676e-06 - masked_acc: 1.0000 - masked_loss: 2.4676e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 243ms/step - loss: 2.4676e-06 - masked_acc: 1.0000 - masked_loss: 2.4676e-06\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3244e-06 - masked_acc: 1.0000 - masked_loss: 2.3244e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 2.3244e-06 - masked_acc: 1.0000 - masked_loss: 2.3244e-06\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2040e-06 - masked_acc: 1.0000 - masked_loss: 2.2040e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 245ms/step - loss: 2.2040e-06 - masked_acc: 1.0000 - masked_loss: 2.2040e-06\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0788e-06 - masked_acc: 1.0000 - masked_loss: 2.0788e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 246ms/step - loss: 2.0788e-06 - masked_acc: 1.0000 - masked_loss: 2.0788e-06\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9755e-06 - masked_acc: 1.0000 - masked_loss: 1.9755e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 1.9755e-06 - masked_acc: 1.0000 - masked_loss: 1.9755e-06\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.8694e-06 - masked_acc: 1.0000 - masked_loss: 1.8694e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 1.8694e-06 - masked_acc: 1.0000 - masked_loss: 1.8694e-06\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.7711e-06 - masked_acc: 1.0000 - masked_loss: 1.7711e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 250ms/step - loss: 1.7711e-06 - masked_acc: 1.0000 - masked_loss: 1.7711e-06\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.6793e-06 - masked_acc: 1.0000 - masked_loss: 1.6793e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 252ms/step - loss: 1.6793e-06 - masked_acc: 1.0000 - masked_loss: 1.6793e-06\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5849e-06 - masked_acc: 1.0000 - masked_loss: 1.5849e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 253ms/step - loss: 1.5849e-06 - masked_acc: 1.0000 - masked_loss: 1.5849e-06\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4976e-06 - masked_acc: 1.0000 - masked_loss: 1.4976e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 252ms/step - loss: 1.4976e-06 - masked_acc: 1.0000 - masked_loss: 1.4976e-06\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4204e-06 - masked_acc: 1.0000 - masked_loss: 1.4204e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 23s 235ms/step - loss: 1.4204e-06 - masked_acc: 1.0000 - masked_loss: 1.4204e-06\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3514e-06 - masked_acc: 1.0000 - masked_loss: 1.3514e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 245ms/step - loss: 1.3514e-06 - masked_acc: 1.0000 - masked_loss: 1.3514e-06\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2898e-06 - masked_acc: 1.0000 - masked_loss: 1.2898e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 247ms/step - loss: 1.2898e-06 - masked_acc: 1.0000 - masked_loss: 1.2898e-06\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2217e-06 - masked_acc: 1.0000 - masked_loss: 1.2217e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 1.2217e-06 - masked_acc: 1.0000 - masked_loss: 1.2217e-06\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1518e-06 - masked_acc: 1.0000 - masked_loss: 1.1518e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 1.1518e-06 - masked_acc: 1.0000 - masked_loss: 1.1518e-06\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0807e-06 - masked_acc: 1.0000 - masked_loss: 1.0807e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 1.0807e-06 - masked_acc: 1.0000 - masked_loss: 1.0807e-06\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0274e-06 - masked_acc: 1.0000 - masked_loss: 1.0274e-06"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 250ms/step - loss: 1.0274e-06 - masked_acc: 1.0000 - masked_loss: 1.0274e-06\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.8180e-07 - masked_acc: 1.0000 - masked_loss: 9.8180e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 250ms/step - loss: 9.8180e-07 - masked_acc: 1.0000 - masked_loss: 9.8180e-07\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 9.2507e-07 - masked_acc: 1.0000 - masked_loss: 9.2507e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 250ms/step - loss: 9.2507e-07 - masked_acc: 1.0000 - masked_loss: 9.2507e-07\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.5916e-07 - masked_acc: 1.0000 - masked_loss: 8.5916e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 8.5916e-07 - masked_acc: 1.0000 - masked_loss: 8.5916e-07\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 8.1748e-07 - masked_acc: 1.0000 - masked_loss: 8.1748e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 8.1748e-07 - masked_acc: 1.0000 - masked_loss: 8.1748e-07\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.8531e-07 - masked_acc: 1.0000 - masked_loss: 7.8531e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 248ms/step - loss: 7.8531e-07 - masked_acc: 1.0000 - masked_loss: 7.8531e-07\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.4465e-07 - masked_acc: 1.0000 - masked_loss: 7.4465e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 7.4465e-07 - masked_acc: 1.0000 - masked_loss: 7.4465e-07\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 7.0504e-07 - masked_acc: 1.0000 - masked_loss: 7.0504e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 24s 237ms/step - loss: 7.0504e-07 - masked_acc: 1.0000 - masked_loss: 7.0504e-07\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 6.6434e-07 - masked_acc: 1.0000 - masked_loss: 6.6434e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 250ms/step - loss: 6.6434e-07 - masked_acc: 1.0000 - masked_loss: 6.6434e-07\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 6.2416e-07 - masked_acc: 1.0000 - masked_loss: 6.2416e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 6.2416e-07 - masked_acc: 1.0000 - masked_loss: 6.2416e-07\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.9145e-07 - masked_acc: 1.0000 - masked_loss: 5.9145e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 252ms/step - loss: 5.9145e-07 - masked_acc: 1.0000 - masked_loss: 5.9145e-07\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.6396e-07 - masked_acc: 1.0000 - masked_loss: 5.6396e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 251ms/step - loss: 5.6396e-07 - masked_acc: 1.0000 - masked_loss: 5.6396e-07\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.3143e-07 - masked_acc: 1.0000 - masked_loss: 5.3143e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 247ms/step - loss: 5.3143e-07 - masked_acc: 1.0000 - masked_loss: 5.3143e-07\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.0491e-07 - masked_acc: 1.0000 - masked_loss: 5.0491e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 252ms/step - loss: 5.0491e-07 - masked_acc: 1.0000 - masked_loss: 5.0491e-07\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.8348e-07 - masked_acc: 1.0000 - masked_loss: 4.8348e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 246ms/step - loss: 4.8348e-07 - masked_acc: 1.0000 - masked_loss: 4.8348e-07\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.6381e-07 - masked_acc: 1.0000 - masked_loss: 4.6381e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 4.6381e-07 - masked_acc: 1.0000 - masked_loss: 4.6381e-07\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.4662e-07 - masked_acc: 1.0000 - masked_loss: 4.4662e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 249ms/step - loss: 4.4662e-07 - masked_acc: 1.0000 - masked_loss: 4.4662e-07\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.1788e-07 - masked_acc: 1.0000 - masked_loss: 4.1788e-07"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,masked_acc,masked_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 25s 253ms/step - loss: 4.1788e-07 - masked_acc: 1.0000 - masked_loss: 4.1788e-07\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=9)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "38rLdlmtQHCm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "68d38784-d3a8-46cd-d48d-131c28f987d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f242c1758d0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KkhXRASNG80_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "ab561196-fdb1-4b8f-b7b0-ad8f37ed80af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f242c1d2a70>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_excel('University_OM_test.xlsx')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "id": "Nsx0IyYZ9k3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2361bbdb-eadd-407b-d88e-7d7a8a1a2f41"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  module OM_name:0, open Declaration one sig cla...              1\n",
              "1  module OM_name:0, open Declaration one sig cla...              1\n",
              "2  module OM_name:0, open Declaration one sig cla...              1\n",
              "3  module OM_name:0, open Declaration one sig cla...              1\n",
              "4  module OM_name:0, open Declaration one sig cla...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8b9b536-6ae7-4a31-9b0b-589e857c2025\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name:0, open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name:0, open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name:0, open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name:0, open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name:0, open Declaration one sig cla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8b9b536-6ae7-4a31-9b0b-589e857c2025')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8b9b536-6ae7-4a31-9b0b-589e857c2025 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8b9b536-6ae7-4a31-9b0b-589e857c2025');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"X data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "id": "VcNO_Ews2q8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2350ee-3b33-4fd0-f639-dfca1c66017e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31,)\n",
            "(31,)\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "id": "XZFASLWP95TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9768ac8a-f7cf-4bcf-da39-b6e20ba4ae3a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   # mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   # print(model.translate([t])[0].numpy().decode())\n",
        "#   output = model.translate([t])[0].numpy().decode()\n",
        "#   output = output.replace(' ', '')\n",
        "#   print(output)\n",
        "\n",
        "#  print()\n",
        "\n",
        "\n",
        "\n",
        "# import time\n",
        "\n",
        "# # Increase the time parameter\n",
        "# time_limit = 60  # in seconds\n",
        "\n",
        "# for t in inputs:\n",
        "#     start_time = time.time()\n",
        "#     output = \"\"\n",
        "#     while True:\n",
        "#         partial_output = model.translate([t], max_length=len(output) + 10)[0].numpy().decode()\n",
        "#         output += partial_output\n",
        "#         if time.time() - start_time > time_limit:\n",
        "#             break\n",
        "#     output = output.replace(' ', '')\n",
        "#     print(output)\n",
        "\n",
        "# print()\n",
        "\n",
        "\n",
        " %%time\n",
        " for t in inputs:\n",
        "  mylist_res = model.translate([t])[0].numpy().decode()\n",
        "  print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        " print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a6a6d7-3831-404f-de72-b0c35907f7dc"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "NP, module OM_name:0, open Declaration one sig class1_name extends Class attr Set =c1_at1+c1_at2id=c1_at1 no parentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_type, onesigclass2_nameextendsClassattrSet=c2_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc2_at1extendsc2_at1_type, onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4+c3_at5id=c3_at1 no parentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at1extendsc3_at1_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigc3_at5extendsc3_at5_type, onesigclass4_nameextendsClassattrSet=c4_at1+c4_at2id=c4_at1 no parentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_type, onesigclass5_nameextendsClassattrSet=c5_at1+c3_at1id=c5_at1 no parentisAbstract=No}onesigc5_at1extendsc5_at1_type, onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3id=c6_at1 no parentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_type, onesigclass7_nameextendsClassattrSet=c7_at1oneparentparentinclass5_nameid=c3_at1isAbstract=No}onesigc7_at1extendsc7_at1_type, one sig assoc1extendsAssociationsrc=class6_namedst=class4_name, src_multiplicity=src_mlpcdst_multiplicity=dst_mlpc | \n",
            "\n",
            "CPU times: user 3min 20s, sys: 855 ms, total: 3min 21s\n",
            "Wall time: 3min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# dd = pd.read_excel('University_OM_test_pred.xlsx')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dd.head()"
      ],
      "metadata": {
        "id": "v9M2iW1MGjfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test_pred2 = dd['OM_Regular'].values\n",
        "# y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print (y_test_pred2 )"
      ],
      "metadata": {
        "id": "Wy2Fvt1fHYJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# precision = precision_score(y_test2, y_test_pred2) \n",
        "# print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "# recall = recall_score(y_test2, y_test_pred2)\n",
        "# print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "# f1 = f1_score(y_test2, y_test_pred2)\n",
        "# print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "\n",
        "\n",
        "# print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "id": "w7RY4modHkts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "id": "nd3P-TGIIN6b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}