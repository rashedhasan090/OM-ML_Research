{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53kuZAzgHqa1"
      },
      "source": [
        "# English-to-Spanish translation with a sequence-to-sequence Transformer\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2021/05/26<br>\n",
        "**Last modified:** 2023/02/25<br>\n",
        "**Description:** Implementing a sequence-to-sequene Transformer and training it on a machine translation task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtBEUtVnHqa4"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we'll build a sequence-to-sequence Transformer model, which\n",
        "we'll train on an English-to-Spanish machine translation task.\n",
        "\n",
        "You'll learn how to:\n",
        "\n",
        "- Vectorize text using the Keras `TextVectorization` layer.\n",
        "- Implement a `TransformerEncoder` layer, a `TransformerDecoder` layer,\n",
        "and a `PositionalEmbedding` layer.\n",
        "- Prepare data for training a sequence-to-sequence model.\n",
        "- Use the trained model to generate translations of never-seen-before\n",
        "input sentences (sequence-to-sequence inference).\n",
        "\n",
        "The code featured here is adapted from the book\n",
        "[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
        "(chapter 11: Deep learning for text).\n",
        "The present example is fairly barebones, so for detailed explanations of\n",
        "how each building block works, as well as the theory behind Transformers,\n",
        "I recommend reading the book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGG9yjvYHqa4"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2Ut3uI8UHqa4"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yIDuvfJHqa5"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "We'll be working with an English-to-Spanish translation dataset\n",
        "provided by [Anki](https://www.manythings.org/anki/). Let's download it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoNkzS7eHqa6",
        "outputId": "6063f6cd-4cad-4c16-91c8-7dd059e13adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  new.zip\n",
            "   creating: new/\n",
            "  inflating: new/10_OM_60_label.txt  \n",
            "  inflating: __MACOSX/new/._10_OM_60_label.txt  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!unzip new.zip\n",
        "\n",
        "import pathlib\n",
        "\n",
        "file_path = \"/content/new.zip\"\n",
        "extracted_dir = pathlib.Path(file_path).parent / \"new\"\n",
        "text_file = extracted_dir / \"10_OM_60_label.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEuvPsK1Hqa6"
      },
      "source": [
        "## Parsing the data\n",
        "\n",
        "Each line contains an English sentence and its corresponding Spanish sentence.\n",
        "The English sentence is the *source sequence* and Spanish one is the *target sequence*.\n",
        "We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CwTUqXKkHqa6"
      },
      "outputs": [],
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lKYYxnRHqa6"
      },
      "source": [
        "Here's what our sentence pairs look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "W71EWhMAHqa7"
      },
      "outputs": [],
      "source": [
        "# for _ in range(5):\n",
        "#     print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W_CONhiHqa7"
      },
      "source": [
        "Now, let's split the sentence pairs into a training set, a validation set,\n",
        "and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URk0VYj5Hqa7",
        "outputId": "b2315052-d7d2-424e-d245-15a1195b18cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30700 total pairs\n",
            "21490 training pairs\n",
            "4605 validation pairs\n",
            "4605 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sph5JNZfHqa7"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "We'll use two instances of the `TextVectorization` layer to vectorize the text\n",
        "data (one for English and one for Spanish),\n",
        "that is to say, to turn the original strings into integer sequences\n",
        "where each integer represents the index of a word in a vocabulary.\n",
        "\n",
        "The English layer will use the default string standardization (strip punctuation characters)\n",
        "and splitting scheme (split on whitespace), while\n",
        "the Spanish layer will use a custom standardization, where we add the character\n",
        "`\"Â¿\"` to the set of punctuation characters to be stripped.\n",
        "\n",
        "Note: in a production-grade machine translation model, I would not recommend\n",
        "stripping the punctuation characters in either language. Instead, I would recommend turning\n",
        "each punctuation character into its own token,\n",
        "which you could achieve by providing a custom `split` function to the `TextVectorization` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MjmfEsJaHqa7"
      },
      "outputs": [],
      "source": [
        "strip_chars = string.punctuation + \"\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 300\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaQljM4HHqa8"
      },
      "source": [
        "Next, we'll format our datasets.\n",
        "\n",
        "At each training step, the model will seek to predict target words N+1 (and beyond)\n",
        "using the source sentence and the target words 0 to N.\n",
        "\n",
        "As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n",
        "\n",
        "- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n",
        "`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\n",
        "that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n",
        "- `target` is the target sentence offset by one step:\n",
        "it provides the next words in the target sentence -- what the model will try to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HIrpGv30Hqa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": spa[:, :-1],}, spa[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7VKHafcHqa8"
      },
      "source": [
        "Let's take a quick look at the sequence shapes\n",
        "(we have batches of 64 pairs, and all sequences are 20 steps long):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BNuIpcepHqa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3cf40c-9a2a-4da3-e201-142f1c6d6787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 300)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 300)\n",
            "targets.shape: (64, 300)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCZrNjuJHqa8"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together. To make the model aware of word order,\n",
        "we also use a `PositionalEmbedding` layer.\n",
        "\n",
        "The source sequence will be pass to the `TransformerEncoder`,\n",
        "which will produce a new representation of it.\n",
        "This new representation will then be passed\n",
        "to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n",
        "\n",
        "A key detail that makes this possible is causal masking\n",
        "(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n",
        "The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n",
        "sure that it only uses information from target tokens 0 to N when predicting token N+1\n",
        "(otherwise, it could use information from the future, which would\n",
        "result in a model that cannot be used at inference time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u7QpLXimHqa8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"vocab_size\": self.vocab_size,\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"latent_dim\": self.latent_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nWPRP0IHqa9"
      },
      "source": [
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jwMSG2sEHqa9"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxau2QMGHqa9"
      },
      "source": [
        "## Training our model\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n",
        "\n",
        "Here we only train for 1 epoch, but to get the model to actually converge\n",
        "you should train for at least 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yJC2FQxmHqa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb02184-6056-4baa-8885-19ea734a4900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   3916800     ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 15000)  13031320    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,103,576\n",
            "Trainable params: 20,103,576\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 29s 356ms/step - loss: 0.0936 - accuracy: 0.9781\n",
            "Validation Loss: 0.0936, Validation Accuracy: 0.9781\n",
            "Epoch 2/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 0.0274 - accuracy: 0.9957\n",
            "Validation Loss: 0.0274, Validation Accuracy: 0.9957\n",
            "Epoch 3/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0178 - accuracy: 0.9969\n",
            "Validation Loss: 0.0178, Validation Accuracy: 0.9969\n",
            "Epoch 4/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0143 - accuracy: 0.9974\n",
            "Validation Loss: 0.0143, Validation Accuracy: 0.9974\n",
            "Epoch 5/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 356ms/step - loss: 0.0208 - accuracy: 0.9952\n",
            "Validation Loss: 0.0208, Validation Accuracy: 0.9952\n",
            "Epoch 6/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 0.0112 - accuracy: 0.9978\n",
            "Validation Loss: 0.0112, Validation Accuracy: 0.9978\n",
            "Epoch 7/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0103 - accuracy: 0.9980\n",
            "Validation Loss: 0.0103, Validation Accuracy: 0.9980\n",
            "Epoch 8/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 0.0093 - accuracy: 0.9981\n",
            "Validation Loss: 0.0093, Validation Accuracy: 0.9981\n",
            "Epoch 9/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 0.0092 - accuracy: 0.9982\n",
            "Validation Loss: 0.0092, Validation Accuracy: 0.9982\n",
            "Epoch 10/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 357ms/step - loss: 0.0089 - accuracy: 0.9982\n",
            "Validation Loss: 0.0089, Validation Accuracy: 0.9982\n",
            "Epoch 11/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 354ms/step - loss: 0.0085 - accuracy: 0.9986\n",
            "Validation Loss: 0.0085, Validation Accuracy: 0.9986\n",
            "Epoch 12/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 354ms/step - loss: 0.0088 - accuracy: 0.9984\n",
            "Validation Loss: 0.0088, Validation Accuracy: 0.9984\n",
            "Epoch 13/80\n",
            "\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0080 - accuracy: 0.9988\n",
            "Validation Loss: 0.0080, Validation Accuracy: 0.9988\n",
            "Epoch 14/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0074 - accuracy: 0.9988\n",
            "Validation Loss: 0.0074, Validation Accuracy: 0.9988\n",
            "Epoch 15/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 0.0070 - accuracy: 0.9990\n",
            "Validation Loss: 0.0070, Validation Accuracy: 0.9990\n",
            "Epoch 16/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0072 - accuracy: 0.9989\n",
            "Validation Loss: 0.0072, Validation Accuracy: 0.9989\n",
            "Epoch 17/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 354ms/step - loss: 0.0070 - accuracy: 0.9989\n",
            "Validation Loss: 0.0070, Validation Accuracy: 0.9989\n",
            "Epoch 18/80\n",
            "\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0067 - accuracy: 0.9990\n",
            "Validation Loss: 0.0067, Validation Accuracy: 0.9990\n",
            "Epoch 19/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0065 - accuracy: 0.9991\n",
            "Validation Loss: 0.0065, Validation Accuracy: 0.9991\n",
            "Epoch 20/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0062 - accuracy: 0.9991\n",
            "Validation Loss: 0.0062, Validation Accuracy: 0.9991\n",
            "Epoch 21/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 348ms/step - loss: 4.3262 - accuracy: 0.1424\n",
            "Validation Loss: 4.3262, Validation Accuracy: 0.1424\n",
            "Epoch 22/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 349ms/step - loss: 3.7467 - accuracy: 0.2053\n",
            "Validation Loss: 3.7467, Validation Accuracy: 0.2053\n",
            "Epoch 23/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 350ms/step - loss: 3.0134 - accuracy: 0.2695\n",
            "Validation Loss: 3.0134, Validation Accuracy: 0.2695\n",
            "Epoch 24/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 2.3235 - accuracy: 0.4112\n",
            "Validation Loss: 2.3235, Validation Accuracy: 0.4112\n",
            "Epoch 25/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 1.9260 - accuracy: 0.4748\n",
            "Validation Loss: 1.9260, Validation Accuracy: 0.4748\n",
            "Epoch 26/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 1.5922 - accuracy: 0.5453\n",
            "Validation Loss: 1.5922, Validation Accuracy: 0.5453\n",
            "Epoch 27/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 351ms/step - loss: 1.1163 - accuracy: 0.6595\n",
            "Validation Loss: 1.1163, Validation Accuracy: 0.6595\n",
            "Epoch 28/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 352ms/step - loss: 1.1055 - accuracy: 0.6595\n",
            "Validation Loss: 1.1055, Validation Accuracy: 0.6595\n",
            "Epoch 29/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 356ms/step - loss: 2.4454 - accuracy: 0.4442\n",
            "Validation Loss: 2.4454, Validation Accuracy: 0.4442\n",
            "Epoch 30/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 0.7006 - accuracy: 0.8151\n",
            "Validation Loss: 0.7006, Validation Accuracy: 0.8151\n",
            "Epoch 31/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.5162 - accuracy: 0.8523\n",
            "Validation Loss: 0.5162, Validation Accuracy: 0.8523\n",
            "Epoch 32/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.3755 - accuracy: 0.9040\n",
            "Validation Loss: 0.3755, Validation Accuracy: 0.9040\n",
            "Epoch 33/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.4397 - accuracy: 0.8862\n",
            "Validation Loss: 0.4397, Validation Accuracy: 0.8862\n",
            "Epoch 34/80\n",
            "\n",
            "72/72 [==============================] - 24s 336ms/step - loss: 0.2398 - accuracy: 0.9387\n",
            "Validation Loss: 0.2398, Validation Accuracy: 0.9387\n",
            "Epoch 35/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 344ms/step - loss: 0.1995 - accuracy: 0.9462\n",
            "Validation Loss: 0.1995, Validation Accuracy: 0.9462\n",
            "Epoch 36/80\n",
            "\n",
            "72/72 [==============================] - 24s 330ms/step - loss: 0.1817 - accuracy: 0.9482\n",
            "Validation Loss: 0.1817, Validation Accuracy: 0.9482\n",
            "Epoch 37/80\n",
            "\n",
            "72/72 [==============================] - 24s 330ms/step - loss: 0.1610 - accuracy: 0.9512\n",
            "Validation Loss: 0.1610, Validation Accuracy: 0.9512\n",
            "Epoch 38/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 341ms/step - loss: 0.1511 - accuracy: 0.9520\n",
            "Validation Loss: 0.1511, Validation Accuracy: 0.9520\n",
            "Epoch 39/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 343ms/step - loss: 0.1482 - accuracy: 0.9546\n",
            "Validation Loss: 0.1482, Validation Accuracy: 0.9546\n",
            "Epoch 40/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 344ms/step - loss: 0.5235 - accuracy: 0.8569\n",
            "Validation Loss: 0.5235, Validation Accuracy: 0.8569\n",
            "Epoch 41/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 344ms/step - loss: 0.2323 - accuracy: 0.9409\n",
            "Validation Loss: 0.2323, Validation Accuracy: 0.9409\n",
            "Epoch 42/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 344ms/step - loss: 0.1838 - accuracy: 0.9499\n",
            "Validation Loss: 0.1838, Validation Accuracy: 0.9499\n",
            "Epoch 43/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 344ms/step - loss: 0.1610 - accuracy: 0.9542\n",
            "Validation Loss: 0.1610, Validation Accuracy: 0.9542\n",
            "Epoch 44/80\n",
            "\n",
            "72/72 [==============================] - 24s 332ms/step - loss: 0.1531 - accuracy: 0.9552\n",
            "Validation Loss: 0.1531, Validation Accuracy: 0.9552\n",
            "Epoch 45/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 343ms/step - loss: 0.1336 - accuracy: 0.9580\n",
            "Validation Loss: 0.1336, Validation Accuracy: 0.9580\n",
            "Epoch 46/80\n",
            "\n",
            "72/72 [==============================] - 24s 332ms/step - loss: 0.1292 - accuracy: 0.9581\n",
            "Validation Loss: 0.1292, Validation Accuracy: 0.9581\n",
            "Epoch 47/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 343ms/step - loss: 0.1227 - accuracy: 0.9591\n",
            "Validation Loss: 0.1227, Validation Accuracy: 0.9591\n",
            "Epoch 48/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 0.1196 - accuracy: 0.9615\n",
            "Validation Loss: 0.1196, Validation Accuracy: 0.9615\n",
            "Epoch 49/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.4071 - accuracy: 0.8748\n",
            "Validation Loss: 0.4071, Validation Accuracy: 0.8748\n",
            "Epoch 50/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 0.1626 - accuracy: 0.9521\n",
            "Validation Loss: 0.1626, Validation Accuracy: 0.9521\n",
            "Epoch 51/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 0.1362 - accuracy: 0.9569\n",
            "Validation Loss: 0.1362, Validation Accuracy: 0.9569\n",
            "Epoch 52/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.1442 - accuracy: 0.9516\n",
            "Validation Loss: 0.1442, Validation Accuracy: 0.9516\n",
            "Epoch 53/80\n",
            "\n",
            "72/72 [==============================] - 25s 352ms/step - loss: 0.1299 - accuracy: 0.9538\n",
            "Validation Loss: 0.1299, Validation Accuracy: 0.9538\n",
            "Epoch 54/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 357ms/step - loss: 0.1413 - accuracy: 0.9530\n",
            "Validation Loss: 0.1413, Validation Accuracy: 0.9530\n",
            "Epoch 55/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 0.0971 - accuracy: 0.9667\n",
            "Validation Loss: 0.0971, Validation Accuracy: 0.9667\n",
            "Epoch 56/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0923 - accuracy: 0.9671\n",
            "Validation Loss: 0.0923, Validation Accuracy: 0.9671\n",
            "Epoch 57/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0886 - accuracy: 0.9695\n",
            "Validation Loss: 0.0886, Validation Accuracy: 0.9695\n",
            "Epoch 58/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0911 - accuracy: 0.9709\n",
            "Validation Loss: 0.0911, Validation Accuracy: 0.9709\n",
            "Epoch 59/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0875 - accuracy: 0.9705\n",
            "Validation Loss: 0.0875, Validation Accuracy: 0.9705\n",
            "Epoch 60/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0800 - accuracy: 0.9743\n",
            "Validation Loss: 0.0800, Validation Accuracy: 0.9743\n",
            "Epoch 61/80\n",
            "\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0776 - accuracy: 0.9757\n",
            "Validation Loss: 0.0776, Validation Accuracy: 0.9757\n",
            "Epoch 62/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 356ms/step - loss: 0.0750 - accuracy: 0.9762\n",
            "Validation Loss: 0.0750, Validation Accuracy: 0.9762\n",
            "Epoch 63/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 354ms/step - loss: 0.0732 - accuracy: 0.9761\n",
            "Validation Loss: 0.0732, Validation Accuracy: 0.9761\n",
            "Epoch 64/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 0.0680 - accuracy: 0.9782\n",
            "Validation Loss: 0.0680, Validation Accuracy: 0.9782\n",
            "Epoch 65/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 357ms/step - loss: 0.0664 - accuracy: 0.9781\n",
            "Validation Loss: 0.0664, Validation Accuracy: 0.9781\n",
            "Epoch 66/80\n",
            "\n",
            "72/72 [==============================] - 25s 350ms/step - loss: 0.0662 - accuracy: 0.9773\n",
            "Validation Loss: 0.0662, Validation Accuracy: 0.9773\n",
            "Epoch 67/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 358ms/step - loss: 0.0660 - accuracy: 0.9784\n",
            "Validation Loss: 0.0660, Validation Accuracy: 0.9784\n",
            "Epoch 68/80\n",
            "\n",
            "72/72 [==============================] - 25s 352ms/step - loss: 1.4896 - accuracy: 0.6873\n",
            "Validation Loss: 1.4896, Validation Accuracy: 0.6873\n",
            "Epoch 69/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 357ms/step - loss: 0.1535 - accuracy: 0.9582\n",
            "Validation Loss: 0.1535, Validation Accuracy: 0.9582\n",
            "Epoch 70/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 356ms/step - loss: 0.1015 - accuracy: 0.9674\n",
            "Validation Loss: 0.1015, Validation Accuracy: 0.9674\n",
            "Epoch 71/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 351ms/step - loss: 0.0872 - accuracy: 0.9719\n",
            "Validation Loss: 0.0872, Validation Accuracy: 0.9719\n",
            "Epoch 72/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 354ms/step - loss: 0.0821 - accuracy: 0.9725\n",
            "Validation Loss: 0.0821, Validation Accuracy: 0.9725\n",
            "Epoch 73/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 0.0714 - accuracy: 0.9774\n",
            "Validation Loss: 0.0714, Validation Accuracy: 0.9774\n",
            "Epoch 74/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 359ms/step - loss: 0.0689 - accuracy: 0.9780\n",
            "Validation Loss: 0.0689, Validation Accuracy: 0.9780\n",
            "Epoch 75/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 356ms/step - loss: 0.0644 - accuracy: 0.9800\n",
            "Validation Loss: 0.0644, Validation Accuracy: 0.9800\n",
            "Epoch 76/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 354ms/step - loss: 0.3178 - accuracy: 0.9141\n",
            "Validation Loss: 0.3178, Validation Accuracy: 0.9141\n",
            "Epoch 77/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 25s 353ms/step - loss: 0.0853 - accuracy: 0.9752\n",
            "Validation Loss: 0.0853, Validation Accuracy: 0.9752\n",
            "Epoch 78/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 357ms/step - loss: 0.0668 - accuracy: 0.9803\n",
            "Validation Loss: 0.0668, Validation Accuracy: 0.9803\n",
            "Epoch 79/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 355ms/step - loss: 0.0629 - accuracy: 0.9807\n",
            "Validation Loss: 0.0629, Validation Accuracy: 0.9807\n",
            "Epoch 80/80\n",
            "Step 100/100\n",
            "72/72 [==============================] - 26s 356ms/step - loss: 0.0613 - accuracy: 0.9814\n",
            "Validation Loss: 0.0613, Validation Accuracy: 0.9814\n"
          ]
        }
      ],
      "source": [
        "# epochs = 200  # This should be at least 30 for convergence\n",
        "# steps_per_epoch = 100,\n",
        "# transformer.summary()\n",
        "# transformer.compile(\n",
        "#     \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "# )\n",
        "# transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n",
        "\n",
        "\n",
        "epochs = 80  # This should be at least 30 for convergence\n",
        "steps_per_epoch = 100  # Number of steps per epoch (customize as needed)\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Manually control the training loop\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for step, (x_train, y_train) in enumerate(train_ds.take(steps_per_epoch)):\n",
        "        transformer.train_on_batch(x_train, y_train)\n",
        "        print(f\"Step {step + 1}/{steps_per_epoch}\", end=\"\\r\")\n",
        "    print()\n",
        "\n",
        "    # Perform validation at the end of each epoch\n",
        "    val_loss, val_accuracy = transformer.evaluate(val_ds)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# epochs = 100  # This should be at least 30 for convergence\n",
        "# steps_per_epoch = 100  # Number of steps per epoch (customize as needed)\n",
        "\n",
        "# transformer.summary()\n",
        "# transformer.compile(\n",
        "#     \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "# )\n",
        "\n",
        "# # Create lists to store the metrics\n",
        "# train_loss = []\n",
        "# train_accuracy = []\n",
        "# val_loss = []\n",
        "# val_accuracy = []\n",
        "\n",
        "# # Manually control the training loop\n",
        "# for epoch in range(epochs):\n",
        "#     print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "#     for step, (x_train, y_train) in enumerate(train_ds.take(steps_per_epoch)):\n",
        "#         transformer.train_on_batch(x_train, y_train)\n",
        "#         print(f\"Step {step + 1}/{steps_per_epoch}\", end=\"\\r\")\n",
        "#     print()\n",
        "\n",
        "#     # Calculate metrics for training data\n",
        "#     train_metrics = transformer.evaluate(train_ds, verbose=0)\n",
        "#     train_loss.append(train_metrics[0])\n",
        "#     train_accuracy.append(train_metrics[1])\n",
        "\n",
        "#     # Calculate metrics for validation data\n",
        "#     val_metrics = transformer.evaluate(val_ds, verbose=0)\n",
        "#     val_loss.append(val_metrics[0])\n",
        "#     val_accuracy.append(val_metrics[1])\n",
        "\n",
        "#     print(f\"Train Loss: {train_loss[-1]:.4f}, Train Accuracy: {train_accuracy[-1]:.4f}\")\n",
        "#     print(f\"Validation Loss: {val_loss[-1]:.4f}, Validation Accuracy: {val_accuracy[-1]:.4f}\")\n",
        "\n",
        "# # Plot the metrics\n",
        "# plt.plot(train_loss, label='Train Loss')\n",
        "# plt.plot(train_accuracy, label='Train Accuracy')\n",
        "# plt.plot(val_loss, label='Validation Loss')\n",
        "# plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Metrics')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mltZPv8ClL-d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# history = transformer.history  # Replace 'transformer' with your model's history object\n",
        "\n",
        "# # plt.plot(history.history['loss'], label='loss')\n",
        "# plt.plot(history.history['val_accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_loss'], label='val_loss')\n",
        "\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Metrics')\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "QA19vfoVqH70"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjx1ptXzHqa9"
      },
      "source": [
        "## Decoding test sentences\n",
        "\n",
        "Finally, let's demonstrate how to translate brand new English sentences.\n",
        "We simply feed into the model the vectorized English sentence\n",
        "as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n",
        "we hit the token `\"[end]\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tSflJcBEHqa9"
      },
      "outputs": [],
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 300\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5idcwgsIIt7I"
      },
      "source": [
        "## Adding data from Test set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N3p0oR60I0x8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "\n",
        "dc = pd.read_excel('4-OM-test-set.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iocoqiuuJYo9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3338a64f-18a1-4613-9c1f-72800571b80e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "1  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "2  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "3  module OM_name:0 ,open Declaration one sig cla...              1\n",
              "4  module OM_name:0 ,open Declaration one sig cla...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb48b95b-0aad-48c7-9492-076a6e2ad8d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>module OM_name:0 ,open Declaration one sig cla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb48b95b-0aad-48c7-9492-076a6e2ad8d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb48b95b-0aad-48c7-9492-076a6e2ad8d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb48b95b-0aad-48c7-9492-076a6e2ad8d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WEcoRd5hJGDT"
      },
      "outputs": [],
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "npksdP3PJOq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb339044-b8cc-4613-e39f-a297baff8138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127,)\n",
            "(127,)\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ],
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"X data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l6Xn1sFBJQsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b09be1d-1608-4f9e-8b20-80e1e9d942f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_test2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t_WywObeJdMJ"
      },
      "outputs": [],
      "source": [
        "inputs = X_test2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYRa3kkQJgA2"
      },
      "source": [
        "## Output from Unseen Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GKIRmrcoJlG3"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "\n",
        "# start_time = time.time()\n",
        "# mylist_res = []\n",
        "# for sentence in inputs:\n",
        "#     result = decode_sequence(sentence)\n",
        "#     mylist_res.append(result)\n",
        "#     print(result)\n",
        "#     time.sleep(1)  # Add a 1-second delay between each print statement\n",
        "\n",
        "# end_time = time.time()\n",
        "# execution_time = end_time - start_time\n",
        "\n",
        "# print(f\"Execution time: {execution_time} seconds\")\n",
        "# print(mylist_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkeF3s1IJpWP"
      },
      "source": [
        "## Result Computation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "KdsbTahpeSiP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_excel('4-OM-test-set-pred-new.xlsx')"
      ],
      "metadata": {
        "id": "RFlUXSNheTt6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "SznLVsNbeWLx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "id": "9iykq6NSeY0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa3daa4-e921-448b-f399-346260822554"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "id": "drSHPblTebi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1beaf7-bda1-4de0-bb2d-e2c348cfefbf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.238095\n",
            "Testing: Recall = 0.156250\n",
            "Testing: F1 Score = 0.188679\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[79 16]\n",
            " [27  5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "id": "QwNDwGXVeeV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d276f77-011c-45ee-9ccd-844bd761c3f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.83      0.79        95\n",
            "           1       0.24      0.16      0.19        32\n",
            "\n",
            "    accuracy                           0.66       127\n",
            "   macro avg       0.49      0.49      0.49       127\n",
            "weighted avg       0.62      0.66      0.64       127\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}