{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP EUndersample Distribution  \n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###6 OM - Dataset , Camping,OnlineStore, Decider , Bank, Customer_order, E-Commerce\n",
        "\n",
        "###3 OM - Testing - Library Management, School OM, Student-course (unseen)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 70% - 30%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "\n",
        "### Total instances - 590\n",
        "\n",
        "### P samples - 413  P \n",
        "### NP samples -  177 NP\n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 170\n",
        "\n",
        "### P samples - 32\n",
        "### NP samples - 138\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "# !pip install \"tensorflow-text>=2.10\"\n",
        "# !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('6-OM-70P-30NP.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "62fc78e2-c020-4c67-a9d8-cc4df2b4a8f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e5a104d-ecc5-48ce-af15-dd675f6995a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e5a104d-ecc5-48ce-af15-dd675f6995a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e5a104d-ecc5-48ce-af15-dd675f6995a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e5a104d-ecc5-48ce-af15-dd675f6995a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "fd0adf62-6827-490c-9a73-c9ffcd0161c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 51, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "566a7658-0091-4d81-d403-c7fcda1e6aed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "4a907721-6feb-443a-ecff-6b2a570c1af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 53  3]\n",
            "\n",
            "[ 2 53]\n",
            "[53  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "8df8ccb5-c3cd-4854-aa1a-dd5e5317a8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "1d2eaba2-1e0e-4046-b3cb-9f2fd1d03229"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "4fc29990-1e9e-4a96-b2ba-4b57a7a85097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0000001, 1.       ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "0538a1f9-d2ae-444d-e07a-af8cd6952831"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "bdf7e61d-9a72-4f25-c5ee-90c9c553a360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 253)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "79c1f630-c4a7-4926-ddbd-2254a6d1c7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 253)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "354cc032-989c-40be-8abe-c299b3aa0f93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.5333896, 'expected_acc': 0.003952569169960474}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "a14185ab-d125-4168-a64c-e3716aa7b322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 7s 9ms/step - loss: 5.7006 - masked_acc: 0.0000e+00 - masked_loss: 5.7006\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.700587749481201,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 5.700587749481201}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "995e58a1-7707-48d4-a4ac-6df547291752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.4887 - masked_acc: 0.8500 - masked_loss: 0.4887 - val_loss: 2.1560 - val_masked_acc: 0.8286 - val_masked_loss: 2.1560\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.3366 - masked_acc: 0.8900 - masked_loss: 0.3366 - val_loss: 2.1459 - val_masked_acc: 0.7714 - val_masked_loss: 2.1459\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.3690 - masked_acc: 0.9000 - masked_loss: 0.3690 - val_loss: 2.3626 - val_masked_acc: 0.8071 - val_masked_loss: 2.3626\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.2706 - masked_acc: 0.9300 - masked_loss: 0.2706 - val_loss: 1.7779 - val_masked_acc: 0.8357 - val_masked_loss: 1.7779\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.2554 - masked_acc: 0.9250 - masked_loss: 0.2554 - val_loss: 1.7609 - val_masked_acc: 0.8571 - val_masked_loss: 1.7609\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 5s 55ms/step - loss: 0.1338 - masked_acc: 0.9750 - masked_loss: 0.1338 - val_loss: 2.0123 - val_masked_acc: 0.8500 - val_masked_loss: 2.0123\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.0787 - masked_acc: 0.9950 - masked_loss: 0.0787 - val_loss: 1.9526 - val_masked_acc: 0.8643 - val_masked_loss: 1.9526\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.0746 - masked_acc: 0.9750 - masked_loss: 0.0746 - val_loss: 1.5417 - val_masked_acc: 0.8714 - val_masked_loss: 1.5417\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.1623 - masked_acc: 0.9500 - masked_loss: 0.1623 - val_loss: 2.3733 - val_masked_acc: 0.8357 - val_masked_loss: 2.3733\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.2074 - masked_acc: 0.9500 - masked_loss: 0.2074 - val_loss: 1.9614 - val_masked_acc: 0.8571 - val_masked_loss: 1.9614\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.1012 - masked_acc: 0.9800 - masked_loss: 0.1012 - val_loss: 1.8592 - val_masked_acc: 0.8786 - val_masked_loss: 1.8592\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.0669 - masked_acc: 0.9850 - masked_loss: 0.0669 - val_loss: 1.9698 - val_masked_acc: 0.8643 - val_masked_loss: 1.9698\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.0479 - masked_acc: 0.9900 - masked_loss: 0.0479 - val_loss: 1.9016 - val_masked_acc: 0.8786 - val_masked_loss: 1.9016\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 6s 62ms/step - loss: 0.0432 - masked_acc: 0.9950 - masked_loss: 0.0432 - val_loss: 1.5455 - val_masked_acc: 0.8929 - val_masked_loss: 1.5455\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.0428 - masked_acc: 0.9900 - masked_loss: 0.0428 - val_loss: 2.0535 - val_masked_acc: 0.8500 - val_masked_loss: 2.0535\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0506 - masked_acc: 0.9800 - masked_loss: 0.0506 - val_loss: 1.4887 - val_masked_acc: 0.9071 - val_masked_loss: 1.4887\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 4s 45ms/step - loss: 0.0676 - masked_acc: 0.9850 - masked_loss: 0.0676 - val_loss: 1.7655 - val_masked_acc: 0.8929 - val_masked_loss: 1.7655\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 0.0277 - masked_acc: 0.9950 - masked_loss: 0.0277 - val_loss: 1.9714 - val_masked_acc: 0.8786 - val_masked_loss: 1.9714\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.0543 - masked_acc: 0.9900 - masked_loss: 0.0543 - val_loss: 2.1923 - val_masked_acc: 0.8643 - val_masked_loss: 2.1923\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0413 - masked_acc: 0.9900 - masked_loss: 0.0413 - val_loss: 2.3687 - val_masked_acc: 0.8500 - val_masked_loss: 2.3687\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.0589 - masked_acc: 0.9850 - masked_loss: 0.0589 - val_loss: 2.2310 - val_masked_acc: 0.8571 - val_masked_loss: 2.2310\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.0213 - masked_acc: 0.9950 - masked_loss: 0.0213 - val_loss: 2.1755 - val_masked_acc: 0.8571 - val_masked_loss: 2.1755\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0074 - masked_acc: 1.0000 - masked_loss: 0.0074 - val_loss: 1.8356 - val_masked_acc: 0.8786 - val_masked_loss: 1.8356\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.0247 - masked_acc: 0.9900 - masked_loss: 0.0247 - val_loss: 2.5148 - val_masked_acc: 0.8429 - val_masked_loss: 2.5148\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "28569255-1191-4e08-9f5f-421c109a5376"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f33dfbd4910>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "KkhXRASNG80_",
        "outputId": "056a9a3f-f808-4530-bc2f-564e421ffe54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f33df2aae20>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsXklEQVR4nO3deXxV1b338c+PDIQkEAKBMAZQoMyz4vQoSmmhDwoOiNRaRav1Vu3g7WBta2nV3tbWtmq9Vux1wGKthdJrFWewOIGAD5VJZBBIGEMSEhIImdbzxzoJJ5AJyMlJsr/v1yuvnLP3Pvuss3Oyv3uvvfZa5pxDRESCq020CyAiItGlIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYCLWBCY2ZNmtt/M1tUy38zsYTPbYmYfm9mYSJVFRERqFxvBdT8N/AGYV8v8KcCA0M944LHQ7zqlpaW5vn37Nk4JRUQCYvXq1Qecc11qmhexIHDOLTOzvnUsMg2Y5/wdbcvNrKOZdXfO7alrvX379mXVqlWNWVQRkVbPzHbUNi+SZwT16Qlkhj3PCk2rMwhERJob5xxFJeXkFpaQe7iE3KKj5BSWkFvkf3KKSsgL/c4tKuFwSTl9OicyoGsy/UM/A9Lb0yMlATNr8vJHMwgazMxuAW4ByMjIiHJpgsM5x4Y9Bby6bi/LPs3mjC7JTB7WjYsGdiEhLibaxWuRnHMUHCkjp+ho1U4iN2wHUX1nUUbHxHg6JcXTOcn/Dv/pnNSWTsl+XnP7ezjnyD50lC37C9m8v5DN+w+xZX8hBwpLSE2MIzUxns7JlZ+lLZ2S4uiU1Lba52yOn2lvQbH/TPsK2ZJdyJZ9hWTmHSanqISSsooaXxcf26ba5+rTOZGE2Bi25xTx5sZ9PL/y2PFwYnyMD4YuyfRP978HpLcno1MiMW0iFxAWyb6GQlVDLznnhtUw73HgbefcX0LPNwET6qsaGjdunFPVUOQ451iTeZBX1+3llXV72Zl7mDYGo3p3ZNuBIg4eLiUxPoaLB3VlyrBuXPy5riS1bRHHExFRVl5B7uES8opKq+3ccwpLyDsc2qlXHhke9jv6soqa/+cS42Oq7SAT42M4eLi02hFlba9tFxdDp6R40pLj6ZeWFDrKbM+A9GT6dEokNiYy7UIqKhy7Dh6p2iluCdvpFxSXVS3XPiGW/l2TSW+fwMEjlQFYSt7hEsrr2B6dkuJJTYynzSnsBDskxJIaHqSh0Dy2jdvSsV3cCesur3Bk5R2uCrHK31v3F1J49Nhn6pgYx4CuyWR0SiItOSygQ+vunBRPalI8SfExdR7l5xaVsGV/9W23ZX8he/KLq5aJj2nDGV2S+NbEAUwZ3v2ktwWAma12zo2raV40/4NfBG43s+fxF4nz6wsBiYzyCsfqHXksXruH19bvZU9+MbFtjPP7p/GNCWcyaUg6nZPbUlpewYptuSxet4fX1+/l5Y/30Da2DRcO7MKUYd2YODidlHZx0f44p6W4tLxq5338UXv4Drnycf6R0lrXldIurupIMKNzIqMzOlbbWaQmHjuq75QYT7v4uo+AnXMUFJeFynK0xrDJLjzKyu15/GPN7qrXxcVY9XAIVUX0S0uq9ai7pKzCr7uw8rMerfa5c4tKyMo7wpb9hRwpLa96XVpyPGd2SeayUT2qjmb7d02ma/u2Ne4MKyocBcWlJ1SdhP8cPFxCLVlR+7YCCo6UsiPnMHlFJRwK24GHa2OQmuh32J2S4jlUXMa27EKOhh3dd23flv5dk7lyTE/6p7cPfa5kOifFN0o1TqekeM7u14mz+3WqNv1QcSlbs4vYvO9YONT3HTlVETsjMLO/ABOANGAf8FMgDsA590fzW/APwGTgMDDbOVfvob7OCBpH5U79lXV7eG39Pg4UHiU+tg0XDvA79c8PTiclsfadenmFY9X2XF5Zt5dX1+1lb0ExcTE+PKYM68akId3olBTfhJ/o5GzcU8Cfl+9g18EjVUfwuUUl1XZq4WLbmN9ZhI4wK48ua6quSU3yVR9xEToKb4iio2VszT52NLt5XyFbswvZkVNUtVNtY5DRKZH+XZMBju2ECxu24+yeksCAru1D9du+GiO1mf7Nj5aVn3DWVq1aLvT3bxcfw4DKzxP6bC394KZSXWcEEa0aigQFwenZV1DMb1//lNc27OXg4VLaxcVw8aAuTB7WnUsGdSX5FKp5Kioca7Iqq5P2kJl7hJg2xvh+nZg+qidTR3YnMb55VB+tzcrn4SWbeWPDPhLjYzizS3JV1UFqUvX6+PCj9g7tYqNyEa+xFZeWsz2nyNdxh44yt2YX0sbsuECLrzpTCa/uSGkXF9G6aokcBYEA8NHOPG59djUFxaV8cWg3pgzrzkUDuzTq6aZzjvW7C3hl3R5eWbuXbQeKaJ8QyxWje/Ll8X34XLf2jfZeJ2P1jjweWbKZtzdl0yEhlhsv6McN5/WlY2LzPIIVaWwKAuGFVZn8eNE60lPa8sRXxzGoW4eIv6dzjlU78pi/fAeL1+6lpLyCs/qmcu34Pkwe1i3irUKccyzflssjSzbz/tYcOiXFc9MF/fjquX1on9A6TvdFGkpBEGBl5RXcv3gjT723nfP7d+YPs8ZEpR43t6iEBaszmb9iJztyDpOaGMeMcb2ZdXYG/dKSGvW9nHO8s/kAjyzZzMrteaQlt+XrF57BtedkNJsqKpGmpiAIqLyiEm577iPe35rDjef34+4vDYpYM8KGqqhwvL81h/krdvD6hn2UVzgu6J/GteMz+PyQ9NO6wOqc462N+3lk6Rb+nXmQ7ikJ3HrRmcw8q3eza5Mu0tQUBAH0yd4Cbp63in35R7n/8mHMGNc72kU6wb6CYl5YmclfPtzJ7vxiurRvyzVn9WbSkHRi25xcIGw7UMh/L93Khj0F9Eptxzcm9OfKsT1pG6sAEAEFQeC8um4Pd77wb5LbxvLH68YyJiM12kWqU3mF4+1N+5m/YidLN+3nVL+S/dKSuO3i/kwb1SOqTTdFmqPmekOZNLKKCsdDb23mobc2M6p3Rx6/bizpHRKiXax6xbQxJg5OZ+LgdLLyDrNuV8FJryO5bSznntlZTRtFToGCoJUoPFrGnX9dw+sb9nHlmF7cf/mwFlkv3is1kV6pidEuhkigKAhagR05Rdw8bxVbs4u4Z+oQZp/ft1Xc/CQiTUNB0Aws35bDY29vJTP38Al3t9bU22R4vzTvbj7Abc99BMAzs8/mggFp0fwoItICKQiixDnHu1sO8MhbW/hwey5pyW0Z368TeYdLyMw9zJrMgw3qbXJP/hEGdG3P3K+OpU/nxm2PLyLBoCBoYs45lnyyn0eWbGFN5kG6dUhgzqVDuObsjBPq9GvqbbKyO+PKTrI6JsZz5xcGnlIfQSIioCBoMhUVjtc37OWRJVtYv9u3df/F5cPrbOtuZqS0iyOlXVyj330rIlJJQRBh5RWOl9fu4dElW9i07xD90pL49VUjmD66p9q6i0izoCCIkNLyCv53zW7+e+kWth0oYkDXZB66ZhRTR/RQW3dpPnK2wt9ugPJSyDjH//QeD6l9QS3PAkNB0Ihyi0rYvO8Q63YX8PT7n5GZe4TB3Tvw2LVj+OLQbqc03J5IxOxdC89eAa4cuo+CdQth9VN+XnI3yBgPGef6YOg2AmK0u2it9Jc9Sc459hUcrTa+aOW4prlFJVXLjeyVwk+nDmXi4K5q0y/Nz87lMP9qaJsM170MXQZCRTns3wiZy/38nStgw//65eOSoNdY6B06a+h1FiREvitzaRrqa6gOFRWO97YeYOOeAj+iU2iA7vBh/FLaxVUNbXdm2BitPVISFAByco4egqxVkLkCdn4ARw7CpJ/DGRc17vtsfgP+eh2k9ITr/gEd6+iQMH9XKBhCZdq3DlwFWBvoOvRYdVLGOZDSq3HLKY1Knc6dgq3Zhdy18GNWbs8DoEv7tlWDfg/omsyZXZMZ0LU9acmNM4C1BFDBbr9z3bnC72z3rj22k00f6oMhbzuceztc8hOIa4R+o9YugEVf9+u/diEkdzm511eG1c7lvsyZK6G0yM/r0Kt6dVL6UGjT8ro5aa0UBCehrLyCue9s4/dvbqZdXAw/+tJgvji0W50DuYvUq1q1ywq/I83f6efFJUKvcSdWu5QUwRv3wMo/QZfBcOUT0G34qZdh5f/Ay/8Jfc6HWX9pnKqd8jJ/llB5FrNzORza4+fFt4feZx0Lhl7jIF7NoKNFQdBA63fn84OFH7NuVwGTh3bj59OH0rV98++9U05S7jZYuxC2vOmrMyqrNroOabwj2JLDsGv1sfr2zJVwNN/PO+FC7HCIqeNAY/Mb8L+3weFcuOTHcN4dJ1dO5+CdB2HJvTBwCsx4CuLand7nq+u9Du4MBUPos+/fADiwGOg+IhR44/3vDt0jU47myDnY/ZH/7u39GM6+GQZf1mStsxQE9SguLeeRJZv547+2kZoYz73ThjJleIC+oI2t7CgU7PL1y537N49/9oI9sP7vvmpkt++biR6j/fTCvf552w7+aLwyGHqObfgRbOH+Yzu+zOWw599QEbqW1GVw9R3/qTTNLMqBl74FG/8JGefB5X+E1D71v845eP3H8MEfYMRMmPZo3aETCUcOhqqTQmcMu1ZD2RE/r2Mfv10qt0/a5+AkByVq9vZ/AusW+FZZudsgJt4fDOTvhL7/B6b8ylejRZiCoA6rd+Ty/QUfszW7iCvH9OInUwfTMbHpx/RtMZyDomzIz/Q7+vys0E9maOefBYX7ji0f2w4u+Dac902Ib+LupQ/nwsYX/c5/+7uA880gh18FQ6/wF0mdg4M7jtXT71zuq3DCj2Ard+AZ50D7blBRATmbj9Xv7/wA8j4Lfd4EHyCVy/c6CxI7Nc7ncQ7+/Tws/p5//qUHYOSs2kOlvAz++S1Y82c4++sw+ZfNYydbXgp7PvbbrbKqrGi/n5eQcmzb9T4Heo6J3NlLJOXt8Dv+dQt91Zm1gX4XwrCrYPClEJ/sm+ouvR+K82HcjXDxjxrvu1IDBUENio6W8evXNvHMB9vpkdKOX1wxnIsGnuSFs9auuACyVvrT/KyV/sJl/i4oP1p9ubhEX8WS0gs69ISU3v5xcjqsme+PxFN6+xYwQy+P7Knw0ULY9Io/AtvyFlSU+rOSYVfBsCt9M8n6HMnzVTmVO6ldq6Cs2M/r2AeOFvhlABLTjt2ElXEudB8JsRE+kMjbAYtuhZ3v+53K1IcgqXP1ZUqLYeFN8MlLMOGHcNEPmu8NYs75I+Wq6wwr4MAmP69NHPQYdWz7ZpwDSc20h93C/bD+H/67l7nCT+t1lv/uDb0c2qef+JrDufD2f/nrN23b+zAYd2NE7tlQEBxn2afZ/PDva9mdf4SvntOH700e1DI7batsVdK+hz+SON1/9PxdoaO0yqaC66s3FewysPqOvvKnXWrd7739PXj1B75VTMZ5MOWXfofZWMqO+vr+tQvg01eh9LAv57Ar/D9h95Gnt23KSnyd7s7lkPWh/4fNONcfsXY+Mzo72IpyX93z1r1++097FAZ+wc87egie/zJ8tgymPADjv9705Ttdh3OrX2fY/RGUh+7T6dz/2HWGjHP989P9GxTn+7PZkqKTf+2BT/1377N/+f+XrkNh+JX+wCO1b8PWsW8DvHqXX0eXwf5/5IwJJ1+WOigIQvIPl3LvyxtYsDqLM7ok8asrR3BW38idikVEaTFsft0fdXz62rEj1dh2vl14Si/fjK9qRx3acXfoWb1qpqLcX8Srqtde4at3IHTz0LhjR7qNcfNQRTl8NM9fsDycC2Ov900iT/XorqIctr8Da//m682L86FdJxg63e/8M85tHtUgkbZ3Lfz9Fv+3HHcTXPAdeOGr/hrF9Mdg5Mxol7BxlBbDnjXHvqs7l8ORXD8vsXP1YOg+EmLbHnttWYmvtqysujy+WrNglz/LOx0d+/gqx2FXQfqQU1uHc/DJy/Da3b66ctBU+MJ90Knf6ZUtREEALPlkHz9YuJbcohK+fuEZfHPigJYzlGN5GXz2tm9t8MlL/kub1MWfbmacA4XZ1evo87Pg0F7guL9tu04+HBJS/I6i8suf3K36jUHpwyPXncCRPPjXA/DhXB84E+7yrScacgHTOX/Rcd0CWL/IX4uIT/b/MMOv8kdQTX0htDkoLYal98H7f/BHxjHxMONp+NyUaJcscpyDA5urn8HmbvPzYtr66qSK8rBrVsf9LySmVT+rrazWPJUDnsS00z/rDFda7M/23vmtb3Bw3u1wwZ3+LvDToCAAXl23h4ff2sIDV41gWM+UCJSskVVU+C/4ugW+3vHwAd+qZfBl/rSz74V176zLSnx77qqjnqxjjw/n+iaLla01OvZp+uqN7E3+VHjrEkgbCJP/C/p/vuZl9633p97rFvojpZi2vhpk2FUw8Ist82JiJHz2jm8meuF3oe8F0S5N06tsuZW5wh8wxLU7cWef0hs69GgZ35mC3fDmz+Dj56F9d/j8z2D4jFM+01UQhJRXuObd86dz/lR/3QJY93d/lB+bAAMn+yPe/pMa5+7S5sI5X6f/6g99q5uBU+CL9/t699zP/HZYuxCyN/oWPGdcFGp1MdWf1YgEQeaH8MoP/HWSz//Mt8I7BQqC5q44H1Y95VvYHPgU2sTCmZf4nd6gL/mLk61Z2VFY/hgs+7V/3HWQD0Twdb/Dr4Ih00++OwSR1qKiwp8ZDJx8yk1MFQTgN2TuNkjr3/iFOlUFe2D5f/sQKDnkW9SMmAGDp53YHDAIDu31F5OzN/l6/2FXQMeMaJdKpFWoKwhaYJvJU/TOb+Dd38M18+HMi6NblgOb4b2H4OO/+otBQy/3N1z1GBXdckVb+26+GaSINKngBMGYr/qWJs9dDVf+Dwy5rOnLkLkS3vu9byIW29aX6dzbG615mIjIqQhOELTvBrMX+8E4/nY9XPowjLku8u/rnO807L3fw473IKGjb9Vx9tdV5y0izUJEg8DMJgMPATHAn5xzvzxufgbwDNAxtMxdzrnFEStQu1T46j/gr1+BF2+H4oO+J8dIKC/1LX/eewj2r/dtlL/4Cxhz/Wm3BxYRaUwRCwIziwEeBSYBWcBKM3vRObchbLEfAy845x4zsyHAYqBvpMoE+N4kZ/0V/n6z75XxSJ6/w7Wx2tGXlcDqp+H9h33zzy6DYfoffcuXIN7sJCLNXiTPCM4GtjjntgGY2fPANCA8CBxQeStfCrA7guU5JjYernoSXkrxN+AczoX/++Dp90W/+U1/k1TOZn+z1pd+AwO+EIyuDkSkxYpkEPQEMsOeZwHjj1tmDvC6md0BJAG13FoaAW1i4NKHfJvcd3/n2/Jf/vip9Rx5YIvvH2Tza9DpTPjyCz4AmmtvjyIiYaJ9sXgW8LRz7kEzOxd41syGOecqwhcys1uAWwAyMhqxXbkZfH6Ov3bwxj2+752rn214v/nFBbDsAVj+R38H8KR7Yfytke+GWESkEUUyCHYBvcOe9wpNC3cTMBnAOfeBmSUAacD+8IWcc3OBueBvKGv0kp7/Ld+a56Vvw7PT4ct/9eFQm4oKfxfwWz/zg7SM+gpMvKfm/sZFRJq5SFZerwQGmFk/M4sHrgFePG6ZncBEADMbDCQA2REsU+3GXg9XPQW7PoKnp8KhfTUvt3MFPHGxb3WU2g9uXgLTH1UIiEiLFbEgcM6VAbcDrwEb8a2D1pvZz82s8m6u/wRuNrN/A38BbnDR7PNi6HS49gXf4dmTX/SDvlTK3wULvwZPfsF3a3vFE3DT635YQhGRFiw4fQ2djMyVMP8q31XtrL/40a/e+a3v3/y8O/zgH7oXQERaEPU1dLJ6nwWzX4FnL4e5E/y0wZf6i8HqDkJEWhkFQW3Sh8BNr8Hbv/LD/TXy+KEiIs2FgqAuqX3h8seiXQoRkYjSLa8iIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBFxEg8DMJpvZJjPbYmZ31bLM1Wa2wczWm9lzkSyPiIicKDZSKzazGOBRYBKQBaw0sxedcxvClhkA/BA43zmXZ2ZdI1UeERGpWSTPCM4GtjjntjnnSoDngWnHLXMz8KhzLg/AObc/guUREZEaRDIIegKZYc+zQtPCDQQGmtl7ZrbczCZHsDwiIlKDiFUNncT7DwAmAL2AZWY23Dl3MHwhM7sFuAUgIyOjiYsoItK6NTgIzOw8oG/4a5xz8+p4yS6gd9jzXqFp4bKAFc65UuAzM/sUHwwrwxdyzs0F5gKMGzfONbTMIiJSvwYFgZk9C5wJrAHKQ5MdUFcQrAQGmFk/fABcA3z5uGX+AcwCnjKzNHxV0bYGll1ERBpBQ88IxgFDnHMNPhp3zpWZ2e3Aa0AM8KRzbr2Z/RxY5Zx7MTTvC2a2AR8w33PO5ZzcRxARkdPR0CBYB3QD9pzMyp1zi4HFx027J+yxA+4M/YiISBQ0NAjSgA1m9iFwtHKic+6yiJRKRESaTEODYE4kCyEiItHToCBwzv3LzPoAA5xzb5pZIr7eX0REWrgG3VBmZjcDC4DHQ5N64lv8iIhIC9fQO4tvA84HCgCcc5sB9QskItIKNDQIjob6CwLAzGLx9xGIiEgL19Ag+JeZ3Q20M7NJwN+Af0auWCIi0lQaGgR3AdnAWuDrwGLn3I8iVioREWkyDW4+GroR7AnwYw2Y2Xzn3LWRK5qIiDSFhp4R9DazHwKYWTywENgcsVKJiEiTaWgQ3AgMD4XBS8C/nHNzIlYqERFpMnVWDZnZmLCnD+HvI3gPf/F4jHPuo0gWTkREIq++awQPHvc8DxgSmu6ASyJRKBERaTp1BoFz7uKmKoiIiERHQ7uYSDGz35rZqtDPg2aWEunCiYhI5DX0YvGTwCHg6tBPAfBUpAolIiJNp6H3EZzpnLsy7PnPzGxNBMojIiJNrKFnBEfM7ILKJ2Z2PnAkMkUSEZGm1NAzgluBeWHXBfKA6yNTJBERaUoNDYIC59xIM+sA4JwrMLN+ESyXiIg0kYZWDS0EHwDOuYLQtAWRKZKIiDSl+u4sHgQMBVLM7IqwWR2AhEgWTEREmkZ9VUOfA6YCHYFLw6YfAm6OUJlERKQJ1RcEicB3gbnOuQ+aoDwiItLE6guCDPxoZHFm9hbwCvChc07DVIqItBJ1Xix2zv3KOXcJ8CXg3/juqD8ys+fM7Ktmlt4UhRQRkchpUPNR59whYFHoBzMbAkwB5gFfjFjpREQk4uo8IzCzr4Q9Pr/ysXNuA3DUOacQEBFp4eq7j+DOsMePHDfvxkYui4iIREF9QWC1PK7puYiItED1BYGr5XFNz0VEpAWq72LxIDP7GH/0f2boMaHnZ0S0ZCIi0iTqC4KRQDqQedz03sDeiJRIRESaVH1VQ78D8p1zO8J/gPzQPBERaeHqC4J059za4yeGpvWtb+VmNtnMNpnZFjO7q47lrjQzZ2bj6i2xiIg0qvqCoGMd89rV9UIziwEexd94NgSYFboR7fjl2gPfAlbUUxYREYmA+oJglZmd0MuomX0NWF3Pa88GtjjntjnnSoDngWk1LHcv8CuguAHlFRGRRlbfxeJvA4vM7FqO7fjHAfHA5fW8tifVLzJnAePDFzCzMUBv59zLZva9hhZaREQaT51B4JzbB5xnZhcDw0KTX3bOLTndNzazNsBvgRsasOwtwC0AGRkZp/vWIiISpqGdzi0Flp7kunfhm5lW6hWaVqk9PlzeNjOAbsCLZnaZc27Vce8/F5gLMG7cON3IJiLSiBo6ZvGpWAkMMLN+ZhYPXAO8WDnTOZfvnEtzzvV1zvUFlgMnhICIiERWxILAOVcG3A68BmwEXnDOrTezn5vZZZF6XxEROTkNqho6Vc65xcDi46bdU8uyEyJZFhERqVkkq4ZERKQFUBCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEXESDwMwmm9kmM9tiZnfVMP9OM9tgZh+b2Vtm1ieS5RERkRNFLAjMLAZ4FJgCDAFmmdmQ4xb7f8A459wIYAHwQKTKIyIiNYvkGcHZwBbn3DbnXAnwPDAtfAHn3FLn3OHQ0+VArwiWR0REahDJIOgJZIY9zwpNq81NwCsRLI+IiNQgNtoFADCzrwDjgItqmX8LcAtARkZGE5ZMRKT1i+QZwS6gd9jzXqFp1ZjZ54EfAZc5547WtCLn3Fzn3Djn3LguXbpEpLAiIkEVySBYCQwws35mFg9cA7wYvoCZjQYex4fA/giWRUREahGxIHDOlQG3A68BG4EXnHPrzeznZnZZaLFfA8nA38xsjZm9WMvqREQkQiJ6jcA5txhYfNy0e8Ief74x3qe0tJSsrCyKi4sbY3VymhISEujVqxdxcXHRLoqINECzuFh8urKysmjfvj19+/bFzKJdnEBzzpGTk0NWVhb9+vWLdnFEpAFaRRcTxcXFdO7cWSHQDJgZnTt31tmZSAvSKoIAUAg0I/pbiLQsrSYIRETk1CgIWpiysrJoF0FEWhkFQSOaPn06Y8eOZejQocydOxeAV199lTFjxjBy5EgmTpwIQGFhIbNnz2b48OGMGDGChQsXApCcnFy1rgULFnDDDTcAcMMNN3Drrbcyfvx4vv/97/Phhx9y7rnnMnr0aM477zw2bdoEQHl5Od/97ncZNmwYI0aM4JFHHmHJkiVMnz69ar1vvPEGl19+eRNsDRFpKVpFq6FwP/vnejbsLmjUdQ7p0YGfXjq03uWefPJJOnXqxJEjRzjrrLOYNm0aN998M8uWLaNfv37k5uYCcO+995KSksLatWsByMvLq3fdWVlZvP/++8TExFBQUMA777xDbGwsb775JnfffTcLFy5k7ty5bN++nTVr1hAbG0tubi6pqal84xvfIDs7my5duvDUU09x4403nt4GEZFWpdUFQTQ9/PDDLFq0CIDMzEzmzp3LhRdeWNWMslOnTgC8+eabPP/881WvS01NrXfdM2bMICYmBoD8/Hyuv/56Nm/ejJlRWlpatd5bb72V2NjYau933XXX8ec//5nZs2fzwQcfMG/evEb6xCLSGrS6IGjIkXskvP3227z55pt88MEHJCYmMmHCBEaNGsUnn3zS4HWEt7Y5vvllUlJS1eOf/OQnXHzxxSxatIjt27czYcKEOtc7e/ZsLr30UhISEpgxY0ZVUIiIgK4RNJr8/HxSU1NJTEzkk08+Yfny5RQXF7Ns2TI+++wzgKqqoUmTJvHoo49Wvbayaig9PZ2NGzdSUVFRdWZR23v17Ol79H766aerpk+aNInHH3+86oJy5fv16NGDHj16cN999zF79uzG+9Ai0iooCBrJ5MmTKSsrY/Dgwdx1112cc845dOnShblz53LFFVcwcuRIZs6cCcCPf/xj8vLyGDZsGCNHjmTp0qUA/PKXv2Tq1Kmcd955dO/evdb3+v73v88Pf/hDRo8eXa0V0de+9jUyMjIYMWIEI0eO5Lnnnquad+2119K7d28GDx4coS0gIi2VOeeiXYaTMm7cOLdq1apq0zZu3KgdXD1uv/12Ro8ezU033dQk76e/iUjzYmarnXPjapqnyuIAGDt2LElJSTz44IPRLoqINEMKggBYvXp1tIsgIs2YrhGIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQiiILyXURGRaFMQBJjGNhARaI33EbxyF+xd27jr7DYcpvyy1tl33XUXvXv35rbbbgNgzpw5xMbGsnTpUvLy8igtLeW+++5j2rRp9b5VYWEh06ZNq/F18+bN4ze/+Q1mxogRI3j22WfZt28ft956K9u2bQPgscceo0ePHkydOpV169YB8Jvf/IbCwkLmzJlT1Rneu+++y6xZsxg4cCD33XcfJSUldO7cmfnz55Oenk5hYSF33HEHq1atwsz46U9/Sn5+Ph9//DG///3vAXjiiSfYsGEDv/vd705n64pIlLW+IIiCmTNn8u1vf7sqCF544QVee+01vvnNb9KhQwcOHDjAOeecw2WXXVbveL4JCQksWrTohNdt2LCB++67j/fff5+0tLSqDuW++c1vctFFF7Fo0SLKy8spLCysd3yDkpISKrvpyMvLY/ny5ZgZf/rTn3jggQd48MEHaxwzIS4ujvvvv59f//rXxMXF8dRTT/H444+f7uYTkShrfUFQx5F7pIwePZr9+/eze/dusrOzSU1NpVu3bnznO99h2bJltGnThl27drFv3z66detW57qcc9x9990nvG7JkiXMmDGDtLQ04NhYA0uWLKkaXyAmJoaUlJR6g6Cy8zvwA97MnDmTPXv2UFJSUjV2Qm1jJlxyySW89NJLDB48mNLSUoYPH36SW0tEmpvWFwRRMmPGDBYsWMDevXuZOXMm8+fPJzs7m9WrVxMXF0ffvn1PGGOgJqf6unCxsbFUVFRUPa9rbIM77riDO++8k8suu4y3336bOXPm1Lnur33ta/ziF79g0KBB6tJapJXQxeJGMnPmTJ5//nkWLFjAjBkzyM/Pp2vXrsTFxbF06VJ27NjRoPXU9rpLLrmEv/3tb+Tk5ADHxhqYOHEijz32GODHLM7Pzyc9PZ39+/eTk5PD0aNHeemll+p8v8qxDZ555pmq6bWNmTB+/HgyMzN57rnnmDVrVkM3j4g0YwqCRjJ06FAOHTpEz5496d69O9deey2rVq1i+PDhzJs3j0GDBjVoPbW9bujQofzoRz/ioosuYuTIkdx5550APPTQQyxdupThw4czduxYNmzYQFxcHPfccw9nn302kyZNqvO958yZw4wZMxg7dmxVtRPUPmYCwNVXX83555/foCE2RaT503gEctKmTp3Kd77zHSZOnFjrMvqbiDQvdY1HoDMCabCDBw8ycOBA2rVrV2cIiEjLoovFUbJ27Vquu+66atPatm3LihUrolSi+nXs2JFPP/002sUQkUamIIiS4cOHs2bNmmgXQ0Sk9VQNtbRrHa2Z/hYiLUurCIKEhARycnK0A2oGnHPk5OSQkJAQ7aKISAO1iqqhXr16kZWVRXZ2drSLIvhg7tWrV7SLISINFNEgMLPJwENADPAn59wvj5vfFpgHjAVygJnOue0n+z5xcXFVXSOIiMjJiVjVkJnFAI8CU4AhwCwzG3LcYjcBec65/sDvgF9FqjwiIlKzSF4jOBvY4pzb5pwrAZ4Hju+HeRpQ2a/BAmCi1dc9p4iINKpIBkFPIDPseVZoWo3LOOfKgHygcwTLJCIix2kRF4vN7BbgltDTQjPbdIqrSgMONE6pWjRth2O0LTxtB681b4c+tc2IZBDsAnqHPe8VmlbTMllmFguk4C8aV+OcmwvMPd0Cmdmq2vraCBJth2O0LTxtBy+o2yGSVUMrgQFm1s/M4oFrgBePW+ZF4PrQ46uAJU43A4iINKmInRE458rM7HbgNXzz0Sedc+vN7OfAKufci8D/AM+a2RYgFx8WIiLShCJ6jcA5txhYfNy0e8IeFwMzIlmG45x29VIroe1wjLaFp+3gBXI7tLjxCEREpHG1ir6GRETk1AUmCMxsspltMrMtZnZXtMsTLWa23czWmtkaM1tV/ytaBzN70sz2m9m6sGmdzOwNM9sc+h2IsTdr2RZzzGxX6Huxxsy+FM0yRpqZ9TazpWa2wczWm9m3QtMD+Z0IRBA0sLuLILnYOTcqYM3kngYmHzftLuAt59wA4K3Q8yB4mhO3BcDvQt+LUaHre61ZGfCfzrkhwDnAbaF9QiC/E4EIAhrW3YW0Ys65ZfiWaeHCuzh5BpjelGWKllq2RaA45/Y45z4KPT4EbMT3dBDI70RQgqAh3V0EhQNeN7PVoTu2gyzdObcn9HgvkB7NwjQDt5vZx6Gqo0BUiQCYWV9gNLCCgH4nghIEcswFzrkx+Gqy28zswmgXqDkI3cgY5CZ0jwFnAqOAPcCDUS1NEzGzZGAh8G3nXEH4vCB9J4ISBA3p7iIQnHO7Qr/3A4vw1WZBtc/MugOEfu+Pcnmixjm3zzlX7pyrAJ4gAN8LM4vDh8B859zfQ5MD+Z0IShA0pLuLVs/MksysfeVj4AvAurpf1aqFd3FyPfC/USxLVFXu/EIup5V/L0Ld3f8PsNE599uwWYH8TgTmhrJQc7jfc6y7i/ujW6KmZ2Zn4M8CwN9V/lxQtoOZ/QWYgO9dch/wU+AfwAtABrADuNo51+ovotayLSbgq4UcsB34elhdeatjZhcA7wBrgYrQ5Lvx1wmC950IShCIiEjNglI1JCIitVAQiIgEnIJARCTgFAQiIgGnIBARCTgFgQSamZWH9bi5pjF7pjWzvuE9fDZg+SQzezP0+N3QON4iEacvmgTdEefcqGgXIuRc4INQPz9FzrmyaBdIgkFnBCI1CI3b8EBo7IYPzax/aHpfM1sS6pztLTPLCE1PN7NFZvbv0M95oVXFmNkToT7vXzezdjW815lmtgb4M/BlYDUwMnSG0rVpPrEEmYJAgq7dcVVDM8Pm5TvnhgN/wN+VDvAI8IxzbgQwH3g4NP1h4F/OuZHAGGB9aPoA4FHn3FDgIHDl8QVwzm0NnZWsxvfx8wxwU2hcgED0dSPRpTuLJdDMrNA5l1zD9O3AJc65baHOyfY65zqb2QGgu3OuNDR9j3MuzcyygV7OuaNh6+gLvBEa5AQz+wEQ55y7r5ayrHTOnWVmC4FvOeeyGvvzitREZwQitXO1PD4ZR8Mel1PDdTkz+2PoovKAUBXRZOAlM/vOKb6nyElREIjUbmbY7w9Cj9/H914LcC2+4zLwwxr+B/ihUc0spaFv4py7FfgZcC9+RKyXQ9VCvzut0os0kFoNSdC1Cx2FV3rVOVfZhDTVzD7GH9XPCk27A3jKzL4HZAOzQ9O/Bcw1s5vwR/7/gR/gpaEuAuYB/wf416l8EJFTpWsEIjUIXSMY55w7EO2yiESaqoZERAJOZwQiIgGnMwIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMD9f4ucwt0KXt2bAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('3-OM-test-set.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "7befb306-7704-46be-a33a-bf41a0e3e627"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e35d5c9-a6b6-4893-aa5f-a5fcca5acd47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e35d5c9-a6b6-4893-aa5f-a5fcca5acd47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e35d5c9-a6b6-4893-aa5f-a5fcca5acd47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e35d5c9-a6b6-4893-aa5f-a5fcca5acd47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "11df59ab-3204-4ae5-b717-a5de675422be"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(170,)\n",
            "(170,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "bee97722-3ca2-42c1-8372-0245918ad00a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('3-OM-pred-set.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "6d11441c-63fb-4f58-c430-f8883956fbc5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0,opendeclarationonesigclass1_na...              0\n",
              "4  moduleom_name:0opendeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d546a75c-b14c-4948-946a-fc12298ca253\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d546a75c-b14c-4948-946a-fc12298ca253')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d546a75c-b14c-4948-946a-fc12298ca253 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d546a75c-b14c-4948-946a-fc12298ca253');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "fdd48d71-e146-4746-b343-f6211b233d2a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "dbf8f079-d830-433c-a04f-405d6e1d9dd0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.774194\n",
            "Testing: Recall = 0.750000\n",
            "Testing: F1 Score = 0.761905\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[131   7]\n",
            " [  8  24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "5d72beed-869b-407b-8b80-4182e403bd55"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.95       138\n",
            "           1       0.77      0.75      0.76        32\n",
            "\n",
            "    accuracy                           0.91       170\n",
            "   macro avg       0.86      0.85      0.85       170\n",
            "weighted avg       0.91      0.91      0.91       170\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}