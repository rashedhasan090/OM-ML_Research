{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP EUndersample Distribution  \n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###8 OM - Dataset , Camping,OnlineStore, Decider , Bank, Customer_order, E-Commerce, School Management, Student-Course\n",
        "\n",
        "###1 OM - Testing - Library Management (unseen)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 60% - 40%\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "\n",
        "### Total instances - 652\n",
        "\n",
        "### P samples - 392  P \n",
        "### NP samples - 260 NP \n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 100\n",
        "\n",
        "### P samples - 15\n",
        "### NP samples - 85\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('8-OM-60p-40np.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "f4316580-ce8c-491b-898f-83a00bf79952"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b001c91b-0702-47a3-887b-3df8f272c6e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b001c91b-0702-47a3-887b-3df8f272c6e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b001c91b-0702-47a3-887b-3df8f272c6e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b001c91b-0702-47a3-887b-3df8f272c6e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "#  print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "c73523e4-b419-4bbe-e4cd-2a971831a091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 109, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "50294268-fd90-46ee-965c-5fcd4d391858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "136e4bae-f35e-4ba9-9078-1d1e22596a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 212   3]\n",
            "\n",
            "[  2 214]\n",
            "[214   3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "c471750c-d03c-492c-9e5c-54d779a6d370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "1eda643c-b9a3-4b23-b645-ebbee15d8e69"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "51cb1964-f8f6-47d2-b8f9-2946b52a9ac2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "b2d15beb-45e5-4859-a9ef-d22bb6b52d93"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "d39ad3b1-b206-4041-83f6-e7eb4111b777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 261)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "ff7f71c7-8006-4873-b9a2-bd52426ee723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 261)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "0efea533-6e7d-4eab-b006-7177eab09961"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.5645204, 'expected_acc': 0.0038314176245210726}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "84a2204d-a632-4d28-bda6-0f9ab7197d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 9s 15ms/step - loss: 5.4541 - masked_acc: 0.0214 - masked_loss: 5.4541\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.454081058502197,\n",
              " 'masked_acc': 0.02142857201397419,\n",
              " 'masked_loss': 5.454081058502197}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "0a546082-aea3-42d8-f47f-2da947de9737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.1311 - masked_acc: 0.9650 - masked_loss: 0.1311 - val_loss: 1.4304 - val_masked_acc: 0.8857 - val_masked_loss: 1.4304\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.0636 - masked_acc: 0.9900 - masked_loss: 0.0636 - val_loss: 1.4649 - val_masked_acc: 0.8857 - val_masked_loss: 1.4649\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 6s 63ms/step - loss: 0.0715 - masked_acc: 0.9950 - masked_loss: 0.0715 - val_loss: 1.7473 - val_masked_acc: 0.8571 - val_masked_loss: 1.7473\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.1075 - masked_acc: 0.9800 - masked_loss: 0.1075 - val_loss: 1.5122 - val_masked_acc: 0.8786 - val_masked_loss: 1.5122\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.1325 - masked_acc: 0.9750 - masked_loss: 0.1325 - val_loss: 1.5044 - val_masked_acc: 0.8857 - val_masked_loss: 1.5044\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 6s 55ms/step - loss: 0.0567 - masked_acc: 0.9950 - masked_loss: 0.0567 - val_loss: 1.5870 - val_masked_acc: 0.8786 - val_masked_loss: 1.5870\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 7s 67ms/step - loss: 0.0701 - masked_acc: 0.9900 - masked_loss: 0.0701 - val_loss: 1.6111 - val_masked_acc: 0.8786 - val_masked_loss: 1.6111\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0915 - masked_acc: 0.9850 - masked_loss: 0.0915 - val_loss: 1.2524 - val_masked_acc: 0.9000 - val_masked_loss: 1.2524\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.0187 - masked_acc: 1.0000 - masked_loss: 0.0187 - val_loss: 1.4323 - val_masked_acc: 0.8857 - val_masked_loss: 1.4323\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.0429 - masked_acc: 0.9950 - masked_loss: 0.0429 - val_loss: 1.6976 - val_masked_acc: 0.8714 - val_masked_loss: 1.6976\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 4s 42ms/step - loss: 0.0119 - masked_acc: 1.0000 - masked_loss: 0.0119 - val_loss: 1.0128 - val_masked_acc: 0.9214 - val_masked_loss: 1.0128\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0245 - masked_acc: 0.9950 - masked_loss: 0.0245 - val_loss: 1.2822 - val_masked_acc: 0.9071 - val_masked_loss: 1.2822\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 5s 52ms/step - loss: 0.0687 - masked_acc: 0.9850 - masked_loss: 0.0687 - val_loss: 1.6712 - val_masked_acc: 0.8643 - val_masked_loss: 1.6712\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 0.0220 - masked_acc: 0.9950 - masked_loss: 0.0220 - val_loss: 1.4976 - val_masked_acc: 0.8857 - val_masked_loss: 1.4976\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0052 - masked_acc: 1.0000 - masked_loss: 0.0052 - val_loss: 1.1739 - val_masked_acc: 0.9143 - val_masked_loss: 1.1739\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0392 - masked_acc: 0.9900 - masked_loss: 0.0392 - val_loss: 1.5726 - val_masked_acc: 0.8857 - val_masked_loss: 1.5726\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 6s 61ms/step - loss: 0.0041 - masked_acc: 1.0000 - masked_loss: 0.0041 - val_loss: 1.0734 - val_masked_acc: 0.9214 - val_masked_loss: 1.0734\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.0043 - masked_acc: 1.0000 - masked_loss: 0.0043 - val_loss: 0.8957 - val_masked_acc: 0.9357 - val_masked_loss: 0.8957\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0597 - masked_acc: 0.9850 - masked_loss: 0.0597 - val_loss: 1.6663 - val_masked_acc: 0.8714 - val_masked_loss: 1.6663\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.0209 - masked_acc: 0.9950 - masked_loss: 0.0209 - val_loss: 1.4658 - val_masked_acc: 0.8929 - val_masked_loss: 1.4658\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.0250 - masked_acc: 0.9950 - masked_loss: 0.0250 - val_loss: 1.0925 - val_masked_acc: 0.9214 - val_masked_loss: 1.0925\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0204 - masked_acc: 0.9950 - masked_loss: 0.0204 - val_loss: 0.6982 - val_masked_acc: 0.9500 - val_masked_loss: 0.6982\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0034 - masked_acc: 1.0000 - masked_loss: 0.0034 - val_loss: 1.4847 - val_masked_acc: 0.8929 - val_masked_loss: 1.4847\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 6s 61ms/step - loss: 0.0390 - masked_acc: 0.9900 - masked_loss: 0.0390 - val_loss: 1.5799 - val_masked_acc: 0.8786 - val_masked_loss: 1.5799\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.0165 - masked_acc: 0.9950 - masked_loss: 0.0165 - val_loss: 1.2586 - val_masked_acc: 0.9071 - val_masked_loss: 1.2586\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0196 - masked_acc: 0.9950 - masked_loss: 0.0196 - val_loss: 1.1593 - val_masked_acc: 0.9143 - val_masked_loss: 1.1593\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0040 - masked_acc: 1.0000 - masked_loss: 0.0040 - val_loss: 1.5447 - val_masked_acc: 0.8857 - val_masked_loss: 1.5447\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.0316 - masked_acc: 0.9900 - masked_loss: 0.0316 - val_loss: 1.4476 - val_masked_acc: 0.8929 - val_masked_loss: 1.4476\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0200 - masked_acc: 0.9950 - masked_loss: 0.0200 - val_loss: 1.3620 - val_masked_acc: 0.9000 - val_masked_loss: 1.3620\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0265 - masked_acc: 0.9900 - masked_loss: 0.0265 - val_loss: 1.2065 - val_masked_acc: 0.9071 - val_masked_loss: 1.2065\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "e409e564-8b27-4ac9-984e-52e522fecb45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7f9cfc5760>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABVyUlEQVR4nO3dd3zV9fX48df7Jjd7hwySsAkrhIQQQEARUBQn1FZx1q1o1ba2Vjqs1tpfW7WOb61bVBRXcaFVERkiAjITVtiEkJAdstdN7vn9kXvjJSQ3N8kdCbyfj0ce3Pu5n3E+ueSe+95KRNA0TdO0jhg8HYCmaZrWu+lEoWmaptmlE4WmaZpml04UmqZpml06UWiapml2eXs6AGfq16+fDB482NNhaJqm9Rlbt24tEZEoe/ucVoli8ODBbNmyxdNhaJqm9RlKqaOd7aOrnjRN0zS7dKLQNE3T7NKJQtM0TbNLJwpN0zTNLp0oNE3TNLtc1utJKbUIuBQoEpGx7bz+AHCdTRyjgSgRKVNKZQNVQDPQJCLpropT0zRNs8+VJYo3gDkdvSgiT4hIqoikAr8HvhWRMptdZlpe10lC0zTNg1yWKERkLVDW6Y4trgHedVUsmqZpWvd5vI1CKRVAS8njQ5vNAnytlNqqlLqjk+PvUEptUUptKS4udmWoDjOZTVz04UW8vut1T4eiaZrWYx5PFMBlwPdtqp3OFpE04CLgF0qp6R0dLCIvi0i6iKRHRdkdhe422wq3kVudy7t738UsZk+Ho2ma1iO9IVFcTZtqJxHJs/xbBHwMTPJAXN22KmcVAPk1+Wwq2OThaDRN03rGo4lCKRUKnAt8arMtUCkVbH0MXADs8kyEXScirDq2imlx0wg2BvPJwU88HZKmaVqPuLJ77LvADKCfUioXeBgwAojIi5bdfgJ8LSI1NofGAB8rpazxvSMiX7kqTmfbU7aHgpoCfpH6C+KD4ll2aBlVk6sI9gn2dGiapmnd4rJEISLXOLDPG7R0o7XddhhIcU1UrrcqZxUGZeDchHMZFjqMD/Z/wPLs5fxsxM88HVqvYxYzNaYanUQ1rZfrDW0Up5VVOauYEDOBcL9wxvYby9DQoXx68NPODzwDLdq1iIs/upgmc5OnQ9E0zQ6dKJwopzKHg+UHmTVgFgBKKeYNn0dGcQbZFdmeDa6XERE+Pfgp5Q3lFNYWejocTdPs0InCiay9nWYOnNm67dKhl2JQBj49pEsVtvaf2E92ZTYAeVV5HolBRDxyXU3ra3SicKJVx1YxKmIU8UHxrduiAqKYFjeNZYeW0Wxu9mB0vcvy7OWtj3Orc91+fVOziTkfzmFJ1hK3X7s3+PbYt1Q0VHg6DK2P0InCSUrqSsgoymDWwFmnvDZv+DyKaovYmL/RA5H1PiLCiqMrSI9Jx6AM5Fa5P1FklWVxvOY4z2c8T3Vjtduv70kVDRXcs+oentzypKdD0foInSicZM2xNQjS2j5ha8aAGYT6hupGbQtrtdNFQy4iNiCWvGr3Vz1lFGUAUNlYyVtZb7n9+p6UX5MPwP8O/4+SuhIPR6P1BTpROMmqnFXEB8UzInzEKa/5ePlw8ZCLWZmzUhf3aal2MigD5w86n/jgeM8kiuIM4oPimTlgJm/tfuuMel8KagqAljnJPtj3gYej0foCnSicoMZUw8b8jcwaOAvLQMFTzB0+l0Zz40l182ciEeHro18zMXYiEX4RxAe5P1GICNuLtpMancovUn9BlamKxXsWuzUGT7ImirGRY3l/3/s0NDd4OCKtt9OJwgnW5a3DZDZx3sDzOtxnTMQYEsMTz/jqp/0n9nO08igXDr4QgPigeErqSqhvqndbDMdrjlNSV0JqVCojI0Yye9Bs3t7zNuX15W6LwZPya/IxGozcl3YfZfVlfHH4C0+HpPVyOlE4wcqclYT7hpMaldrhPkop5g6by46SHRwuP+y+4HqZ5dnL8VJerUnV2kPsePVxt8VgbZ9IjU4F4O6Uu6lrquP13WfGtPAFNQXEBMRwVv+zGBE+grey3tJdhTW7dKLoIVOzie9yv2PGgBl4Gbzs7nvJ0EvwUl58cugT9wTXgYqGCr7O/pq/bPgL8z6Zx1fZ7plKq221E8CA4AGAe7vIbi/aToB3AMPDhgMwPHw4c4bM4d2971JaV+q2ODyloKaA2MBYlFJcP/p6Dpw4oHvkaXbpRNFDmws2U22qbrdbbFv9/PtxTsI5fHboM7dOW2Eym9hauJV/b/831/7vWqa/P53ffPsbvjryFfk1+Xx+6HO3xLHvxD6OVh7lgsEXtG6zlijc2U6RWZzJuKhxeBt+nOrsrpS7aGhuYNGuRW6Lw1MKagroH9gfgIuHXkyEX8QZ1UajdZ1OFD206tgq/L39Oav/WQ7tP2/YPErqSlh/fL1L48quyOadrHe4d+W9nP3u2dz01U28uvNVDMrAnePu5K2L3uK7q7/j4qEXs61wm1sGA36d/fVJ1U7Qkjx9vXzdNjq7xlTD/hP7W6udrIaEDuHSoZfy/r73Ka7tHSslukKzuZnC2kJiA2MB8PXy5eqRV7Mub90ZXSWq2acTRQ+YxcyqnFWcHX82ft5+Dh0zPWE64b7hLlunosncxMPrH+ayTy7j75v+zqGKQ1w69FKemfEM3139HW9f/DZ3p95NanQq3gZv0mPSqTJVse/EPpfEYyUiLM9eflK1E7S03cQFxbmtRLGzZCdmMbfbnrRg3AKazE28uvNVt8TiCSV1JTRLc2uiALhq5FX4GHx4O+ttD0bWM03mpjOmM4In6ETRA7tKdlFcV8zMATM739nC6GXkkqGXsObYGqf/x25sbuSBbx/gowMfcVPSTXzxky/44ooveGjKQ5w36DxCfEJOOSY9Jh2ALQVbnBpLW/tO7COnKuekaier+KB4t7VRbC/ajkIxLmrcKa8NCBnA3OFz+e/+/7Z2IXWVqsYq9p/Y79JrtKegtuW+bBNFpH8klw67lM8OfdYnP2xrTbXc/NXNXLHsCj0TsYvoRNEDq3JW4a28mZ7Q4ZLe7Zo3fB4ms4kvs790Wiy1plruWXkP3+R8w4MTH+Q36b9hQMiATo+LCYxhQPAAthS6NlG07e1kKz4o3m1VT5lFmQwPH97hGhh3jLsDQXhlxysujePFzBe5/ovrMTWbXHqdtqyjsm0TBcD1o6+nvrme/+7/r1vj6SlTs4n719xPRnEGxXXF7CrpM4th9ik6UfTAqmOrSI9NJ9Q3tEvHjYwYyaiIUU6rfqpoqOD2FbfzQ8EP/HXaX7l+zPVdOj49Jp1tRdswi9kp8bQlInyd/fUp1U5WCUEJVJmqXD462ixmMosz7XZjjg+K54rhV/DRwY9cWh22rXAbdU11HKk84rJrtKewpmVKd2tjtlVieCJT+k/h3b3vuj15dVezuZnfr/s93x//nt+m/xaDMri87e9MpRNFNx2uOMyRiiMO9XZqz9xhc9lTuqfH1Q8ldSXcvPxmskqzeOrcp5g3fF6XzzExdiIVDRUcOHGgR7F0xFrtZB1k11Z8sHt6Ph0qP0S1qfqUhuy2bh93OwrFyztedkkc9U317C3bC+D26qf8mnwCjYHtlqhuGHMDxXXFbusu3RMiwmM/PMby7OX8Nv233Jh0I2P7jeX74997LJ7TmU4U3dS69kQX2idsXTL0ErwN3j0aqZ1blcvPv/w5uVW5/Oe8/3DeoI5HhtvT2k7houone9VO4L4ustuLtgMwPmq83f1iA2O5csSVfHrwU45VHnN6HHtK99AkLXXprkrOHbHtGtvWtPhpDAkdwlt7ev8AvGe3PcvS/Uu5Pfl2bky6EYBpcdPYVbLL7fN2VTdWM/ODmS77YtEb6ETRTatzVpMUmXRKXa+jwv3COTfhXD4//Dkmc9eL+ofKD3HjlzdS0VDBqxe8ypS4Kd2KA6B/UH/ig+Jd0qBtrXaaFDuJcL/wdvdJCE4AXL+AUWZxJhF+Ea3Xs+e25NvwNnjz4o4XXRIHQExAjNtLFAU1BcQExrT7mkEZuH709WSVZbG1cKtb4+qKRbsW8dqu17hqxFXcO/7e1u1T46ZiFjM/5P/g1ngyijMorS/l39v/fdpOsqgTRTcU1Raxo2SH3bmdHDFv+DzK6stYl7uuS8ftKtnFTV/dhCC8MeeNdnvwdNWEmAlsLdzq9G+Se8v2dtjbySrEJ4Rgn2CX93zKKMogNSq1w4kbbUUFRDF/5Hw+P/w5Ryqc246QWZzJgOABpMemu71EkV+T32GJAuCyYZcR6hvKW3t659TrS/cv5emtT3PR4Iv4w+Q/nPReju03lmBjsNvbKbYXbcdLeTEtbhqPbXyMr7O/duv13cFliUIptUgpVaSUarcbglJqhlKqQimVYfn5s81rc5RS+5RSB5VSC10VY3etzlkN0O32Catp8dOI8Itg6YGllNWXOTTobXPBZm5dfiuBxkDenPMmieGJPYrBKj0mnRMNJzhUfsgp57P6+uipg+zakxCU4NKqp9K6UnKqcjptn7B1y9hb8PXy5YXMF5wWh4iQWZxJSlQKI8JHUFhb6LaqkobmBsrqy4gN6LgU7O/tz1UjrmL1sdUuqXbrieXZy3l0w6OcHX82fzv7b6dMmeNt8GZy/8msP77erVVnGUUZjAgfwdMznyYlKoWF3y10e6nG1VxZongDmNPJPt+JSKrl51EApZQX8B/gImAMcI1SaowL4+yyVcdWMShkEENDh/boPEaDkcuHXc7a3LWc+/65pL2dxoz3Z3DFsiu4/evbeXDtgzy++XFe3fkqHx/4mHf3vsuCFQuIC4pj8UWLHer+6qj0WOe3U1gH2dmrdrJy9XTjGcUZAIyPtt8+YSvSP5JrRl3DV0e+4uCJg06JI78mn5K6ElKiUkgMa0ny7ipVWHs8dVZdevWoq/EyeLFkb+9ZJnZ93noWfreQ1OhUnprxFEYvY7v7TY2fSn5Nvtt6k5nMJnaW7GR89Hj8vf157rznGBQyiPtW3cee0j1uicEdXJYoRGQtUNaNQycBB0XksIg0Au8Bc50aXA9UNlayKX8TswZ0vPZEV9yVchdPnvskCyct5Lbk25gxYAYJQQnUNtWyo3gHS/cv5dltz/Ln9X/m//3w/xgZMZLXL3yd6IBoJ9zNjxKCEogNjGVzwWannXNv2V6OVR2zW+1kFR8Uz/Hq4y7roptZlInRYGR05OguHXdz0s0EGAN4PvN558RhaZ8YFzWudZGrA+XuSRTWQYT2qp4AogOimTN4Dh8f+JjKxkp3hGZXRlEGv1rzK4aFDuO5857D39u/w32nxk0FYMPxDW6Jbf+J/dQ11bV+AQn1DeXF818k1DeUu765i6OVR90Sh6t5d76LS01RSmUCx4HfishuIB6wLfPmApM7OoFS6g7gDoCBAwe6MNQW63LX0SRNPa52sgowBnTYbdSq1lRLWX0ZFY0VJIYl4uPl45Rr21JKkR6T3lpsd0YS7Ky3k6344HgamhsoqStxehKElhLFmMgx+Hr5dum4ML8w5o+cz+u7XudE/YlOS0adySzOxN/bnxHhI/BSXoT4hLitQbujwXbtuWHMDXx++HM+2v8RN429ycWRdWxf2T7uXnk3Uf5RvDj7xXZnF7AVHxTP4JDBfJ/3PdeNvs7l8bWdsh5aBrG+NPslbvzyRu5c0TKvWlRAlMtjcSVPNmZvAwaJSArwb+CT7pxERF4WkXQRSY+Kcv2bsTJnJZF+kU5pQHZUgDGAhOAEkiKTXJIkrNJj0imrL3NKsd06pbgj1U7g2i6yjc2N7C7ZbXegnT2zBs5CEKfUO2cWZZIUmYS3wRulFCPCR7it6slaouio15OtMZFjmBAzgXf2vuOxaTFMzSbuXnk3/t7+vHzBy/Tz7+fQcVPiprClcAuNzY0ujrClITs2MPaU5DskdAjPn/88ZfVlLPhmQa8omfWExxKFiFSKSLXl8ReAUSnVD8gDbCvfEyzbPK6huYF1eeuYOXAmBnX6dRhrbadwQjfZrLIsjlUd67S0ZJUQ1NJlNbfK+T2f9pTuodHc2KX2CVtJkUkE+/S8N411oF1KVErrtsTwRA6WH3RZlZutgtoCIvwiHC5V3TDmBvJr8vkm5xsXR9a+4zXHKaot4p7Ue1q/SDhiWtw06prqWsfNuIp1Sd2OxuWM7TeWZ2Y+w+GKw9y78l63ruLobB77tFNKxSpL/YZSapIlllJgM5ColBqilPIBrgaWeSpOK1Oziff2vkdtUy2zBjin2qm3GRg8kCj/KKc0aFunFHe0ii4uKA5wTYnC2i6QEp3SyZ7t8zZ4c1b/s3rcm8Y60K5toqgx1bhlhb/8mvwujfuZkdDSXvb2Hs/MKmstAXUlSUDLTAPeBm+Xj9LOr8mnqLbIbk+6qXFT+fvZf2d70XZ+t/Z3fXbSQld2j30X2ACMVErlKqVuVUotUEotsOzyM2CXpY3i/4CrpUUTcA+wHMgCPrC0XXjEofJDPLH5Cc7773k8ueVJhocNZ3L/DptM+jSlFOmx6Wwp2NKjD8Su9Hay8vP2I8o/yiWJIqMog4SgBIerLtozJW4KhbWFPRpTYduQbdXaoO2G6qfCmsJOG7JteRm8uCLxCjKLMymr706/lJ6xJoquDmoNMAYwPnq8yxu0W0f6d1JSnTNkDgsnLWT1sdU8uuHRXj/qvT0ua8wWkWs6ef054LkOXvsC8NiK77WmWpZnL+ejAx+RUZyBt/JmxoAZXJF4BVPjpna65Glflh6TzpdHviSnKodBIYO6dY6ssixyq3O5Lfm2Lh3nii6yIkJGcYbDC0t1ZEr/lpHv64+vZ2hY97pFZxZnkhCUQKR/ZOs263Ks+0/sZ+bA7k0H46j8mvwuf8mxVkduL9ze7SliuquwtqU7ryNtKm1NjZvKs9uepaSupEdfEOzJKMogwDvAobFM146+lrL6Ml7a8RLhfuH8Ku1XTukw4i6nX0V7N4kIO4t38sj6R5j5wUz+vP7PlDeU85sJv2HFlSt4eubTnJNwzmmdJMA57RTW3k5d7RkWH+z86cbzqvMoqSvpdvuEVUJwAoNCBnW7naJ1oF2b6q9AYyAJQQku7yJb1VhFjammSyUKaGmf8TH4sLXI/VN6FNQUEO4b3uWeauCebrIZxRmnLKlrzy9Sf8FVI65i0a5FPL3t6T5VsvB091iPa2huYOn+pXx44EMOnDiAn5cfFw6+kCsSr2B89Pg+lfWdYUjIECL9ItlSuIWfjvhpl483i5mvs79mcv/JXe5KGh8Uz5dHvsRkNmE0tD+gqqus1QO27QLdNaX/FD499CmNzY1d7n1mO9CurcTwRJdXPXWlx5MtHy8fxvYby/ZC1zYMt6egpqDbc6mNihhFhF8E64+v57Jhlzk5sh+X1L1j3B0OH6OU4o9n/RGlFK/vep3G5kYenPhgn/iMOeNLFAZl4JUdr+Bj8OGhsx5i1VWreOzsx0iLSesTb6CzKaWYEDOBLYXda6dYnbOa3Orcbv1xJgQlYBazU1eXyyzOJNAY2FrF0xNT46ZS11TX2ne+q3FA+wkrMTyRo5VHaWhu6GmIHWodQ2Fn+o6OTIiZQFZZFrWmWmeHZVdBbccTGHbGoAyc1f8sNhzf4JIeZZnFmZjF3OlMxO3F9cfJf+SGMTewJGsJj2581C093nrqjE8URoORj+Z+xHuXvsdVI6/qcOWzM0l6bDoFNQVdnqRPRHhxx4sMDB7InMGdzd5yKleMpcgoymBcv3FOqTKcGDsRb+Xdreon24F2bY0IH0GzNHO4/HCPY+yIo6Oy25MWk0azNLcmO3cpqCnoVmKzmhY/jdL6UpcMaMwoysCgDN0aT6WU4oH0B7g9+XaW7l/KQ98/5NA8b550xicKoN1V185kE2MmAl1vp/g291v2lu3l9nG3O1xva8u6gJGzxlJUN1ZzoPxAj9snrIJ8ghgXNa57icJmoF1b1sZQV47QLqgpwFt5d6thNzUqFYMyuHxcgq1aUy1VjVXdrnqCHzsgfJ/n/G6y24u2kxiWSJBPULeOV0pxX9p93JN6D8sOLWPhdwu7tdyAu+hEoZ1iWNgwwn3DuzSeQkR4MfNF4oPiuWToJd26bkxADF7Ky2klih0lOzCLudvjJ9ozNW4qWWVZXeou2t5AO1sDgwfi6+Xr0naKgpoCogOiu1WyCvIJYkT4CLYVbnNBZO0rqO1em4qtqIAoRoSPcHqDdrO5mR3FO7o0E3FH7ky5k/sn3M9X2V/x2zW/dcto8u7QiUI7hbWdoiuL16zLW8fu0t3cnnx7txuivQ3exAbGOq3nU2ZRJgrFuH7Om27F2ptm4/GNDh9jHWjXUTWFt8GboaFDXVqi6Opgu7bSotPYUbLDbd96W8dQ9KDqCVrer21F25zavnKg/AC1TbVOK6nePPZmFk5ayKpjq/jl6l/2yhHcOlFo7UqPTSevOs+hEcPW0kT/wP5cPuzyHl03Idh561JkFGeQGN796oH2jIkcQ4hPSJeqn3YU7wDs97xKDE90aRfZnvQggpZ2irqmOrJKs5wYVcccnRK9M1PjpmIym5w6fb61Cs4ZJQqr60Zfx8NTHub7vO+5Z9U9bu840BmdKLR2dWUd7Q35G9hRsoPbkm/rcJ0ARyUEJThlpTtr9YCzvvVZeRm8WnvTONorrL2Bdm2NCB9BSV2JS0ZAm8VMYW1hj0sUgNvaKQpqClAoYgK6X/UELQnOz8vPqavebS/aTrR/NHGBcU47J8DPRvyMv539NzYXbOaub+6iurHaqefvCZ0otHYlhicS4hPSaYO2tTQRHRDNvOHzenzd+KB4yurLevyN6mD5QapN1U4ZP9HW1LipFNUVObQaYEcD7dqyNmi7op2irL4Mk9nUo0QRFRDFgOABbltLu6C2gEj/yB5/8fD18mVC7ASnJoqMogxSox1bUrerLht2Gf+c/k8yizO5c8WdvWbWWZ0otHYZlKF1PIU9mws2s71oO7eOvdUpU6Bbu8j2dJI8a1dOZ1YPWE2J+3E6j87k1+RTXFfcacJy5ZxPPekaaystOo3tRdvd0u+/sKawx6UJq6n9p3Kk4gj51fk9PldBTQH5NflOL6namjN4Dk/NeIo9pXt4euvTLrtOV+hEoXUoPSadY1XHWuuL2/PSjpeI8o/q1iju9li7yPa0nSKjKINIv8jW6cudKS4ojsEhg1mf33misDfQzlY//35E+EW4pEG7KwsW2TMhZgLlDeVkV2Q7ISr7etqmYmta/DQAp8wm250ldbtj1sBZXD3qaj468BH7yva59FqO0IlC61Bn62hvLdzKpoJN3Dz25m7Nx9Mea4mip+0UGcUZLp2CZVr8NLYWbO10NHVmcSZ+Xn7tDrRry1VTeTirRGH9cHTHvE8Ftc5LFENDhxITEOOU6qeMooyWgZMRnb+fPbUgZQHBPsE8vvlxj88LpROF1qGR4SMJNgZ3uI72S5kvEeEXwc9G/Mxp14z0i8Tf279HJYqSuhKOVR1zSbWT1dS4qdQ313fauJtZlElSv/YH2rWVGJbIoYpDTh+lW1BTgL+3f6fLiHZmUMggIvwiXD6ewjqBYU+7xloppZgaN5WN+Rt7vB7E9qLtjO031mlzkdkT6hvK3Sl3s6lgE6uPrXb59ezRiULrkJfBi/Ex49ttwMwoymBD/gZuTrrZ7mL3XaWUIi4wrkejszOLHKvu6Yn0mHS8Dfan8+hsoF1bI8JHUNdU55ReX7bya/KJCYjpcenKOr7G1Ymiu+tQ2DM1fipVjVXsLu3+0ja1plr2le3r9pK63XHlyCsZGjqUf235F6Zmz43c1olCsys9Jp3symyKa4tP2v7SjpcI9w3nqpFXOf2a8cE9W5ciozgDH4MPYyLHODGqkzmyOE5WWdYpK9rZ46oG7a4uWGRPWnQax2uOO3Xixras61A4M1GcFXsWCsX6vO5XP+0s2UmzNLu8fcKW0WDkgYkPkFOVwzt733HbddvSiUKza2Jsy7xPtqWKXSW7WJe3jp8n/ZwAY4DTr2ldwKi79bIZRRkk9UtySi8se6bGTWVv2V5K6krafb2rJZuhYUNRKKc3aPd0VLat8TEtH5KuLFW0TonupF5PAGF+YYztN7ZH7RTbi7ajUE6dEsYRZ8efzdnxZ/NS5kseWWkQdKLQOjEqYhSBxsCTGrRfynyJUN9QrhlldxHDbksISqDGVENFQ0WXj21obmB36W63VA9Yu8luzG9/Og9HBtrZ8vf2Z1DIIKeWKEzNJkrqSpxWohgZPpIA7wC2Fbk2URiUgaiAKKeed0rcFHaW7Oz22ISM4gyGhQ3rcVtPdzyQ/gC1TbU8n/G8268NOlFonfA2eJMandraoJ1VmsWa3DXcMPoGAo2BLrlmT7rIZpVmYTKb3PKtb3TEaMJ8w9qtfnJ0oF1bzp7Ko6iuCEGcVqKw/n9wdaLo59+vWzMQ2zMtbhrN0sym/E1dPtYsZnYUOX+kv6OGhg3lqpFX8d/9/3XL+upt6UShdSo9Jp3DFYcprSvlpR0vEWwM5trR17rsetaxD91p1LV+gLmyIdvKoAxM6T+F9cfXn1JN5uhAu7YSwxLJqcxx2lw/1kFmzqzvT4tO4+CJg90q8TnCmV1jbSVHJRNoDOzWeIqD5QepMlW5tCddZ+5OuZtAYyBPbH7C7d1lXZYolFKLlFJFSqldHbx+nVJqh1Jqp1JqvVIqxea1bMv2DKWU82bz0rrFOu/Tu3vfZWXOSq4fc71LF3jqyQJGq3NWMzJ8ZLfWXeiOKXFTKKkrOaUUYB1o19WFbUaEj0AQDlc4ZxEj63TdTk0UMWkI0q2V/hxRWFPotK6xtowGI5NjJ7M+79TE3hnrvXZ1RTtnCvML4+6Uu9mQv4Hv8r5z67VdWaJ4A7C3zNkR4FwRSQb+Crzc5vWZIpIqIukuik9zUFK/JPy9/Xll5ysEGgO5bvR1Lr1ekE8Qob6hXZ5uvLCmkIziDC4YfIGLIjuVtZ2ibfVTVwba2XL2Ikau6Gqa3C8Zb4O3SwbeiQiFtYU9WofCnqlxUzlec5yjlUe7dNz2ou0tI/2DnT/Svyvmj5rP4JDBPLH5CbcudOSyRCEia4EOm+hFZL2InLA83Qh49h3QOmQ0GEmNSsUsZq4ddS2hvqEuv6a151NXfJPzDQCzB812RUjtig2MZVjosFN60+wo3kFSv6QuD8xKCE7A39vfafXQBTUFhPmGOXWsi5+3H0mRSWwvdP5MspWNldQ11bmkRAEt4ykA3tj9RpdKFduLtrt0pL+jrN1lsyuzeX/v+267bm9po7gV+NLmuQBfK6W2KqXu8FBMmo1zB5xLuG84N4y5wS3X606iWHF0BcPDhjMkdIiLomrflLgpbC3c2rrgTENzA1llWd1qJzEoA8PDhjstUTiza6yttOg0dpXucvoiO64oAdkaEDyAm8fezIcHPuS1Xa85dExxbTF51XkebZ+wdU78OUzpP4XnM5+nvL7cLdf0eKJQSs2kJVE8aLP5bBFJAy4CfqGUmm7n+DuUUluUUluKi4s72k3roWtHXcs3V35DuF+4W66XENSygJGjM5UW1xazrXCbW6udrKbGTaWhuaG1IX1P6R6azI4PtGsrMTyR/Sf2O6XB0pmT69lKi0mjydzEzpKdTj2vqxMFwK/SfsUlQy/h2W3P8unBTzvd310TATpKKcUDEx+gxlTD85nu6S7r0UShlBoHvArMFZFS63YRybP8WwR8DEzq6Bwi8rKIpItIelSUc/tdaz9SSrl8AJut+KB4TGYTRbVFDu2/MmclgnDBIPcnigkxEzAajK3tFD2dQmRE+AhONJygtL608507UVBT4JJqHOuHprMXMnJHojAoA3+d+lcm95/MI+sf4fs8+72gthdtx9fLl9ERo10WU1clhidy5Ygr+WDfBxwud07HB3s8liiUUgOBj4AbRGS/zfZApVSw9TFwAdBuzynt9GVtNHS0+mnF0RUMDR3KsLBhrgyrXQHGANKi01rbKbo60K6txDBLg3ZZzxq0a021VDZWuuRDN9Q3lOFhw50+QruwthBv5U2kX/d+d44yehl5ZsYzDA8fzq/X/NruHFAZRRkkRSb1eBElZ7s79W4CvAN4YssTLr+WK7vHvgtsAEYqpXKVUrcqpRYopRZYdvkzEAk836YbbAywTimVCWwC/iciX7kqTq136koX2dK6UrYUbnFrI3ZbU+KmsP/Efopri8kszuxyt1hbravd9XDgnbOmF+9IWnQaGcUZTp3ttqCmgKiAKLwMXk47Z0eCfIJ4/rznCfcN5+5v7uZY1bFT9rGuE95bqp1sRfhFcGfKnazLW8d3ua7tLuvKXk/XiEh/ETGKSIKIvCYiL4rIi5bXbxORcEsX2NZusCJyWERSLD9JIvI3V8Wo9V5xQXEolENdZFcdW4VZzB5NFFPjWnrTfHTgo24NtLMV7hdOlH9Uj7vIOmvBoo6kxaRRY6ph3wnnLazjqsF2HYkKiOKF2S/QLM3c9c1dp8yltKtkF03S1CsTBbS0HQ4MHsiTW550aXdZjzdma1p7fLx8iAqIcmh09orsFQwKGdTlMQvONDJiJBF+ESzesxigx1OIOGMRI1eXKCbETACc207hqjYVe4aGDuW5Wc9RUFPAPSvvOWlUvCuX1HUGo5eRByc9yNzhc1v6irqIThRar2Xt+WTPifoTbCrYxAWDLvBoH3eDMnBW/7OobKzs1kC7tkaEj+BQ+aEeLbRTUOuayfWsYgNjiQuMa3e9ku4QkZZR2W4sUVilRqfyz+n/ZHfpbn639netv/ftRdsZGjrULWOHumt6wnRuGXuLS9tQdKLQei1HxlKsPraaZmn2aLWTlbX6qTsD7dpKDE+k0dxITmVOt8+RX53vksn1bI2PGc+2wm1O6cpbVl9Go7nRZaOyO3PewPP44+Q/8m3utzy28THMYiajKKPXlibcSScKrdeKD46nsKbQ7speXx/9moSgBEZFjHJjZO2bEjcFhXJKfba1RLK/vPvtFAW1BS6rdrJKi06jtL6UnKruJzSr1gWL3Fz1ZOuqkVdxx7g7+PDAh/xh3R+obKx064p2vZVOFFqvFR8UjyCtjbJtVTRU8MPxH5g9eLbHp1YAiA6I5rULX+OmpJt6fK6hoUPxUl496iLrqsF2tqztFM7oJuuOMRSOuCf1HuYOm8v/Dv8P6D0D7TxJJwqt17J2ke2oQXvNsTU0SZNHBtl1ZGLsRKfUZ/t4+TA4ZHC3u8iKCAU1ri9RDAkdQqhvqFPWp2hd2c5DVU9WSikenvow58SfQ1xgHINCBnk0nt7AdZWXmtZDA4IHAJBb1X6iWHF0BXGBcSRFJrkzLLdJDE/s9hQZJxpO0NDc4PJv5wZlYHz0eOeUKGoLMBqMRPhFOCGynjEajDx33nPUN9X3itKqp+kShdZrRflH4W3wbrdBu6qxivXH1zN7UO+odnKFxPBE8qrzqDHVdPlYd1bjTIieQE5VTodrhzuqoKaAmIAYDKp3fCwZlMEla8L3Rb3jHdG0dngZvIgLjGs3Uaw5tgaT2cTswZ7v7eQq1gbt7oyncGeiSItJA3reTlFY47p1KLSe0YlC69Xig+LbHZ294ugKYgJiSO6X7IGo3KMnixi1jsp2Qw+i0RGj8fPy63E7RWGtZ8ZQaJ3TiULr1eKDTx1LUWOq4fu875k9aHavqaZwhbjAOAKNgd0qURTWFOJj8HFLfb/Ry8i4qHE9KlGYxdySKDzYNVbr2On7V6adFuKD4jnRcOKkaRXW5q6l0dzYKwbZuZJSisSwxG71fLIuWOSu9pu0mDT2ndhHdWN1t44vrSulydykSxS9lE4UWq+WENQy3bhtF9kVR1cQ5R91RoyY7e4iRu7oGmsrLToNs5hb50bqqt4yhkJrn04UWq/WOt24pZ2i1lTLd7nfcf6g80/raierEeEjqGqsah217KiC2gK3NgynRKVgUIZut1MU1FrGUAToxuze6PT/S9P6tPjgk9el+C7vO+qb60/7aier7jRoN5mbKKotcuu38wBjACPDR3a7RFFYY5m+Q5coeiWHB9wppaYCg22PEZHFLohJ01qF+4YT4B3QmihWHF1BhF8EadFpHo7MPRLDE1EothRsYXpCh0vHn6SkrgSzmN1a9QQwLmocnx36jGZzc5cXHiqoKcDXy5cw3zDXBKf1iEMlCqXUW8CTwNnARMtPugvj0jSgpUE3Pjie3Kpc6prqWJu7lvMHnu+WFdB6gxCfEGYPms0H+z+goqHCoWNcvWBRR1KjU6ltquVg+cEuH2tdsOh0HTzZ1zla9ZQOTBORu0XkXsvPfa4MTNOs4oPiya3OZX3eeuqa6k7rQXbtWZCygBpTTeuiSJ1x9YJFHbGu6ted6idPLFikOc7RRLEL0O+i5hHWBYyWH11OuG846TFnVmE2MTyR2YNmsyRriUOlCk+VKBKCEoj0iySjKKPLxxbUuLfxXesaRxNFP2CPUmq5UmqZ9ceVgWmaVXxQPHVNdaw8upJZA2e5dCGe3spaqnhrz1ud7ltQU0CwTzCBxkA3RPYjpRQpUSldLlE0mZsorivWPZ56MUf/4h5xZRCaZo+1i2yjubFXTSnuTiPCR7SWKm4Yc4PdqczdsQ5FR1KjU1l1bBWldaVE+kc6dIy18V33eOq9HCpRiMi3QDZgtDzeDHTaYVoptUgpVaSU2tXB60op9X9KqYNKqR1KqTSb125USh2w/Nzo0N1opyVrF9kQnxAm9p/o4Wg8585xd1Jtqu60VOHJ+n5rO8WO4h0OH6MH2/V+jvZ6uh1YCrxk2RQPfOLAoW8Ac+y8fhGQaPm5A3jBcr0I4GFgMjAJeFgpFe5IrNrpxzo6e+aAmT1ei7ovGxkx0qG2CnePyrY1JnIM3gZvMoozHD7GOthOJ4rey9E2il8A04BKABE5AER3dpCIrAXK7OwyF1gsLTYCYUqp/sCFwAoRKRORE8AK7Ccc7TQWYAzgX+f+i3vH3+vpUDzOWqp4O+vtdl+va6rjRMMJj33o+nn7MTpidJfaKfRgu97P0UTRICKN1idKKW+ga5PPtC8eOGbzPNeyraPtp1BK3aGU2qKU2lJcXOyEkLTe6ILBF+heMbSUKs4feD5L9iyhsrHylNd7w4duSlQKu0t2YzKbHNq/oKYAf29/go3BLo5M6y5HE8W3Sqk/AP5KqdnAf4HPXBeW40TkZRFJF5H0qKgoT4ejaS63IGUBVaYq3t5zaqmiN1TjpESnUN9cz/4yx6Ydsa5DoQfb9V6OJoqFQDGwE7gT+EJE/uiE6+cBA2yeJ1i2dbRd0854IyNGct7A83h7z9unlCryqz0zhsJWalQqgMPtFHqwXe/naKJ4REReEZErReRnwCKl1BInXH8Z8HNL76ezgAoRyQeWAxcopcItjdgXWLZpmsaPpYole07+MyyoLUChPDomITYwlpiAGDKLHGun8GR3Xs0xjiaKAUqp3wMopXyAD4FOV1NRSr0LbABGKqVylVK3KqUWKKUWWHb5AjgMHAReAe4GEJEy4K+0dMPdDDxq2aZpGjAqYhSzBszirT1vnVSqKKgpINI/Eh8vHw9G1zKewpEShanZREldiU4UvZyjA+5uAZZYksVM4EsRebqzg0Tkmk5eF1p6VLX32iJgkYPxadoZZ0HKAlYdW8WSrCXclXIX4NmusbZSolJYnr2cwppCu50QiuqKEESPyu7l7JYolFJplkFw44Fngfm0lCS+tR0cp2ma+42OHM3MATN5a89bVDVWAT8ugeppjk4QqAfb9Q2dVT39y+bnH8AJYIzl+ZOuDU3TtM7clXIXVY1VLMlagoi0TK7XC76dj44YjY/Bp9NE0Ru682qds1v1JCIz3RWIpmldZy1VLN6zmMuGXUZdU12vqHoyehlJ6pfUaTtFb+jOq3XO0Sk8QpVST1kHtiml/qWU6nhWMk3T3GZBygKqGqv415Z/Ab3nQzc1KpWs0iwamhs63KegpoBgo/tnutW6xtFeT4uAKuAqy08l8LqrgtI0zXFjIscwY8AMVhxdAbh/waKOpESlYDKbyCrN6nAfvQ5F3+BoohgmIg+LyGHLz1+Aoa4MTNM0xy1IWdD6uLeUKFKiO2/Q1omib3A0UdQppc62PlFKTQPqXBOSpmldlRSZxIyEGfh5+Tm8DoSr9fPvR3xQvN0V7wprC/Wo7D7A0XEUC4DFNu0SJwC9RoSm9SJ/nfZXsiuzMShHv/+5Xmp0Kj/k/4CInDKXU0NzA2X1Zb2mBKR1zNH/UZUikgKMA8aJyHha2iw0TeslwvzCSI1O9XQYJ0mJSqGkroTjNcdPea2opgjoPVVlWsccTRQfAohIpYhY5wtY6pqQNE07XVgnCGxv3ifdNbbvsFv1pJQaBSQBoUqpK2xeCgH8XBmYpml9X2J4Iv7e/mQUZ3Dx0ItPes06Krs3DBDU7OusjWIkcCkQBlxms70KuN1FMWmadprwNniT3C+53Z5PevqOvqOzRBEA/BZ4WUQ2uCEeTdNOMylRKSzatYhaUy0BxoDW7YW1hYT6huLv7e/B6DRHdNZGMZCW1eweV0o9opSarPQyVJqmdUFqdCrN0szu0t0nbdcLFvUddhOFiPxTRGYBFwOZtEw3vk0p9Y5S6udKKV25qGmaXeP6jQNOHXinFyzqOxzq9SQiVSLysYjcaeka+xgQBSx2aXSapvV5YX5hDA4ZfErPp4La3jHTrda5ztajuN7m8TTrYxHZAzSIyIUujE3TtNNESlQKmcWZtKxVBnVNdVQ0VOgSRR/RWYnifpvH/27z2i1OjkXTtNNUanQqJxpOkFOVA+geT31NZ4lCdfC4veeapmntsq54Z533qbBWL1jUl3SWKKSDx+091zRNa9ewsGEEGYNaG7RbSxS611Of0Nk4ilFKqR20lB6GWR5jea6nGdc0zSEGZWBc1LjWFe+siSI6MNqDUWmO6ixRpAAxwLE22wcABZ2dXCk1B3gW8AJeFZF/tHn9acC63GoAEC0iYZbXmoGdltdyROTyzq6naVrvlRqVyguZL1DdWE1BTQERfhH4evl6OizNAZ0liqeB34vIUduNSqkQy2uXtXtUyz5ewH+A2UAusFkptczSYwoAEfm1zf73AuNtTlEnIqkO3oemab1cSlQKgrCjZIfuGtvHdNZGESMiO9tutGwb3Mmxk4CDlhXxGoH3gLl29r8GeLeTc2qa1kclRyWjUGQWZ1JYU6gbsvuQzhJFmJ3XOpugJZ6Tq6xyLdtOoZQaBAwBVtls9lNKbVFKbVRKzevoIkqpOyz7bSkuLu4kJE3TPCXYJ5hhYcPILNKJoq/pLFFsUUqdMkusUuo2YKsT47gaWCoizTbbBolIOnAt8IxSalh7B4rIyyKSLiLpUVFRTgxJ0zRnS4lKYVvRNqpMVTpR9CGdtVH8CvhYKXUdPyaGdMAH+Eknx+bR0uhtlWDZ1p6rgV/YbhCRPMu/h5VSa2hpvzjUyTU1TevFUqNT+fDAh4Beh6IvsZsoRKQQmKqUmgmMtWz+n4issnOY1WYgUSk1hJYEcTUtpYOTWBZHCgc22GwLB2pFpEEp1Q+YBjzuwDU1TevFrAPvQA+260s6K1EAICKrgdVdObGINCml7gGW09I9dpGI7FZKPQpsEZFlll2vBt4T6yQwLUYDLymlzLRUj/3DtreUpml90+CQwYT6hup5nvoYhxJFd4nIF8AXbbb9uc3zR9o5bj2Q7MrYNE1zP6UUKVEpfJf7HdEBerBdX+HSRKFpmtbW/JHzGRg8EKPB6OlQNAfpRKFpmltNT5jO9ITpng5D6wKHFi7SNE3Tzlw6UWiapml26UShaZqm2aUThaZpmmaXThSapmmaXTpRaJqmaXbpRKFpmqbZpROFpmmaZpdOFJqmaZpdOlFomqZpdulEoWmaptmlE4WmaZpml04UmqZpml06UWiapml26UShaZqm2aUThaZpmmaXThSapmmaXTpRaJqmaXa5NFEopeYopfYppQ4qpRa28/pNSqlipVSG5ec2m9duVEodsPzc6Mo4NU3TtI65bM1spZQX8B9gNpALbFZKLRORPW12fV9E7mlzbATwMJAOCLDVcuwJV8WraZqmtc+VJYpJwEEROSwijcB7wFwHj70QWCEiZZbksAKY46I4NU3TNDtcmSjigWM2z3Mt29r6qVJqh1JqqVJqQBeP1TRN01zM043ZnwGDRWQcLaWGN7t6AqXUHUqpLUqpLcXFxU4PUNM07UznykSRBwyweZ5g2dZKREpFpMHy9FVggqPH2pzjZRFJF5H0qKgopwSuaZqm/ciViWIzkKiUGqKU8gGuBpbZ7qCU6m/z9HIgy/J4OXCBUipcKRUOXGDZpmmaprmZy3o9iUiTUuoeWj7gvYBFIrJbKfUosEVElgH3KaUuB5qAMuAmy7FlSqm/0pJsAB4VkTJXxappmqZ1TImIp2NwmvT0dNmyZYunw9C0Ps1kMpGbm0t9fb2nQ9GcyM/Pj4SEBIxG40nblVJbRSTd3rEuK1FomtY35ebmEhwczODBg1FKeToczQlEhNLSUnJzcxkyZEiXj/d0rydN03qZ+vp6IiMjdZI4jSiliIyM7HYpUScKTdNOoZPE6acn76lOFJqmaZpdOlFomtbrBAUFeToEzYZOFJqmaZpduteTpmkd+stnu9lzvNKp5xwTF8LDlyU5tK+I8Lvf/Y4vv/wSpRR/+tOfmD9/Pvn5+cyfP5/Kykqampp44YUXmDp1KrfeeitbtmxBKcUtt9zCr3/9a6fGfqbSiULTtF7ro48+IiMjg8zMTEpKSpg4cSLTp0/nnXfe4cILL+SPf/wjzc3N1NbWkpGRQV5eHrt27QKgvLzcs8GfRnSi0DStQ45+83eVdevWcc011+Dl5UVMTAznnnsumzdvZuLEidxyyy2YTCbmzZtHamoqQ4cO5fDhw9x7771ccsklXHDBBR6N/XSi2yg0Tetzpk+fztq1a4mPj+emm25i8eLFhIeHk5mZyYwZM3jxxRe57bbbOj+R5hCdKDRN67XOOecc3n//fZqbmykuLmbt2rVMmjSJo0ePEhMTw+23385tt93Gtm3bKCkpwWw289Of/pTHHnuMbdu2eTr804auetI0rdf6yU9+woYNG0hJSUEpxeOPP05sbCxvvvkmTzzxBEajkaCgIBYvXkxeXh4333wzZrMZgL///e8ejv70oScF1DTtJFlZWYwePdrTYWgu0N5768ikgLrqSdM0TbNLJwpN0zTNLp0oNE3TNLt0otA0TdPs0olC0zRNs0snCk3TNM0unSg0TdM0u3Si0DTttJednc3YsWO7fby99TF6eu6+wKUjs5VSc4BnAS/gVRH5R5vX7wduA5qAYuAWETlqea0Z2GnZNUdELndlrJqmtePLhVCws/P9uiI2GS76R+f7ab2Gy0oUSikv4D/ARcAY4Bql1Jg2u20H0kVkHLAUeNzmtToRSbX86CShaWeQ7OxsRo0axU033cSIESO47rrr+Oabb5g2bRqJiYls2rSJTZs2MWXKFMaPH8/UqVPZt28fALt372bSpEmkpqYybtw4Dhw4cNK5Dx8+zPjx49m8eTOHDh1izpw5TJgwgXPOOYe9e/cCcOTIEaZMmUJycjJ/+tOfHI67vr6em2++meTkZMaPH8/q1as7jKmmpoZLLrmElJQUxo4dy/vvv++k354LiIhLfoApwHKb578Hfm9n//HA9zbPq7t6zQkTJoimaT2zZ88eT4cgR44cES8vL9mxY4c0NzdLWlqa3HzzzWI2m+WTTz6RuXPnSkVFhZhMJhERWbFihVxxxRUiInLPPffI22+/LSIiDQ0NUltbK0eOHJGkpCTZu3evpKamSkZGhoiIzJo1S/bv3y8iIhs3bpSZM2eKiMhll10mb775poiIPPfccxIYGGg31qSkJBERefLJJ+Xmm28WEZGsrCwZMGCA1NXVtRvT0qVL5bbbbms9T3l5uXN+eXa0994CW6STz1ZXVj3FA8dsnucCk+3sfyvwpc1zP6XUFlqqpf4hIp+0d5BS6g7gDoCBAwf2JF5N03qRIUOGkJycDEBSUhLnnXceSimSk5PJzs6moqKCG2+8kQMHDqCUwmQyATBlyhT+9re/kZubyxVXXEFiYiIAxcXFzJ07l48++ogxY8ZQXV3N+vXrufLKK1uv2dDQAMD333/Phx9+CMANN9zAgw8+6FDM69at49577wVg1KhRDBo0iP3797cbU3JyMr/5zW948MEHufTSSznnnHOc84tzgV7RmK2Uuh5IB56w2TxIWiaquhZ4Rik1rL1jReRlEUkXkfSoqCg3RKtpmjv4+vq2PjYYDK3PDQYDTU1NPPTQQ8ycOZNdu3bx2WefUV9fD8C1117LsmXL8Pf35+KLL2bVqlUAhIaGMnDgQNatWweA2WwmLCyMjIyM1p+srKzWayqlnHYv7cU0YsQItm3b1lq99eijjzrtes7mykSRBwyweZ5g2XYSpdT5wB+By0WkwbpdRPIs/x4G1tBSNaVpmgZARUUF8fHxALzxxhut2w8fPszQoUO57777mDt3Ljt27ADAx8eHjz/+mMWLF/POO+8QEhLCkCFD+O9//wu0VMNnZmYCMG3aNN577z0AlixZ4nBM55xzTuv++/fvJycnh5EjR7Yb0/HjxwkICOD666/ngQce6NXrZ7gyUWwGEpVSQ5RSPsDVwDLbHZRS44GXaEkSRTbbw5VSvpbH/YBpwB4XxqppWh/zu9/9jt///veMHz+epqam1u0ffPABY8eOJTU1lV27dvHzn/+89bXAwEA+//xznn76aZYtW8aSJUt47bXXSElJISkpiU8//RSAZ599lv/85z8kJyeTl3fK99sO3X333ZjNZpKTk5k/fz5vvPEGvr6+7ca0c+fO1gbuv/zlL11qNHc3l65HoZS6GHiGlu6xi0Tkb0qpR2lpPFmmlPoGSAbyLYfkiMjlSqmptCQQMy3J7BkRea2z6+n1KDSt5/R6FKev7q5H4dJxFCLyBfBFm21/tnl8fgfHraclgWiapmkeppdC1TRNc8DOnTu54YYbTtrm6+vLDz/84KGI3EcnCk3TNAckJyeTkZHh6TA8old0j9U0TdN6L50oNE3TNLt0otA0TdPs0olC0zRNs0snCk3T+jx760W4wpo1a7j00ku7dWxn61f05Nyuons9ARve/APR4y9l2Lipng6lXRUnSjj0w+c0Hl5PUPIljD1nrqdD0s4Q/9z0T/aW7XXqOUdFjOLBSY5Nsqf1Dmd8iaKitJBhR94l/sPL2fThM4jZ7OmQMDc3cyDjOza8sZCsv00l8JlE0jb+kkmFHzD6mxv54YPHOz+JpvVhCxcu5D//+U/r80ceeYTHHnuM8847j7S0NJKTk1un2+jMmjVrOPfcc5k7dy5Dhw5l4cKFLFmyhEmTJpGcnMyhQ4cA+Oyzz5g8eTLjx4/n/PPPp7CwEIBvv/2W1NRUUlNTGT9+PFVVVSedf/PmzYwfP55Dhw6xdetWzj33XCZMmMCFF15Ifn7LpBNbt24lJSWFlJSUk+6rM2VlZcybN49x48Zx1llntc5b1V5M+fn5TJ8+ndTUVMaOHct3333n8HU61dk85H3pp7vrUZQUHJOd/2+6yMMhsumpq6S2urJb5+mJ0sJc2bzsRdn01M+k5OEBIg+HiDwcIvsfTZP1L/9S9mz8SsrLimX7Py4QeThENjx/hzRZ5uLXNGfqDetRbNu2TaZPn976fPTo0ZKTkyMVFRUiIlJcXCzDhg0Ts9ksImJ3vYjVq1dLaGioHD9+XOrr6yUuLk7+/Oc/i4jIM888I7/85S9FRKSsrKz1fK+88orcf//9IiJy6aWXyrp160REpKqqSkwmk6xevVouueQS+f777yUtLU2OHj0qjY2NMmXKFCkqKhIRkffee691bYrk5GT59ttvRUTkt7/9bev6FR3Fe8kll4hIy9oajzzyiIiIrFy5UlJSUjqM6cknn5THHntMRESampqksvLUz7HeuB5FnxEZk0DYAyvZ+MbvmHRsEUf/NQ2vqxczcESqS69bUVpI1lcvEXHkM4abDpCuhBMEcyhkMkeGn8/gSZeSGDuARJtjkn/zPza+tICzCt9j+1M5jLz7PQKCQl0ap6a52/jx4ykqKuL48eMUFxcTHh5ObGwsv/71r1m7di0Gg4G8vDwKCwuJjY3t9HwTJ06kf//+AAwbNowLLrgAaBlEZ12FLjc3l/nz55Ofn09jYyNDhgwBWmaSvf/++7nuuuu44oorSEhIAFrmTbrjjjv4+uuviYuLY9euXezatYvZs2cD0NzcTP/+/SkvL6e8vJzp06cDLetbfPnllzhi3bp1retizJo1i9LSUiorK9uNaeLEidxyyy2YTCbmzZtHamqqg7/tzp3xVU9WXt7enHXbU+ya+Rph5jIil1zI1i86nYewy8RsZu+WlWx++ip8/y+Jsw78C4AfBt/J/suXEfKnbNLv/5D0y++iX+yAU4738vbmrF+8yg+jFjKuZgPHn55J8fFsp8epaZ525ZVXsnTpUt5//33mz5/PkiVLKC4uZuvWrWRkZBATE9O6BkVnOlvbAuDee+/lnnvuYefOnbz00kut5164cCGvvvoqdXV1TJs2rXW51P79++Pn58f27duBltqZpKSk1rUtdu7cyddff+2034et9mKaPn06a9euJT4+nptuuonFixc77Xq6RNHGuBk/pWBYCoVvXs+ETffzw+HvSb3tOXz9Anp03urKE+z+6lX67VvCqOYj1Igfmf0uod+MuxiRfFaXzzf56t+TuWoIw7/9JdUvz+LQT99hWDfOY4+YzeQc2EHBjpV4HduAwdxIwjXPEh0/xKnX0bT2zJ8/n9tvv52SkhK+/fZbPvjgA6KjozEajaxevZqjR4869Xq261u8+eabrdsPHTpEcnIyycnJbN68mb179xIWFkZYWBivvfYas2fPJjAwkKlTp1JcXMyGDRuYMmUKJpOJ/fv3k5SURFhYGOvWrePss8/u1voWDz30EGvWrKFfv36EhIS0G5O/vz8JCQncfvvtNDQ0sG3btpOmWO8JnSjaETtgOJG/+5aNr93HWYXvsf/JnQTf8Db9B43s8rkO7dxIyZrnGVuynMmqnkNeQ/gh6SGSLryVySHhPYozZdbVHIoaTPCH1xC7dC6Zxf8mZdZV3T5fc1MT2Xs2Ubx7NT65Gxlck8EgKhkElBBGgNRR88pM9l26iJHps3oUu6Z1JikpiaqqKuLj4+nfvz/XXXcdl112GcnJyaSnpzNq1CinXu+RRx7hyiuvJDw8nFmzZnHkyBEAnnnmGVavXo3BYCApKYmLLrqIDRs2ABATE8Pnn3/ORRddxKJFi1i6dCn33XcfFRUVNDU18atf/YqkpCRef/11brnlFpRSrdVejsZ0yy23MG7cOAICAloTWHsxvffeezzxxBMYjUaCgoKcWqJw6XoU7uaK9Si2ffUGiRsWYlYGsqc/Rcqsq0/ZR8xmaqorqCg5TlXJcWpPFNBYlkP4oWWMbNpLvRjZGXYeIefcyYi0GSiDc2v8ivKOULnopwxpOsyW0Q8y+erfd3qMmM2cKMmn4NAOKg6sJyB/I0NrdxKs6gA4rqLJCxmPDJxC/3GzSBiWTHbWZnyX3kCkuYydE/5K+uV3OfU+3K25qQmDweD096Ov0+tRnL66ux6FThQOyD24i4Z3r2dY8xE2h16IGIz4NJQS0FhKUHM54eZy/FXjKcflGOI5PvwaRl94B6GRMU6Py1ZNVTkHXria1NoNbIy6kol3voiXtzf1dTXkH9nDiZzdNBbsx+vEQUJqsunflEsINa3HHzUMoCA8Da9BU0lIPY/YgYntXudEcT7HX7mKpMYdbIy9jom3/R9e3n2rYFp8PJtDHz/G+KJPOGocQsP0P5E8XY9NsdKJ4vSlEwWuXeGuvraazFfvIrX0S6pUIBVe4dR6h9PgG0mTfz8IisYrOBrf0FgCIvoT0i+OqP6D3Ppttbmpic0v381ZRe+TbRiIjzQQay7CoH58j4uIoMh3IDVBg5HI4fj3H0XCmClExiQ4fB1TYwPbXrqDyaWfkOk/iSF3vkdIWKQrbsmpivKOcOSTx0gt+hQvmskMmUF81Q5iKWGXbyrG2Q+f9lVq5uZmNn/4FMP2PEehzwAa0xcwbtbVJyX7vpoo+tp6EcuXL+fBB08eeDhkyBA+/vhjl11TJwrcsxSqmM29vqrih/8+Sei+pdT496cxbBjGmBGEDRhD/6FjCQwOc951PnicCbv/Tp5XPF7XvkfC8I6nJeiIO36ftgnCgJntEXOIv+wh4oeOpr6uhoyPn2Lk/pcJp5LtAdMIv+xRBo+2+3fTJx3Z/QONH9/HyKa9ZBmTCDMV0Z9ijqsYchJvIOmSXxAcGkFWVhajRo1CKeXpkDUnEhH27t2rE4VeM9v9dn3/GQkrFqAQjp33QqfTi1SWl3Lwhy8w7f+GhLINhJvL2RNyNt6pVzHm7Hn4+Po5LbaivCMc+fivpBYvsySIi0i4/CHihpzaCFpdeYKdH/6DsdlvEkg9W8MuIP4nfyVucNc7MHSmpqqc3d8sprksh7izr2fQyFSnX8NWXU0VGW//gfTjS6hWgRxK+wMTLr2T5uYmdqx8B/+tLzPatJtq8WdXzGWEnnsfUTH9iYyM7BPJwmxupq6yDGmqx+AbjF9AMAYvL0+H1auICKWlpVRVVbWOD7HSiUJzi7zDWZjevoqE5ly2jHqAyfMXtpYSmkyNHMxYy4mdywnPX8fwxr14KzM14sf+wDRMvuGMOPEtYVRTThD7Is8jaMLVjJ58Ybf/2K0JYnzxpyjEboJoq7ykgL1LHyU1/4OW5BI1j2E/e4R+sQO7FYuVmM3s27KSyg2vk1S2kkD1Y///Pcax1CZfz9jzb8AvwLmT2+1YvZR+a/9AnBSyKexiRlz/NGH9Th2gdmD7WipWP0tKxWrMPiFkTfoHhqgRGH38oJcmiyZTI831VRib6zDw49Q7gqJJGTF7+WIw+uHt44tSnq0FEBGaTA2YG2pBmkF5gZc3yuCNwduIl5d395KyCGYRRMx4edlvK/Tz8yMhIQGj0XjSdp0oNLepqijj0EvXklq7gU3hlyJx4zFmr2F4zVZCqMUsioPGREpjzyZ07IUkps3E6NMy6KmxoZ6s7z/BlPFfxlR8R4BqoJBIjsTOod+UaxmWPLXd6qnqyhMUHNlDRd5eTEWHMJQfIbjmKMMa97UkiMiLWxJEN0oFRXlHOPLhn5lQ+jmNGNkRfTnGIVOITkwnfuhYh5NYScExDq54hf5HPmSQOZda8WVX+HmETL2FfgNHcfDrl0k48l8SJJ9KAtkTdTExM+9kyJiJXY755OvmcHTJL5lQtYqjhgSqz3+CpKkXd3pc8fFsDv7vGUblLSWcKg55DaV4wEWIuQnVWI0y1WBoqsW7qRav5jp8muvwaa7FV+rwlQaaMFJnCKDBEECjdwBN3oE0eQdhNgYivsEonyCUXzA+oTFEJ04ibvDILlU9NtTXsnPlEvwzF5PUuAOTeLEzeBrGSbcxaNzZHNm2krr9a4gs2cRQ00G8lNAgRg76jqGy/xRCR89k+PgZrSXX5qYmGupraKirpaG+BlNDHab6Wkz1NTQ11uPl40t84niCQyO6/B40NtSzd8P/qNu5jCGla4mmjCYxUGToR5S5FKNqbt3Xur3MJ47agHjMoYPxjhiI2VSPuaYUqSvHq74MY2M5vqYKApoqCDJXEiJV+Khmiogg+pEjXY4RekGiUErNAZ4FvIBXReQfbV73BRYDE4BSYL6IZFte+z1wK9AM3Cciyzu7nk4UnmVubuaHRfczJe8NAAroR074WXglns+wSRe1+022rdrqCvZ8+wHeuz9kTM0mfFQzOYZ48uIvBi9vvMuzCao5SpTpOP0oP+nYYsIp9kmgMmw0Ay/+rVOqjXIP7qLg0z+TUrmm9Q+7RvzI8RlKZehoDHEphA+bwICRaa2DMptMjexasxTZ/hbJNRvxVmayjGOoHn01Y2bfeEo7kbm5mT0bv6Bh4yKSK9fio5rY5z2KiqTrGDv7xi5N0WJubmbzR08zeve/8JNGtg6+jbRrHu7ygNH62mp2fPkK0bsXMdic07JNjNQpf+qUHw3Kn0aDP41e/jR5+dPsHYDZ2x/V3Ih3Uw3eTTX4Ntfga67Dz1xLgNQSSP1JHSsAKgngmM8wqsKT8IpLoV/iRAYkpuBt9Dlpv2MHd5L3zQuMLPiMcCo5rmI4OvhnJF64oMPSXsWJEo5sXUH9gTVElWxiSNMRDJbE0Yg3vjTiY/NhbU8+URT6D6MufCTGuLFEDh1PwvBxrV92Wu+nvJT933+E2vs/RlRuJFjVUSu+7A2ajHnkxSROu4LQyBiaTI0UHz9Cae5+6goP01R6BGPVMYJrc4lsKjjl/3ajeFGpgqk2hFDrHUqDMRSTTxjNfhGogHC8QmKZOPduh+6lLY8mCqWUF7AfmA3kApuBa0Rkj80+dwPjRGSBUupq4CciMl8pNQZ4F5gExAHfACNExO67qhNF73Box3qMfgEMGD6uRw3VFaWF7Fu9hMD9HzO6YScGJRQRQbFPPDWBA2kOH4Zv9DBC40cRO3iUUxvq22qor+XYvm2cOLQV8/FMQiqyGNh4uLUKqVG8OOY9kPKAwQyq2k4/yikhjAP9LyVuxu0Ot0OcKM5n39cv0//QBwwy51Il/uzpdyESMbRlh9a/V5u/W+s2EcKOfcMo0x52+6QQcuW/GZCY0qP7to4R8vMPPOXDuzvnqqutoraynLKCbE4c2gIFOwiryGKg6UhrF/N6MZJjHMKJ0NFIxDCCclYxtiGDJjGwM2gqXhNvYew587pcNVlRWsjhrStoOLwezCbE2w+8/VHevmD0x+Djj8Hoh8HHHy+fALx8/WmqraI+bxfG0iwiaw4S35zX+oWhUbzI8xpAadBwTKGDCSzezqi6DHxUM6WEcij8HHyTL2PklMvw8w/sUqy11RUU5x7C6BdISEQ0gUGhLuv04elEMQV4REQutDz/PYCI/N1mn+WWfTYopbyBAiAKWGi7r+1+9q6pE8Xpq7ykAB8//141AaK5uZm8I3so2r+JxtxMAsv2EF1/hPyAEajxN5B07k9P+cbpKDGb2bt5BdXrXyW5fDV+yuTQcScI4WDqg6Rffnev751nq8nUSO7BHZQc2ExTXibBJ3YzoPEgIdRSQBRHBv2U4RfeRVTcYI/G2dhQT+6BTMoOb8eUv5uA8r3E1B0hlmKOqTjyYmYSlvYTEtNm9pnxRY4kClfeSTxwzOZ5LjC5o31EpEkpVQFEWrZvbHNsfHsXUUrdAdxheVqtlNrXzXj7ASXdPLY3Ot3uB/rMPR0GvgKu62xHF9xPJXCv5ccjXHRPj1t+3K4L91MJ7AVecGE4TtH2ngZ1dkDfSHl2iMjLwMs9PY9SaktnWbUvOd3uB06/ezrd7gdOv3s63e4HundPriyb5gG282QnWLa1u4+l6imUlkZtR47VNE3T3MCViWIzkKiUGqKU8gGuBpa12WcZcKPl8c+AVZYVl5YBVyulfJVSQ4BEYJMLY9U0TdM64LKqJ0ubwz3Aclq6xy4Skd1KqUdpWXpvGfAa8JZS6iBQRksywbLfB8AeoAn4RWc9npygx9VXvczpdj9w+t3T6XY/cPrd0+l2P9CNezqtBtxpmqZpztd3+s9pmqZpHqEThaZpmmbXGZ8olFJzlFL7lFIHlVILPR2PMyilspVSO5VSGUqpPjkCUSm1SClVpJTaZbMtQim1Qil1wPJvz9aSdaMO7ucRpVSe5X3KUEp1PhlTL6GUGqCUWq2U2qOU2q2U+qVle19+jzq6pz75Piml/JRSm5RSmZb7+Ytl+xCl1A+Wz7z3LZ2N7J/rTG6jcGSakb5IKZUNpItIHxic1j6l1HSgGlgsImMt2x4HykTkH5akHi4iD9o7T2/Rwf08AlSLyJOejK07lFL9gf4isk0pFQxsBeYBN9F336OO7ukq+uD7pFqmow0UkWqllBFYB/wSuB/4SETeU0q9CGSKiN1Rgmd6iWIScFBEDotII/AeoNfE7AVEZC0tPeFszQXetDx+k5Y/4j6hg/vps0QkX0S2WR5XAVm0zJ7Ql9+jju6pT5IW1ZanRsuPALOApZbtDr1HZ3qiaG+akT77H8OGAF8rpbZapjg5XcSISL7lcQHg2oXI3eMepdQOS9VUn6mmsaWUGgyMB37gNHmP2twT9NH3SSnlpZTKAIqAFcAhoFxEmiy7OPSZd6YnitPV2SKSBlwE/MJS7XFasQzM7Ov1pi8Aw4BUIB/4l0ej6QalVBDwIfArEam0fa2vvkft3FOffZ9EpFlEUmmZ3WIS0PnqXe040xPFaTlViIjkWf4tAj6m5T/I6aDQUo9srU8u8nA8PSIihZY/ZDPwCn3sfbLUe38ILBGRjyyb+/R71N499fX3CUBEyoHVwBQgzDJlEjj4mXemJwpHphnpU5RSgZaGOJRSgcAFwC77R/UZtlO+3Ah86sFYesz6gWrxE/rQ+2RpKH0NyBKRp2xe6rPvUUf31FffJ6VUlFIqzPLYn5ZOO1m0JIyfWXZz6D06o3s9AVi6uj3Dj9OM/M2zEfWMUmooLaUIaJmi5Z2+eE9KqXeBGbRMiVwIPAx8AnwADASOAleJSJ9oIO7gfmbQUp0hQDZwp039fq+mlDob+A7YCa0LVv+Bljr9vvoedXRP19AH3yel1DhaGqu9aCkUfCAij1o+I94DIoDtwPUi0mD3XGd6otA0TdPsO9OrnjRN07RO6EShaZqm2aUThaZpmmaXThSapmmaXTpRaJqmaXbpRKFp7VBKNdvMFprhzJmFlVKDbWeRdWD/QKXUN5bH62wGS2maW+j/cJrWvjrL1Ae9wRRgg2WOoRqbeXo0zS10iULTusCy1sfjlvU+Nimlhlu2D1ZKrbJMHLdSKTXQsj1GKfWxZU2ATKXUVMupvJRSr1jWCfjaMnK27bWGWSZ0exu4lpZpr1MsJZxo99yxpulEoWkd8W9T9TTf5rUKEUkGnqNlVD/Av4E3RWQcsAT4P8v2/wO+FZEUIA3YbdmeCPxHRJKAcuCnbQMQkUOWUs1WWuYXehO4VURSLfN4aZpb6JHZmtYOpVS1iAS1sz0bmCUihy0TyBWISKRSqoSWRW9Mlu35ItJPKVUMJNhOkWCZwnqFiCRanj8IGEXksQ5i2SwiE5VSHwK/FJFcZ9+vptmjSxSa1nXSweOusJ1bp5l22guVUi9aGr0TLVVQc4DPlVK/7uY1Na1bdKLQtK6bb/PvBsvj9bTMPgxwHS2TywGsBO6C1kVkQh29iIgsAP4C/JWWVcj+Z6l2erpH0WtaF+leT5rWPn/Lt3irr0TE2kU2XCm1g5ZSwTWWbfcCryulHgCKgZst238JvKyUupWWksNdtCx+46hzgcXAOcC33bkRTesp3UahaV1gaaNIF5EST8eiae6iq540TdM0u3SJQtM0TbNLlyg0TdM0u3Si0DRN0+zSiULTNE2zSycKTdM0zS6dKDRN0zS7/j+C6oI5Ul2TygAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KkhXRASNG80_",
        "outputId": "a3dbdd88-c429-45df-9609-2df9de512fab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7f9c7541c0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('libm.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "59b00f83-2fbe-4e62-a799-7fe3c4f63f26"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2aee43e5-394f-42fe-90c6-030f02c59a6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aee43e5-394f-42fe-90c6-030f02c59a6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2aee43e5-394f-42fe-90c6-030f02c59a6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2aee43e5-394f-42fe-90c6-030f02c59a6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "4197b526-5752-4edf-e756-3052dda1b5ee"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "14185090-c5eb-4bf5-e32e-24763d934c10"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('libm_Pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "db82f609-657d-4e8b-fe9b-f83bf6183819"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "1  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "2  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "3  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "4  moduleom_name:0,opendeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bba7e66-d99b-4deb-929e-ff33dc13ad6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bba7e66-d99b-4deb-929e-ff33dc13ad6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3bba7e66-d99b-4deb-929e-ff33dc13ad6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3bba7e66-d99b-4deb-929e-ff33dc13ad6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "875f6224-b34d-4caf-d3d0-1941a5e40c40"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "d4c3303e-11e4-464c-ff9e-ed1639de29f2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.187500\n",
            "Testing: Recall = 1.000000\n",
            "Testing: F1 Score = 0.315789\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[20 65]\n",
            " [ 0 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "e985b360-8f48-4acc-ab55-35147bac9a7a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.24      0.38        85\n",
            "           1       0.19      1.00      0.32        15\n",
            "\n",
            "    accuracy                           0.35       100\n",
            "   macro avg       0.59      0.62      0.35       100\n",
            "weighted avg       0.88      0.35      0.37       100\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}