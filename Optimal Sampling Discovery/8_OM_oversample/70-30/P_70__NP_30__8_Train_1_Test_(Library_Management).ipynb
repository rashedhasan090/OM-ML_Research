{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP EUndersample Distribution  \n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###8 OM - Dataset , Camping,OnlineStore, Decider , Bank, Customer_order, E-Commerce, School Management, Student-Course\n",
        "\n",
        "###1 OM - Testing - Library Management (unseen)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 70% - 30%\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "\n",
        "### Total instances - 652\n",
        "\n",
        "### P samples - 456 P \n",
        "### NP samples - 196  NP \n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 100\n",
        "\n",
        "### P samples - 15\n",
        "### NP samples - 85\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('8-OM-70p-30np.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "cd9ee1d7-a017-4ffe-9472-295f0b89a42f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a4b86f6-5012-4f30-9c96-d597dcc5800e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a4b86f6-5012-4f30-9c96-d597dcc5800e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a4b86f6-5012-4f30-9c96-d597dcc5800e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a4b86f6-5012-4f30-9c96-d597dcc5800e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,â€‹OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "891b8a37-160c-4a1c-c9e1-dfc0fb87a52b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 154, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "ab9dde03-ed11-4990-de56-4f162981b6ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "ffb4d0d1-b068-4668-f59a-f03c2b15b80b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 105   3]\n",
            "\n",
            "[  2 105]\n",
            "[105   3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "2237f3c0-7ad3-466e-8341-60c3559c0337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "a01c41e1-20c7-4152-cdde-d3f2cde0fa87"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "da8a37c7-a539-4cc9-9cf5-da3b2931b524"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "2ded1c61-ff7a-491d-e26a-ab5e04928536"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "615160b3-ebec-481b-fcee-c319e7b985a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 255)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "4a7fad85-3171-4acf-f4ba-d2cc1f93fdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 255)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "2e7615c5-7024-4de3-8258-5b98d4f89f9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.5412636, 'expected_acc': 0.00392156862745098}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "0b20a631-8cdb-4878-fcc2-61e8daedaa1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 10s 15ms/step - loss: 5.6019 - masked_acc: 0.0000e+00 - masked_loss: 5.6019\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.60191011428833, 'masked_acc': 0.0, 'masked_loss': 5.60191011428833}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "3c42b183-04eb-4843-8882-25b59732c78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6883 - masked_acc: 0.8200 - masked_loss: 0.6883 - val_loss: 2.1391 - val_masked_acc: 0.6857 - val_masked_loss: 2.1391\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.7528 - masked_acc: 0.7950 - masked_loss: 0.7528 - val_loss: 1.9891 - val_masked_acc: 0.7500 - val_masked_loss: 1.9891\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8673 - masked_acc: 0.7550 - masked_loss: 0.8673 - val_loss: 1.9657 - val_masked_acc: 0.7571 - val_masked_loss: 1.9657\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.6777 - masked_acc: 0.8350 - masked_loss: 0.6777 - val_loss: 1.7117 - val_masked_acc: 0.7786 - val_masked_loss: 1.7117\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.6394 - masked_acc: 0.8500 - masked_loss: 0.6394 - val_loss: 1.9728 - val_masked_acc: 0.7714 - val_masked_loss: 1.9728\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 6s 60ms/step - loss: 0.5802 - masked_acc: 0.8400 - masked_loss: 0.5802 - val_loss: 2.2815 - val_masked_acc: 0.7214 - val_masked_loss: 2.2815\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.4384 - masked_acc: 0.8850 - masked_loss: 0.4384 - val_loss: 2.0445 - val_masked_acc: 0.7500 - val_masked_loss: 2.0445\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.5811 - masked_acc: 0.8550 - masked_loss: 0.5811 - val_loss: 2.1014 - val_masked_acc: 0.7500 - val_masked_loss: 2.1014\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.6545 - masked_acc: 0.8200 - masked_loss: 0.6545 - val_loss: 1.9978 - val_masked_acc: 0.7500 - val_masked_loss: 1.9978\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 5s 52ms/step - loss: 0.5134 - masked_acc: 0.8700 - masked_loss: 0.5134 - val_loss: 1.6875 - val_masked_acc: 0.7714 - val_masked_loss: 1.6875\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.3985 - masked_acc: 0.8850 - masked_loss: 0.3985 - val_loss: 1.8733 - val_masked_acc: 0.8000 - val_masked_loss: 1.8733\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4048 - masked_acc: 0.9050 - masked_loss: 0.4048 - val_loss: 2.3607 - val_masked_acc: 0.7429 - val_masked_loss: 2.3607\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 5s 51ms/step - loss: 0.3969 - masked_acc: 0.9050 - masked_loss: 0.3969 - val_loss: 1.3696 - val_masked_acc: 0.8143 - val_masked_loss: 1.3696\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.5740 - masked_acc: 0.8350 - masked_loss: 0.5740 - val_loss: 1.7581 - val_masked_acc: 0.8214 - val_masked_loss: 1.7581\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.4684 - masked_acc: 0.8550 - masked_loss: 0.4684 - val_loss: 1.8903 - val_masked_acc: 0.7357 - val_masked_loss: 1.8903\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 6s 62ms/step - loss: 0.4606 - masked_acc: 0.8850 - masked_loss: 0.4606 - val_loss: 2.0594 - val_masked_acc: 0.7500 - val_masked_loss: 2.0594\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.3366 - masked_acc: 0.9200 - masked_loss: 0.3366 - val_loss: 1.8515 - val_masked_acc: 0.7857 - val_masked_loss: 1.8515\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 3s 35ms/step - loss: 0.3339 - masked_acc: 0.9000 - masked_loss: 0.3339 - val_loss: 2.3151 - val_masked_acc: 0.7857 - val_masked_loss: 2.3151\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.3217 - masked_acc: 0.9100 - masked_loss: 0.3217 - val_loss: 1.8539 - val_masked_acc: 0.7714 - val_masked_loss: 1.8539\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 0.4924 - masked_acc: 0.8500 - masked_loss: 0.4924 - val_loss: 1.8749 - val_masked_acc: 0.7714 - val_masked_loss: 1.8749\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 6s 56ms/step - loss: 0.4440 - masked_acc: 0.8700 - masked_loss: 0.4440 - val_loss: 1.8099 - val_masked_acc: 0.8071 - val_masked_loss: 1.8099\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "b78af670-9bcc-4898-b457-03ef422d09c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8af8fdb5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "5a24b81a-db93-4e81-9e31-8b06ee21d228"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8af9f87850>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('libm.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "57b92791-62cc-443a-86ee-cbd0b252ee9f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a6741cb-2af8-46ab-ac66-af587079bc3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a6741cb-2af8-46ab-ac66-af587079bc3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a6741cb-2af8-46ab-ac66-af587079bc3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a6741cb-2af8-46ab-ac66-af587079bc3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "c930f0f5-5ee3-4951-aecd-d3d5f22464ab"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "068cac15-7b85-47fe-f4f6-9221fd150ff5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('libm_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "da84f498-92c0-4535-d58d-e2350b3c2af5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "4  moduleom_name:0,opendeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0de5cd3-088a-4bff-9f82-8eaf488345ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0de5cd3-088a-4bff-9f82-8eaf488345ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0de5cd3-088a-4bff-9f82-8eaf488345ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0de5cd3-088a-4bff-9f82-8eaf488345ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "5c4deb31-b4e0-4c58-93e8-bccd86b2f82b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
            " 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "45923f1b-03b9-4d0d-e34a-7dbf24560fbc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.466667\n",
            "Testing: Recall = 0.466667\n",
            "Testing: F1 Score = 0.466667\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[77  8]\n",
            " [ 8  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "eb922802-955b-4be9-a1f1-beaf11f57a9c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91        85\n",
            "           1       0.47      0.47      0.47        15\n",
            "\n",
            "    accuracy                           0.84       100\n",
            "   macro avg       0.69      0.69      0.69       100\n",
            "weighted avg       0.84      0.84      0.84       100\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}