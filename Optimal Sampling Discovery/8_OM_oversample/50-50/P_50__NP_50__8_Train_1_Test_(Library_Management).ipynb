{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP EUndersample Distribution  \n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###9 OM - Dataset , Camping,OnlineStore, Decider , Bank, Customer_order, E-Commerce, School Management, Student-Course\n",
        "\n",
        "###1 OM - Testing - Library Management (unseen)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 50% - 50%\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Total instances - 652\n",
        "\n",
        "### P samples - 326  P \n",
        "### NP samples - 326 NP \n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 100\n",
        "\n",
        "### P samples - 15\n",
        "### NP samples - 85\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('8-OM-50p-50np.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "63412be8-ea6c-427d-a49a-758d11bb5cff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47abeb84-3829-4614-b566-8b701b3827a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47abeb84-3829-4614-b566-8b701b3827a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47abeb84-3829-4614-b566-8b701b3827a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47abeb84-3829-4614-b566-8b701b3827a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "target_raw =  Y\n",
        "context_raw = X\n",
        "#print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36594e25-b32f-434a-fb06-c74f859a6b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1id=c1_at1isAbstract=Nonoparent}onesigc1_at1extendsc1_at1_type,onesigclass01_nameextendsClassattrSet=c01_at1id=c01_at1isAbstract=Nonoparent}onesigc01_at1extendsc01_at1_type,onesigassoc1extendsAssociationsrc=class1_namedst=class01_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass2_nameextendsClassattrSet=c2_at1id=c2_at1isAbstract=Nonoparent}onesigc2_at1extendsc2_at1_type,onesigassoc2extendsAssociationsrc=class1_namedst=class2_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2id=c3_at1isAbstract=Nonoparent}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_type,onesigclass4_nameextendsClassattrSet=c4_at1oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc4_at1extendsc4_at1_type,onesigassoc3extendsAssociationdst=class2_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass5_nameextendsClassattrSet=c5_at1+c5_at2oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc5_at2extendsc5_at2_typeonesigc5_at1extendsc5_at1_typeonesigassoc4extendsAssociationsrc=class01_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2id=categoryIDisAbstract=Nonoparent}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigclass7_nameextendsClassattrSet=c7_at1+c7_at2+c7_at3+c7_at4id=c7_at1isAbstract=Nonoparent}onesigc7_at1extendsc7_at1_typeonesigc7_at2extendsc7_at2_typeonesigc7_at3extendsc7_at3_typeonesigc7_at4extendsc7_at4_typeonesigassoc5extendsAssociationsrc=class7_namesrc=class6_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass8_nameextendsClassattrSet=c8_at1id=c8_at1isAbstract=Nonoparent}onesigc8_at1extendsIntegeronesigassoc6extendsAssociationsrc=class7_namedst=class8_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc7extendsAssociationsrc=class7_namedst=class3_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass9_nameextendsClassattrSet=c9_at1+c10_at2oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc9_at1extendsc9_at1_typeonesigc10_at2extendsc10_at2_typeonesigclass10_nameextendsClassattrSet=c10_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc10_at1extendsc10_at1_typeonesigclass11_nameextendsClassattrSet=c11_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc11_at1extendsstringonesigclass12_nameextendsClassattrSet=c12_at1+c12_at2+c12_at3id=c12_at1isAbstract=Nonoparent}onesigc12_at1extendsc12_at1_typeonesigc12_at2extendsc12_at2_typeonesigc12_at3extendsc12_at3_typeonesigassoc8extendsAssociationsrc=class7_namesrc=class12_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass13_nameextendsClassattrSet=c13_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc13_at1extendsc13_at1_typeonesigclass14_nameextendsClassattrSet=c14_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc14_at1extendsc14_at1_typepredshowrunshow,TableName:class1_nameTableName:class01_nameMappingStrategyforclass1_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass7_name:map_str2MappingStrategyforclass9_name:map_str2MappingStrategyforclass10_name:map_str3MappingStrategyforclass11_name:map_str3MappingStrategyforclass4_name:map_str1MappingStrategyforclass5_name:map_str1MappingStrategyforclass12_name:map_str1MappingStrategyforclass11_name:map_str1MappingStrategyforclass14_name:map_str1AssociationStrategyforassoc1:assoc_str2AssociationStrategyforassoc2:assoc_str2AssociationStrategyforassoc3:assoc_str2AssociationStrategyforassoc4:assoc_str2AssociationStrategyforassoc5:assoc_str2AssociationStrategyforassoc6:assoc_str2AssociationStrategyforassoc7:assoc_str2AssociationStrategyforassoc8:assoc_str2,USEOM_name_0CREATETABLE`class01_name`(`c01_at1`c01_at1_typeNOTNULL,PRIMARYKEY(`c01_at1`),);CREATETABLE`class6_name`(`c7_at1`c7_at1_type(64)`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`),);CREATETABLE`class1_name`(`c1_at1`c1_at1_typeNOTNULLPRIMARYKEY(`c1_at1`),);CREATETABLE`class7_name`(`c7_at3`c7_at3_type(64)`c7_at2`c7_at2_type`c7_at4`c7_at4_type(20,5)`c7_at1`c7_at1_typeNOTNULLPRIMARYKEY(`c7_at1`),);CREATETABLE`class11_name`(`c11_at1`c11_at1_type(64)`c7_at1`c7_at1_typeNOTNULLKEY`FK_class11_name_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c7_at1`),);CREATETABLE`assoc1`(`c01_at1`c01_at1_typeNOTNULL,`c1_at1`c1_at1_typeNOTNULLKEY`FK_assoc1_c01_at1_idx`(`c01_at1`),KEY`FK_assoc1_c1_at1_idx`(`c1_at1`),KEY`FK_assoc1_c1_at1_idx`(`c1_at1`),);CREATETABLE`class2_name`(`c2_at1`c2_at1_typeNOTNULLPRIMARYKEY(`c2_at1`),);CREATETABLE`class8_name`(`c8_at1`c8_at1_typeNOTNULLPRIMARYKEY(`c8_at1`),);CREATETABLE`assoc7`(`c7_at1`c7_at1_typeNOTNULL`c3_at1`c3_at1_typeNOTNULLKEY`FK_assoc7_c7_at1_idx`(`c7_at1`)KEY`FK_assoc7_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c7_at1`,`c3_at1`),);CREATETABLE`class3_name`(`DType`varchar(64),`c5_at1`c5_at1_type,`c5_at2`c5_at2_type,`c4_at1`c4_at1_type,`c3_at2`c3_at2_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`),);CREATETABLE`class10_name`(`c10_at1`c10_at1_type(64)`c7_at1`c7_at1_typeNOTNULLKEY`FK_class10_name_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c7_at1`),);CREATETABLE`class9_name`(`c10_at2`c10_at2_type,`c7_at3`c7_at3_type(64)`c7_at2`c7_at2_type`c9_at1`c9_at1_type(20,5),`c7_at4`c7_at4_type(20,5)`c7_at1`c7_at1_typeNOTNULLPRIMARYKEY(`c7_at1`),);CREATETABLE`assoc2`(`c2_at1`c2_at1_typeNOTNULL`c1_at1`c1_at1_typeNOTNULLKEY`FK_assoc2_c2_at1_idx`(`c2_at1`)KEY`FK_assoc2_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c2_at1`,`c1_at1`));CREATETABLE`assoc8`(`c12_at1`c12_at1_typeNOTNULL`c7_at1`c7_at1_typeNOTNULLKEY`FK_assoc8_c12_at1_idx`(`c12_at1`)KEY`FK_assoc8_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c12_at1`,`c7_at1`),);CREATETABLE`class12_name`(`DType`varchar(64),`c14_at1`c14_at1_type(64)`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c13_at1`c13_at1_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`assoc4`()`c3_at1`c3_at1_typeNOTNULL`c01_at1`c01_at1_typeNOTNULL,KEY`FK_assoc4_c3_at1_idx`(`c3_at1`)KEY`FK_assoc4_c01_at1D_idx`(`c01_at1`)PRIMARYKEY(`c3_at1`,`c01_at1`));CREATETABLE`assoc5`(`c7_at1`c7_at1_typeNOTNULL`c6_at1`c6_at1_typeNOTNULLKEY`FK_assoc5_c7_at1_idx`(`c7_at1`)KEY`FK_assoc5_c6_at1_idx`(`c6_at1`)PRIMARYKEY(`c7_at1`,`c6_at1`),);ALTERTABLE`class11_name`ADDCONSTRAINT`FK_class11_name_c7_at1`FOREIGNKEY(`c12_at1`)REFERENCES`class12_name`(`c12_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c01_at1`FOREIGNKEY(`c01_at1`)REFERENCES`class01_name`(`c01_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc7`ADDCONSTRAINT`FK_assoc7_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc7_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`class10_name`ADDCONSTRAINT`FK_class10_name_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc8`ADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINTFK_assoc8_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c01_at1`FOREIGNKEY(`c01_at1`)REFERENCES`class01_name`(`c01_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,'], shape=(1,), dtype=string)\n",
            "\n",
            "tf.Tensor([b'moduleOM_name:0,openDeclarationonesigclass1_nameextendsClassattrSet=c1_at1id=c1_at1isAbstract=Nonoparent}onesigc1_at1extendsc1_at1_type,onesigclass01_nameextendsClassattrSet=c01_at1id=c01_at1isAbstract=Nonoparent}onesigc01_at1extendsc01_at1_type,onesigassoc1extendsAssociationsrc=class1_namedst=class01_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass2_nameextendsClassattrSet=c2_at1id=c2_at1isAbstract=Nonoparent}onesigc2_at1extendsc2_at1_type,onesigassoc2extendsAssociationsrc=class1_namedst=class2_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass3_nameextendsClassattrSet=c3_at1+c3_at2id=c3_at1isAbstract=Nonoparent}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_type,onesigclass4_nameextendsClassattrSet=c4_at1oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc4_at1extendsc4_at1_type,onesigassoc3extendsAssociationdst=class2_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass5_nameextendsClassattrSet=c5_at1+c5_at2oneparentid=c3_at1isAbstract=Noparentinclass3_name}onesigc5_at2extendsc5_at2_typeonesigc5_at1extendsc5_at1_typeonesigassoc4extendsAssociationsrc=class01_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigclass6_nameextendsClassattrSet=c6_at1+c6_at2id=categoryIDisAbstract=Nonoparent}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigclass7_nameextendsClassattrSet=c7_at1+c7_at2+c7_at3+c7_at4id=c7_at1isAbstract=Nonoparent}onesigc7_at1extendsc7_at1_typeonesigc7_at2extendsc7_at2_typeonesigc7_at3extendsc7_at3_typeonesigc7_at4extendsc7_at4_typeonesigassoc5extendsAssociationsrc=class7_namesrc=class6_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass8_nameextendsClassattrSet=c8_at1id=c8_at1isAbstract=Nonoparent}onesigc8_at1extendsIntegeronesigassoc6extendsAssociationsrc=class7_namedst=class8_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc,}onesigassoc7extendsAssociationsrc=class7_namedst=class3_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass9_nameextendsClassattrSet=c9_at1+c10_at2oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc9_at1extendsc9_at1_typeonesigc10_at2extendsc10_at2_typeonesigclass10_nameextendsClassattrSet=c10_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc10_at1extendsc10_at1_typeonesigclass11_nameextendsClassattrSet=c11_at1oneparentid=c7_at1isAbstract=Noparentinclass7_name}onesigc11_at1extendsstringonesigclass12_nameextendsClassattrSet=c12_at1+c12_at2+c12_at3id=c12_at1isAbstract=Nonoparent}onesigc12_at1extendsc12_at1_typeonesigc12_at2extendsc12_at2_typeonesigc12_at3extendsc12_at3_typeonesigassoc8extendsAssociationsrc=class7_namesrc=class12_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc,}onesigclass13_nameextendsClassattrSet=c13_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc13_at1extendsc13_at1_typeonesigclass14_nameextendsClassattrSet=c14_at1oneparentid=c12_at1isAbstract=Noparentinclass12_name}onesigc14_at1extendsc14_at1_typepredshowrunshow,TableName:class1_nameTableName:class01_nameMappingStrategyforclass1_name:map_str2MappingStrategyforclass6_name:map_str2MappingStrategyforclass7_name:map_str2MappingStrategyforclass9_name:map_str2MappingStrategyforclass10_name:map_str3MappingStrategyforclass11_name:map_str3MappingStrategyforclass4_name:map_str1MappingStrategyforclass5_name:map_str1MappingStrategyforclass12_name:map_str1MappingStrategyforclass11_name:map_str1MappingStrategyforclass14_name:map_str1AssociationStrategyforassoc1:assoc_str2AssociationStrategyforassoc2:assoc_str2AssociationStrategyforassoc3:assoc_str2AssociationStrategyforassoc4:assoc_str2AssociationStrategyforassoc5:assoc_str2AssociationStrategyforassoc6:assoc_str2AssociationStrategyforassoc7:assoc_str2AssociationStrategyforassoc8:assoc_str2,USEOM_name_0CREATETABLE`class01_name`(`c01_at1`c01_at1_typeNOTNULL,PRIMARYKEY(`c01_at1`),);CREATETABLE`class6_name`(`c7_at1`c7_at1_type(64)`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`),);CREATETABLE`class1_name`(`c1_at1`c1_at1_typeNOTNULLPRIMARYKEY(`c1_at1`),);CREATETABLE`class7_name`(`c7_at3`c7_at3_type(64)`c7_at2`c7_at2_type`c7_at4`c7_at4_type(20,5)`c7_at1`c7_at1_typeNOTNULLPRIMARYKEY(`c7_at1`),);CREATETABLE`class11_name`(`c11_at1`c11_at1_type(64)`c7_at1`c7_at1_typeNOTNULLKEY`FK_class11_name_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c7_at1`),);CREATETABLE`assoc1`(`c01_at1`c01_at1_typeNOTNULL,`c1_at1`c1_at1_typeNOTNULLKEY`FK_assoc1_c01_at1_idx`(`c01_at1`),KEY`FK_assoc1_c1_at1_idx`(`c1_at1`),KEY`FK_assoc1_c1_at1_idx`(`c1_at1`),);CREATETABLE`class2_name`(`c2_at1`c2_at1_typeNOTNULLPRIMARYKEY(`c2_at1`),);CREATETABLE`class8_name`(`c8_at1`c8_at1_typeNOTNULLPRIMARYKEY(`c8_at1`),);CREATETABLE`assoc7`(`c7_at1`c7_at1_typeNOTNULL`c3_at1`c3_at1_typeNOTNULLKEY`FK_assoc7_c7_at1_idx`(`c7_at1`)KEY`FK_assoc7_c3_at1_idx`(`c3_at1`)PRIMARYKEY(`c7_at1`,`c3_at1`),);CREATETABLE`class3_name`(`DType`varchar(64),`c5_at1`c5_at1_type,`c5_at2`c5_at2_type,`c4_at1`c4_at1_type,`c3_at2`c3_at2_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`),);CREATETABLE`class10_name`(`c10_at1`c10_at1_type(64)`c7_at1`c7_at1_typeNOTNULLKEY`FK_class10_name_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c7_at1`),);CREATETABLE`class9_name`(`c10_at2`c10_at2_type,`c7_at3`c7_at3_type(64)`c7_at2`c7_at2_type`c9_at1`c9_at1_type(20,5),`c7_at4`c7_at4_type(20,5)`c7_at1`c7_at1_typeNOTNULLPRIMARYKEY(`c7_at1`),);CREATETABLE`assoc2`(`c2_at1`c2_at1_typeNOTNULL`c1_at1`c1_at1_typeNOTNULLKEY`FK_assoc2_c2_at1_idx`(`c2_at1`)KEY`FK_assoc2_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c2_at1`,`c1_at1`));CREATETABLE`assoc8`(`c12_at1`c12_at1_typeNOTNULL`c7_at1`c7_at1_typeNOTNULLKEY`FK_assoc8_c12_at1_idx`(`c12_at1`)KEY`FK_assoc8_c7_at1_idx`(`c7_at1`)PRIMARYKEY(`c12_at1`,`c7_at1`),);CREATETABLE`class12_name`(`DType`varchar(64),`c14_at1`c14_at1_type(64)`c12_at3`c12_at3_type(64)`c12_at2`c12_at2_type(64)`c13_at1`c13_at1_type(64)`c12_at1`c12_at1_typeNOTNULLPRIMARYKEY(`c12_at1`),);CREATETABLE`assoc4`()`c3_at1`c3_at1_typeNOTNULL`c01_at1`c01_at1_typeNOTNULL,KEY`FK_assoc4_c3_at1_idx`(`c3_at1`)KEY`FK_assoc4_c01_at1D_idx`(`c01_at1`)PRIMARYKEY(`c3_at1`,`c01_at1`));CREATETABLE`assoc5`(`c7_at1`c7_at1_typeNOTNULL`c6_at1`c6_at1_typeNOTNULLKEY`FK_assoc5_c7_at1_idx`(`c7_at1`)KEY`FK_assoc5_c6_at1_idx`(`c6_at1`)PRIMARYKEY(`c7_at1`,`c6_at1`),);ALTERTABLE`class11_name`ADDCONSTRAINT`FK_class11_name_c7_at1`FOREIGNKEY(`c12_at1`)REFERENCES`class12_name`(`c12_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c01_at1`FOREIGNKEY(`c01_at1`)REFERENCES`class01_name`(`c01_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc7`ADDCONSTRAINT`FK_assoc7_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc7_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`class10_name`ADDCONSTRAINT`FK_class10_name_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc8`ADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,ADDCONSTRAINTFK_assoc8_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c01_at1`FOREIGNKEY(`c01_at1`)REFERENCES`class01_name`(`c01_at1`)ONDELETECASCADEONUPDATECASCADE,ALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c7_at1`FOREIGNKEY(`c7_at1`)REFERENCES`class7_name`(`c7_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINTFK_assoc5_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADE,P'], shape=(1,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "  print(example_context_strings[:5])\n",
        "  print()\n",
        "  print(example_target_strings[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,â€‹OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bmsI1Yql8FYe"
      },
      "outputs": [],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "8e0876e5-111e-4e8b-db4d-bea46254e3ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 131, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "a4f59ca1-db49-4fbf-a57a-f97363839c1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "2011f930-c183-4fee-cdaf-112d4005807e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 14  3]\n",
            "\n",
            "[ 2 13]\n",
            "[13  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "f0be1046-7038-4256-aad5-31833914acde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "6c0b80d0-6afd-403e-a304-7c5c4ee87f2b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "70136ac2-2fe6-4a6c-88bf-abb0853ed5ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "77c64333-cb6f-4feb-ff69-3f7042c1b5a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "367d224a-7a10-4647-cb89-4b2ef6c89dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 276)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "7e0fc005-e6d7-44eb-8abc-d037c8face76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 276)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "37c29b9e-e045-4211-824c-c2c9362100ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.620401, 'expected_acc': 0.0036231884057971015}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "be1923c4-f895-4ea6-9a74-0f9c1a93f6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 9s 16ms/step - loss: 5.6986 - masked_acc: 0.0000e+00 - masked_loss: 5.6986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.698607444763184,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 5.698607444763184}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "1689be1d-dcf4-42a1-b1a0-c79554933b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.3504 - masked_acc: 0.9100 - masked_loss: 0.3504 - val_loss: 1.8460 - val_masked_acc: 0.7571 - val_masked_loss: 1.8460\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2978 - masked_acc: 0.9300 - masked_loss: 0.2978 - val_loss: 2.2187 - val_masked_acc: 0.7714 - val_masked_loss: 2.2187\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.4834 - masked_acc: 0.8550 - masked_loss: 0.4834 - val_loss: 1.8400 - val_masked_acc: 0.7929 - val_masked_loss: 1.8400\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 0.4084 - masked_acc: 0.8750 - masked_loss: 0.4084 - val_loss: 1.6827 - val_masked_acc: 0.8000 - val_masked_loss: 1.6827\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 6s 56ms/step - loss: 0.4702 - masked_acc: 0.8700 - masked_loss: 0.4702 - val_loss: 1.4040 - val_masked_acc: 0.8071 - val_masked_loss: 1.4040\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.2715 - masked_acc: 0.9200 - masked_loss: 0.2715 - val_loss: 1.5542 - val_masked_acc: 0.8214 - val_masked_loss: 1.5542\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.3201 - masked_acc: 0.8900 - masked_loss: 0.3201 - val_loss: 1.7034 - val_masked_acc: 0.8071 - val_masked_loss: 1.7034\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 6s 60ms/step - loss: 0.3372 - masked_acc: 0.9000 - masked_loss: 0.3372 - val_loss: 1.9733 - val_masked_acc: 0.8071 - val_masked_loss: 1.9733\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.3952 - masked_acc: 0.8950 - masked_loss: 0.3952 - val_loss: 1.9813 - val_masked_acc: 0.8571 - val_masked_loss: 1.9813\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.3500 - masked_acc: 0.8850 - masked_loss: 0.3500 - val_loss: 1.8578 - val_masked_acc: 0.8000 - val_masked_loss: 1.8578\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.3108 - masked_acc: 0.9200 - masked_loss: 0.3108 - val_loss: 1.6107 - val_masked_acc: 0.8143 - val_masked_loss: 1.6107\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 6s 56ms/step - loss: 0.2631 - masked_acc: 0.9100 - masked_loss: 0.2631 - val_loss: 1.5625 - val_masked_acc: 0.8357 - val_masked_loss: 1.5625\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.2916 - masked_acc: 0.9050 - masked_loss: 0.2916 - val_loss: 2.1346 - val_masked_acc: 0.7929 - val_masked_loss: 2.1346\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "b4a77f23-2369-4901-8b62-982d7382ac58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f69edfd1220>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA76ElEQVR4nO3deVhV1f7H8fdiBhERUUBAccARBFMcKm3wpmaWZYNdzQnNTDN/DaZWZnPp7WaTXTPn0ibNUsupm+aYiooCDqgIiqAMCsgMh/X7gyOXDAGRwwHP9/U8PJ6zz2bv70Y4n7P3WnstpbVGCCGE5bIydwFCCCHMS4JACCEsnASBEEJYOAkCIYSwcBIEQghh4WzMXcD1cnd3135+fuYuQwgh6pT9+/enaK0bl/VanQsCPz8/wsLCzF2GEELUKUqpuGu9JpeGhBDCwkkQCCGEhZMgEEIICydBIIQQFk6CQAghLJwEgRBCWDgJgmp2KfcShiKDucsQQohKkyCoRjFpMfRb1Y8p26Ygw3sLIeoKCYJqkmfIY8q2KRQYCtgct5nVJ1ebuyQhhKgUCYJq8mHYh0Rfiuajuz6iu2d33t/7PrHpseYuSwghKiRBUA22nt3KimMreKL9E9zhewfv3P4OdtZ2TN0+lQJDgbnLE0KIckkQ3KCk7CRm7JxBO7d2PNflOQA86nnwRs83OJJ6hLnhc81coRBClE+C4AYYigy8vP1l8gx5zOo9Cztru5LX+jTvw8P+D7MochF7E/easUohhCifBMENWBy1mD3n9zCt2zRaNmj5t9dfCnmJ5i7Nmb5jOul56WaoUAghKiZBUEWHkw/z2cHP6OfXj4daP1TmOk62Trzf+30u5l7kjd1vSJdSIUSVbY7bTEpOikm2LUFQBZfzL/PStpfwcPLgtZ6voZS65rodG3VkUudJbI7bzE8nf6q5IoUQN43zWed5adtLzD883yTblyC4Tlpr3vrzLc5nnWdW71m42LlU+D2jOo6im2c33tv7HnEZ15wbQgghyrTsyDK01ozsONIk25cguE5rTq1h/en1PB30NMFNgiv1PVbKindufwdbK1umbptKQZF0KRVCVE5abhoro1dyb4t78Xb2Nsk+JAiuQ2x6LO/seYeuHl0ZGzj2ur7Xs54nr9/6OlGpUXwe/rmJKhRC3GxWHFtBTmEOYwLGmGwfEgSVVGAo4KVtL2Fnbcd7vd7D2sr6urdxT/N7GOw/mIURC9l3fp8JqhRC3EyyC7JZfnQ5d/reSeuGrU22HwmCSvr4wMccvXiUN259A896nlXeztSQqTRzacb07dKlVAhRvh+ifyAjP+O6r0BcLwmCSth5bidLjyxlSNsh9GnW54a25WTrxKxes0jNSeXN3W9Kl1IhRJnyDfksi1pGiGcIQY2DTLovCYIKpOSk8PKOl2nt2poXu75YLdvs6N6RiZ0nsiluk3QpFUKUaV3MOpJykhgbYNqzAZAgKFeRLuLVHa+SVZDF7N6zcbBxqLZtj+44mhDPEN7b+x5nMs5U23aFEHWfocjAoshFtHdrT8+mPU2+PwmCcnx15Ct2JuxkStcp+Df0r9ZtW1tZ8+7t70qXUiHE3/x25jfiMuIYGzi23BtWq4vJgkAp5auU2qKUOqKUilJKTS5jHaWU+kQpdVIpdVgpdYup6rleUalRfHTgI+72vZvH2j5mkn141vNkZs+ZRKZG8p/w/5hkH0KIukVrzcKIhfi5+N1wm2RlmfKMoBB4QWvdAegBTFRKdbhqnXsBf+PXOKBWvBtmF2QzddtUGjk04s3b3jRpIvf168tDrR9iQcQCws6HmWw/Qoi6YVfCLo5ePEpoQGiVuqlXhcmCQGudqLU+YHx8GTgKXH1b3CBgmS72J+CqlPIyVU2V9e6edzmTcYb3er1HA/sGJt/ftG7T8K3vK6OUCiFYELGAJk5NGNhyYI3ts0baCJRSfkBnYM9VL3kDZ0s9j+fvYYFSapxSKkwpFZacnGyyOgF+jfmVn0/9zLhO4wjxDDHpvq5wsnViVu9ZpGSn8Nafb0mXUiEsVHhSOGEXwhjZYSS21rY1tl8bU+9AKeUMrAL+T2udUZVtaK3nA/MBunbtarJ3ybOXz/LWn28R3DiY8UHjTbWbMgW4BzCx80Q+PvAxvbx7Maj1oBrdv6gbsgqyiM2IJd+QT74hnzxDHgWGAvIMecWPi4ofl349vyj/r88N+eQX5f9tvdLf62jjyMP+D/NY28dq5KxYFFsYsZAG9g14pM0jNbpfkwaBUsqW4hBYrrX+sYxVzgG+pZ77GJfVuIKiAqZtm4ZCMav3LGysTJ6RfzO642h2ntvJu3vepXOTzjRzaVbjNYjaKy4jjtCNoSRlJ1X6e2ysbLC3tsfe2h5bK1vsre2xs7bDztqu+LGVHc62zn9bdvbyWT45+AlfRnzJw/4PM7zDcJo6NzXh0YkTl06wNX4rE4Im4GTrVKP7Ntm7nSpuYV0IHNVaf3iN1dYAzyilvgW6A+la60RT1VSez8M/53DKYT644wOz/cJbW1nzXq/3GLxmMNO2T2PpvUuxtaq500NRe10JgQJDAbN7z6aBfQPsrOz+8sZe8kZubYedVfFzK1X1q7/HLx5nadRSvj32Ld8c+4a+fn0Z3XE07Ru1r8YjE1csjFyIo40jQ9sPrfF9K1Ndj1ZK3Q5sByKAIuPil4FmAFrrecaw+AzoD2QDo7XW5Xad6dq1qw4Lq97eNXsS9/DkpicZ7D+Y1299vVq3XRUbYzfy4h8v8mTgkzx7y7PmLkeYWekQWNBvAW0atqnR/Z/POs/XR75m5YmVZBVk0d2rO6M7jubWprfWSB93SxB/OZ6BqwcyrP0wpoRMMck+lFL7tdZdy3ytrjVMVncQXMq9xMNrHsbZzplv7/u2xk/JrmXGzhn8fPJnFvVbRFfPMv/vhAWIy4gjdEMoBUXmCYHSMvIzWBm9kuVHlpOUk0Sbhm0Y1XEU/Vv0lzPXG/T2n2+z6sQqNgzegEc9D5Pso7wgsOg7i7XWvLbzNdLy0pjde3atCQGA6d2m41vfl5d3vExGfpXa2EUdV5tCAMDFzoXQgFDWP7yeN299E0ORgZd3vMyAHwewNGopWQVZZq2vrkrJSWH1idUMajXIZCFQEYsOgm+OfcPW+K280PUF2rm1M3c5f+Fk68T7vd4nOTuZt3ZLl1JLUzoEFvZbaPYQKM3O2o6H/B/ix0E/MrfPXHycffgg7APu+eEe5uyfc12N2aJ4KJtCXcjogNFmq8Fig+D4xeP8O+zf9PbpzdB2Nd84UxmBjQOZEDyBDbEbWBuz1tzliBpydQhU9zhX1cVKWdHbpzeL+y/mm/u+oWfTniyJWkK/Vf2YsXMGp9JOmbvEWi8jP4Pvjn/HPc3voblLc7PVYZFBkFOYw0vbXsLF3oW3bnurVjd4hQaE0sWjC+/8+Q5nM85W/A2iTotNj60TIXC1APcA/n3nv1n34Doe8X+EDac38ODPDzLxvxPZd36fnNFew/fHvyerIMuk01BWhkUGwex9szmdfpp3b38XNwc3c5dTLmsra967vXhqzGnbp8kopTex2PRYxmwcQ6EurFMhUJqviy+v9HiFTY9sYkLwBCKSIwjdGMrQX4ayMXYjhiKDuUusNXILc/nqyFfc5n2b2bvkWlwQbIrdxMrolYwOGF0j43xXBy9nL17r+RqHUw7zxaEvzF2OMIHSIbCg74I6GQKlNXRoyNNBT7PpkU3M6DGDjPwMXvzjRQauHsg3x74hpzDH3CWa3eqTq7mYe7FGJp6piEV1H03MTOThtQ/j5+JXJ2/WenXHq6yNWcuifovo4tHF3OWIahKbHkvoxlAM2nBThEBZDEUGtpzdwuLIxRxOOYyrvSuPt3uckR1G4mznbO7yalxBUQEDfxxIE6cmLLt3WY1cnpbuo0BhUSHTtk+jSBcxq9esOhcCANO7T8fb2Zvp26dLl9KbhCWEABRf4vxH83/w9YCvWdJ/CcGNg5l3aB6jN44mJSfF3OXVuA2nN5CQlcCYwDG1oo3SYoLgp5M/cSDpAK/2eBVfF9+Kv6EWqmdbj/d7vU9SdhIvb39Zhqyu4ywlBEpTStHFowuf9vmU//zjP8RlxDFi/QjOXracjhBFuoiFEQtp7dqa3j69zV0OYEFB8GDrB5lz55waHePbFDo17sSUkClsP7ed+1bfx7fHvqWwqNDcZYnrVDoEFvatmw3DN+p279tZ0HcBGfkZjFg/guMXj5u7pBqx9exWTqWfYkzgmBsaC6o61Y4qaoCNlQ3/aP4Pc5dRLYa1H8YP9/9A24ZteWfPOzy27jH2nd9n7rJEJZ1OP/2XEGjdsLW5SzKbTo07saz/MqyVNaM3jGb/hf3mLsmkrkxD6e3sTX+//uYup4TFBMHNpk3DNizou4AP7/yQrPwsQjeG8vzW50nITDB3aaIcp9NPM2bjGAmBUlq6tuSre7/C3cmdpzY/xZYzW8xdksnsO7+PwymHGd1xtFmGur8WCYI6TCnFPc3v4ecHf2Zi8ES2x2/ngZ8e4LODn0n3vFpIQuDavJy9WNp/KW0atuG5rc+x+sRqc5dkEgsiFtDIoREP+j9o7lL+QoLgJuBg48D4oPGsfWgtdze7my8Of8H9q+9n/en1ckdnLSEhULGGDg1Z0HcB3b2689qu11gUucjcJVWrqNQodifuZniH4dhb25u7nL+QILiJeNbzZHbv2SztvxQ3Bzde2vYSozaM4mjqUXOXZtEkBCrPydaJz+7+jHv97mXO/jn8O+zfFOmiir+xDlgYsZD6tvUZ0naIuUv5GwmCm9AtHrfwzX3fMLPnTE6nn2bIuiG8sfsNLuZeNHdpFqd0w/CifoskBCrB1tqW93u/zz/b/ZMlUUuYsXNGnR9aJSY9ht/ifuPxdo/XyhvoJAhuUtZW1jzS5hHWDV7HsPbD+OnETwxcPZCvj3xd5/+o6oorIVCki1jUbxGtXFuZu6Q6w0pZMb3bdCYGT2TNqTU8t+W5Ot3utThyMXbWdgxrP8zcpZRJguAm52LnwtRuU1n1wCoC3QOZtW8Wj655lF0Ju8xd2k0tJj1GQuAGKaUYHzSeGT1msC1+G09tfqpO3kR5Pus8606tY7D/YBo5NjJ3OWWSILAQLV1bMu8f8/jkrk/IL8rnqc1P8ezvz8rQ1iYQkx7DmI1j0FpLCFSDx9o+xgd3fEBkSiSjNoyqcxPfLI1aikYzquMoc5dyTRIEFkQpxV3N7uKnQT8x+ZbJ/Jn4J4N+HsTHBz4muyDb3OXdFEqHwMJ+CyUEqklfv758/o/PSchMYPivw4lNjzV3SZVyKfcSq06sYkCLATR1bmrucq5JgsAC2VnbMTZwLOseWkd/v/4siFjA/avvZ+2ptdLd9AZICJhWD68eLOq/iFxDLiM3jCQqNcrcJVVoxbEV5BTmEBoQau5SyiVBYMGaODXh3V7v8vWAr2ni1ISXd7zM8PXDiUqp/X9gtUmRLuLXmF8J3RAqIWBiHRt1ZGn/pThYOxC6IZQ9iXvMXdI1ZRVkseLoCu7yvavW9xaTIBAENQ5i+X3LefPWN4m/HM8/f/knr+18zSKHB75e+87vY+gvQ5m6fSruju7SJlAD/Br48dWAr2jq3JSnf3uazXGbzV1SmVZGryQjP4OxgeafeKYiFjUxjahYZn4m8w/P56ujX+Fg7cBHd31Ed6/u5i6r1olJj2HO/jlsPbsVDycPnr3lWQa2HFhrRpO0BOl56Tzz32c4lHyIV3u8ymNtHzN3SSXyDfncu+pe/Br4sbDfQnOXA8jENOI6ONs583zX51n9wGo863ky6fdJHLhwwNxl1RopOSm8/efbDP55MPvO72PyLZNZ99A6Hmj1gIRADWtg34D5fefTy6cXb/35Fl8c+qLWtHGtObWGpJwkxgSad1L6ypIzAnFNKTkpjN4wmuScZObfM59OjTuZuySzySnMYVnUMhZFLiLfkM8jbR5hfND4Wtsv3JIUFBUwc+dM1sasZWi7oUztNtWsoWwoMvDATw/gbOfMt/d9WytmIAM5IxBV5O7ozoK+C3BzcGP85vEcST1i7pJqnKHIwOoTqxn440A+C/+Mnk17snrQal7p8YqEQC1ha2XL27e/zYgOI1hxbAXTtk+jwGC+u+c3x23mzOUzjA0cW2tCoCISBKJcHvU8WNh3IfXt6jNu8ziiL0Wbu6Qas+vcLh5b9xiv7XoNj3oeLO2/lI/u+gi/Bn7mLk1cxUpZ8WLXF3muy3OsP72eZ35/xiz3xmitWRCxAD8XP/o061Pj+68qCQJRIS9nLxb0W4C9tT1PbnqSmLQYc5dkUscvHuepzU/x1G9PkVWQxb96/4vlA5Zzi8ct5i5NlEMpRWhAKG/e+iZ/Jv7J2E1juZR7qUZr2HFuB8cvHSc0ILROtRnVnUqFWfnW92Vh34UoFGM3jeVMxhlzl1TtLmRdYMbOGTy69lEiUyKZ0nUKax5cQ/8W/evMKb6Ah/wfYs6dczh+8TgjN4zk7OWaG0ZlQcQCPJw86tzc6NJYLK7LyUsnCd0Yir2NPUv6L8Hb2dvcJd2wrIIsFkYs5KsjX2HQBoa2G8qTnZ6kgX0Dc5cmbkDY+TAm/T6JzIJMmjg2wb+hP20atin5t0WDFthZ21Xb/g4mHWTE+hFMDZnKEx2eqLbtVpfyGoslCMR1O37xOKEbQ6lvV58l/ZfgWc/T3CVVSUFRAT9G/8jnhz7nYu5F7vW7l2dveRaf+j7mLk1UkzMZZ9hydgvRl6I5cekEJ9NOlgzDbqNs8GvgVxIMV748nDyqdAY48b8TOZx8mI0Pb8TJ1qm6D+WGSRCIaheVEsXYTWNp5NiIxf0W09ipsblLqjStNVvPbuXD/R8SmxFLF48uvNj1RQLcA8xdmjCxwqJC4jLiOHHpREk4RF+KJiEroWSd+rb18W/o/5eAaO3autwJZY5fPM4jax9hQvAEng56uiYO5bpJEAiTCE8KZ9zmcXjV82JRv0V1ojtlZEokH4R9wP4L+/Fz8eO5Ls9xl+9d0gZg4S7nX+Zk2kmiL0YXB0RacUBkFWSVrOPt7P2XcPBv6E+z+s2wsbLhpW0v8cfZP9j0yKZae0lRgkCYzL7z+5jw2wSauTRjUb9FtfaP4FzmOT4+8DHrT6/HzcGNCUETGNxmMLZWtuYuTdRSWmsSsxKJvhT9l7OHuIw4DNoAgL21PS0btOT4peMMbz+cF0NeNHPV1yZBIExqd8JunvnvM7Ru2Jov+36Ji52LuUsqkZ6XzoKIBSw/uhwrZcWIDiMIDQitlfPGirohz5BHTFrMX8IhPT+dz+7+rFZfIpUgECa3LX4bk7dMpkOjDsy/Zz71bOuZtZ4CQwHfHf+OeYfnkZGXwf2t7mdS50l1tmFbiBslQ0wIk+vt05sPen9AVEoUE36bYLYZz7TW/Bb3Gw/+/CCz9s2inVs7vr//e965/R0JASGuwWRBoJRapJRKUkpFXuP1O5VS6UqpcOPXa6aqRdSMPs378H6v9wlPDufZLc+SW5hbo/s/nHyYURtG8dzW57C1smVun7l8ec+XtHNrV6N1CFHX2Jhw20uAz4Bl5ayzXWtdt27BE+Xq36I/BUUFvLLjFZ7f+jwf3fVRtd60U5b4y/F8cuAT1scWNwS/1vM1Hmr9EDZWpvz1FuLmYbK/FK31NqWUn6m2L2qv+1vdT54hjzd2v8GUP6bwwZ0fmKR3TkZ+Bl8e/pLlR5djrawZ12kcoQGhZm+fEKKuMfdHpp5KqUNAAvCi1rrMyXKVUuOAcQDNmjWrwfJEVT3S5hHyDfm8t/c9pm+fzvu93q+2T+gFhgK+j/6e/xz6jzQEC1ENzBkEB4DmWutMpdQA4CfAv6wVtdbzgflQ3GuoxioUN2Ro+6EUFBXwQVjxGcHbt72NtZV1lbenteb3M7/z4f4POXP5DN09u/NC1xdo36h9NVYthOUxWxBorTNKPf5VKfW5Uspday0zpt9ERnYcSZ4hj08Pfoq9tT2v9XytSsPzRiRH8EHYBxxIOkDLBi2Z22cuvbx7yR3BQlQDswWBUsoTuKC11kqpbhT3YEo1Vz3CdMZ1Gke+IZ8vDn+BrZUtL3d/udJv4Ocyz/Hx/o9LGoJn9JjBYP/B0hAsRDUy2V+TUuob4E7AXSkVD8wEbAG01vOAR4CnlVKFQA7wuK5rd7eJSpsYPJF8Qz6LoxZjZ23Hi11fLDcMMvIzWHB4AV8f/RorZcWTgU8yJnCMNAQLYQKm7DX0zwpe/4zi7qXCAiileK7Lc+QZ8lh2ZBn21vZM6jzpb2FwpSF43qF5pOelS0OwEDVAzq9FjVFKMa3bNPKL8vky4kvsrO0YHzQe+F9D8JwDc4jLiJOGYCFqkASBqFFKKWb0mEG+IZ+54XOxs7YjxCNEGoLNoKCggPj4eHJza/YOcGFaDg4O+Pj4YGtb+Xt3JAhEjbNSVrx565sUGAqYs38OgDQEm0F8fDz169fHz89PQvcmobUmNTWV+Ph4WrRoUenvk784YRbWVta80+sd3BzdcLZ1ZlTHUTI0dA3Lzc2VELjJKKVo1KgRycnJ1/V9EgTCbGytbJnWbZq5y7BoEgI3n6r8n8ow1EIIYeEkCIQQZuPsLJcDa4NKXxpSSt0K+JX+Hq11eUNMCyGEqAMqdUaglPoK+AC4HQgxfpU55ZkQQlwvrTVTpkwhICCAwMBAvvvuOwASExPp3bs3wcHBBAQEsH37dgwGA6NGjSpZd86cOWauvu6r7BlBV6CDDAEhxM3pjbVRHEnIqHjF69ChqQsz7+9YqXV//PFHwsPDOXToECkpKYSEhNC7d29WrFhBv379eOWVVzAYDGRnZxMeHs65c+eIjCye/DAtLa1a67ZElW0jiATkHn8hhEns2LGDf/7zn1hbW+Ph4cEdd9zBvn37CAkJYfHixbz++utERERQv359WrZsSUxMDJMmTWLDhg24uLiYu/w6r7JnBO7AEaXUXiDvykKt9QMmqUoIUaMq+8m9pvXu3Ztt27bxyy+/MGrUKJ5//nlGjBjBoUOH2LhxI/PmzeP7779n0aJF5i61TqtsELxuyiKEEJatV69efPHFF4wcOZKLFy+ybds2/vWvfxEXF4ePjw9PPvkkeXl5HDhwgAEDBmBnZ8fDDz9M27ZteeKJJ8xdfp1XqSDQWv+hlGoO+Gutf1NKOQFVn2pKCCFKeeihh9i9ezdBQUEopZg9ezaenp4sXbqUf/3rX9ja2uLs7MyyZcs4d+4co0ePpqioCID33nvPzNXXfaoy7b9KqScpnjPYTWvdSinlD8zTWvcxdYFX69q1qw4LC6vp3Qpx0zl69Cjt28vorjejsv5vlVL7tdZl9vasbGPxROA2IANAa30CaHIDdQohhKglKhsEeVrr/CtPlFI2gHQlFUKIm0Blg+APpdTLgKNS6h7gB2Ct6coSQghRUyobBNOAZCACeAr4VWv9ismqEkIIUWMq3X1Ua/0a8CWAUspaKbVcaz3MdKUJIYSoCZU9I/BVSk0HUErZAauAEyarSgghRI2pbBCEAoHGMFgH/KG1ft1kVQkhhKgx5QaBUuoWpdQtQGfgY2AIxWcCfxiXCyFErREbG0tAQECVv7+8+RFudNu1WUVtBP++6vkloINxuQbuNkVRQgghak65QaC1vqumChFCmNH6aXA+onq36RkI975f7iqxsbH079+fHj16sGvXLkJCQhg9ejQzZ84kKSmJ5cuXAzB58mRyc3NxdHRk8eLFtG3blqioKEaPHk1+fj5FRUWsWrUKW1vbkm3HxMTw8MMPM3/+fNzc3Jg4cSLJyck4OTnx5Zdf0q5dO06fPs3QoUPJzMxk0KBBlT603Nxcnn76acLCwrCxseHDDz/krrvuKrOmpk2b8thjjxEfH4/BYGDGjBkMGTKkaj9TE6lUryGlVANgJtDbuOgP4E2tdbqpChNCWIaTJ0/yww8/sGjRIkJCQlixYgU7duxgzZo1vPvuuyxbtozt27djY2PDb7/9xssvv8yqVauYN28ekydPZtiwYeTn52MwGLhw4QIAx48f5/HHH2fJkiUEBQXRp08f5s2bh7+/P3v27GHChAn8/vvvTJ48maeffpoRI0Ywd+7cStc8d+5clFJERERw7Ngx+vbtS3R0dJk1/frrrzRt2pRffvkFgPT02ve2Wdnuo4sonpPgMePz4cBiYLApihJC1LAKPrmbUosWLQgMDASgY8eO9OnTB6UUgYGBxMbGkp6ezsiRIzlx4gRKKQoKCgDo2bMn77zzDvHx8QwePBh/f38AkpOTGTRoED/++CMdOnQgMzOTXbt28eijj5bsMy+veDT9nTt3smrVKgCGDx/O1KlTK1Xzjh07mDRpEgDt2rWjefPmREdHl1lTYGAgL7zwAlOnTmXgwIH06tWren5w1aiyvYZaaa1naq1jjF9vAC1NWZgQwjLY29uXPLaysip5bmVlRWFhITNmzOCuu+4iMjKStWvXkpubC8DQoUNZs2YNjo6ODBgwgN9//x2ABg0a0KxZM3bs2AFAUVERrq6uhIeHl3wdPXq0ZJ9KqWo7lrJqatOmDQcOHCAwMJBXX32VN998s9r2V10qGwQ5SqnbrzxRSt0G5JimJCGE+J/09HS8vb0BWLJkScnymJgYWrZsybPPPsugQYM4fPgwAHZ2dqxevZply5axYsUKXFxcaNGiBT/88ANQPD/yoUOHALjtttv49ttvAUraIyqjV69eJetHR0dz5swZ2rZtW2ZNCQkJODk58cQTTzBlyhQOHDhwwz+T6lbZIBgPzFVKxSqlYoHPKB5qQgghTOqll15i+vTpdO7cmcLCwpLl33//PQEBAQQHBxMZGcmIESNKXqtXrx7r1q1jzpw5rFmzhuXLl7Nw4UKCgoLo2LEjP//8MwAff/wxc+fOJTAwkHPnzlW6pgkTJlBUVERgYCBDhgxhyZIl2Nvbl1lTREQE3bp1Izg4mDfeeINXX321+n441aSy8xG00FqfVkq5AGitM64sM3mFV5H5CISoHjIfwc3LVPMRrILiANBaZxiXraxylUIIIWqNcnsNKaXaAR2BBkqp0j2EXAAHUxYmhBDmEBERwfDhw/+yzN7enj179pipItOrqPtoW2Ag4ArcX2r5ZeBJE9UkhBBmExgYSHh4uLnLqFEVBYET8CIwX2u9uwbqEUIIUcMqCoJmFM9GZquU+i+wHtirK9PCLIQQok4ot7FYaz1La303MAA4RPFw1AeUUiuUUiOUUh41UaQQQgjTqdQQE1rry8Bq4xdKqQ7AvcAyoJ/JqhNCCGFyFc1H8ESpx7ddeay1PgLkaa2vGQJKqUVKqSSlVOQ1XldKqU+UUieVUodlfgMhRHnKmyvAFLZu3crAgQOr9L0VzV1wI9s2hYruI3i+1ONPr3ottILvXQL0L+f1ewF/49c44D8VbE8IIYQJVHRpSF3jcVnP/0JrvU0p5VfOKoOAZcaG5z+VUq5KKS+tdWIFNQkhqtmsvbM4dvFYtW6znVs7pna79mie06ZNw9fXl4kTJwLw+uuvY2Njw5YtW7h06RIFBQW8/fbblZonYOvWrcycORNXV1ciIiJ47LHHCAwM5OOPPyYnJ4effvqJVq1asXbtWt5++23y8/Np1KgRy5cvx8PDgz/++IPJkycDxYPQbdu27S/b37dvH+PGjWPlypWkpaXx/PPPk5mZibu7O0uWLMHLy4v9+/cTGlr8+bhv376V/jldvHiR0NBQYmJicHJyYv78+XTq1KnMmjIzMxkyZAgZGRkUFhbyn//8p1pGM63ojEBf43FZz6+XN3C21PN447K/UUqNU0qFKaXCkpOTb3C3QojaYMiQIXz//fclz7///ntGjhzJ6tWrOXDgAFu2bOGFF16gsp0UDx06xLx58zh69ChfffUV0dHR7N27l7Fjx/Lpp8UXNG6//Xb+/PNPDh48yOOPP87s2bMB+OCDD5g7dy7h4eFs374dR0fHku3u2rWL8ePH8/PPP9OsWTMmTZrEypUrS974X3nlFQBGjx7Np59+WjKgXWXNnDmTzp07c/jwYd59992SMZPKqmnFihX069eP8PBwDh06RHBw8HXt61oqOiNop5Q6TPGn/1bGxxif19gw1Frr+cB8KB5rqKb2K4SlKO+Tu6l07tyZpKQkEhISSE5OpmHDhnh6evLcc8+xbds2rKysOHfuHBcuXMDT07PC7YWEhODl5QVAq1atSj6VBwYGsmXLFgDi4+MZMmQIiYmJ5Ofn06JFC6B4FNLnn3+eYcOGMXjwYHx8fIDiMXvGjRvHpk2baNq0KZGRkURGRnLPPfcAYDAY8PLyIi0tjbS0NHr3Lp67a/jw4axfv75SP4cdO3aUzIlw9913k5qaSkZGRpk1hYSEEBoaSkFBAQ8++GC1BUFFZwRBwASK7y5uT/HdxfcDTxtfuxHnAN9Sz32My4QQFuLRRx9l5cqVfPfddwwZMoTly5eTnJzM/v37CQ8Px8PDo2T+gYpUNK8BwKRJk3jmmWeIiIjgiy++KNn2tGnTWLBgATk5Odx2220cO1Z8mczLywsHBwcOHjwIFA9h3bFjx5J5DSIiIti0aVO1/TxKK6um3r17s23bNry9vRk1ahTLli2rln1VFARzgHStdVzpLyDd+NqNWAOMMPYe6mHcj7QPCGFBhgwZwrfffsvKlSt59NFHSU9Pp0mTJtja2rJlyxbi4uKqdX+l5zZYunRpyfJTp04RGBjI1KlTCQkJKQkCV1dXfvnlF6ZPn87WrVtp27YtycnJ7N5dPNBCQUEBUVFRuLq64urqWjIZTlXnNti6dSvu7u64uLiUWVNcXBweHh48+eSTjB07ttrmNqgoCDy01n+b0dq4zK+8b1RKfQPsBtoqpeKVUmOUUuOVUuONq/wKxAAngS8pPvMQQliQjh07cvnyZby9vfHy8mLYsGGEhYURGBjIsmXLaNeuXbXu7/XXX+fRRx+lS5cuuLu7lyz/6KOPCAgIoFOnTtja2nLvvfeWvObh4cG6deuYOHEiBw8eZOXKlUydOpWgoCCCg4PZtWsXAIsXL2bixIkEBwdXul3jSk379++nU6dOTJs2rSSgyqpp69atBAUF0blzZ7777ruSxuQbVe58BEqpE1pr/2u8dlJr3bpaqrgOMh+BENVD5iO4eVX3fARhSqm/jTKqlBoL7K9ylUIIIWqNinoN/R+wWik1jP+98XcF7ICHTFiXEEL8TV2bK2Djxo1MnfrXHlktWrRg9erVZqqobOUGgdb6AnCrUuou4Mr90r9orX83eWVCCJPTWqNUufeG1ip1ba6Afv360a9fzQ7HVpXBoSs76NwWYMt1b10IUWs5ODiQmppKo0aN6lQYiGvTWpOamoqDw/VNIFmpIBBC3Hx8fHyIj49H7ta/uTg4OJTcEFdZEgRCWChbW9uSO2uFZauo15AQQoibnASBEEJYOAkCIYSwcBIEQghh4SQIhBDCwkkQCCGEhZMgEEIICydBIIQQFk6CQAghLJwEgRBCWDgJAiGEsHASBEIIYeEkCIQQwsJJEAghhIWTIBBCCAsnQSCEEBZOgkAIISycBIEQQlg4CQIhhLBwEgRCCGHhJAiEEMLCSRAIIYSFkyAQQggLJ0EghBAWToJACCEsnASBEEJYOAkCIYSwcBIEQghh4SQIhBDCwkkQCCGEhZMgEEIICydBIIQQFs6kQaCU6q+UOq6UOqmUmlbG66OUUslKqXDj11hT1iOEEOLvbEy1YaWUNTAXuAeIB/YppdZorY9ctep3WutnTFWHEEKI8pnyjKAbcFJrHaO1zge+BQaZcH9CCCGqwJRB4A2cLfU83rjsag8rpQ4rpVYqpXzL2pBSapxSKkwpFZacnGyKWuuUlPNnObpnI3m52eYuRQhxEzDZpaFKWgt8o7XOU0o9BSwF7r56Ja31fGA+QNeuXXXNllh76KIi9q/7gjYH3qQ92WT/as8hpyBymt1J0y734du6E8qqbrX/5+flYmtrV+fqFuJmYsogOAeU/oTvY1xWQmudWurpAmC2Ceup0y4mnSN26Xi6Zm3jqG0HTgSPofD0TrxTd+NzfDYcn00ijTnj1hPbtn1p3X0ALq6NzF3231yIP0X8oS0Uxu7G7WI4LQpjOGHbmnpDl+DdsqO5yxPCIimtTfMBWyllA0QDfSgOgH3AUK11VKl1vLTWicbHDwFTtdY9yttu165ddVhYmElqrq3CN6/Ad+c06ussDrSaQMjQmVjb/C/Dz8UcJT5sLXaxW/DPOoizyqFQW3HCrj1pTXvRKGgArYNux8raukbrLizIJ/bIXlKObMM2YR/elw/jSQoA2dqe0/btuOzajg5J67DSRRzv9jZd7pOOY0KYglJqv9a6a5mvmSoIjDseAHwEWAOLtNbvKKXeBMK01muUUu8BDwCFwEXgaa31sfK2aUlBcDn9IkcXT6Rb2q+csm6B1eAvaNGxe7nfU5Cfx4n9v5MeuQH38zvwN5wE4BL1iakfgqHl3bTs/gDuTZtXe70ZaanEHtxC9qldOCfvp2XuUZxUHgBJuHHWuRMF3t1o1L43fh26YWtnD0Bi3HHSvxpJu8Kj7G04kMCx83CsV7/a6xPCkpktCEzBUoIgatevuG16liY6hb0+I+kyYhZ29g7XvZ2LSeeI2bMOffI3WqTvxZ00AGKs/EhqchvOHfvhH3IP9g5O17VdXVREQuxREiL+oOjMnzS5FE5zwxmslMagFadtWpLaMBjrFj3xCbwTz2b+5W6vID+PsCVT6H5uGWesfdCPLKZFh5DrPl4hRNkkCOqQ3Jwswpe8QLfz35Jg5UnmgM9oF/KPatl2kcHA6ag9JIWvxyX+D/zzIrFTBrK1PScqaHTOy83mdMQu0o7vwD5xH75ZkSWhclk7ctqxI1keXanf+lZaBN9BvfquVaoxYttqvH7/P5x1FocCptPt4eekIVmIaiBBUEecCN+O3ZqnaV50lj3ugwkc9RFOzg1Mtr+sy2mc2LuBvKObaJq6G1+dAFDS6Kx8u2FIOoZrykFa5kdjrwoAOKc8SHAJosinO0069KJZ2y5/abO4USnnz5KwZCSdcvdzwPkOWo1ZRIOG7tW2fSEskQRBLVeQn0fY1zPoGreAS6oBF+76N4F3DK7xOhJOH+PsviuNzgdwVjnka2tO2/pzqVFn7Fv2xDfoLtw9m5m8liKDgT3LXyfk1GckWblz+b4vaNv1bz2LhYkUFuRjY2tn7jJENZIgqMXijoeT98OTtCmMJszlH/iPmkcDt8bmLouC/DzOnYrA0689Do71zFbHsX2/0eCX8bjri+xv/Qzdhs6s8d5PN7vszHROH97J5VN/Ynf+IN5ZUTTWF0m0akKyY0tyXP2x9eyAa/NAfPyDcXByNnfJogokCGqhIoOBvd+/T/CxOeQoB2K6vUWXAaPNXVatlH4phVMLRnNL1jYOO4TgPXoJjTx8zF1WnWQoLORM9EGSj+6Ec2G4p0XQ3BCHtSp+HzinPEh0DqDAxRe79FgaZcfQ1HAOO2UAoEgrEqw8SHZsSa5ra2NAdMLHP0gCopaTIKhlzp85QerXY+iYf4hwxx74jPyyRi631GW6qIi9K/9NcNQsLqt6nO/zCQG9ZOiqiqQkxHE2cju5sXtwSTlE87xonFUOABnUI9ahHdnuwTi27IZvQC/cmvx9FJiC/DwSTkWSGnuYvMQj2F88jlt2DN6GBGyNAWHQikQrT5IdW5BrPINo6NcJb/8gs55Riv+RIKgldFERYWs+p93Bt7FCE9VpOiEPPSu9Yq5DTOQerH8Mxddwjj0+owgZNVuuZRvlZF3mdMROMk7uxu78AZpmHim5ga9AWxNr04KLDTth5dMVjw634dMq8IYus+Xn5ZIYE0XK6cPkJ0Zhf+k4btmnrx0QDdsYAyII79aBEhA1TIIAiNyxhvq/v0yyc1sKmwTi3KILvh161lhvlNQL8ZxZOo7O2Ts5YhuA69CFNG3Rrkb2fbPJzkwncsF4uqX9ylHbDjQcvqzC+xRuNkUGA2ejw7lwbCc63niJpzAWG1UEQILyING5AwWet+Dq3xO/gJ41dukmPy+XhJhIUk8fIj/xKPaXjtMo+zRNrwqIBCsvUh2akevih2rUCifPtrg3b4eHT2tpBzIBCQLg2J5N5Pwxh6bZx/Hgf0McnVMeXKjXlnz3QJya34J3hx7Vfv354Kavab5rOs46mwP+kwh5/NVq7W5pqcLWfkH7sNcoVNbE3Dqbzn2fMHdJN8RQWEhmxiWy0lPJzkgh9/JFCrIuUZiVhiEnDZ2ThlVuOvUun6J57nHql1zicSLOvh2ZjYNxbNEd34Dba2Ubyl8D4gj2F6NxzTmDlyEBR5Vfsl6utuW8tReXHHzJc/HDyr019bza0tivA429mssZdBVJEFwl9UI8547uISvuAPbJETTJOo6PPl/yehJuJDi2Icc9AAffzni1646HT6vr/gXMSEvl+OIJhKRv4KR1K2wemY9f+zL/H0QVxZ+MJOebkfgbTrKn8SMEhX5itksOuqiIzMtpxjfyi+RkpJKfeZHC7DQM2Wno3HRUbhrWeRnYFGRgV3gZB0Mm9QyZ1NOZJW/s11KkFZeVE8nWnqS6BmLlG0KT9rfj2/rGLvGYW5HBQHJiLMlxR8hKiEannsI+4zQNc8/S1JCInSosWTdb25No05R0R1/yXFpg3bg19Zu2pXHzDjRq4i0hUQ4JgkrISEvl7JE9XD4dhs2Fw7hnHsPXEF/Sm+IS9Ym39yfTLQA7nyCatO2Od4sO1/wDjNyxBvffnsNdXyTMdzS3DH+3SkNEiIrl5+VyYNFkelz4llPWLbF7fAm+/kEm258uKiI1KZ7E42FknT2EdfIR3DJP4Ft49i9vWmW5rB3JUs5kW9Ujx6Y++Tb1KbR1wWDvgrZvgHJ0xdrJFRsnV+yc3XCo70a9Bo2Kv5wb1Ok3/KowFBZyIf4UqWeOkJ1YHBKOl2Nxyz2LZ9GFkktNUPyzPW/jTYZTMwoaGEPCuy1erYLkhkQkCKosJ+sycUf3kn4qDHX+MG4ZR2lWGFvSlS5TO3LGvjUZru2xbhqMe5tuNPZpTeTXL9Ej6XvOqqZk3zdXboSqIeH//Zbm21/EXucT1XkmIQ9OvOFt5uZkER99kIsxByk6H4lz2jGa5sXgRkbJOkm4kejQihzXNuDcBGunhtjUc8W2XkMc6rvhWL8Rzq7uOLs0lEuC1aiwIJ/zcdGknj1KzvloVOopHDPjaJR3Fs+ipJIPcQAXaMR5h5ZkN2yPrVdH3Fp2xsc/yKI+nEkQVKP8vFzOHNvPpVNhFCWE0yDtKM0KYkpG2bxiT+NH6DTqIxlFs4YlnTtN8tLhdMyPYF+DvnQY+2Wlxj3SRUVcOBfD+egwcs8exjb1CO5ZJ/E2nCtpgM3Rdpy19SOtvj9FTTpSv1kw3m274OruaeKjEtcrPy+XxNhjXDp7lJyEI9imHMEt8yQ+hrMlH+QKtDXnrL1JrdeafPf2OPp0wqN1Zzx9/WvNJaYig4GLyQmkXThDZspZGni2qHAE4muRIDAxQ2Eh8ScPkxy9l4LzUdTv2JeA2+43d1kWy1BYyN5l0+kW9yUJVl7kPbiA1kG3lbyedTmN+OMHSI8NR5+PpH5GND75MbiQVbJOgmrCBcfW5Lq1w65pJxq37ox3ywD5RF/HXbljPuXUAQoSInG8dByPnFN48b8pcC9rR87ZtSDdpQ006UD95kF4t+1a7ZeXcrMzSUmIJT3pDDmpZylMOweXE7HLPo9TbjKuhSm46YslwQXwp+cweoz/vEr7kyAQFilq16803jQRV53BwcYPYJuTTJPskzQtOo+V8bJBlnbgrF3L4j96j440aB5M07ZdauXsbsJ0MtJSSTi+n/S4Q5B0hPrp0fgUnP7Lh4PKXl4qMhi4lJLIpfNxZKacJe9iPDo9AavMRBxyk6ifn4xbUQoNSm37iiztQKp1Iy7buJPj0ISCel4oFy/s3bxxauRLk+btadjYq0rHKEEgLNal5ERiF4fSKWs3CVZeJNdrTV6jDjh4B+Lh3xXPZv4W1wArKufK5cILJw6QHR9R7uWlSw4+OBak0aAgmUZXfYqH4h5fqcqVNBt3Mu0ak+/kiXb2wtq1KQ5uvrg08cXNy4/6DdxMdjwSBMLiyWiaoroU5OcRf/IwqTEHSy4vNchLJNvGtcxP8a6ezWnk4Wv237/ygkAueAqLYO4/QnHzsLWzp0WHkJtqBr3a0TQuhBDCbCQIhBDCwkkQCCGEhZMgEEIICydBIIQQFk6CQAghLJwEgRBCWDgJAiGEsHASBEIIYeEkCIQQwsJJEAghhIWTIBBCCAsnQSCEEBZOgkAIISycBIEQQlg4CQIhhLBwEgRCCGHhJAiEEMLCSRAIIYSFkyAQQggLZ9IgUEr1V0odV0qdVEpNK+N1e6XUd8bX9yil/ExZjxBCiL8zWRAopayBucC9QAfgn0qpDletNga4pLVuDcwBZpmqHiGEEGUz5RlBN+Ck1jpGa50PfAsMumqdQcBS4+OVQB+llDJhTUIIIa5iY8JtewNnSz2PB7pfax2tdaFSKh1oBKSUXkkpNQ4YZ3yaqZQ6XsWa3K/edh0mx1I73SzHcrMcB8ixXNH8Wi+YMgiqjdZ6PjD/RrejlArTWnethpLMTo6ldrpZjuVmOQ6QY6kMU14aOgf4lnruY1xW5jpKKRugAZBqwpqEEEJcxZRBsA/wV0q1UErZAY8Da65aZw0w0vj4EeB3rbU2YU1CCCGuYrJLQ8Zr/s8AGwFrYJHWOkop9SYQprVeAywEvlJKnQQuUhwWpnTDl5dqETmW2ulmOZab5ThAjqVCSj6ACyGEZZM7i4UQwsJJEAghhIWzmCCoaLiLukIp5auU2qKUOqKUilJKTTZ3TTdCKWWtlDqolFpn7lpuhFLKVSm1Uil1TCl1VCnV09w1VZVS6jnj71akUuobpZSDuWuqLKXUIqVUklIqstQyN6XUZqXUCeO/Dc1ZY2Vd41j+ZfwdO6yUWq2Ucq2OfVlEEFRyuIu6ohB4QWvdAegBTKzDxwIwGThq7iKqwcfABq11OyCIOnpMSilv4Fmgq9Y6gOKOHqbuxFGdlgD9r1o2Dfiv1tof+K/xeV2whL8fy2YgQGvdCYgGplfHjiwiCKjccBd1gtY6UWt9wPj4MsVvON7mrapqlFI+wH3AAnPXciOUUg2A3hT3gkNrna+1TjNrUTfGBnA03tvjBCSYuZ5K01pvo7gHYmmlh7JZCjxYkzVVVVnHorXepLUuND79k+L7s26YpQRBWcNd1Mk3z9KMo7V2BvaYuZSq+gh4CSgycx03qgWQDCw2XuZaoJSqZ+6iqkJrfQ74ADgDJALpWutN5q3qhnlorRONj88DHuYsphqFAuurY0OWEgQ3HaWUM7AK+D+tdYa567leSqmBQJLWer+5a6kGNsAtwH+01p2BLOrO5Ye/MF4/H0RxuDUF6imlnjBvVdXHeMNqne8zr5R6heLLxMurY3uWEgSVGe6izlBK2VIcAsu11j+au54qug14QCkVS/GluruVUl+bt6QqiwfitdZXzsxWUhwMddE/gNNa62StdQHwI3CrmWu6UReUUl4Axn+TzFzPDVFKjQIGAsOqayQGSwmCygx3UScYh+leCBzVWn9o7nqqSms9XWvto7X2o/j/43etdZ385Km1Pg+cVUq1NS7qAxwxY0k34gzQQynlZPxd60MdbfgupfRQNiOBn81Yyw1RSvWn+HLqA1rr7OrarkUEgbFx5cpwF0eB77XWUeatqspuA4ZT/Ak63Pg1wNxFCSYBy5VSh4Fg4F3zllM1xrOalcABIILi94g6M0SDUuobYDfQVikVr5QaA7wP3KOUOkHxGc/75qyxsq5xLJ8B9YHNxr/9edWyLxliQgghLJtFnBEIIYS4NgkCIYSwcBIEQghh4SQIhBDCwkkQCCGEhZMgEBZNKWUo1Q03vDpHplVK+ZUeObIS69dTSv1mfLzDONaPECYnv2jC0uVorYPNXYRRT2C3cZiHrFKDiwlhUnJGIEQZlFKxSqnZSqkIpdRepVRr43I/pdTvxvHg/6uUamZc7mEcH/6Q8evKsAzWSqkvjeP7b1JKOZaxr1ZKqXDga2AosB8IMp6hNKmZIxaWTIJAWDrHqy4NDSn1WrrWOpDiuzk/Mi77FFhqHA9+OfCJcfknwB9a6yCKxxm6cue6PzBXa90RSAMevroArfUp41nJfoqHTF8KjNFaB2ut6/S4OKJukDuLhUVTSmVqrZ3LWB4L3K21jjEO8ndea91IKZUCeGmtC4zLE7XW7kqpZMBHa51Xaht+wGbjhCgopaYCtlrrt69Ryz6tdYhSahUwWWsdX93HK0RZ5IxAiGvT13h8PfJKPTZQRrucUmqesVHZ33iJqD+wTin1XBX3KcR1kSAQ4tqGlPp3t/HxLv43deMwYLvx8X+Bp6FkHuYGld2J1no88AbwFsWzZ/1ivCw054aqF6KSpNeQsHSOxk/hV2zQWl/pQtrQOJpoHvBP47JJFM9ENoXiWclGG5dPBuYbR4g0UBwKiVTeHcAyoBfwR1UORIiqkjYCIcpgbCPoqrVOMXctQpiaXBoSQggLJ2cEQghh4eSMQAghLJwEgRBCWDgJAiGEsHASBEIIYeEkCIQQwsL9PzmQqakeHVtJAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "1ebb962c-a104-4b7b-9263-971f784c85a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f69ec767c40>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('libm.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "cce03b2d-59d7-4f2d-89a6-b666564ffc40"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "1  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "2  moduleOM_name:0,openDeclarationonesigclass1_na...              0\n",
              "3  moduleOM_name:0,openDeclarationonesigclass1_na...              1\n",
              "4  moduleOM_name:0,openDeclarationonesigclass1_na...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d46c021-aaed-4847-a01b-5de78bf061bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0,openDeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d46c021-aaed-4847-a01b-5de78bf061bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d46c021-aaed-4847-a01b-5de78bf061bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d46c021-aaed-4847-a01b-5de78bf061bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "3fd5f461-f056-4528-fc1c-955f5913adc0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "c1b0a599-56c3-4e72-b5ad-0d08ffb1ebb4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('libm_pred.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "4fa6688f-2e86-4e94-9c7a-1a178d6a4650"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_nameonesigclass1_nameextendsclassattr...              0\n",
              "1  moduleom_nameonesigclass1_nameextendsclassattr...              0\n",
              "2  moduleom_nameonesigclass1_nameextendsclassattr...              0\n",
              "3  moduleom_name:0,opendeclarationonesigclass1_na...              1\n",
              "4  moduleom_nameonesigclass1_nameextendsclassattr...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4097387-e77c-4c77-b0c2-54def3925105\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_nameonesigclass1_nameextendsclassattr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_nameonesigclass1_nameextendsclassattr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_nameonesigclass1_nameextendsclassattr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0,opendeclarationonesigclass1_na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_nameonesigclass1_nameextendsclassattr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4097387-e77c-4c77-b0c2-54def3925105')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4097387-e77c-4c77-b0c2-54def3925105 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4097387-e77c-4c77-b0c2-54def3925105');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "b30730bd-b41a-4151-e5a8-4d5d489cea8d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "6c16cafc-0d03-408c-e4a6-99297cad3299"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 1.000000\n",
            "Testing: Recall = 0.333333\n",
            "Testing: F1 Score = 0.500000\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[85  0]\n",
            " [10  5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "a033d355-5d23-4fd0-dfd1-2258f86e216c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        85\n",
            "           1       1.00      0.33      0.50        15\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.95      0.67      0.72       100\n",
            "weighted avg       0.91      0.90      0.88       100\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}