{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP Undersample Distribution  \n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###9 OM - Dataset , Camping,OnlineStore,  Library Management, Bank, Customer_order, E-Commerce, School Management, Student-Course\n",
        "\n",
        "###1 OM - Testing - Decider (Seen by Model)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 70% - 30%\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 772\n",
        "\n",
        "### P samples - 540 P \n",
        "### NP samples - 232 NP \n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 80\n",
        "\n",
        "### P samples - 12\n",
        "### NP samples - 68\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('8OM-p-70-np-30.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "e880c8fb-7efc-46b6-cf1f-e5f166473eef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-312e33c1-3cef-43ef-b715-0e91425c39e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-312e33c1-3cef-43ef-b715-0e91425c39e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-312e33c1-3cef-43ef-b715-0e91425c39e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-312e33c1-3cef-43ef-b715-0e91425c39e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,​OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d767d2-c7c8-4ce2-c537-018f23416b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "22e854ed-a58c-49f9-b701-67f62d83c0f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 141, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "98g9rcxGQY0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "7e32a0a0-2875-46dd-8667-36a595e3656e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] moduleom_name:0opendeclarationonesigclass1_nameextendsclassattrset=c1_at1+c1_at2id=c1_at1noparentisabstract=no}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsclassattrset=c2_at1+c2_at2id=c2_at1noparentisabstract=no}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigclass3_nameextendsclassattrset=c3_at1+c3_at2id=c3_at1noparentisabstract=no}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigclass4_nameextendsclassattrset=c4_at1+c4_at2+c4_at3+c4_at4id=c4_at1noparentisabstract=no}onesigc4_at1extendsc4_at1_typeonesigc4_at2extendsc4_at2_typeonesigc4_at3extendsc4_at3_typeonesigc4_at4extendsc4_at4_typeonesigclass5_nameextendsclassattrset=c5_at1+c5_at2oneparentparentinclass4_nameid=c4_at1isabstract=no}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigclass6_nameextendsclassattrset=c6_at1+c6_at2+c6_at3id=c6_at1noparentisabstract=no}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigassoc1extendsassociationsrc=class6_namedst=class4_namesrc_multiplicity=src_mlpc2dst_multiplicity=dst_mlpc}onesigassoc2extendsassociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsassociationsrc=class4_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsassociationsrc=class3_namedst=class1_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}predshowrunshowfor30\\u200b,mappingstrategyoftableclass4_name:map_str2mappingstrategyoftableclass5_name:map_str2mappingstrategyoftableclass7_name:map_str2mappingstrategyoftableclass8_name:map_str2mappingstrategyoftableclass6_name:map_str3associationstrategyforassoc1:assoc_type1associationstrategyforassoc4:assoc_type1associationstrategyforassoc2:assoc_type2associationstrategyforassoc3:assoc_type2associationstrategyforassoc4:assoc_type2,useom_name_0createtable`assoc2`(`c7_at1`c7_at1_typenotnull`c4_at1`c4_at1_typenotnullkey`fk_assoc2_c7_at1_idx`(`c7_at1`)key`fk_assoc2_c4_at1_idx`(`c4_at1`)primarykey(`c7_at1`,`c4_at1`));createtable`class2_name`(`c2_at2`c2_at2_type`c2_at1`c2_at1_typenotnullprimarykey(`c2_at1`));createtable`class8_name`(`c8_at2`c8_at2_type(64),`c8_at1`c8_at1_type(64),`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class1_name`(`c1_at2`c1_at2_type`c5_at1`c5_at1_type`c1_at1`c1_at1_typenotnullkey`fk_class1_name_c5_at1_idx`(`c5_at1`),primarykey(`c1_at1`));createtable`class10_name`(`c10_at1`c10_at1_type`c7_at1`c7_at1_typenotnullkey`fk_class10_name_c7_at1_idx`(`c7_at1`),primarykey(`c7_at1`));createtable`class9_name`(`c9_at1`c9_at1_type`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class4_name`(`c4_at2`c4_at2_type`c4_at1`c4_at1_typenotnullprimarykey(`c4_at1`));createtable`class7_name`(`c7_at1`c7_at1_typenotnullprimarykey(`c7_at1`));createtable`class6_name`(`c6_at2`c6_at2_type(64)`c6_at1`c6_at1_typenotnullprimarykey(`c6_at1`));createtable`class3_name`(`c3_at2`c3_at2_type(64)`c3_at1`c3_at1_typenotnull`c2_at1`c2_at1_typekey`fk_class3_name_c2_at1_idx`(`c2_at1`)primarykey(`c3_at1`));createtable`assoc4`(`c6_at1`c6_at1_typenotnull`c2_at1`c2_at1_typenotnullkey`fk_assoc4_c6_at1_idx`(`c6_at1`)key`fk_assoc4_c2_at1_idx`(`c2_at1`)primarykey(`c6_at1`,`c2_at1`));createtable`assoc3`(`c7_at1`c7_at1_typenotnull`c6_at1`c6_at1_typenotnullkey`fk_assoc3_c7_at1_idx`(`c7_at1`),key`fk_assoc3_c6_at1_idx`(`c6_at1`),primarykey(`c7_at1`,`c6_at1`));altertable`assoc2`addconstraint`fk_assoc2_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc2_c4_at1`foreignkey(`c4_at1`)references`class4_name`(`c4_at1`)ondeletecascadeonupdatecascadealtertable`class1_name`addconstraint`fk_class1_name_c5_at1`foreignkey(`c5_at1`)references`class5_name`(`c5_at1`)ondeletecascadeonupdatecascadealtertable`class10_name`addconstraint`fk_class10_name_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadealtertable`class3_name`addconstraint`fk_class3_name_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc4`addconstraint`fk_assoc4_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc4_c2_at1`foreignkey(`c2_at1`)references`class2_name`(`c2_at1`)ondeletecascadeonupdatecascadealtertable`assoc3`addconstraint`fk_assoc3_c7_at1`foreignkey(`c7_at1`)references`class7_name`(`c7_at1`)ondeletecascadeonupdatecascadeaddconstraint`fk_assoc3_c6_at1`foreignkey(`c6_at1`)references`class6_name`(`c6_at1`)ondeletecascadeonupdatecascade\\u200b [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "c6c36399-4762-407d-e2a7-e50d03e37370"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "e805749d-62ad-4021-b928-e96cbd14975f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 8 3]\n",
            "\n",
            "[2 7]\n",
            "[7 3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "694c941e-37f6-47c3-b4e9-7b0241285dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "f66b9f91-12ed-4139-b662-31e62ef28ec5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "21b234cd-de67-466a-c2e8-21dac9e35636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99999994, 1.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "b279feea-3606-441d-baa2-049b0c009d95"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "08b54f46-de7d-454f-f073-4724b1c5b963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 285)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "6228abdb-04d3-4d62-8234-50f97d466b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 285)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "56744a4e-76ea-4cfe-e633-cef677570767"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.652489, 'expected_acc': 0.0035087719298245615}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "a86ad9de-42b9-4a3f-d611-87ef75ed6221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 8s 13ms/step - loss: 5.6204 - masked_acc: 0.0143 - masked_loss: 5.6204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.620436668395996,\n",
              " 'masked_acc': 0.014285714365541935,\n",
              " 'masked_loss': 5.620436668395996}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "f8ac0209-414d-43e2-ce33-3cd84ec0c62d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.3108 - masked_acc: 0.9000 - masked_loss: 0.3108 - val_loss: 0.8751 - val_masked_acc: 0.8071 - val_masked_loss: 0.8751\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 4s 40ms/step - loss: 0.4086 - masked_acc: 0.9000 - masked_loss: 0.4086 - val_loss: 1.3486 - val_masked_acc: 0.8143 - val_masked_loss: 1.3486\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.3365 - masked_acc: 0.9100 - masked_loss: 0.3365 - val_loss: 1.5325 - val_masked_acc: 0.7857 - val_masked_loss: 1.5325\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.6353 - masked_acc: 0.8450 - masked_loss: 0.6353 - val_loss: 1.2318 - val_masked_acc: 0.7429 - val_masked_loss: 1.2318\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 0.4540 - masked_acc: 0.8800 - masked_loss: 0.4540 - val_loss: 1.1328 - val_masked_acc: 0.8214 - val_masked_loss: 1.1328\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.3160 - masked_acc: 0.9150 - masked_loss: 0.3160 - val_loss: 0.9321 - val_masked_acc: 0.8571 - val_masked_loss: 0.9321\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.2800 - masked_acc: 0.9250 - masked_loss: 0.2800 - val_loss: 1.2598 - val_masked_acc: 0.8500 - val_masked_loss: 1.2598\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.2502 - masked_acc: 0.9300 - masked_loss: 0.2502 - val_loss: 1.0878 - val_masked_acc: 0.8500 - val_masked_loss: 1.0878\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.2231 - masked_acc: 0.9300 - masked_loss: 0.2231 - val_loss: 1.4635 - val_masked_acc: 0.8143 - val_masked_loss: 1.4635\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "e0d7cda5-5b83-40ae-d529-71a0bebac443"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6b00262e50>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "d1286b9b-8e19-4de6-c58e-f0f642449ccc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6a78771f70>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('decider_test_set.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "18b83d27-955a-4185-d4de-9569efefa148"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f3f8f65-a313-47db-a29f-74ae2f3cea96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f3f8f65-a313-47db-a29f-74ae2f3cea96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f3f8f65-a313-47db-a29f-74ae2f3cea96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f3f8f65-a313-47db-a29f-74ae2f3cea96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "824621ae-ded1-4972-ff44-a175b76b5239"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80,)\n",
            "(80,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "35d780a6-f935-49b2-bdd9-27cd12fc80e4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('decider_pred_set.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "ffb709c9-7360-4e71-e554-38ae2c66e137"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  oduleom_name:0opendeclarationonesigclass1_name...              1\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "4  moduleom_name:0opendeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40c5ac2d-d65b-4bba-b04f-05809c3a7dc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oduleom_name:0opendeclarationonesigclass1_name...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40c5ac2d-d65b-4bba-b04f-05809c3a7dc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40c5ac2d-d65b-4bba-b04f-05809c3a7dc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40c5ac2d-d65b-4bba-b04f-05809c3a7dc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "b6e90fa0-b30b-411b-cf44-61509ba61de7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "330bd149-d854-4713-f6de-d9d350ec1eb8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.647059\n",
            "Testing: Recall = 0.916667\n",
            "Testing: F1 Score = 0.758621\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[62  6]\n",
            " [ 1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "f14082ca-7eb3-4e27-95b8-c3718ce48678"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.95        68\n",
            "           1       0.65      0.92      0.76        12\n",
            "\n",
            "    accuracy                           0.91        80\n",
            "   macro avg       0.82      0.91      0.85        80\n",
            "weighted avg       0.93      0.91      0.92        80\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}