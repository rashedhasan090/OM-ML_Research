{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Equal , NP Equal Distribution  \n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###9 OM - Dataset , Camping,OnlineStore,  Library Management, Bank, Customer_order, E-Commerce, School Management, Student-Course\n",
        "\n",
        "###1 OM - Testing - Decider (Seen by Model)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 50% - 50%\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 471\n",
        "\n",
        "### P samples - 386 P \n",
        "### NP samples - 386 NP \n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 80\n",
        "\n",
        "### P samples - 12\n",
        "### NP samples - 68\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('8OM-p-50-np-50.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "de7ffdaf-69cb-433e-8486-48f4f5f7e0a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-131ff9fa-2e8d-45cf-abfc-b2a1a3a8e9f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-131ff9fa-2e8d-45cf-abfc-b2a1a3a8e9f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-131ff9fa-2e8d-45cf-abfc-b2a1a3a8e9f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-131ff9fa-2e8d-45cf-abfc-b2a1a3a8e9f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,â€‹OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2287e03f-f9da-4bc8-cc89-4acd4e124f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "b4677524-c4b3-428e-94b7-3c8567cdc0b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 4, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "31ee6e4a-a180-4f26-fd92-33ddb6d587cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "80e6d130-017c-4378-a595-cb6935ede4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 25  3]\n",
            "\n",
            "[ 2 24]\n",
            "[24  3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "4eb3503a-8568-404b-b6b2-69354a87e567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "42caad5f-1125-46e4-b53f-1de606bda249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "b48b71bb-63d1-4ae4-cdf4-69a6229a9fc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "3dac61fb-bfdb-4196-f4c9-8c65c9f7d11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "5c684489-44aa-4ce8-82e6-4e797fb9eec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 276)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "7f253c30-c9bf-42ea-d933-e7f977b01a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 276)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "61554c9a-5e10-4237-fd29-1ab0e199077f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.620401, 'expected_acc': 0.0036231884057971015}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "ec89dfca-ce0e-409d-f50c-d39eb024eee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7552 - masked_acc: 0.8214 - masked_loss: 1.7552\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 1.7552189826965332,\n",
              " 'masked_acc': 0.8214285969734192,\n",
              " 'masked_loss': 1.7552189826965332}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "2c3f52ad-f2ea-4de3-dd2b-e882f94ac0b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.1830 - masked_acc: 0.9550 - masked_loss: 0.1830 - val_loss: 1.4038 - val_masked_acc: 0.8857 - val_masked_loss: 1.4038\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.2106 - masked_acc: 0.9550 - masked_loss: 0.2106 - val_loss: 1.3847 - val_masked_acc: 0.8571 - val_masked_loss: 1.3847\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.1731 - masked_acc: 0.9450 - masked_loss: 0.1731 - val_loss: 1.6316 - val_masked_acc: 0.8643 - val_masked_loss: 1.6316\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.1960 - masked_acc: 0.9400 - masked_loss: 0.1960 - val_loss: 1.2275 - val_masked_acc: 0.8929 - val_masked_loss: 1.2275\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.1968 - masked_acc: 0.9500 - masked_loss: 0.1968 - val_loss: 2.1415 - val_masked_acc: 0.8429 - val_masked_loss: 2.1415\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 4s 35ms/step - loss: 0.2387 - masked_acc: 0.9350 - masked_loss: 0.2387 - val_loss: 1.6839 - val_masked_acc: 0.8714 - val_masked_loss: 1.6839\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 3s 31ms/step - loss: 0.1691 - masked_acc: 0.9500 - masked_loss: 0.1691 - val_loss: 2.0407 - val_masked_acc: 0.8643 - val_masked_loss: 2.0407\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 5s 53ms/step - loss: 0.1096 - masked_acc: 0.9800 - masked_loss: 0.1096 - val_loss: 1.4566 - val_masked_acc: 0.9000 - val_masked_loss: 1.4566\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.1085 - masked_acc: 0.9650 - masked_loss: 0.1085 - val_loss: 1.8485 - val_masked_acc: 0.8929 - val_masked_loss: 1.8485\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 3s 32ms/step - loss: 0.0756 - masked_acc: 0.9850 - masked_loss: 0.0756 - val_loss: 1.6108 - val_masked_acc: 0.8714 - val_masked_loss: 1.6108\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.1363 - masked_acc: 0.9550 - masked_loss: 0.1363 - val_loss: 1.6854 - val_masked_acc: 0.8929 - val_masked_loss: 1.6854\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.1322 - masked_acc: 0.9550 - masked_loss: 0.1322 - val_loss: 1.5514 - val_masked_acc: 0.8929 - val_masked_loss: 1.5514\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "21261502-4237-4883-ce23-7d4f721cd1cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc199fe2640>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "cd51a42e-f585-4244-8918-4829ba2bcf94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc19bfb0eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('decider_test_set.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "fcce6ec8-7462-4d02-9644-3b1fad69b32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ead11e6-83dc-4a85-98b3-b8591a9a722b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ead11e6-83dc-4a85-98b3-b8591a9a722b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ead11e6-83dc-4a85-98b3-b8591a9a722b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ead11e6-83dc-4a85-98b3-b8591a9a722b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "b6face52-656e-4371-d417-58eb97e72aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80,)\n",
            "(80,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "2fa5dbc9-0fde-4cf2-ec92-adb7b0f7761a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('decider_pred_set.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "6c211071-131e-4379-cf10-49c3f0e13d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "4  moduleom_name:0opendeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a01872ae-c891-427f-8757-b70ea1701e4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a01872ae-c891-427f-8757-b70ea1701e4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a01872ae-c891-427f-8757-b70ea1701e4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a01872ae-c891-427f-8757-b70ea1701e4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "2be83be3-cc20-412c-e004-7b34a78fc800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "c741ff17-7260-48f4-8c26-c0e43604bcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 1.000000\n",
            "Testing: Recall = 0.916667\n",
            "Testing: F1 Score = 0.956522\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[68  0]\n",
            " [ 1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "183d154e-b9bc-4a54-f4eb-7bc7fbf750e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        68\n",
            "           1       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.96      0.97        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}