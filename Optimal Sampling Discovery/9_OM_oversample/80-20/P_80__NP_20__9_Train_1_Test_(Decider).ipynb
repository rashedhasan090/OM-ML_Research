{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "\n",
        "# P Oversample , NP EUndersample Distribution  \n",
        "\n",
        "P instances have been increased through oversampling. \n",
        "\n",
        "###9 OM - Dataset , Camping,OnlineStore,  Library Management, Bank, Customer_order, E-Commerce, School Management, Student-Course\n",
        "\n",
        "###1 OM - Testing - Decider (Seen by Model)\n",
        "\n",
        "## P - NP Distribution \n",
        "\n",
        "### 80% - 20%\n",
        "\n",
        "\n",
        "## Training \n",
        "\n",
        "### Total instances - 772\n",
        "\n",
        "### P samples - 695 P \n",
        "### NP samples - 77NP \n",
        "\n",
        "## Testing \n",
        "\n",
        "### Total instances - 80\n",
        "\n",
        "### P samples - 12\n",
        "### NP samples - 68\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup (installing necessary libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "DGFTkuRvzWqc"
      },
      "outputs": [],
      "source": [
        "#  !pip install \"tensorflow-text>=2.10\"\n",
        "#  !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries "
      ],
      "metadata": {
        "id": "A07RWC45HcG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Shapechecker"
      ],
      "metadata": {
        "id": "h87kqCNBHly5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7rgJDbeBDF"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "daNcrh1lVej7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ORM_data = pd.read_csv('9OM-p-80-np-20.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Data from Dataset"
      ],
      "metadata": {
        "id": "KbiGtupGHyJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ve7kyoOxWY1u",
        "outputId": "4360d373-03a1-48f7-c03d-64facbd7e346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  \\\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...   \n",
              "\n",
              "                                       OM_Prediction  \n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...  \n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1176a5e1-f95f-42c7-9625-6bf3a746df65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1176a5e1-f95f-42c7-9625-6bf3a746df65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1176a5e1-f95f-42c7-9625-6bf3a746df65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1176a5e1-f95f-42c7-9625-6bf3a746df65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "ORM_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V7OaHrVYV-Xd"
      },
      "outputs": [],
      "source": [
        "OM_Regular = ORM_data['OM_Regular'].values\n",
        "OM_Prediction = ORM_data['OM_Prediction'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jTBVOEjFWAI5"
      },
      "outputs": [],
      "source": [
        "X = OM_Regular\n",
        "Y = OM_Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOujEo2geGod"
      },
      "source": [
        "#### Dividing data as Target and Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "# target_raw =  Y\n",
        "# context_raw = X\n",
        "# print(context_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lH_dPY8TRp3c"
      },
      "outputs": [],
      "source": [
        "# print(target_raw[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3rZFgz69nMPa"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "outputs": [],
      "source": [
        "# for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "#   print(example_context_strings[:5])\n",
        "#   print()\n",
        "#   print(example_target_strings[:5])\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation, We may or may not decide to Use this for ORM data. I kept it in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "mD0e-DWGQ2Vo"
      },
      "outputs": [],
      "source": [
        "# example_text = tf.constant('moduleOM_nameopenDeclarationonesigclass1_nameextendsClassattrSet=c1_at1+c1_at2id=c1_at1noparentisAbstract=No}onesigc1_at1extendsc1_at1_typeonesigc1_at2extendsc1_at2_typeonesigclass2_nameextendsClassattrSet=c2_at1+c2_at2+c2_at3+c2_at4id=c2_at1noparentisAbstract=No}onesigc2_at1extendsc2_at1_typeonesigc2_at2extendsc2_at2_typeonesigc2_at3extendsc2_at3_typeonesigc2_at4extendsc2_at4_typeonesigclass3_nameextendsClassattrSet=c3_at1+c3_at2+c3_at3+c3_at4id=c3_at1noparentisAbstract=No}onesigc3_at1extendsc3_at1_typeonesigc3_at2extendsc3_at2_typeonesigc3_at3extendsc3_at3_typeonesigc3_at4extendsc3_at4_typeonesigclass4_nameextendsClassattrSet=c4_at1id=c4_at1noparentisAbstract=No}onesigc4_at1extendsc4_at1_typeonesigclass5_nameextendsClassattrSet=c5_at1+c5_at2+c5_at3+c5_at4id=c5_at1noparentisAbstract=No}onesigc5_at1extendsc5_at1_typeonesigc5_at2extendsc5_at2_typeonesigc5_at3extendsc5_at3_typeonesigc5_at4extendsc5_at4_typeonesigclass6_nameextendsClassattrSet=c6_at1+c6_at2+c6_at3+c6_at4id=c6_at1noparentisAbstract=No}onesigc6_at1extendsc6_at1_typeonesigc6_at2extendsc6_at2_typeonesigc6_at3extendsc6_at3_typeonesigc6_at4extendsc6_at4_typeonesigassoc1extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc2extendsAssociationsrc=class1_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc3extendsAssociationsrc=class4_namedst=class5_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc}onesigassoc4extendsAssociationsrc=class1_namedst=class6_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}onesigassoc5extendsAssociationsrc=class1_namedst=class3_namesrc_multiplicity=src_mlpcdst_multiplicity=dst_mlpc2}predshowrunshowfor38,â€‹OM_name_Solution:0Table:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class1_nameAttributec1_at2:c1_at2_typeTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at2:c2_at2_typeTable:class2_nameAttributec2_at3:c2_at3_typeTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class3_nameAttributec3_at4:c3_at4_typeTable:class3_nameAttributec3_at2:c3_at2_typeTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class5_nameAttributec5_at3:c5_at3_typeTable:class5_nameAttributec5_at4:c5_at4_typeTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTable:class6_nameAttributec6_at2:c6_at2_typeTable:class6_nameAttributec6_at3:c6_at3_typeTable:class6_nameAttributec6_at4:c6_at4_typeTable:class1_nameAttributec1_at1:c1_at1_typePrimaryKeyTable:class2_nameAttributec2_at1:c1_at1_typePrimaryKeyTable:class3_nameAttributec3_at1:c3_at1_typePrimaryKeyTable:class4_nameAttributec4_at1:c4_at1_typePrimaryKeyTable:class6_nameAttributec6_at1:c6_at1_typePrimaryKeyTableName:class1_nameTableName:class2_nameTableName:class3_nameTableName:class4_nameTableName:class5_nameTableName:class6_nameMappingStrategyofTableclass1_name:map_str2MappingStrategyofTableclass2_name:map_str2MappingStrategyofTableclass3_name:map_str2MappingStrategyofTableclass4_name:map_str2MappingStrategyofTableclass6_name:map_str2AssociationStrategyforassoc1:assoc_type1AssociationStrategyforassoc2:assoc_type1AssociationStrategyforassoc3:assoc_type2AssociationStrategyforassoc4:assoc_type2AssociationStrategyforassoc5:assoc_type2,USEOM_name0----CREATETABLE`assoc1`(`c5_at1`c5_at1_type`c1_at1`c1_at1_typeKEY`FK_assoc1_c5_at1_idx`(`c5_at1`)KEY`FK_assoc1_c1_at1_idx`(`c1_at1`)PRIMARYKEY(`c5_at1``c1_at1`));----CREATETABLE`assoc3``c5_at1`c5_at1_type`c4_at1`c4_at1_typeKEY`FK_assoc3_c5_at1_idx`(`c5_at1`)KEY`FK_assoc3_c4_at1_idx`(`c4_at1`)PRIMARYKEY(`c5_at1``c4_at1`));----CREATETABLE`class5_name`(`c5_at4`c5_at4_type(64)`c5_at3`c5_at3_type(64)`c1_at1`c1_at1_type`c5_at1`c5_at1_typePRIMARYKEY(`c5_at1`));----CREATETABLE`class3_name`(`c3_at3`c3_at3_type(64)`c3_at2`c3_at2_type(64)`c3_at4`c3_at4_type`c3_at1`c3_at1_typeNOTNULLPRIMARYKEY(`c3_at1`));----CREATETABLE`class2_name`(`c2_at3`c2_at3_type(64)`c2_at2`c2_at2_type(64)`c2_at4`c2_at4_type`c2_at1`c2_at1_typePRIMARYKEY(`c2_at1`));----CREATETABLE`class4_name`(`c4_at1`c4_at1_typePRIMARYKEY(`c4_at1`));----CREATETABLE`class1_name`(`c1_at2`c1_at2_type(64)`c1_at1`c1_at1_typePRIMARYKEY(`c1_at1`));----CREATETABLE`class6_name`(`c6_at4`c6_at4_type`c6_at3`c6_at3_type`c6_at2`c6_at2_type`c6_at1`c6_at1_typeNOTNULLPRIMARYKEY(`c6_at1`));----CREATETABLE`assoc2`(`c5_at1`c5_at1_type`c2_at1`c2_at1_typeKEY`FK_assoc2_c5_at1_idx`(`c5_at1`)KEY`FK_assoc2_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c5_at1``c2_at1`));----CREATETABLE`assoc5`(`c3_at1`c3_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc5_c3_at1_idx`(`c3_at1`)KEY`FK_assoc5_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c3_at1``c2_at1`));----CREATETABLE`assoc4`(`c6_at1`c6_at1_typeNOTNULL`c2_at1`c2_at1_typeKEY`FK_assoc4_c6_at1_idx`(`c6_at1`)KEY`FK_assoc4_c2_at1_idx`(`c2_at1`)PRIMARYKEY(`c6_at1``c2_at1`));ALTERTABLE`assoc1`ADDCONSTRAINT`FK_assoc1_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc1_c1_at1`FOREIGNKEY(`c1_at1`)REFERENCES`class1_name`(`c1_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc3`ADDCONSTRAINT`FK_assoc3_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc3_c4_at1`FOREIGNKEY(`c4_at1`)REFERENCES`class4_name`(`c4_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc2`ADDCONSTRAINT`FK_assoc2_c5_at1`FOREIGNKEY(`c5_at1`)REFERENCES`class5_name`(`c5_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc2_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADEALTERTABLE`assoc5`ADDCONSTRAINT`FK_assoc5_c3_at1`FOREIGNKEY(`c3_at1`)REFERENCES`class3_name`(`c3_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc5_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE;ALTERTABLE`assoc4`ADDCONSTRAINT`FK_assoc4_c6_at1`FOREIGNKEY(`c6_at1`)REFERENCES`class6_name`(`c6_at1`)ONDELETECASCADEONUPDATECASCADEADDCONSTRAINT`FK_assoc4_c2_at1`FOREIGNKEY(`c2_at1`)REFERENCES`class2_name`(`c2_at1`)ONDELETECASCADEONUPDATECASCADE')\n",
        "\n",
        "# #example_text = tf.constant('class1,table2,obj1,atr1')\n",
        "# print(example_text.numpy())\n",
        "# print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#def tf_lower_and_split_punct(text):\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '', r'')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "UREvDg3sEKYa"
      },
      "outputs": [],
      "source": [
        "# print(example_text.numpy().decode())\n",
        "# print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0ced78-71c3-4966-cd18-803f0011e3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "#context_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the context data  `TextVectorization` layer, now build and `.adapt()` for the Target Data one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jlC4xuZnKLBS"
      },
      "outputs": [],
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "#target_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KZxj8IrNZ9S",
        "outputId": "ccbd796a-3542-47d9-f3a7-95598678a5e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 38, 3]]>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "98g9rcxGQY0I"
      },
      "outputs": [],
      "source": [
        "# context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "# tokens = context_vocab[example_tokens[0].numpy()]\n",
        "# ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_jx4Or_eFRSz",
        "outputId": "65825a1e-c3c4-4331-e59b-01aa78743ff9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O0B4XdFlRgc"
      },
      "source": [
        "### Process the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVCuyuSp_whd"
      },
      "source": [
        "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wk5tbZWQl5u1"
      },
      "outputs": [],
      "source": [
        "def process_text(context, target):\n",
        "  context = context_text_processor(context).to_tensor()\n",
        "  target = target_text_processor(target)\n",
        "  targ_in = target[:,:-1].to_tensor()\n",
        "  targ_out = target[:,1:].to_tensor()\n",
        "  return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGi7X2m_tbM"
      },
      "source": [
        "Here is the first sequence of each, from the first batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQBWAjLsJkr",
        "outputId": "813c918a-67c1-440e-b264-73ad20b40c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 122   3]\n",
            "\n",
            "[  2 122]\n",
            "[122   3]\n"
          ]
        }
      ],
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder\n",
        "\n",
        "  <th colspan=1>This tutorial's model</th>\n",
        "<tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `context_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
        "5. Returns the processed sequence. This will be passed to the attention head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gSVh05Jl6l",
        "outputId": "44333084-6367-487d-f119-940ca06b26b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (1, 3)\n",
            "Encoder output, shape (batch, s, units): (1, 3, 256)\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention layer\n",
        "\n",
        "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-Ql3ymqwD8LS"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "       query=x,\n",
        "       value=context,\n",
        "      return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "  #Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bRzduCU4tGN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                 output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLdvss3zN4v",
        "outputId": "31634298-72a7-4451-9992-d2bbc79f348d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (1, 3, 256)\n",
            "Target sequence, shape (batch, t, units): (1, 2, 256)\n",
            "Attention result, shape (batch, t, units): (1, 2, 256)\n",
            "Attention weights, shape (batch, t, s):    (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d14A2DcPtQhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9fUhi3Pmwp"
      },
      "source": [
        "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxyR7cmQPn9P",
        "outputId": "e77aadb3-8954-474f-f1aa-7dc6952c3649"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagyXMH-Jhqt"
      },
      "source": [
        "\n",
        "\n",
        "Here are the attention weights across the context sequences at `t=0`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "LDc9M_CUtYWD",
        "outputId": "fad66eaa-850a-488e-dd0a-4c13ceceb5cb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cpq_sCKHtZzS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
        "\n",
        "1. It looks up embeddings for each token in the target sequence.\n",
        "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
        "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
        "4. At each location in the output it predicts the next token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8-nRNzFR8x"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "Next, the `call` method, takes 3 arguments:\n",
        "\n",
        "* `inputs` -  a `context, x` pair where:\n",
        "  * `context` - is the context from the encoder's output.\n",
        "  * `x` - is the target sequence input.\n",
        "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
        "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1-mLAcUEXpK"
      },
      "source": [
        "That will be sufficient for training. Create an instance of the decoder to test out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWaI4wqzt4t"
      },
      "source": [
        "Decoder usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YM-lD7bzx18",
        "outputId": "0fd5d728-1792-445a-8150-d5b6ce9d51f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (1, 3, 256)\n",
            "input target tokens shape: (batch, t) (1, 2)\n",
            "logits shape shape: (batch, target_vocabulary_size) (1, 2, 182)\n"
          ]
        }
      ],
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhS_tbk7VQkX"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "For inference usage couple more methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SPm12cnIVRQr"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TzeOhpBvVS5L"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "v6ildnz_V1MA"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiXLrVs-FTE"
      },
      "source": [
        "With those extra functions, you can write a generation loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "SuehagxL-JBZ"
      },
      "outputs": [],
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "#result[:3].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## The model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPi0FkS2iA5"
      },
      "source": [
        "During training the model will be used like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhjTh84K6Mg",
        "outputId": "bd0a86be-c104-4ea0-f2a9-4b03c0cf9477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (1, 3)\n",
            "Target tokens, shape: (batch, t) (1, 2)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (1, 2, 182)\n"
          ]
        }
      ],
      "source": [
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nRB1CTmQWOIL"
      },
      "outputs": [],
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32GuAhw2nXm"
      },
      "source": [
        "Configure the model for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "9g0DRRvm3l9X"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWLI3pssjnx"
      },
      "source": [
        "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuP3_LFENMJG",
        "outputId": "38e2900e-0c6f-402d-b3af-41ed1ea3051c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 5.2040067, 'expected_acc': 0.005494505494505495}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frVba49Usd0Z"
      },
      "source": [
        "That should roughly match the values returned by running a few steps of evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJITfxEsHKR",
        "outputId": "c6f496d1-bbcc-4844-c825-77f6057e816c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 8s 18ms/step - loss: 5.1909 - masked_acc: 0.0000e+00 - masked_loss: 5.1909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 5.190946578979492,\n",
              " 'masked_acc': 0.0,\n",
              " 'masked_loss': 5.190946578979492}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "model.evaluate(val_ds, steps=70, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd_esVVoSf3",
        "outputId": "ec5bad2b-7f31-433e-a022-470f398b8771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 19s 33ms/step - loss: 3.2832 - masked_acc: 0.4950 - masked_loss: 3.2832 - val_loss: 3.3210 - val_masked_acc: 0.5214 - val_masked_loss: 3.3210\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 2.6504 - masked_acc: 0.5550 - masked_loss: 2.6504 - val_loss: 2.8643 - val_masked_acc: 0.5714 - val_masked_loss: 2.8643\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 2.6013 - masked_acc: 0.5800 - masked_loss: 2.6013 - val_loss: 2.5356 - val_masked_acc: 0.5500 - val_masked_loss: 2.5356\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 2.3094 - masked_acc: 0.6000 - masked_loss: 2.3094 - val_loss: 1.8215 - val_masked_acc: 0.6500 - val_masked_loss: 1.8215\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 1.7354 - masked_acc: 0.6550 - masked_loss: 1.7354 - val_loss: 1.6880 - val_masked_acc: 0.7000 - val_masked_loss: 1.6880\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 1.5263 - masked_acc: 0.6950 - masked_loss: 1.5263 - val_loss: 1.6478 - val_masked_acc: 0.6929 - val_masked_loss: 1.6478\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.8454 - masked_acc: 0.8100 - masked_loss: 0.8454 - val_loss: 1.4585 - val_masked_acc: 0.7643 - val_masked_loss: 1.4585\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.9228 - masked_acc: 0.8050 - masked_loss: 0.9228 - val_loss: 1.0812 - val_masked_acc: 0.8143 - val_masked_loss: 1.0812\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.7100 - masked_acc: 0.8300 - masked_loss: 0.7100 - val_loss: 1.0993 - val_masked_acc: 0.8500 - val_masked_loss: 1.0993\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 5s 55ms/step - loss: 0.5614 - masked_acc: 0.8950 - masked_loss: 0.5614 - val_loss: 0.9587 - val_masked_acc: 0.8429 - val_masked_loss: 0.9587\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.7276 - masked_acc: 0.8550 - masked_loss: 0.7276 - val_loss: 0.6554 - val_masked_acc: 0.9214 - val_masked_loss: 0.6554\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.4971 - masked_acc: 0.9200 - masked_loss: 0.4971 - val_loss: 0.7862 - val_masked_acc: 0.8857 - val_masked_loss: 0.7862\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.3903 - masked_acc: 0.9050 - masked_loss: 0.3903 - val_loss: 0.7944 - val_masked_acc: 0.8857 - val_masked_loss: 0.7944\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.2498 - masked_acc: 0.9400 - masked_loss: 0.2498 - val_loss: 0.8067 - val_masked_acc: 0.9000 - val_masked_loss: 0.8067\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.2804 - masked_acc: 0.9350 - masked_loss: 0.2804 - val_loss: 0.9626 - val_masked_acc: 0.8786 - val_masked_loss: 0.9626\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.2013 - masked_acc: 0.9600 - masked_loss: 0.2013 - val_loss: 0.8396 - val_masked_acc: 0.9143 - val_masked_loss: 0.8396\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.2738 - masked_acc: 0.9250 - masked_loss: 0.2738 - val_loss: 0.9167 - val_masked_acc: 0.9000 - val_masked_loss: 0.9167\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.2285 - masked_acc: 0.9500 - masked_loss: 0.2285 - val_loss: 0.5743 - val_masked_acc: 0.9500 - val_masked_loss: 0.5743\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.1119 - masked_acc: 0.9650 - masked_loss: 0.1119 - val_loss: 0.5813 - val_masked_acc: 0.9357 - val_masked_loss: 0.5813\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.0554 - masked_acc: 0.9950 - masked_loss: 0.0554 - val_loss: 0.9768 - val_masked_acc: 0.9000 - val_masked_loss: 0.9768\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.1149 - masked_acc: 0.9800 - masked_loss: 0.1149 - val_loss: 0.7643 - val_masked_acc: 0.9143 - val_masked_loss: 0.7643\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 3s 35ms/step - loss: 0.1176 - masked_acc: 0.9800 - masked_loss: 0.1176 - val_loss: 0.5298 - val_masked_acc: 0.9500 - val_masked_loss: 0.5298\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.0630 - masked_acc: 0.9800 - masked_loss: 0.0630 - val_loss: 0.7208 - val_masked_acc: 0.9286 - val_masked_loss: 0.7208\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.1909 - masked_acc: 0.9500 - masked_loss: 0.1909 - val_loss: 0.7237 - val_masked_acc: 0.9286 - val_masked_loss: 0.7237\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0638 - masked_acc: 0.9900 - masked_loss: 0.0638 - val_loss: 0.8605 - val_masked_acc: 0.9143 - val_masked_loss: 0.8605\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 5s 51ms/step - loss: 0.0676 - masked_acc: 0.9850 - masked_loss: 0.0676 - val_loss: 0.7667 - val_masked_acc: 0.9214 - val_masked_loss: 0.7667\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0186 - masked_acc: 1.0000 - masked_loss: 0.0186 - val_loss: 0.5070 - val_masked_acc: 0.9500 - val_masked_loss: 0.5070\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.0360 - masked_acc: 0.9950 - masked_loss: 0.0360 - val_loss: 0.9119 - val_masked_acc: 0.9071 - val_masked_loss: 0.9119\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.0407 - masked_acc: 0.9950 - masked_loss: 0.0407 - val_loss: 0.5740 - val_masked_acc: 0.9429 - val_masked_loss: 0.5740\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.0181 - masked_acc: 1.0000 - masked_loss: 0.0181 - val_loss: 0.8146 - val_masked_acc: 0.9143 - val_masked_loss: 0.8146\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.0364 - masked_acc: 0.9950 - masked_loss: 0.0364 - val_loss: 0.4884 - val_masked_acc: 0.9500 - val_masked_loss: 0.4884\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.0032 - masked_acc: 1.0000 - masked_loss: 0.0032 - val_loss: 0.4194 - val_masked_acc: 0.9571 - val_masked_loss: 0.4194\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0298 - masked_acc: 0.9950 - masked_loss: 0.0298 - val_loss: 0.6892 - val_masked_acc: 0.9286 - val_masked_loss: 0.6892\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.0796 - masked_acc: 0.9900 - masked_loss: 0.0796 - val_loss: 0.8030 - val_masked_acc: 0.9214 - val_masked_loss: 0.8030\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 6s 55ms/step - loss: 0.0387 - masked_acc: 0.9950 - masked_loss: 0.0387 - val_loss: 0.7188 - val_masked_acc: 0.9286 - val_masked_loss: 0.7188\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.0339 - masked_acc: 0.9950 - masked_loss: 0.0339 - val_loss: 0.4282 - val_masked_acc: 0.9571 - val_masked_loss: 0.4282\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.0020 - masked_acc: 1.0000 - masked_loss: 0.0020 - val_loss: 0.6416 - val_masked_acc: 0.9357 - val_masked_loss: 0.6416\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 0.0259 - masked_acc: 0.9950 - masked_loss: 0.0259 - val_loss: 0.6420 - val_masked_acc: 0.9357 - val_masked_loss: 0.6420\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 4s 41ms/step - loss: 0.0232 - masked_acc: 0.9950 - masked_loss: 0.0232 - val_loss: 0.7129 - val_masked_acc: 0.9286 - val_masked_loss: 0.7129\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.0767 - masked_acc: 0.9850 - masked_loss: 0.0767 - val_loss: 0.4286 - val_masked_acc: 0.9571 - val_masked_loss: 0.4286\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 70,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=8)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss from Training "
      ],
      "metadata": {
        "id": "Uq9lHbPgenz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "38rLdlmtQHCm",
        "outputId": "f757acdc-f922-4e65-b747-55d26bcb4676"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f08ff236eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['masked_loss'], label='masked_loss')\n",
        "plt.plot(history.history['val_masked_loss'], label='val_masked_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the aacuracy from the training"
      ],
      "metadata": {
        "id": "lUssYQFZet7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KkhXRASNG80_",
        "outputId": "4235431c-f234-49ce-bf6a-66f5632f499a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0906fb2df0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "### Translate Module Development\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "mmgYPCVgEwp_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "  # Process the input texts\n",
        "  context = self.encoder.convert_input(texts)\n",
        "  batch_size = tf.shape(texts)[0]\n",
        "\n",
        "  # Setup the loop inputs\n",
        "  tokens = []\n",
        "  attention_weights = []\n",
        "  next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # Generate the next token\n",
        "    next_token, done, state = self.decoder.get_next_token(\n",
        "        context, next_token, done,  state, temperature)\n",
        "        \n",
        "    # Collect the generated tokens\n",
        "    tokens.append(next_token)\n",
        "    attention_weights.append(self.decoder.last_attention_weights)\n",
        "    \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Stack the lists of tokens and attention weights.\n",
        "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "  result = self.decoder.tokens_to_text(tokens)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XufRntbbva"
      },
      "source": [
        "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Individual translator mechanism, can be used to translate each data separately\n",
        "\n",
        "\n",
        "result1 = model.translate([''])\n",
        "\n",
        "result2 = model.translate([''])\n",
        "\n",
        "result23 = model.translate([''])\n",
        "\n",
        "result222 = model.translate([''])\n",
        "#result1[0].numpy().decode()\n",
        "#result2[0].numpy().decode()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ1iU63cVgfs"
      },
      "source": [
        "### Attention plot generation after model training has been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def plot_attention(self, text, **kwargs):\n",
        "  assert isinstance(text, str)\n",
        "  output = self.translate([text], **kwargs)\n",
        "  output = output[0].numpy().decode()\n",
        "\n",
        "  attention = self.last_attention_weights[0]\n",
        "\n",
        "  context = tf_lower_and_split_punct(text)\n",
        "  context = context.numpy().decode().split()\n",
        "\n",
        "  output = tf_lower_and_split_punct(output)\n",
        "  output = output.numpy().decode().split()[1:]\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "rrGawQv2eiA4"
      },
      "outputs": [],
      "source": [
        "#model.plot_attention('') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBdOf9duumm"
      },
      "source": [
        "Translate a few more sentences and plot them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3xI3NzrRJt"
      },
      "source": [
        "The short sentences often work well, but if the input is too long the model literally loses focus and stops providing reasonable predictions. There are two main reasons for this:\n",
        "\n",
        "1. The model was trained with teacher-forcing feeding the correct token at each step, regardless of the model's predictions. The model could be made more robust if it were sometimes fed its own predictions.\n",
        "2. The model only has access to its previous output through the RNN state. If the RNN state looses track of where it was in the context sequence there's no way for the model to recover. [Transformers](transformer.ipynb) improve on this by letting the decoder look at what it has output so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtz6QBoGWqT2"
      },
      "source": [
        "The raw data is sorted by length, so try translating the longest sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-FUHFLEvSMbG"
      },
      "outputs": [],
      "source": [
        "long_text = context_raw[-1]\n",
        "\n",
        "import textwrap\n",
        "#print('Expected output:\\n', '\\n'.join(textwrap.wrap(target_raw[-1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing unseen samples"
      ],
      "metadata": {
        "id": "Rc1aekzi9dLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dc = pd.read_csv('decider_test_set.csv')"
      ],
      "metadata": {
        "id": "6OIFQKZI9bc5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nsx0IyYZ9k3v",
        "outputId": "d79897fd-4096-4568-d93f-372effd4d37d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "1  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "2  moduleOM_name:0openDeclarationonesigclass1_nam...              0\n",
              "3  moduleOM_name:0openDeclarationonesigclass1_nam...              1\n",
              "4  moduleOM_name:0openDeclarationonesigclass1_nam...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e415bf8-8dc1-4f5d-af56-3be5e3baa728\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleOM_name:0openDeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e415bf8-8dc1-4f5d-af56-3be5e3baa728')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e415bf8-8dc1-4f5d-af56-3be5e3baa728 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e415bf8-8dc1-4f5d-af56-3be5e3baa728');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Columns in X_test and y_test"
      ],
      "metadata": {
        "id": "er0zQybAgoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = dc['OM_Regular'].values\n",
        "y_test2 = dc['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "naG54qF791Hs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test2.shape)\n",
        "print(y_test2.shape)\n",
        "\n",
        "print(\"\\nX data type: \", X_test2.dtype)\n",
        "print(\"y data type: \", y_test2.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcNO_Ews2q8x",
        "outputId": "6db282c0-d565-4e08-9b6e-4367716d2600"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80,)\n",
            "(80,)\n",
            "\n",
            "X data type:  object\n",
            "y data type:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFASLWP95TU",
        "outputId": "520e1d61-f680-4ff2-cd64-3379a2721b45"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_test2"
      ],
      "metadata": {
        "id": "hgO5sa73-3f1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtaining results from the model of the unseen dataset"
      ],
      "metadata": {
        "id": "K_yUzQq_gyYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  %%time\n",
        "#  for t in inputs:\n",
        "#   mylist_res = model.translate([t])[0].numpy().decode()\n",
        "#   print(model.translate([t])[0].numpy().decode())\n",
        "\n",
        "#  print()"
      ],
      "metadata": {
        "id": "4qjPTIDB-8UZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report (Unseen samples)\n"
      ],
      "metadata": {
        "id": "1t4_2FqbE9da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, classification_report"
      ],
      "metadata": {
        "id": "fVaZsDnJhkz5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The result is obtained and captured in a separate file, labels are converted to 1 and 0 . Where 1 denotes P and 0 denotes NP. "
      ],
      "metadata": {
        "id": "TbThCFoRhLHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING the predicted dataset"
      ],
      "metadata": {
        "id": "9Jz3Rt18lUtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv('decider_pred_set.csv')"
      ],
      "metadata": {
        "id": "jhKnUY4XFCSj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v9M2iW1MGjfM",
        "outputId": "78f4d6c7-b86b-4016-c860-98554d1656c2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          OM_Regular  OM_Prediction\n",
              "0  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "1  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "2  moduleom_name:0opendeclarationonesigclass1_nam...              0\n",
              "3  moduleom_name:0opendeclarationonesigclass1_nam...              1\n",
              "4  moduleom_nameopendeclarationonesigclass1_namee...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48a2bf3b-6d17-4310-89b0-dc0ace765e3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OM_Regular</th>\n",
              "      <th>OM_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>moduleom_name:0opendeclarationonesigclass1_nam...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>moduleom_nameopendeclarationonesigclass1_namee...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48a2bf3b-6d17-4310-89b0-dc0ace765e3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48a2bf3b-6d17-4310-89b0-dc0ace765e3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48a2bf3b-6d17-4310-89b0-dc0ace765e3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred2 = dd['OM_Regular'].values\n",
        "y_test_pred2 = dd['OM_Prediction'].values"
      ],
      "metadata": {
        "id": "1tO_WHmVHQDR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing predicted labels"
      ],
      "metadata": {
        "id": "0nbGKNUjldCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (y_test_pred2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy2Fvt1fHYJO",
        "outputId": "488d7c04-141d-439c-9cd4-bcdf5d39bc16"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_test2, y_test_pred2) \n",
        "print(\"Testing: Precision = %f\" % precision)\n",
        "\n",
        "\n",
        "recall = recall_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: Recall = %f\" % recall)\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test2, y_test_pred2)\n",
        "print(\"Testing: F1 Score = %f\" % f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test2, y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7RY4modHkts",
        "outputId": "92a0a424-5222-4dc3-fb20-952c19ccb938"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Precision = 0.189655\n",
            "Testing: Recall = 0.916667\n",
            "Testing: F1 Score = 0.314286\n",
            "\n",
            "Confusion Matrix (Test Data):\n",
            " [[21 47]\n",
            " [ 1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2,y_test_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3P-TGIIN6b",
        "outputId": "5577d208-8581-4de4-98d3-56198384e6ba"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.31      0.47        68\n",
            "           1       0.19      0.92      0.31        12\n",
            "\n",
            "    accuracy                           0.40        80\n",
            "   macro avg       0.57      0.61      0.39        80\n",
            "weighted avg       0.84      0.40      0.44        80\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}